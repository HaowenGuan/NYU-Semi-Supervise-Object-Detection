[11/18 14:20:09] detectron2 INFO: Rank of current process: 0. World size: 6
[11/18 14:20:11] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 14:20:11] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/18 14:20:11] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "../../output/supervised/model_supervised.pth"
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (102000, 108000)
  MAX_ITER: 111000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.02
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: "../../output/supervised"
[11/18 14:20:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ../../output/supervised/model_supervised.pth
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.02
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 111000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 102000
  - 108000
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/18 14:20:11] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/18 14:20:11] d2.utils.env INFO: Using a generated random seed 14139846
[11/18 14:20:13] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/18 14:20:13] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 14:20:13] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/18 14:20:13] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/18 14:20:14] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 283          |     bird      | 4331         | hat with a .. | 206          |
|    person     | 4657         |      dog      | 8341         |    lizard     | 640          |
|     sheep     | 196          |  wine bottle  | 154          |     bowl      | 335          |
|   airplane    | 217          | domestic cat  | 395          |      car      | 1171         |
|   porcupine   | 126          |     bear      | 361          |  tape player  | 109          |
|      ray      | 198          |    laptop     | 172          |     zebra     | 135          |
| computer ke.. | 102          |    pitcher    | 120          |   artichoke   | 180          |
| tv or monitor | 212          |     table     | 786          |     chair     | 905          |
|    helmet     | 433          | traffic light | 142          |   red panda   | 108          |
|  sunglasses   | 243          |     lamp      | 319          |    bicycle    | 187          |
|   backpack    | 148          |   mushroom    | 124          |      fox      | 292          |
|     otter     | 127          |    guitar     | 295          |  microphone   | 259          |
|  strawberry   | 232          |     stove     | 156          |    violin     | 118          |
|   bookshelf   | 106          |     sofa      | 160          |  bell pepper  | 146          |
|     bagel     | 125          |     lemon     | 170          |    orange     | 207          |
|     bench     | 150          |     piano     | 199          |  flower pot   | 189          |
|   butterfly   | 453          |     purse     | 130          |  pomegranate  | 188          |
|     train     | 178          |     drum      | 251          | hippopotamus  | 118          |
|      ski      | 109          |    ladybug    | 138          |    banana     | 244          |
|    monkey     | 1004         |      bus      | 322          |   miniskirt   | 118          |
|     camel     | 276          |     cream     | 194          |    lobster    | 253          |
|     seal      | 224          |     horse     | 265          |     cart      | 281          |
|   elephant    | 242          |     snake     | 1001         |      fig      | 133          |
|  watercraft   | 1038         |     apple     | 216          |   antelope    | 288          |
|    cattle     | 148          |     whale     | 155          | coffee maker  | 143          |
|   baby bed    | 185          |     frog      | 245          |  bathing cap  | 163          |
|    crutch     | 138          |  koala bear   | 139          |      tie      | 124          |
|   dumbbell    | 180          |     tiger     | 159          |   dragonfly   | 175          |
|   goldfish    | 228          |   cucumber    | 114          |    turtle     | 313          |
|     harp      | 152          |   jellyfish   | 184          |     swine     | 259          |
|    pretzel    | 124          |  motorcycle   | 278          |    beaker     | 115          |
|    rabbit     | 235          |     nail      | 86           |      axe      | 127          |
| salt or pep.. | 129          | croquet ball  | 135          |     skunk     | 99           |
|   starfish    | 130          |               |              |               |              |
|     total     | 41293        |               |              |               |              |[0m
[11/18 14:20:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/18 14:20:14] d2.data.build INFO: Using training sampler TrainingSampler
[11/18 14:20:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 14:20:15] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/18 14:20:15] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/18 14:20:15] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_supervised.pth ...
[11/18 14:20:15] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/18 14:20:15] d2.engine.train_loop INFO: Starting training from iteration 0
[11/18 14:20:37] d2.utils.events INFO:  eta: 21:48:59  iter: 19  total_loss: 0.1409  loss_cls: 0.0522  loss_box_reg: 0.06995  loss_rpn_cls: 0.006047  loss_rpn_loc: 0.01457  time: 0.6964  data_time: 0.3743  lr: 0.01019  max_mem: 11811M
[11/18 14:20:51] d2.utils.events INFO:  eta: 21:06:07  iter: 39  total_loss: 0.1456  loss_cls: 0.05442  loss_box_reg: 0.06855  loss_rpn_cls: 0.006812  loss_rpn_loc: 0.01548  time: 0.6873  data_time: 0.0613  lr: 0.01039  max_mem: 11811M
[11/18 14:21:05] d2.utils.events INFO:  eta: 21:07:47  iter: 59  total_loss: 0.1518  loss_cls: 0.05685  loss_box_reg: 0.07463  loss_rpn_cls: 0.006685  loss_rpn_loc: 0.01438  time: 0.6868  data_time: 0.0627  lr: 0.01059  max_mem: 11811M
[11/18 14:21:18] d2.utils.events INFO:  eta: 21:03:52  iter: 79  total_loss: 0.1457  loss_cls: 0.05539  loss_box_reg: 0.07227  loss_rpn_cls: 0.006124  loss_rpn_loc: 0.01384  time: 0.6844  data_time: 0.0675  lr: 0.01079  max_mem: 11811M
[11/18 14:21:32] d2.utils.events INFO:  eta: 21:01:15  iter: 99  total_loss: 0.1514  loss_cls: 0.05557  loss_box_reg: 0.07316  loss_rpn_cls: 0.006235  loss_rpn_loc: 0.01574  time: 0.6833  data_time: 0.0680  lr: 0.01099  max_mem: 11811M
[11/18 14:21:45] d2.utils.events INFO:  eta: 20:57:02  iter: 119  total_loss: 0.1465  loss_cls: 0.05508  loss_box_reg: 0.07106  loss_rpn_cls: 0.006467  loss_rpn_loc: 0.01535  time: 0.6825  data_time: 0.0624  lr: 0.01119  max_mem: 11811M
[11/18 14:21:59] d2.utils.events INFO:  eta: 20:59:09  iter: 139  total_loss: 0.1542  loss_cls: 0.05624  loss_box_reg: 0.07412  loss_rpn_cls: 0.007594  loss_rpn_loc: 0.01587  time: 0.6830  data_time: 0.0654  lr: 0.01139  max_mem: 11811M
[11/18 14:22:13] d2.utils.events INFO:  eta: 20:58:59  iter: 159  total_loss: 0.1578  loss_cls: 0.0589  loss_box_reg: 0.07468  loss_rpn_cls: 0.007057  loss_rpn_loc: 0.01528  time: 0.6827  data_time: 0.0652  lr: 0.01159  max_mem: 11811M
[11/18 14:22:27] d2.utils.events INFO:  eta: 20:59:31  iter: 179  total_loss: 0.1596  loss_cls: 0.06004  loss_box_reg: 0.07449  loss_rpn_cls: 0.007451  loss_rpn_loc: 0.01744  time: 0.6843  data_time: 0.0783  lr: 0.01179  max_mem: 11811M
[11/18 14:22:40] d2.utils.events INFO:  eta: 21:00:57  iter: 199  total_loss: 0.1578  loss_cls: 0.06059  loss_box_reg: 0.07485  loss_rpn_cls: 0.007368  loss_rpn_loc: 0.01637  time: 0.6844  data_time: 0.0675  lr: 0.01199  max_mem: 11811M
[11/18 14:22:55] d2.utils.events INFO:  eta: 21:04:41  iter: 219  total_loss: 0.1447  loss_cls: 0.05855  loss_box_reg: 0.06807  loss_rpn_cls: 0.006126  loss_rpn_loc: 0.01486  time: 0.6868  data_time: 0.0885  lr: 0.01219  max_mem: 11811M
[11/18 14:23:08] d2.utils.events INFO:  eta: 21:03:34  iter: 239  total_loss: 0.1508  loss_cls: 0.05882  loss_box_reg: 0.07095  loss_rpn_cls: 0.007131  loss_rpn_loc: 0.01672  time: 0.6865  data_time: 0.0719  lr: 0.01239  max_mem: 11811M
[11/18 14:23:22] d2.utils.events INFO:  eta: 21:01:12  iter: 259  total_loss: 0.1595  loss_cls: 0.06281  loss_box_reg: 0.07185  loss_rpn_cls: 0.006612  loss_rpn_loc: 0.01545  time: 0.6855  data_time: 0.0634  lr: 0.01259  max_mem: 11811M
[11/18 14:23:35] d2.utils.events INFO:  eta: 21:00:52  iter: 279  total_loss: 0.1529  loss_cls: 0.05787  loss_box_reg: 0.07105  loss_rpn_cls: 0.007123  loss_rpn_loc: 0.01488  time: 0.6846  data_time: 0.0650  lr: 0.01279  max_mem: 11811M
[11/18 14:23:49] d2.utils.events INFO:  eta: 20:58:56  iter: 299  total_loss: 0.1558  loss_cls: 0.05904  loss_box_reg: 0.06994  loss_rpn_cls: 0.008397  loss_rpn_loc: 0.01573  time: 0.6840  data_time: 0.0628  lr: 0.01299  max_mem: 11811M
[11/18 14:24:03] d2.utils.events INFO:  eta: 20:58:22  iter: 319  total_loss: 0.1625  loss_cls: 0.06453  loss_box_reg: 0.07536  loss_rpn_cls: 0.007224  loss_rpn_loc: 0.01482  time: 0.6841  data_time: 0.0630  lr: 0.01319  max_mem: 11811M
[11/18 14:24:16] d2.utils.events INFO:  eta: 20:57:26  iter: 339  total_loss: 0.166  loss_cls: 0.06378  loss_box_reg: 0.07512  loss_rpn_cls: 0.00726  loss_rpn_loc: 0.01407  time: 0.6842  data_time: 0.0759  lr: 0.01339  max_mem: 11811M
[11/18 14:24:30] d2.utils.events INFO:  eta: 20:58:15  iter: 359  total_loss: 0.1631  loss_cls: 0.06151  loss_box_reg: 0.07614  loss_rpn_cls: 0.007589  loss_rpn_loc: 0.01645  time: 0.6842  data_time: 0.0710  lr: 0.01359  max_mem: 11811M
[11/18 14:24:44] d2.utils.events INFO:  eta: 20:58:02  iter: 379  total_loss: 0.1583  loss_cls: 0.06449  loss_box_reg: 0.07515  loss_rpn_cls: 0.008001  loss_rpn_loc: 0.01553  time: 0.6843  data_time: 0.0719  lr: 0.01379  max_mem: 11811M
[11/18 14:24:57] d2.utils.events INFO:  eta: 20:56:58  iter: 399  total_loss: 0.1546  loss_cls: 0.06319  loss_box_reg: 0.07171  loss_rpn_cls: 0.006417  loss_rpn_loc: 0.01643  time: 0.6843  data_time: 0.0684  lr: 0.01399  max_mem: 11811M
[11/18 14:25:11] d2.utils.events INFO:  eta: 20:56:00  iter: 419  total_loss: 0.1676  loss_cls: 0.06713  loss_box_reg: 0.07521  loss_rpn_cls: 0.009295  loss_rpn_loc: 0.01456  time: 0.6841  data_time: 0.0694  lr: 0.01419  max_mem: 11811M
[11/18 14:25:24] d2.utils.events INFO:  eta: 20:55:08  iter: 439  total_loss: 0.1586  loss_cls: 0.06442  loss_box_reg: 0.07276  loss_rpn_cls: 0.007214  loss_rpn_loc: 0.01542  time: 0.6836  data_time: 0.0639  lr: 0.01439  max_mem: 11811M
[11/18 14:25:38] d2.utils.events INFO:  eta: 20:54:00  iter: 459  total_loss: 0.1574  loss_cls: 0.06501  loss_box_reg: 0.07041  loss_rpn_cls: 0.006403  loss_rpn_loc: 0.0151  time: 0.6835  data_time: 0.0642  lr: 0.01459  max_mem: 11811M
[11/18 14:25:52] d2.utils.events INFO:  eta: 20:55:17  iter: 479  total_loss: 0.1578  loss_cls: 0.06404  loss_box_reg: 0.07297  loss_rpn_cls: 0.007365  loss_rpn_loc: 0.01503  time: 0.6842  data_time: 0.0660  lr: 0.01479  max_mem: 11811M
[11/18 14:26:06] d2.utils.events INFO:  eta: 20:55:05  iter: 499  total_loss: 0.1619  loss_cls: 0.06514  loss_box_reg: 0.07187  loss_rpn_cls: 0.007718  loss_rpn_loc: 0.01563  time: 0.6841  data_time: 0.0700  lr: 0.01499  max_mem: 11811M
[11/18 14:26:19] d2.utils.events INFO:  eta: 20:54:50  iter: 519  total_loss: 0.1635  loss_cls: 0.064  loss_box_reg: 0.07599  loss_rpn_cls: 0.006731  loss_rpn_loc: 0.01719  time: 0.6839  data_time: 0.0661  lr: 0.01519  max_mem: 11811M
[11/18 14:26:33] d2.utils.events INFO:  eta: 20:54:36  iter: 539  total_loss: 0.1682  loss_cls: 0.06667  loss_box_reg: 0.07717  loss_rpn_cls: 0.007354  loss_rpn_loc: 0.01519  time: 0.6837  data_time: 0.0630  lr: 0.01539  max_mem: 11811M
[11/18 14:26:47] d2.utils.events INFO:  eta: 20:54:25  iter: 559  total_loss: 0.1525  loss_cls: 0.06347  loss_box_reg: 0.07044  loss_rpn_cls: 0.006505  loss_rpn_loc: 0.01509  time: 0.6840  data_time: 0.0761  lr: 0.01559  max_mem: 11811M
[11/18 14:27:00] d2.utils.events INFO:  eta: 20:54:15  iter: 579  total_loss: 0.1603  loss_cls: 0.06214  loss_box_reg: 0.07302  loss_rpn_cls: 0.00733  loss_rpn_loc: 0.01612  time: 0.6840  data_time: 0.0646  lr: 0.01579  max_mem: 11811M
[11/18 14:27:14] d2.utils.events INFO:  eta: 20:53:21  iter: 599  total_loss: 0.161  loss_cls: 0.06681  loss_box_reg: 0.07424  loss_rpn_cls: 0.007911  loss_rpn_loc: 0.01591  time: 0.6835  data_time: 0.0601  lr: 0.01599  max_mem: 11811M
[11/18 14:27:27] d2.utils.events INFO:  eta: 20:52:30  iter: 619  total_loss: 0.1726  loss_cls: 0.0683  loss_box_reg: 0.07554  loss_rpn_cls: 0.007663  loss_rpn_loc: 0.01854  time: 0.6832  data_time: 0.0645  lr: 0.01619  max_mem: 11811M
[11/18 14:27:41] d2.utils.events INFO:  eta: 20:52:28  iter: 639  total_loss: 0.1635  loss_cls: 0.06527  loss_box_reg: 0.07511  loss_rpn_cls: 0.007331  loss_rpn_loc: 0.01574  time: 0.6831  data_time: 0.0585  lr: 0.01639  max_mem: 11811M
[11/18 14:27:55] d2.utils.events INFO:  eta: 20:52:16  iter: 659  total_loss: 0.1688  loss_cls: 0.0676  loss_box_reg: 0.0762  loss_rpn_cls: 0.008239  loss_rpn_loc: 0.01608  time: 0.6833  data_time: 0.0715  lr: 0.01659  max_mem: 11811M
[11/18 14:28:08] d2.utils.events INFO:  eta: 20:53:01  iter: 679  total_loss: 0.1712  loss_cls: 0.06976  loss_box_reg: 0.0785  loss_rpn_cls: 0.00697  loss_rpn_loc: 0.01613  time: 0.6833  data_time: 0.0642  lr: 0.01679  max_mem: 11811M
[11/18 14:28:22] d2.utils.events INFO:  eta: 20:52:47  iter: 699  total_loss: 0.1714  loss_cls: 0.06842  loss_box_reg: 0.0785  loss_rpn_cls: 0.007528  loss_rpn_loc: 0.01622  time: 0.6833  data_time: 0.0641  lr: 0.01699  max_mem: 11811M
[11/18 14:28:36] d2.utils.events INFO:  eta: 20:51:34  iter: 719  total_loss: 0.165  loss_cls: 0.06925  loss_box_reg: 0.07162  loss_rpn_cls: 0.006401  loss_rpn_loc: 0.01566  time: 0.6831  data_time: 0.0657  lr: 0.01719  max_mem: 11811M
[11/18 14:28:49] d2.utils.events INFO:  eta: 20:50:58  iter: 739  total_loss: 0.1657  loss_cls: 0.06685  loss_box_reg: 0.07357  loss_rpn_cls: 0.008042  loss_rpn_loc: 0.01596  time: 0.6830  data_time: 0.0643  lr: 0.01739  max_mem: 11811M
[11/18 14:29:03] d2.utils.events INFO:  eta: 20:51:08  iter: 759  total_loss: 0.1712  loss_cls: 0.07081  loss_box_reg: 0.0745  loss_rpn_cls: 0.007778  loss_rpn_loc: 0.01648  time: 0.6830  data_time: 0.0618  lr: 0.01759  max_mem: 11811M
[11/18 14:29:16] d2.utils.events INFO:  eta: 20:50:41  iter: 779  total_loss: 0.1747  loss_cls: 0.07361  loss_box_reg: 0.07538  loss_rpn_cls: 0.00818  loss_rpn_loc: 0.01476  time: 0.6829  data_time: 0.0676  lr: 0.01779  max_mem: 11811M
[11/18 14:29:30] d2.utils.events INFO:  eta: 20:50:18  iter: 799  total_loss: 0.18  loss_cls: 0.07193  loss_box_reg: 0.07826  loss_rpn_cls: 0.009499  loss_rpn_loc: 0.01558  time: 0.6829  data_time: 0.0640  lr: 0.01799  max_mem: 11811M
[11/18 14:29:44] d2.utils.events INFO:  eta: 20:50:26  iter: 819  total_loss: 0.169  loss_cls: 0.0739  loss_box_reg: 0.07346  loss_rpn_cls: 0.00819  loss_rpn_loc: 0.01538  time: 0.6832  data_time: 0.0734  lr: 0.01819  max_mem: 11811M
[11/18 14:29:58] d2.utils.events INFO:  eta: 20:50:14  iter: 839  total_loss: 0.1799  loss_cls: 0.0766  loss_box_reg: 0.07446  loss_rpn_cls: 0.008539  loss_rpn_loc: 0.01624  time: 0.6832  data_time: 0.0623  lr: 0.01839  max_mem: 11811M
[11/18 14:30:11] d2.utils.events INFO:  eta: 20:50:58  iter: 859  total_loss: 0.1727  loss_cls: 0.07203  loss_box_reg: 0.07497  loss_rpn_cls: 0.008348  loss_rpn_loc: 0.0165  time: 0.6833  data_time: 0.0645  lr: 0.01859  max_mem: 11811M
[11/18 14:30:25] d2.utils.events INFO:  eta: 20:50:45  iter: 879  total_loss: 0.1716  loss_cls: 0.07122  loss_box_reg: 0.07452  loss_rpn_cls: 0.009067  loss_rpn_loc: 0.01512  time: 0.6836  data_time: 0.0831  lr: 0.01879  max_mem: 11811M
[11/18 14:30:39] d2.utils.events INFO:  eta: 20:50:31  iter: 899  total_loss: 0.199  loss_cls: 0.08388  loss_box_reg: 0.0792  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.01788  time: 0.6835  data_time: 0.0619  lr: 0.01899  max_mem: 11811M
[11/18 14:30:53] d2.utils.events INFO:  eta: 20:50:12  iter: 919  total_loss: 0.1929  loss_cls: 0.08416  loss_box_reg: 0.07813  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.01699  time: 0.6836  data_time: 0.0712  lr: 0.01919  max_mem: 11811M
[11/18 14:31:06] d2.utils.events INFO:  eta: 20:50:13  iter: 939  total_loss: 0.1926  loss_cls: 0.08519  loss_box_reg: 0.07876  loss_rpn_cls: 0.009891  loss_rpn_loc: 0.01742  time: 0.6837  data_time: 0.0679  lr: 0.01939  max_mem: 11811M
[11/18 14:31:20] d2.utils.events INFO:  eta: 20:49:52  iter: 959  total_loss: 0.1965  loss_cls: 0.08747  loss_box_reg: 0.07772  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01621  time: 0.6834  data_time: 0.0735  lr: 0.01959  max_mem: 11811M
[11/18 14:31:34] d2.utils.events INFO:  eta: 20:50:22  iter: 979  total_loss: 0.1776  loss_cls: 0.07874  loss_box_reg: 0.07381  loss_rpn_cls: 0.011  loss_rpn_loc: 0.01727  time: 0.6835  data_time: 0.0683  lr: 0.01979  max_mem: 11811M
[11/18 14:31:47] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0000999.pth
[11/18 14:31:48] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 14:31:48] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 14:31:49] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/18 14:31:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 14:31:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 14:31:49] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 14:31:49] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 14:31:49] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 14:31:56] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:13
[11/18 14:32:01] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:11
[11/18 14:32:06] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0017 s/iter. Inference: 0.0393 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/18 14:32:11] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0003 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/18 14:32:16] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/18 14:32:21] d2.evaluation.evaluator INFO: Inference done 621/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/18 14:32:26] d2.evaluation.evaluator INFO: Inference done 746/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/18 14:32:31] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/18 14:32:36] d2.evaluation.evaluator INFO: Inference done 989/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/18 14:32:41] d2.evaluation.evaluator INFO: Inference done 1111/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/18 14:32:46] d2.evaluation.evaluator INFO: Inference done 1233/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/18 14:32:51] d2.evaluation.evaluator INFO: Inference done 1356/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/18 14:32:56] d2.evaluation.evaluator INFO: Inference done 1475/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/18 14:33:01] d2.evaluation.evaluator INFO: Inference done 1599/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:11
[11/18 14:33:06] d2.evaluation.evaluator INFO: Inference done 1721/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/18 14:33:11] d2.evaluation.evaluator INFO: Inference done 1842/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/18 14:33:16] d2.evaluation.evaluator INFO: Inference done 1966/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/18 14:33:21] d2.evaluation.evaluator INFO: Inference done 2089/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/18 14:33:26] d2.evaluation.evaluator INFO: Inference done 2212/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/18 14:33:31] d2.evaluation.evaluator INFO: Inference done 2333/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/18 14:33:36] d2.evaluation.evaluator INFO: Inference done 2455/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/18 14:33:41] d2.evaluation.evaluator INFO: Inference done 2578/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/18 14:33:46] d2.evaluation.evaluator INFO: Inference done 2702/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/18 14:33:51] d2.evaluation.evaluator INFO: Inference done 2825/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:20
[11/18 14:33:56] d2.evaluation.evaluator INFO: Inference done 2948/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/18 14:34:01] d2.evaluation.evaluator INFO: Inference done 3069/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/18 14:34:06] d2.evaluation.evaluator INFO: Inference done 3194/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/18 14:34:12] d2.evaluation.evaluator INFO: Inference done 3324/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:00
[11/18 14:34:12] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.411997 (0.040977 s / iter per device, on 6 devices)
[11/18 14:34:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038988 s / iter per device, on 6 devices)
[11/18 14:34:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 14:34:15] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 14:34:16] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 14:34:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 14:34:42] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.02 seconds.
[11/18 14:34:42] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 14:34:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.03 seconds.
[11/18 14:34:44] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.970 | 22.437 | 9.255  | 1.123 | 4.881 | 13.617 |
[11/18 14:34:44] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 7.698  | bird          | 33.738 | hat with a wide brim | 7.237  |
| person                | 6.395  | dog           | 48.804 | lizard               | 7.822  |
| sheep                 | 8.422  | wine bottle   | 9.789  | bowl                 | 11.841 |
| airplane              | 27.129 | domestic cat  | 16.821 | car                  | 33.242 |
| porcupine             | 20.718 | bear          | 18.426 | tape player          | 10.316 |
| ray                   | 2.694  | laptop        | 8.026  | zebra                | 25.115 |
| computer keyboard     | 12.650 | pitcher       | 7.265  | artichoke            | 18.646 |
| tv or monitor         | 10.557 | table         | 9.314  | chair                | 3.045  |
| helmet                | 10.131 | traffic light | 3.960  | red panda            | 16.953 |
| sunglasses            | 1.447  | lamp          | 3.507  | bicycle              | 10.401 |
| backpack              | 9.241  | mushroom      | 3.524  | fox                  | 11.763 |
| otter                 | 3.102  | guitar        | 4.817  | microphone           | 0.331  |
| strawberry            | 7.263  | stove         | 11.299 | violin               | 0.571  |
| bookshelf             | 11.359 | sofa          | 4.000  | bell pepper          | 9.075  |
| bagel                 | 8.614  | lemon         | 10.840 | orange               | 12.514 |
| bench                 | 1.657  | piano         | 11.250 | flower pot           | 3.601  |
| butterfly             | 29.759 | purse         | 5.030  | pomegranate          | 2.302  |
| train                 | 16.980 | drum          | 1.538  | hippopotamus         | 2.371  |
| ski                   | 0.676  | ladybug       | 28.635 | banana               | 1.558  |
| monkey                | 14.513 | bus           | 33.014 | miniskirt            | 4.230  |
| camel                 | 7.850  | cream         | 10.140 | lobster              | 5.968  |
| seal                  | 1.306  | horse         | 10.121 | cart                 | 11.890 |
| elephant              | 22.986 | snake         | 8.844  | fig                  | 3.113  |
| watercraft            | 24.191 | apple         | 16.780 | antelope             | 27.022 |
| cattle                | 4.391  | whale         | 13.359 | coffee maker         | 22.750 |
| baby bed              | 21.036 | frog          | 14.537 | bathing cap          | 6.485  |
| crutch                | 0.502  | koala bear    | 17.447 | tie                  | 3.873  |
| dumbbell              | 0.388  | tiger         | 12.826 | dragonfly            | 12.106 |
| goldfish              | 4.093  | cucumber      | 2.654  | turtle               | 14.659 |
| harp                  | 6.685  | jellyfish     | 8.344  | swine                | 9.765  |
| pretzel               | 4.200  | motorcycle    | 22.105 | beaker               | 11.632 |
| rabbit                | 21.930 | nail          | 0.665  | axe                  | 4.882  |
| salt or pepper shaker | 4.152  | croquet ball  | 6.146  | skunk                | 9.065  |
| starfish              | 8.568  |               |        |                      |        |
[11/18 14:34:46] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 14:34:46] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 14:34:46] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 14:34:46] d2.evaluation.testing INFO: copypaste: 10.9699,22.4369,9.2552,1.1235,4.8808,13.6171
[11/18 14:34:46] d2.utils.events INFO:  eta: 20:49:44  iter: 999  total_loss: 0.1707  loss_cls: 0.07874  loss_box_reg: 0.07092  loss_rpn_cls: 0.009809  loss_rpn_loc: 0.01531  time: 0.6834  data_time: 0.0639  lr: 0.01999  max_mem: 11811M
[11/18 14:35:00] d2.utils.events INFO:  eta: 20:49:09  iter: 1019  total_loss: 0.1767  loss_cls: 0.07706  loss_box_reg: 0.07518  loss_rpn_cls: 0.008814  loss_rpn_loc: 0.01698  time: 0.6833  data_time: 0.0663  lr: 0.02  max_mem: 11811M
[11/18 14:35:14] d2.utils.events INFO:  eta: 20:49:04  iter: 1039  total_loss: 0.1688  loss_cls: 0.06962  loss_box_reg: 0.07224  loss_rpn_cls: 0.008727  loss_rpn_loc: 0.01746  time: 0.6835  data_time: 0.0815  lr: 0.02  max_mem: 11811M
[11/18 14:35:27] d2.utils.events INFO:  eta: 20:48:47  iter: 1059  total_loss: 0.1758  loss_cls: 0.07284  loss_box_reg: 0.07716  loss_rpn_cls: 0.008676  loss_rpn_loc: 0.01678  time: 0.6835  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 14:35:41] d2.utils.events INFO:  eta: 20:48:28  iter: 1079  total_loss: 0.1728  loss_cls: 0.06918  loss_box_reg: 0.0732  loss_rpn_cls: 0.008743  loss_rpn_loc: 0.01656  time: 0.6833  data_time: 0.0691  lr: 0.02  max_mem: 11811M
[11/18 14:35:55] d2.utils.events INFO:  eta: 20:48:24  iter: 1099  total_loss: 0.1738  loss_cls: 0.06962  loss_box_reg: 0.07512  loss_rpn_cls: 0.009015  loss_rpn_loc: 0.01699  time: 0.6836  data_time: 0.0785  lr: 0.02  max_mem: 11811M
[11/18 14:36:09] d2.utils.events INFO:  eta: 20:49:19  iter: 1119  total_loss: 0.1747  loss_cls: 0.07011  loss_box_reg: 0.07463  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.01748  time: 0.6837  data_time: 0.0718  lr: 0.02  max_mem: 11811M
[11/18 14:36:22] d2.utils.events INFO:  eta: 20:48:37  iter: 1139  total_loss: 0.1702  loss_cls: 0.07167  loss_box_reg: 0.07497  loss_rpn_cls: 0.009177  loss_rpn_loc: 0.01622  time: 0.6837  data_time: 0.0708  lr: 0.02  max_mem: 11811M
[11/18 14:36:36] d2.utils.events INFO:  eta: 20:48:23  iter: 1159  total_loss: 0.1835  loss_cls: 0.07647  loss_box_reg: 0.07861  loss_rpn_cls: 0.009806  loss_rpn_loc: 0.01587  time: 0.6838  data_time: 0.0749  lr: 0.02  max_mem: 11811M
[11/18 14:36:50] d2.utils.events INFO:  eta: 20:48:40  iter: 1179  total_loss: 0.1928  loss_cls: 0.07788  loss_box_reg: 0.08156  loss_rpn_cls: 0.008713  loss_rpn_loc: 0.01721  time: 0.6838  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 14:37:03] d2.utils.events INFO:  eta: 20:47:31  iter: 1199  total_loss: 0.1709  loss_cls: 0.07431  loss_box_reg: 0.07402  loss_rpn_cls: 0.007642  loss_rpn_loc: 0.01596  time: 0.6837  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 14:37:17] d2.utils.events INFO:  eta: 20:46:17  iter: 1219  total_loss: 0.1725  loss_cls: 0.07197  loss_box_reg: 0.07434  loss_rpn_cls: 0.009344  loss_rpn_loc: 0.01513  time: 0.6838  data_time: 0.0716  lr: 0.02  max_mem: 11811M
[11/18 14:37:31] d2.utils.events INFO:  eta: 20:46:17  iter: 1239  total_loss: 0.1696  loss_cls: 0.074  loss_box_reg: 0.07327  loss_rpn_cls: 0.008228  loss_rpn_loc: 0.01657  time: 0.6838  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 14:37:44] d2.utils.events INFO:  eta: 20:46:04  iter: 1259  total_loss: 0.1826  loss_cls: 0.07578  loss_box_reg: 0.07603  loss_rpn_cls: 0.00916  loss_rpn_loc: 0.01512  time: 0.6837  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 14:37:58] d2.utils.events INFO:  eta: 20:46:07  iter: 1279  total_loss: 0.1691  loss_cls: 0.07359  loss_box_reg: 0.07294  loss_rpn_cls: 0.007745  loss_rpn_loc: 0.01579  time: 0.6838  data_time: 0.0795  lr: 0.02  max_mem: 11811M
[11/18 14:38:12] d2.utils.events INFO:  eta: 20:46:34  iter: 1299  total_loss: 0.1777  loss_cls: 0.07518  loss_box_reg: 0.07822  loss_rpn_cls: 0.009133  loss_rpn_loc: 0.01671  time: 0.6838  data_time: 0.0664  lr: 0.02  max_mem: 11811M
[11/18 14:38:26] d2.utils.events INFO:  eta: 20:47:03  iter: 1319  total_loss: 0.1769  loss_cls: 0.07922  loss_box_reg: 0.07454  loss_rpn_cls: 0.00942  loss_rpn_loc: 0.01674  time: 0.6838  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 14:38:39] d2.utils.events INFO:  eta: 20:46:51  iter: 1339  total_loss: 0.174  loss_cls: 0.07806  loss_box_reg: 0.07574  loss_rpn_cls: 0.009358  loss_rpn_loc: 0.01641  time: 0.6837  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 14:38:53] d2.utils.events INFO:  eta: 20:45:25  iter: 1359  total_loss: 0.1784  loss_cls: 0.07801  loss_box_reg: 0.07532  loss_rpn_cls: 0.009428  loss_rpn_loc: 0.01608  time: 0.6836  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 14:39:06] d2.utils.events INFO:  eta: 20:44:28  iter: 1379  total_loss: 0.1737  loss_cls: 0.07804  loss_box_reg: 0.07248  loss_rpn_cls: 0.009364  loss_rpn_loc: 0.01543  time: 0.6834  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 14:39:20] d2.utils.events INFO:  eta: 20:44:00  iter: 1399  total_loss: 0.1687  loss_cls: 0.07616  loss_box_reg: 0.07221  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.01631  time: 0.6833  data_time: 0.0673  lr: 0.02  max_mem: 11811M
[11/18 14:39:33] d2.utils.events INFO:  eta: 20:44:44  iter: 1419  total_loss: 0.1797  loss_cls: 0.07954  loss_box_reg: 0.07622  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.01698  time: 0.6834  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 14:39:47] d2.utils.events INFO:  eta: 20:45:04  iter: 1439  total_loss: 0.1867  loss_cls: 0.07984  loss_box_reg: 0.07836  loss_rpn_cls: 0.009724  loss_rpn_loc: 0.01798  time: 0.6834  data_time: 0.0676  lr: 0.02  max_mem: 11811M
[11/18 14:40:01] d2.utils.events INFO:  eta: 20:45:09  iter: 1459  total_loss: 0.18  loss_cls: 0.07788  loss_box_reg: 0.07392  loss_rpn_cls: 0.009956  loss_rpn_loc: 0.01781  time: 0.6833  data_time: 0.0695  lr: 0.02  max_mem: 11811M
[11/18 14:40:14] d2.utils.events INFO:  eta: 20:44:09  iter: 1479  total_loss: 0.1749  loss_cls: 0.07522  loss_box_reg: 0.07298  loss_rpn_cls: 0.007819  loss_rpn_loc: 0.01595  time: 0.6833  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 14:40:28] d2.utils.events INFO:  eta: 20:43:46  iter: 1499  total_loss: 0.1714  loss_cls: 0.07387  loss_box_reg: 0.07371  loss_rpn_cls: 0.00928  loss_rpn_loc: 0.01512  time: 0.6836  data_time: 0.0840  lr: 0.02  max_mem: 11811M
[11/18 14:40:42] d2.utils.events INFO:  eta: 20:43:21  iter: 1519  total_loss: 0.1548  loss_cls: 0.06387  loss_box_reg: 0.06831  loss_rpn_cls: 0.0071  loss_rpn_loc: 0.0146  time: 0.6834  data_time: 0.0623  lr: 0.02  max_mem: 11811M
[11/18 14:40:55] d2.utils.events INFO:  eta: 20:42:25  iter: 1539  total_loss: 0.1815  loss_cls: 0.0736  loss_box_reg: 0.07766  loss_rpn_cls: 0.008219  loss_rpn_loc: 0.01667  time: 0.6833  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 14:41:09] d2.utils.events INFO:  eta: 20:43:03  iter: 1559  total_loss: 0.1778  loss_cls: 0.07396  loss_box_reg: 0.07829  loss_rpn_cls: 0.009479  loss_rpn_loc: 0.01724  time: 0.6834  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 14:41:23] d2.utils.events INFO:  eta: 20:42:12  iter: 1579  total_loss: 0.165  loss_cls: 0.06777  loss_box_reg: 0.07107  loss_rpn_cls: 0.008719  loss_rpn_loc: 0.01693  time: 0.6833  data_time: 0.0687  lr: 0.02  max_mem: 11811M
[11/18 14:41:36] d2.utils.events INFO:  eta: 20:42:41  iter: 1599  total_loss: 0.1641  loss_cls: 0.06582  loss_box_reg: 0.07115  loss_rpn_cls: 0.006671  loss_rpn_loc: 0.01665  time: 0.6833  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 14:41:50] d2.utils.events INFO:  eta: 20:42:40  iter: 1619  total_loss: 0.181  loss_cls: 0.07493  loss_box_reg: 0.07828  loss_rpn_cls: 0.009833  loss_rpn_loc: 0.01702  time: 0.6832  data_time: 0.0619  lr: 0.02  max_mem: 11811M
[11/18 14:42:03] d2.utils.events INFO:  eta: 20:42:23  iter: 1639  total_loss: 0.1739  loss_cls: 0.07534  loss_box_reg: 0.07499  loss_rpn_cls: 0.00977  loss_rpn_loc: 0.01815  time: 0.6831  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 14:42:17] d2.utils.events INFO:  eta: 20:42:00  iter: 1659  total_loss: 0.176  loss_cls: 0.07376  loss_box_reg: 0.07549  loss_rpn_cls: 0.009395  loss_rpn_loc: 0.01679  time: 0.6831  data_time: 0.0728  lr: 0.02  max_mem: 11811M
[11/18 14:42:31] d2.utils.events INFO:  eta: 20:41:18  iter: 1679  total_loss: 0.1732  loss_cls: 0.07415  loss_box_reg: 0.07241  loss_rpn_cls: 0.009113  loss_rpn_loc: 0.01726  time: 0.6832  data_time: 0.0858  lr: 0.02  max_mem: 11811M
[11/18 14:42:45] d2.utils.events INFO:  eta: 20:41:04  iter: 1699  total_loss: 0.1724  loss_cls: 0.0708  loss_box_reg: 0.07495  loss_rpn_cls: 0.008396  loss_rpn_loc: 0.01634  time: 0.6833  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 14:42:58] d2.utils.events INFO:  eta: 20:41:23  iter: 1719  total_loss: 0.1772  loss_cls: 0.07288  loss_box_reg: 0.08004  loss_rpn_cls: 0.009147  loss_rpn_loc: 0.01592  time: 0.6833  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 14:43:12] d2.utils.events INFO:  eta: 20:41:15  iter: 1739  total_loss: 0.169  loss_cls: 0.07391  loss_box_reg: 0.07306  loss_rpn_cls: 0.007964  loss_rpn_loc: 0.01588  time: 0.6833  data_time: 0.0706  lr: 0.02  max_mem: 11811M
[11/18 14:43:26] d2.utils.events INFO:  eta: 20:40:38  iter: 1759  total_loss: 0.1734  loss_cls: 0.06997  loss_box_reg: 0.0761  loss_rpn_cls: 0.008605  loss_rpn_loc: 0.01733  time: 0.6833  data_time: 0.0735  lr: 0.02  max_mem: 11811M
[11/18 14:43:39] d2.utils.events INFO:  eta: 20:40:35  iter: 1779  total_loss: 0.1754  loss_cls: 0.07136  loss_box_reg: 0.07681  loss_rpn_cls: 0.008274  loss_rpn_loc: 0.01621  time: 0.6833  data_time: 0.0596  lr: 0.02  max_mem: 11811M
[11/18 14:43:53] d2.utils.events INFO:  eta: 20:40:34  iter: 1799  total_loss: 0.1723  loss_cls: 0.07414  loss_box_reg: 0.0746  loss_rpn_cls: 0.008849  loss_rpn_loc: 0.01561  time: 0.6833  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 14:44:06] d2.utils.events INFO:  eta: 20:39:58  iter: 1819  total_loss: 0.1761  loss_cls: 0.07523  loss_box_reg: 0.0774  loss_rpn_cls: 0.009498  loss_rpn_loc: 0.01693  time: 0.6831  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 14:44:20] d2.utils.events INFO:  eta: 20:38:59  iter: 1839  total_loss: 0.1733  loss_cls: 0.07263  loss_box_reg: 0.07304  loss_rpn_cls: 0.008711  loss_rpn_loc: 0.01566  time: 0.6831  data_time: 0.0751  lr: 0.02  max_mem: 11811M
[11/18 14:44:34] d2.utils.events INFO:  eta: 20:38:11  iter: 1859  total_loss: 0.1766  loss_cls: 0.07363  loss_box_reg: 0.07992  loss_rpn_cls: 0.007625  loss_rpn_loc: 0.01663  time: 0.6831  data_time: 0.0745  lr: 0.02  max_mem: 11811M
[11/18 14:44:47] d2.utils.events INFO:  eta: 20:37:59  iter: 1879  total_loss: 0.1717  loss_cls: 0.07698  loss_box_reg: 0.07363  loss_rpn_cls: 0.008962  loss_rpn_loc: 0.01554  time: 0.6831  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 14:45:01] d2.utils.events INFO:  eta: 20:37:19  iter: 1899  total_loss: 0.1845  loss_cls: 0.07941  loss_box_reg: 0.07585  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.0164  time: 0.6830  data_time: 0.0776  lr: 0.02  max_mem: 11811M
[11/18 14:45:15] d2.utils.events INFO:  eta: 20:37:30  iter: 1919  total_loss: 0.1902  loss_cls: 0.08234  loss_box_reg: 0.07593  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.0165  time: 0.6830  data_time: 0.0686  lr: 0.02  max_mem: 11811M
[11/18 14:45:28] d2.utils.events INFO:  eta: 20:36:27  iter: 1939  total_loss: 0.1679  loss_cls: 0.07194  loss_box_reg: 0.07218  loss_rpn_cls: 0.008312  loss_rpn_loc: 0.01525  time: 0.6830  data_time: 0.0631  lr: 0.02  max_mem: 11811M
[11/18 14:45:42] d2.utils.events INFO:  eta: 20:36:38  iter: 1959  total_loss: 0.1816  loss_cls: 0.07931  loss_box_reg: 0.07497  loss_rpn_cls: 0.009549  loss_rpn_loc: 0.01557  time: 0.6830  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 14:45:56] d2.utils.events INFO:  eta: 20:35:56  iter: 1979  total_loss: 0.182  loss_cls: 0.08044  loss_box_reg: 0.0762  loss_rpn_cls: 0.009972  loss_rpn_loc: 0.01634  time: 0.6830  data_time: 0.0782  lr: 0.02  max_mem: 11811M
[11/18 14:46:09] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0001999.pth
[11/18 14:46:10] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 14:46:10] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 14:46:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 14:46:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 14:46:10] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 14:46:10] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 14:46:10] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 14:46:17] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0434 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:02:28
[11/18 14:46:22] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:11
[11/18 14:46:27] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/18 14:46:32] d2.evaluation.evaluator INFO: Inference done 373/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/18 14:46:37] d2.evaluation.evaluator INFO: Inference done 495/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:57
[11/18 14:46:42] d2.evaluation.evaluator INFO: Inference done 616/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:52
[11/18 14:46:47] d2.evaluation.evaluator INFO: Inference done 737/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/18 14:46:52] d2.evaluation.evaluator INFO: Inference done 858/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/18 14:46:58] d2.evaluation.evaluator INFO: Inference done 980/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/18 14:47:03] d2.evaluation.evaluator INFO: Inference done 1102/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/18 14:47:08] d2.evaluation.evaluator INFO: Inference done 1223/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/18 14:47:13] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/18 14:47:18] d2.evaluation.evaluator INFO: Inference done 1470/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:16
[11/18 14:47:23] d2.evaluation.evaluator INFO: Inference done 1590/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:12
[11/18 14:47:28] d2.evaluation.evaluator INFO: Inference done 1711/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/18 14:47:33] d2.evaluation.evaluator INFO: Inference done 1831/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/18 14:47:38] d2.evaluation.evaluator INFO: Inference done 1954/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:57
[11/18 14:47:43] d2.evaluation.evaluator INFO: Inference done 2075/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/18 14:47:48] d2.evaluation.evaluator INFO: Inference done 2197/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:47
[11/18 14:47:53] d2.evaluation.evaluator INFO: Inference done 2318/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 14:47:58] d2.evaluation.evaluator INFO: Inference done 2436/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/18 14:48:03] d2.evaluation.evaluator INFO: Inference done 2555/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/18 14:48:08] d2.evaluation.evaluator INFO: Inference done 2677/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:27
[11/18 14:48:13] d2.evaluation.evaluator INFO: Inference done 2801/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/18 14:48:18] d2.evaluation.evaluator INFO: Inference done 2924/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:16
[11/18 14:48:23] d2.evaluation.evaluator INFO: Inference done 3041/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/18 14:48:28] d2.evaluation.evaluator INFO: Inference done 3162/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/18 14:48:33] d2.evaluation.evaluator INFO: Inference done 3280/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/18 14:48:35] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.209062 (0.041517 s / iter per device, on 6 devices)
[11/18 14:48:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039491 s / iter per device, on 6 devices)
[11/18 14:48:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 14:48:37] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 14:48:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 14:48:39] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 14:49:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.41 seconds.
[11/18 14:49:02] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 14:49:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.79 seconds.
[11/18 14:49:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 12.518 | 25.027 | 11.020 | 1.249 | 4.676 | 15.565 |
[11/18 14:49:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 8.978  | bird          | 36.432 | hat with a wide brim | 6.229  |
| person                | 7.114  | dog           | 50.040 | lizard               | 8.243  |
| sheep                 | 8.834  | wine bottle   | 8.970  | bowl                 | 14.911 |
| airplane              | 30.139 | domestic cat  | 10.993 | car                  | 37.692 |
| porcupine             | 17.844 | bear          | 17.770 | tape player          | 11.138 |
| ray                   | 5.005  | laptop        | 10.090 | zebra                | 23.583 |
| computer keyboard     | 13.577 | pitcher       | 10.144 | artichoke            | 11.040 |
| tv or monitor         | 12.588 | table         | 11.664 | chair                | 8.038  |
| helmet                | 13.408 | traffic light | 6.290  | red panda            | 20.143 |
| sunglasses            | 1.420  | lamp          | 3.159  | bicycle              | 11.565 |
| backpack              | 9.509  | mushroom      | 5.124  | fox                  | 12.045 |
| otter                 | 8.094  | guitar        | 9.432  | microphone           | 0.514  |
| strawberry            | 9.165  | stove         | 9.671  | violin               | 1.326  |
| bookshelf             | 18.077 | sofa          | 7.476  | bell pepper          | 4.374  |
| bagel                 | 9.930  | lemon         | 13.527 | orange               | 16.974 |
| bench                 | 2.654  | piano         | 21.093 | flower pot           | 3.320  |
| butterfly             | 36.145 | purse         | 6.520  | pomegranate          | 4.564  |
| train                 | 22.482 | drum          | 2.575  | hippopotamus         | 3.955  |
| ski                   | 0.868  | ladybug       | 24.563 | banana               | 2.502  |
| monkey                | 14.552 | bus           | 34.444 | miniskirt            | 3.194  |
| camel                 | 9.283  | cream         | 16.752 | lobster              | 8.878  |
| seal                  | 3.263  | horse         | 14.721 | cart                 | 15.255 |
| elephant              | 24.270 | snake         | 9.274  | fig                  | 2.697  |
| watercraft            | 27.369 | apple         | 14.951 | antelope             | 21.018 |
| cattle                | 5.808  | whale         | 16.777 | coffee maker         | 20.623 |
| baby bed              | 25.785 | frog          | 19.672 | bathing cap          | 5.829  |
| crutch                | 0.169  | koala bear    | 21.453 | tie                  | 2.550  |
| dumbbell              | 0.547  | tiger         | 14.993 | dragonfly            | 16.025 |
| goldfish              | 12.082 | cucumber      | 2.871  | turtle               | 18.289 |
| harp                  | 8.118  | jellyfish     | 10.890 | swine                | 12.031 |
| pretzel               | 7.439  | motorcycle    | 21.752 | beaker               | 11.771 |
| rabbit                | 27.884 | nail          | 0.334  | axe                  | 7.850  |
| salt or pepper shaker | 3.780  | croquet ball  | 12.498 | skunk                | 9.021  |
| starfish              | 11.483 |               |        |                      |        |
[11/18 14:49:07] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 14:49:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 14:49:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 14:49:07] d2.evaluation.testing INFO: copypaste: 12.5177,25.0268,11.0199,1.2495,4.6755,15.5651
[11/18 14:49:07] d2.utils.events INFO:  eta: 20:36:04  iter: 1999  total_loss: 0.1783  loss_cls: 0.07859  loss_box_reg: 0.0733  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01644  time: 0.6830  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 14:49:21] d2.utils.events INFO:  eta: 20:36:12  iter: 2019  total_loss: 0.1638  loss_cls: 0.06693  loss_box_reg: 0.06998  loss_rpn_cls: 0.009282  loss_rpn_loc: 0.01691  time: 0.6830  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 14:49:34] d2.utils.events INFO:  eta: 20:36:08  iter: 2039  total_loss: 0.167  loss_cls: 0.06959  loss_box_reg: 0.07235  loss_rpn_cls: 0.008805  loss_rpn_loc: 0.0168  time: 0.6832  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 14:49:48] d2.utils.events INFO:  eta: 20:35:45  iter: 2059  total_loss: 0.1661  loss_cls: 0.0667  loss_box_reg: 0.07228  loss_rpn_cls: 0.008494  loss_rpn_loc: 0.01867  time: 0.6831  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 14:50:02] d2.utils.events INFO:  eta: 20:36:05  iter: 2079  total_loss: 0.1594  loss_cls: 0.06634  loss_box_reg: 0.06962  loss_rpn_cls: 0.008361  loss_rpn_loc: 0.01595  time: 0.6832  data_time: 0.0741  lr: 0.02  max_mem: 11811M
[11/18 14:50:15] d2.utils.events INFO:  eta: 20:35:19  iter: 2099  total_loss: 0.1621  loss_cls: 0.06838  loss_box_reg: 0.07082  loss_rpn_cls: 0.007734  loss_rpn_loc: 0.01578  time: 0.6831  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 14:50:29] d2.utils.events INFO:  eta: 20:34:34  iter: 2119  total_loss: 0.1707  loss_cls: 0.06959  loss_box_reg: 0.07646  loss_rpn_cls: 0.008303  loss_rpn_loc: 0.01673  time: 0.6831  data_time: 0.0663  lr: 0.02  max_mem: 11811M
[11/18 14:50:42] d2.utils.events INFO:  eta: 20:34:10  iter: 2139  total_loss: 0.1831  loss_cls: 0.07827  loss_box_reg: 0.0812  loss_rpn_cls: 0.009721  loss_rpn_loc: 0.01676  time: 0.6830  data_time: 0.0690  lr: 0.02  max_mem: 11811M
[11/18 14:50:56] d2.utils.events INFO:  eta: 20:33:18  iter: 2159  total_loss: 0.1774  loss_cls: 0.07237  loss_box_reg: 0.07675  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.01651  time: 0.6829  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 14:51:10] d2.utils.events INFO:  eta: 20:31:32  iter: 2179  total_loss: 0.1788  loss_cls: 0.07292  loss_box_reg: 0.07666  loss_rpn_cls: 0.008896  loss_rpn_loc: 0.01637  time: 0.6830  data_time: 0.0823  lr: 0.02  max_mem: 11811M
[11/18 14:51:24] d2.utils.events INFO:  eta: 20:32:22  iter: 2199  total_loss: 0.1685  loss_cls: 0.0683  loss_box_reg: 0.07558  loss_rpn_cls: 0.007454  loss_rpn_loc: 0.01745  time: 0.6830  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 14:51:37] d2.utils.events INFO:  eta: 20:32:09  iter: 2219  total_loss: 0.1785  loss_cls: 0.07369  loss_box_reg: 0.07495  loss_rpn_cls: 0.008823  loss_rpn_loc: 0.01692  time: 0.6830  data_time: 0.0651  lr: 0.02  max_mem: 11811M
[11/18 14:51:51] d2.utils.events INFO:  eta: 20:32:33  iter: 2239  total_loss: 0.1698  loss_cls: 0.07119  loss_box_reg: 0.07632  loss_rpn_cls: 0.00857  loss_rpn_loc: 0.01648  time: 0.6831  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 14:52:05] d2.utils.events INFO:  eta: 20:32:42  iter: 2259  total_loss: 0.1826  loss_cls: 0.07777  loss_box_reg: 0.07731  loss_rpn_cls: 0.008614  loss_rpn_loc: 0.01693  time: 0.6831  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 14:52:18] d2.utils.events INFO:  eta: 20:31:30  iter: 2279  total_loss: 0.1724  loss_cls: 0.07203  loss_box_reg: 0.07427  loss_rpn_cls: 0.008494  loss_rpn_loc: 0.01701  time: 0.6830  data_time: 0.0603  lr: 0.02  max_mem: 11811M
[11/18 14:52:32] d2.utils.events INFO:  eta: 20:31:10  iter: 2299  total_loss: 0.1723  loss_cls: 0.07337  loss_box_reg: 0.07891  loss_rpn_cls: 0.008433  loss_rpn_loc: 0.01533  time: 0.6829  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 14:52:45] d2.utils.events INFO:  eta: 20:30:57  iter: 2319  total_loss: 0.1763  loss_cls: 0.07386  loss_box_reg: 0.07616  loss_rpn_cls: 0.00887  loss_rpn_loc: 0.0166  time: 0.6829  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 14:52:59] d2.utils.events INFO:  eta: 20:29:50  iter: 2339  total_loss: 0.1626  loss_cls: 0.0677  loss_box_reg: 0.06968  loss_rpn_cls: 0.007966  loss_rpn_loc: 0.01574  time: 0.6828  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 14:53:12] d2.utils.events INFO:  eta: 20:29:53  iter: 2359  total_loss: 0.173  loss_cls: 0.07241  loss_box_reg: 0.07618  loss_rpn_cls: 0.008253  loss_rpn_loc: 0.01573  time: 0.6828  data_time: 0.0709  lr: 0.02  max_mem: 11811M
[11/18 14:53:26] d2.utils.events INFO:  eta: 20:30:04  iter: 2379  total_loss: 0.1748  loss_cls: 0.07692  loss_box_reg: 0.07666  loss_rpn_cls: 0.009145  loss_rpn_loc: 0.01536  time: 0.6827  data_time: 0.0597  lr: 0.02  max_mem: 11811M
[11/18 14:53:39] d2.utils.events INFO:  eta: 20:30:05  iter: 2399  total_loss: 0.1644  loss_cls: 0.06882  loss_box_reg: 0.07055  loss_rpn_cls: 0.008251  loss_rpn_loc: 0.01523  time: 0.6828  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 14:53:53] d2.utils.events INFO:  eta: 20:29:37  iter: 2419  total_loss: 0.1772  loss_cls: 0.07392  loss_box_reg: 0.07638  loss_rpn_cls: 0.009474  loss_rpn_loc: 0.01575  time: 0.6828  data_time: 0.0730  lr: 0.02  max_mem: 11811M
[11/18 14:54:07] d2.utils.events INFO:  eta: 20:29:05  iter: 2439  total_loss: 0.1732  loss_cls: 0.07106  loss_box_reg: 0.07614  loss_rpn_cls: 0.009297  loss_rpn_loc: 0.01571  time: 0.6827  data_time: 0.0597  lr: 0.02  max_mem: 11811M
[11/18 14:54:20] d2.utils.events INFO:  eta: 20:28:28  iter: 2459  total_loss: 0.1726  loss_cls: 0.07186  loss_box_reg: 0.07566  loss_rpn_cls: 0.008752  loss_rpn_loc: 0.01635  time: 0.6826  data_time: 0.0630  lr: 0.02  max_mem: 11811M
[11/18 14:54:34] d2.utils.events INFO:  eta: 20:28:15  iter: 2479  total_loss: 0.1736  loss_cls: 0.07322  loss_box_reg: 0.07579  loss_rpn_cls: 0.009236  loss_rpn_loc: 0.016  time: 0.6826  data_time: 0.0711  lr: 0.02  max_mem: 11811M
[11/18 14:54:48] d2.utils.events INFO:  eta: 20:28:31  iter: 2499  total_loss: 0.1631  loss_cls: 0.0699  loss_box_reg: 0.07255  loss_rpn_cls: 0.007983  loss_rpn_loc: 0.01561  time: 0.6826  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 14:55:01] d2.utils.events INFO:  eta: 20:28:58  iter: 2519  total_loss: 0.1631  loss_cls: 0.06489  loss_box_reg: 0.07271  loss_rpn_cls: 0.007884  loss_rpn_loc: 0.01504  time: 0.6827  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 14:55:15] d2.utils.events INFO:  eta: 20:28:31  iter: 2539  total_loss: 0.1616  loss_cls: 0.06505  loss_box_reg: 0.0717  loss_rpn_cls: 0.008764  loss_rpn_loc: 0.01712  time: 0.6826  data_time: 0.0751  lr: 0.02  max_mem: 11811M
[11/18 14:55:28] d2.utils.events INFO:  eta: 20:27:53  iter: 2559  total_loss: 0.1665  loss_cls: 0.06694  loss_box_reg: 0.07234  loss_rpn_cls: 0.008219  loss_rpn_loc: 0.01674  time: 0.6826  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 14:55:42] d2.utils.events INFO:  eta: 20:28:00  iter: 2579  total_loss: 0.1743  loss_cls: 0.07082  loss_box_reg: 0.07829  loss_rpn_cls: 0.008411  loss_rpn_loc: 0.01587  time: 0.6826  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 14:55:55] d2.utils.events INFO:  eta: 20:27:16  iter: 2599  total_loss: 0.1685  loss_cls: 0.0687  loss_box_reg: 0.07434  loss_rpn_cls: 0.008058  loss_rpn_loc: 0.01615  time: 0.6825  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 14:56:09] d2.utils.events INFO:  eta: 20:27:21  iter: 2619  total_loss: 0.1641  loss_cls: 0.06767  loss_box_reg: 0.07436  loss_rpn_cls: 0.007711  loss_rpn_loc: 0.0171  time: 0.6825  data_time: 0.0685  lr: 0.02  max_mem: 11811M
[11/18 14:56:23] d2.utils.events INFO:  eta: 20:26:37  iter: 2639  total_loss: 0.1655  loss_cls: 0.06673  loss_box_reg: 0.07515  loss_rpn_cls: 0.007732  loss_rpn_loc: 0.01623  time: 0.6824  data_time: 0.0645  lr: 0.02  max_mem: 11811M
[11/18 14:56:36] d2.utils.events INFO:  eta: 20:26:24  iter: 2659  total_loss: 0.1682  loss_cls: 0.06554  loss_box_reg: 0.07557  loss_rpn_cls: 0.00943  loss_rpn_loc: 0.01703  time: 0.6824  data_time: 0.0704  lr: 0.02  max_mem: 11811M
[11/18 14:56:50] d2.utils.events INFO:  eta: 20:25:59  iter: 2679  total_loss: 0.1651  loss_cls: 0.06747  loss_box_reg: 0.07239  loss_rpn_cls: 0.008444  loss_rpn_loc: 0.01661  time: 0.6825  data_time: 0.0762  lr: 0.02  max_mem: 11811M
[11/18 14:57:04] d2.utils.events INFO:  eta: 20:25:31  iter: 2699  total_loss: 0.1611  loss_cls: 0.06677  loss_box_reg: 0.0703  loss_rpn_cls: 0.00691  loss_rpn_loc: 0.01666  time: 0.6824  data_time: 0.0705  lr: 0.02  max_mem: 11811M
[11/18 14:57:17] d2.utils.events INFO:  eta: 20:24:55  iter: 2719  total_loss: 0.1788  loss_cls: 0.07186  loss_box_reg: 0.07712  loss_rpn_cls: 0.008465  loss_rpn_loc: 0.01628  time: 0.6824  data_time: 0.0611  lr: 0.02  max_mem: 11811M
[11/18 14:57:31] d2.utils.events INFO:  eta: 20:24:48  iter: 2739  total_loss: 0.1538  loss_cls: 0.06319  loss_box_reg: 0.07032  loss_rpn_cls: 0.00633  loss_rpn_loc: 0.01635  time: 0.6824  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 14:57:44] d2.utils.events INFO:  eta: 20:24:34  iter: 2759  total_loss: 0.1596  loss_cls: 0.06398  loss_box_reg: 0.07221  loss_rpn_cls: 0.007327  loss_rpn_loc: 0.0143  time: 0.6824  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 14:57:58] d2.utils.events INFO:  eta: 20:24:21  iter: 2779  total_loss: 0.1691  loss_cls: 0.06774  loss_box_reg: 0.07722  loss_rpn_cls: 0.007674  loss_rpn_loc: 0.01656  time: 0.6824  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 14:58:12] d2.utils.events INFO:  eta: 20:24:07  iter: 2799  total_loss: 0.1674  loss_cls: 0.06737  loss_box_reg: 0.07615  loss_rpn_cls: 0.008168  loss_rpn_loc: 0.01579  time: 0.6824  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 14:58:26] d2.utils.events INFO:  eta: 20:24:50  iter: 2819  total_loss: 0.1694  loss_cls: 0.06856  loss_box_reg: 0.07352  loss_rpn_cls: 0.008873  loss_rpn_loc: 0.01668  time: 0.6825  data_time: 0.0796  lr: 0.02  max_mem: 11811M
[11/18 14:58:39] d2.utils.events INFO:  eta: 20:24:40  iter: 2839  total_loss: 0.1786  loss_cls: 0.07183  loss_box_reg: 0.0808  loss_rpn_cls: 0.008863  loss_rpn_loc: 0.01533  time: 0.6825  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 14:58:53] d2.utils.events INFO:  eta: 20:24:50  iter: 2859  total_loss: 0.165  loss_cls: 0.06739  loss_box_reg: 0.07347  loss_rpn_cls: 0.008417  loss_rpn_loc: 0.01536  time: 0.6825  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 14:59:06] d2.utils.events INFO:  eta: 20:23:54  iter: 2879  total_loss: 0.1627  loss_cls: 0.06504  loss_box_reg: 0.06887  loss_rpn_cls: 0.009203  loss_rpn_loc: 0.016  time: 0.6824  data_time: 0.0609  lr: 0.02  max_mem: 11811M
[11/18 14:59:20] d2.utils.events INFO:  eta: 20:23:41  iter: 2899  total_loss: 0.1673  loss_cls: 0.06974  loss_box_reg: 0.07292  loss_rpn_cls: 0.008944  loss_rpn_loc: 0.01697  time: 0.6823  data_time: 0.0618  lr: 0.02  max_mem: 11811M
[11/18 14:59:34] d2.utils.events INFO:  eta: 20:23:09  iter: 2919  total_loss: 0.1708  loss_cls: 0.07081  loss_box_reg: 0.07167  loss_rpn_cls: 0.008344  loss_rpn_loc: 0.0177  time: 0.6824  data_time: 0.0785  lr: 0.02  max_mem: 11811M
[11/18 14:59:47] d2.utils.events INFO:  eta: 20:23:44  iter: 2939  total_loss: 0.1723  loss_cls: 0.07092  loss_box_reg: 0.07535  loss_rpn_cls: 0.008434  loss_rpn_loc: 0.01526  time: 0.6824  data_time: 0.0595  lr: 0.02  max_mem: 11811M
[11/18 15:00:01] d2.utils.events INFO:  eta: 20:23:30  iter: 2959  total_loss: 0.1709  loss_cls: 0.06995  loss_box_reg: 0.07352  loss_rpn_cls: 0.008656  loss_rpn_loc: 0.01633  time: 0.6824  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 15:00:15] d2.utils.events INFO:  eta: 20:23:32  iter: 2979  total_loss: 0.1788  loss_cls: 0.07542  loss_box_reg: 0.0789  loss_rpn_cls: 0.008392  loss_rpn_loc: 0.0165  time: 0.6825  data_time: 0.0834  lr: 0.02  max_mem: 11811M
[11/18 15:00:29] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0002999.pth
[11/18 15:00:29] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 15:00:29] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 15:00:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 15:00:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 15:00:30] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 15:00:30] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 15:00:30] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 15:00:37] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0437 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:02:29
[11/18 15:00:42] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/18 15:00:47] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/18 15:00:52] d2.evaluation.evaluator INFO: Inference done 372/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:02:03
[11/18 15:00:57] d2.evaluation.evaluator INFO: Inference done 487/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:01:59
[11/18 15:01:02] d2.evaluation.evaluator INFO: Inference done 608/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0003 s/iter. Total: 0.0420 s/iter. ETA=0:01:54
[11/18 15:01:07] d2.evaluation.evaluator INFO: Inference done 727/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0003 s/iter. Total: 0.0420 s/iter. ETA=0:01:49
[11/18 15:01:12] d2.evaluation.evaluator INFO: Inference done 847/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:44
[11/18 15:01:17] d2.evaluation.evaluator INFO: Inference done 966/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:39
[11/18 15:01:22] d2.evaluation.evaluator INFO: Inference done 1090/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/18 15:01:27] d2.evaluation.evaluator INFO: Inference done 1212/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/18 15:01:32] d2.evaluation.evaluator INFO: Inference done 1333/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:23
[11/18 15:01:37] d2.evaluation.evaluator INFO: Inference done 1454/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:18
[11/18 15:01:42] d2.evaluation.evaluator INFO: Inference done 1576/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/18 15:01:47] d2.evaluation.evaluator INFO: Inference done 1697/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:08
[11/18 15:01:52] d2.evaluation.evaluator INFO: Inference done 1818/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:03
[11/18 15:01:57] d2.evaluation.evaluator INFO: Inference done 1938/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:58
[11/18 15:02:02] d2.evaluation.evaluator INFO: Inference done 2056/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:53
[11/18 15:02:07] d2.evaluation.evaluator INFO: Inference done 2178/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:48
[11/18 15:02:12] d2.evaluation.evaluator INFO: Inference done 2299/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:43
[11/18 15:02:17] d2.evaluation.evaluator INFO: Inference done 2420/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:38
[11/18 15:02:22] d2.evaluation.evaluator INFO: Inference done 2540/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:33
[11/18 15:02:27] d2.evaluation.evaluator INFO: Inference done 2661/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:28
[11/18 15:02:32] d2.evaluation.evaluator INFO: Inference done 2781/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/18 15:02:37] d2.evaluation.evaluator INFO: Inference done 2897/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:18
[11/18 15:02:42] d2.evaluation.evaluator INFO: Inference done 3018/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:13
[11/18 15:02:47] d2.evaluation.evaluator INFO: Inference done 3139/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:08
[11/18 15:02:52] d2.evaluation.evaluator INFO: Inference done 3262/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:03
[11/18 15:02:55] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.642169 (0.041647 s / iter per device, on 6 devices)
[11/18 15:02:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039680 s / iter per device, on 6 devices)
[11/18 15:02:58] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 15:02:58] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 15:02:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 15:03:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 15:03:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.25 seconds.
[11/18 15:03:25] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 15:03:26] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.97 seconds.
[11/18 15:03:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 12.692 | 25.490 | 10.924 | 1.434 | 5.169 | 15.796 |
[11/18 15:03:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 9.199  | bird          | 38.050 | hat with a wide brim | 3.861  |
| person                | 8.179  | dog           | 51.117 | lizard               | 10.962 |
| sheep                 | 10.794 | wine bottle   | 10.660 | bowl                 | 17.697 |
| airplane              | 27.203 | domestic cat  | 12.376 | car                  | 35.806 |
| porcupine             | 15.999 | bear          | 20.786 | tape player          | 11.450 |
| ray                   | 6.028  | laptop        | 9.539  | zebra                | 27.592 |
| computer keyboard     | 17.155 | pitcher       | 13.271 | artichoke            | 20.741 |
| tv or monitor         | 13.591 | table         | 8.998  | chair                | 7.680  |
| helmet                | 11.921 | traffic light | 4.165  | red panda            | 16.294 |
| sunglasses            | 1.963  | lamp          | 4.140  | bicycle              | 10.494 |
| backpack              | 9.874  | mushroom      | 5.210  | fox                  | 14.675 |
| otter                 | 5.965  | guitar        | 11.740 | microphone           | 1.109  |
| strawberry            | 8.291  | stove         | 9.293  | violin               | 2.399  |
| bookshelf             | 17.113 | sofa          | 5.192  | bell pepper          | 9.477  |
| bagel                 | 9.961  | lemon         | 13.950 | orange               | 7.773  |
| bench                 | 1.269  | piano         | 22.184 | flower pot           | 2.364  |
| butterfly             | 34.367 | purse         | 4.514  | pomegranate          | 3.424  |
| train                 | 21.344 | drum          | 2.999  | hippopotamus         | 5.772  |
| ski                   | 0.553  | ladybug       | 24.317 | banana               | 0.742  |
| monkey                | 16.638 | bus           | 32.815 | miniskirt            | 5.896  |
| camel                 | 9.729  | cream         | 17.928 | lobster              | 10.148 |
| seal                  | 5.515  | horse         | 12.246 | cart                 | 15.295 |
| elephant              | 20.042 | snake         | 12.770 | fig                  | 1.866  |
| watercraft            | 26.101 | apple         | 16.289 | antelope             | 28.574 |
| cattle                | 4.007  | whale         | 12.926 | coffee maker         | 24.980 |
| baby bed              | 22.948 | frog          | 16.381 | bathing cap          | 12.179 |
| crutch                | 0.266  | koala bear    | 15.301 | tie                  | 3.092  |
| dumbbell              | 0.715  | tiger         | 19.174 | dragonfly            | 14.007 |
| goldfish              | 12.181 | cucumber      | 2.913  | turtle               | 19.742 |
| harp                  | 8.905  | jellyfish     | 9.644  | swine                | 10.088 |
| pretzel               | 5.879  | motorcycle    | 20.172 | beaker               | 13.610 |
| rabbit                | 25.076 | nail          | 1.232  | axe                  | 7.311  |
| salt or pepper shaker | 4.428  | croquet ball  | 14.158 | skunk                | 10.895 |
| starfish              | 11.561 |               |        |                      |        |
[11/18 15:03:29] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 15:03:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 15:03:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 15:03:29] d2.evaluation.testing INFO: copypaste: 12.6920,25.4904,10.9242,1.4336,5.1695,15.7956
[11/18 15:03:29] d2.utils.events INFO:  eta: 20:23:15  iter: 2999  total_loss: 0.1851  loss_cls: 0.07983  loss_box_reg: 0.07848  loss_rpn_cls: 0.009975  loss_rpn_loc: 0.01561  time: 0.6825  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 15:03:43] d2.utils.events INFO:  eta: 20:23:09  iter: 3019  total_loss: 0.1804  loss_cls: 0.07436  loss_box_reg: 0.07953  loss_rpn_cls: 0.00839  loss_rpn_loc: 0.01864  time: 0.6825  data_time: 0.0606  lr: 0.02  max_mem: 11811M
[11/18 15:03:57] d2.utils.events INFO:  eta: 20:22:36  iter: 3039  total_loss: 0.1734  loss_cls: 0.07106  loss_box_reg: 0.07516  loss_rpn_cls: 0.00671  loss_rpn_loc: 0.01572  time: 0.6826  data_time: 0.0743  lr: 0.02  max_mem: 11811M
[11/18 15:04:10] d2.utils.events INFO:  eta: 20:22:37  iter: 3059  total_loss: 0.169  loss_cls: 0.0671  loss_box_reg: 0.07667  loss_rpn_cls: 0.008301  loss_rpn_loc: 0.01683  time: 0.6826  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:04:24] d2.utils.events INFO:  eta: 20:22:21  iter: 3079  total_loss: 0.1698  loss_cls: 0.06878  loss_box_reg: 0.07694  loss_rpn_cls: 0.008216  loss_rpn_loc: 0.01535  time: 0.6826  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 15:04:38] d2.utils.events INFO:  eta: 20:22:55  iter: 3099  total_loss: 0.1764  loss_cls: 0.07201  loss_box_reg: 0.07723  loss_rpn_cls: 0.008881  loss_rpn_loc: 0.01657  time: 0.6827  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:04:52] d2.utils.events INFO:  eta: 20:22:45  iter: 3119  total_loss: 0.1612  loss_cls: 0.06337  loss_box_reg: 0.07496  loss_rpn_cls: 0.007832  loss_rpn_loc: 0.01523  time: 0.6827  data_time: 0.0643  lr: 0.02  max_mem: 11811M
[11/18 15:05:05] d2.utils.events INFO:  eta: 20:23:01  iter: 3139  total_loss: 0.1622  loss_cls: 0.06439  loss_box_reg: 0.0719  loss_rpn_cls: 0.007378  loss_rpn_loc: 0.01624  time: 0.6827  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 15:05:19] d2.utils.events INFO:  eta: 20:22:54  iter: 3159  total_loss: 0.1607  loss_cls: 0.0625  loss_box_reg: 0.07338  loss_rpn_cls: 0.006748  loss_rpn_loc: 0.01626  time: 0.6826  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 15:05:32] d2.utils.events INFO:  eta: 20:22:06  iter: 3179  total_loss: 0.1587  loss_cls: 0.06353  loss_box_reg: 0.07105  loss_rpn_cls: 0.006751  loss_rpn_loc: 0.01594  time: 0.6825  data_time: 0.0670  lr: 0.02  max_mem: 11811M
[11/18 15:05:46] d2.utils.events INFO:  eta: 20:21:50  iter: 3199  total_loss: 0.1641  loss_cls: 0.06773  loss_box_reg: 0.07661  loss_rpn_cls: 0.007698  loss_rpn_loc: 0.01553  time: 0.6825  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 15:05:59] d2.utils.events INFO:  eta: 20:21:34  iter: 3219  total_loss: 0.1677  loss_cls: 0.06469  loss_box_reg: 0.07601  loss_rpn_cls: 0.007627  loss_rpn_loc: 0.01647  time: 0.6825  data_time: 0.0601  lr: 0.02  max_mem: 11811M
[11/18 15:06:13] d2.utils.events INFO:  eta: 20:21:21  iter: 3239  total_loss: 0.1587  loss_cls: 0.06437  loss_box_reg: 0.07263  loss_rpn_cls: 0.006786  loss_rpn_loc: 0.01592  time: 0.6825  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 15:06:27] d2.utils.events INFO:  eta: 20:21:40  iter: 3259  total_loss: 0.1715  loss_cls: 0.0738  loss_box_reg: 0.07764  loss_rpn_cls: 0.007705  loss_rpn_loc: 0.0151  time: 0.6826  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 15:06:40] d2.utils.events INFO:  eta: 20:21:33  iter: 3279  total_loss: 0.1618  loss_cls: 0.06583  loss_box_reg: 0.07221  loss_rpn_cls: 0.007409  loss_rpn_loc: 0.01477  time: 0.6825  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 15:06:54] d2.utils.events INFO:  eta: 20:21:20  iter: 3299  total_loss: 0.1615  loss_cls: 0.06403  loss_box_reg: 0.07347  loss_rpn_cls: 0.008047  loss_rpn_loc: 0.0164  time: 0.6825  data_time: 0.0594  lr: 0.02  max_mem: 11811M
[11/18 15:07:08] d2.utils.events INFO:  eta: 20:20:59  iter: 3319  total_loss: 0.1539  loss_cls: 0.06055  loss_box_reg: 0.07023  loss_rpn_cls: 0.007847  loss_rpn_loc: 0.01719  time: 0.6825  data_time: 0.0733  lr: 0.02  max_mem: 11811M
[11/18 15:07:21] d2.utils.events INFO:  eta: 20:20:54  iter: 3339  total_loss: 0.1658  loss_cls: 0.06758  loss_box_reg: 0.07171  loss_rpn_cls: 0.008074  loss_rpn_loc: 0.01723  time: 0.6824  data_time: 0.0652  lr: 0.02  max_mem: 11811M
[11/18 15:07:35] d2.utils.events INFO:  eta: 20:21:40  iter: 3359  total_loss: 0.1771  loss_cls: 0.07299  loss_box_reg: 0.0743  loss_rpn_cls: 0.00857  loss_rpn_loc: 0.01667  time: 0.6825  data_time: 0.0724  lr: 0.02  max_mem: 11811M
[11/18 15:07:48] d2.utils.events INFO:  eta: 20:20:51  iter: 3379  total_loss: 0.1624  loss_cls: 0.06651  loss_box_reg: 0.07003  loss_rpn_cls: 0.008458  loss_rpn_loc: 0.01645  time: 0.6824  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 15:08:02] d2.utils.events INFO:  eta: 20:20:37  iter: 3399  total_loss: 0.1639  loss_cls: 0.06677  loss_box_reg: 0.0747  loss_rpn_cls: 0.007706  loss_rpn_loc: 0.01534  time: 0.6824  data_time: 0.0617  lr: 0.02  max_mem: 11811M
[11/18 15:08:16] d2.utils.events INFO:  eta: 20:20:01  iter: 3419  total_loss: 0.1745  loss_cls: 0.07017  loss_box_reg: 0.07673  loss_rpn_cls: 0.008349  loss_rpn_loc: 0.01708  time: 0.6824  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 15:08:29] d2.utils.events INFO:  eta: 20:19:48  iter: 3439  total_loss: 0.1795  loss_cls: 0.07248  loss_box_reg: 0.07809  loss_rpn_cls: 0.008551  loss_rpn_loc: 0.01581  time: 0.6824  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 15:08:43] d2.utils.events INFO:  eta: 20:19:56  iter: 3459  total_loss: 0.1725  loss_cls: 0.07192  loss_box_reg: 0.073  loss_rpn_cls: 0.009066  loss_rpn_loc: 0.01634  time: 0.6825  data_time: 0.0747  lr: 0.02  max_mem: 11811M
[11/18 15:08:57] d2.utils.events INFO:  eta: 20:20:13  iter: 3479  total_loss: 0.1703  loss_cls: 0.07078  loss_box_reg: 0.07696  loss_rpn_cls: 0.007885  loss_rpn_loc: 0.0151  time: 0.6825  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 15:09:10] d2.utils.events INFO:  eta: 20:19:05  iter: 3499  total_loss: 0.1706  loss_cls: 0.07075  loss_box_reg: 0.07391  loss_rpn_cls: 0.007952  loss_rpn_loc: 0.01694  time: 0.6824  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 15:09:24] d2.utils.events INFO:  eta: 20:18:43  iter: 3519  total_loss: 0.1571  loss_cls: 0.06261  loss_box_reg: 0.07086  loss_rpn_cls: 0.006746  loss_rpn_loc: 0.01455  time: 0.6825  data_time: 0.0807  lr: 0.02  max_mem: 11811M
[11/18 15:09:38] d2.utils.events INFO:  eta: 20:19:02  iter: 3539  total_loss: 0.1607  loss_cls: 0.06671  loss_box_reg: 0.07556  loss_rpn_cls: 0.007316  loss_rpn_loc: 0.0149  time: 0.6825  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 15:09:51] d2.utils.events INFO:  eta: 20:18:48  iter: 3559  total_loss: 0.1671  loss_cls: 0.06606  loss_box_reg: 0.07566  loss_rpn_cls: 0.007805  loss_rpn_loc: 0.01684  time: 0.6824  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:10:05] d2.utils.events INFO:  eta: 20:19:08  iter: 3579  total_loss: 0.1563  loss_cls: 0.06376  loss_box_reg: 0.06952  loss_rpn_cls: 0.007236  loss_rpn_loc: 0.01636  time: 0.6825  data_time: 0.0653  lr: 0.02  max_mem: 11811M
[11/18 15:10:19] d2.utils.events INFO:  eta: 20:19:19  iter: 3599  total_loss: 0.1662  loss_cls: 0.06478  loss_box_reg: 0.0747  loss_rpn_cls: 0.008268  loss_rpn_loc: 0.01676  time: 0.6825  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 15:10:32] d2.utils.events INFO:  eta: 20:18:57  iter: 3619  total_loss: 0.1676  loss_cls: 0.06435  loss_box_reg: 0.0746  loss_rpn_cls: 0.007995  loss_rpn_loc: 0.0179  time: 0.6825  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 15:10:46] d2.utils.events INFO:  eta: 20:19:39  iter: 3639  total_loss: 0.1551  loss_cls: 0.06117  loss_box_reg: 0.06973  loss_rpn_cls: 0.008838  loss_rpn_loc: 0.01683  time: 0.6825  data_time: 0.0720  lr: 0.02  max_mem: 11811M
[11/18 15:11:00] d2.utils.events INFO:  eta: 20:19:25  iter: 3659  total_loss: 0.1624  loss_cls: 0.06348  loss_box_reg: 0.07227  loss_rpn_cls: 0.007102  loss_rpn_loc: 0.01561  time: 0.6825  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 15:11:13] d2.utils.events INFO:  eta: 20:19:17  iter: 3679  total_loss: 0.1627  loss_cls: 0.06504  loss_box_reg: 0.07287  loss_rpn_cls: 0.007512  loss_rpn_loc: 0.0155  time: 0.6825  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 15:11:27] d2.utils.events INFO:  eta: 20:19:07  iter: 3699  total_loss: 0.1657  loss_cls: 0.06525  loss_box_reg: 0.07476  loss_rpn_cls: 0.007116  loss_rpn_loc: 0.01587  time: 0.6825  data_time: 0.0782  lr: 0.02  max_mem: 11811M
[11/18 15:11:40] d2.utils.events INFO:  eta: 20:18:52  iter: 3719  total_loss: 0.1657  loss_cls: 0.06469  loss_box_reg: 0.07738  loss_rpn_cls: 0.008866  loss_rpn_loc: 0.01549  time: 0.6824  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:11:54] d2.utils.events INFO:  eta: 20:19:35  iter: 3739  total_loss: 0.162  loss_cls: 0.06646  loss_box_reg: 0.07347  loss_rpn_cls: 0.007118  loss_rpn_loc: 0.01549  time: 0.6824  data_time: 0.0711  lr: 0.02  max_mem: 11811M
[11/18 15:12:08] d2.utils.events INFO:  eta: 20:19:33  iter: 3759  total_loss: 0.1756  loss_cls: 0.07445  loss_box_reg: 0.07265  loss_rpn_cls: 0.008322  loss_rpn_loc: 0.01636  time: 0.6825  data_time: 0.0756  lr: 0.02  max_mem: 11811M
[11/18 15:12:22] d2.utils.events INFO:  eta: 20:18:32  iter: 3779  total_loss: 0.1705  loss_cls: 0.06815  loss_box_reg: 0.07812  loss_rpn_cls: 0.008438  loss_rpn_loc: 0.01798  time: 0.6824  data_time: 0.0673  lr: 0.02  max_mem: 11811M
[11/18 15:12:35] d2.utils.events INFO:  eta: 20:18:07  iter: 3799  total_loss: 0.1691  loss_cls: 0.06901  loss_box_reg: 0.07369  loss_rpn_cls: 0.008757  loss_rpn_loc: 0.01775  time: 0.6825  data_time: 0.0788  lr: 0.02  max_mem: 11811M
[11/18 15:12:49] d2.utils.events INFO:  eta: 20:17:42  iter: 3819  total_loss: 0.1681  loss_cls: 0.06955  loss_box_reg: 0.07764  loss_rpn_cls: 0.007103  loss_rpn_loc: 0.01466  time: 0.6825  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:13:03] d2.utils.events INFO:  eta: 20:17:40  iter: 3839  total_loss: 0.1592  loss_cls: 0.06448  loss_box_reg: 0.0693  loss_rpn_cls: 0.007574  loss_rpn_loc: 0.01506  time: 0.6825  data_time: 0.0675  lr: 0.02  max_mem: 11811M
[11/18 15:13:16] d2.utils.events INFO:  eta: 20:17:27  iter: 3859  total_loss: 0.1631  loss_cls: 0.06847  loss_box_reg: 0.06964  loss_rpn_cls: 0.007765  loss_rpn_loc: 0.01527  time: 0.6825  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 15:13:30] d2.utils.events INFO:  eta: 20:17:59  iter: 3879  total_loss: 0.1646  loss_cls: 0.06649  loss_box_reg: 0.07365  loss_rpn_cls: 0.00834  loss_rpn_loc: 0.01616  time: 0.6825  data_time: 0.0622  lr: 0.02  max_mem: 11811M
[11/18 15:13:44] d2.utils.events INFO:  eta: 20:18:11  iter: 3899  total_loss: 0.1655  loss_cls: 0.06679  loss_box_reg: 0.07286  loss_rpn_cls: 0.008607  loss_rpn_loc: 0.01653  time: 0.6825  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 15:13:57] d2.utils.events INFO:  eta: 20:18:18  iter: 3919  total_loss: 0.1708  loss_cls: 0.0716  loss_box_reg: 0.07385  loss_rpn_cls: 0.009098  loss_rpn_loc: 0.01578  time: 0.6825  data_time: 0.0670  lr: 0.02  max_mem: 11811M
[11/18 15:14:11] d2.utils.events INFO:  eta: 20:18:04  iter: 3939  total_loss: 0.1757  loss_cls: 0.07249  loss_box_reg: 0.07725  loss_rpn_cls: 0.008993  loss_rpn_loc: 0.01568  time: 0.6825  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 15:14:25] d2.utils.events INFO:  eta: 20:18:04  iter: 3959  total_loss: 0.1749  loss_cls: 0.07141  loss_box_reg: 0.0763  loss_rpn_cls: 0.009599  loss_rpn_loc: 0.0164  time: 0.6826  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 15:14:39] d2.utils.events INFO:  eta: 20:17:50  iter: 3979  total_loss: 0.1787  loss_cls: 0.07335  loss_box_reg: 0.07719  loss_rpn_cls: 0.00833  loss_rpn_loc: 0.01582  time: 0.6826  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 15:14:52] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0003999.pth
[11/18 15:14:53] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 15:14:53] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 15:14:53] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 15:14:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 15:14:53] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 15:14:53] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 15:14:54] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 15:15:00] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0413 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:02:21
[11/18 15:15:05] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0017 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:12
[11/18 15:15:10] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0017 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/18 15:15:15] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/18 15:15:20] d2.evaluation.evaluator INFO: Inference done 503/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/18 15:15:25] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/18 15:15:30] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:46
[11/18 15:15:35] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/18 15:15:40] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/18 15:15:45] d2.evaluation.evaluator INFO: Inference done 1105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:32
[11/18 15:15:50] d2.evaluation.evaluator INFO: Inference done 1225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/18 15:15:55] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/18 15:16:00] d2.evaluation.evaluator INFO: Inference done 1467/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/18 15:16:05] d2.evaluation.evaluator INFO: Inference done 1585/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/18 15:16:10] d2.evaluation.evaluator INFO: Inference done 1705/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/18 15:16:16] d2.evaluation.evaluator INFO: Inference done 1822/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/18 15:16:21] d2.evaluation.evaluator INFO: Inference done 1942/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/18 15:16:26] d2.evaluation.evaluator INFO: Inference done 2063/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/18 15:16:31] d2.evaluation.evaluator INFO: Inference done 2182/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/18 15:16:36] d2.evaluation.evaluator INFO: Inference done 2300/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:43
[11/18 15:16:41] d2.evaluation.evaluator INFO: Inference done 2421/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:38
[11/18 15:16:46] d2.evaluation.evaluator INFO: Inference done 2541/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:33
[11/18 15:16:51] d2.evaluation.evaluator INFO: Inference done 2661/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:28
[11/18 15:16:56] d2.evaluation.evaluator INFO: Inference done 2780/3334. Dataloading: 0.0017 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/18 15:17:01] d2.evaluation.evaluator INFO: Inference done 2902/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/18 15:17:06] d2.evaluation.evaluator INFO: Inference done 3024/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:12
[11/18 15:17:11] d2.evaluation.evaluator INFO: Inference done 3148/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/18 15:17:16] d2.evaluation.evaluator INFO: Inference done 3270/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/18 15:17:19] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.638043 (0.041646 s / iter per device, on 6 devices)
[11/18 15:17:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039597 s / iter per device, on 6 devices)
[11/18 15:17:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 15:17:21] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 15:17:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 15:17:23] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 15:17:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.38 seconds.
[11/18 15:17:45] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 15:17:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.69 seconds.
[11/18 15:17:47] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.680 | 27.009 | 12.194 | 1.232 | 5.604 | 16.536 |
[11/18 15:17:47] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 12.692 | bird          | 36.574 | hat with a wide brim | 6.530  |
| person                | 7.428  | dog           | 50.035 | lizard               | 11.586 |
| sheep                 | 10.447 | wine bottle   | 7.282  | bowl                 | 15.752 |
| airplane              | 30.538 | domestic cat  | 16.355 | car                  | 36.997 |
| porcupine             | 24.009 | bear          | 17.246 | tape player          | 12.319 |
| ray                   | 3.745  | laptop        | 11.950 | zebra                | 26.079 |
| computer keyboard     | 15.084 | pitcher       | 12.416 | artichoke            | 22.090 |
| tv or monitor         | 12.962 | table         | 9.668  | chair                | 8.221  |
| helmet                | 13.824 | traffic light | 3.866  | red panda            | 22.541 |
| sunglasses            | 4.024  | lamp          | 4.160  | bicycle              | 14.085 |
| backpack              | 9.486  | mushroom      | 5.754  | fox                  | 17.225 |
| otter                 | 6.283  | guitar        | 11.050 | microphone           | 1.295  |
| strawberry            | 10.972 | stove         | 16.402 | violin               | 3.002  |
| bookshelf             | 18.366 | sofa          | 7.969  | bell pepper          | 13.395 |
| bagel                 | 13.406 | lemon         | 16.210 | orange               | 21.507 |
| bench                 | 2.390  | piano         | 23.894 | flower pot           | 3.175  |
| butterfly             | 35.540 | purse         | 6.516  | pomegranate          | 6.748  |
| train                 | 24.676 | drum          | 3.316  | hippopotamus         | 3.663  |
| ski                   | 1.596  | ladybug       | 29.397 | banana               | 2.713  |
| monkey                | 16.030 | bus           | 33.639 | miniskirt            | 6.279  |
| camel                 | 10.933 | cream         | 19.271 | lobster              | 9.129  |
| seal                  | 3.228  | horse         | 12.648 | cart                 | 13.981 |
| elephant              | 21.891 | snake         | 11.246 | fig                  | 5.228  |
| watercraft            | 28.104 | apple         | 15.198 | antelope             | 27.760 |
| cattle                | 6.002  | whale         | 18.925 | coffee maker         | 25.541 |
| baby bed              | 28.170 | frog          | 19.108 | bathing cap          | 10.842 |
| crutch                | 0.306  | koala bear    | 24.021 | tie                  | 1.394  |
| dumbbell              | 0.534  | tiger         | 20.902 | dragonfly            | 12.055 |
| goldfish              | 8.414  | cucumber      | 1.520  | turtle               | 19.348 |
| harp                  | 13.721 | jellyfish     | 6.912  | swine                | 10.298 |
| pretzel               | 5.762  | motorcycle    | 23.251 | beaker               | 12.195 |
| rabbit                | 26.211 | nail          | 0.319  | axe                  | 2.857  |
| salt or pepper shaker | 4.995  | croquet ball  | 12.183 | skunk                | 9.233  |
| starfish              | 12.001 |               |        |                      |        |
[11/18 15:17:49] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 15:17:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 15:17:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 15:17:49] d2.evaluation.testing INFO: copypaste: 13.6804,27.0094,12.1938,1.2316,5.6043,16.5364
[11/18 15:17:49] d2.utils.events INFO:  eta: 20:17:34  iter: 3999  total_loss: 0.1713  loss_cls: 0.07221  loss_box_reg: 0.07326  loss_rpn_cls: 0.009138  loss_rpn_loc: 0.01604  time: 0.6826  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 15:18:03] d2.utils.events INFO:  eta: 20:17:15  iter: 4019  total_loss: 0.1626  loss_cls: 0.0649  loss_box_reg: 0.0717  loss_rpn_cls: 0.007736  loss_rpn_loc: 0.01526  time: 0.6825  data_time: 0.0730  lr: 0.02  max_mem: 11811M
[11/18 15:18:17] d2.utils.events INFO:  eta: 20:16:48  iter: 4039  total_loss: 0.1596  loss_cls: 0.0623  loss_box_reg: 0.07363  loss_rpn_cls: 0.00695  loss_rpn_loc: 0.01519  time: 0.6826  data_time: 0.0828  lr: 0.02  max_mem: 11811M
[11/18 15:18:30] d2.utils.events INFO:  eta: 20:16:19  iter: 4059  total_loss: 0.1598  loss_cls: 0.06364  loss_box_reg: 0.07204  loss_rpn_cls: 0.008086  loss_rpn_loc: 0.01514  time: 0.6825  data_time: 0.0652  lr: 0.02  max_mem: 11811M
[11/18 15:18:44] d2.utils.events INFO:  eta: 20:15:55  iter: 4079  total_loss: 0.1622  loss_cls: 0.06441  loss_box_reg: 0.07496  loss_rpn_cls: 0.007451  loss_rpn_loc: 0.01523  time: 0.6825  data_time: 0.0597  lr: 0.02  max_mem: 11811M
[11/18 15:18:57] d2.utils.events INFO:  eta: 20:14:31  iter: 4099  total_loss: 0.1607  loss_cls: 0.0632  loss_box_reg: 0.07124  loss_rpn_cls: 0.006852  loss_rpn_loc: 0.01558  time: 0.6825  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:19:11] d2.utils.events INFO:  eta: 20:14:21  iter: 4119  total_loss: 0.1614  loss_cls: 0.06311  loss_box_reg: 0.07764  loss_rpn_cls: 0.007195  loss_rpn_loc: 0.01503  time: 0.6825  data_time: 0.0599  lr: 0.02  max_mem: 11811M
[11/18 15:19:24] d2.utils.events INFO:  eta: 20:13:59  iter: 4139  total_loss: 0.1642  loss_cls: 0.06405  loss_box_reg: 0.07509  loss_rpn_cls: 0.007273  loss_rpn_loc: 0.01715  time: 0.6824  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 15:19:38] d2.utils.events INFO:  eta: 20:14:38  iter: 4159  total_loss: 0.1639  loss_cls: 0.06678  loss_box_reg: 0.07261  loss_rpn_cls: 0.007832  loss_rpn_loc: 0.01665  time: 0.6825  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 15:19:52] d2.utils.events INFO:  eta: 20:14:49  iter: 4179  total_loss: 0.1666  loss_cls: 0.06662  loss_box_reg: 0.0776  loss_rpn_cls: 0.007384  loss_rpn_loc: 0.01543  time: 0.6825  data_time: 0.0651  lr: 0.02  max_mem: 11811M
[11/18 15:20:06] d2.utils.events INFO:  eta: 20:14:43  iter: 4199  total_loss: 0.1682  loss_cls: 0.0671  loss_box_reg: 0.07372  loss_rpn_cls: 0.007752  loss_rpn_loc: 0.01561  time: 0.6825  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 15:20:19] d2.utils.events INFO:  eta: 20:14:29  iter: 4219  total_loss: 0.165  loss_cls: 0.06585  loss_box_reg: 0.07392  loss_rpn_cls: 0.008777  loss_rpn_loc: 0.01696  time: 0.6825  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 15:20:33] d2.utils.events INFO:  eta: 20:13:44  iter: 4239  total_loss: 0.1683  loss_cls: 0.06757  loss_box_reg: 0.07603  loss_rpn_cls: 0.008403  loss_rpn_loc: 0.01599  time: 0.6825  data_time: 0.0784  lr: 0.02  max_mem: 11811M
[11/18 15:20:47] d2.utils.events INFO:  eta: 20:12:52  iter: 4259  total_loss: 0.1724  loss_cls: 0.06854  loss_box_reg: 0.07673  loss_rpn_cls: 0.008179  loss_rpn_loc: 0.01656  time: 0.6826  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 15:21:00] d2.utils.events INFO:  eta: 20:12:47  iter: 4279  total_loss: 0.158  loss_cls: 0.06321  loss_box_reg: 0.07334  loss_rpn_cls: 0.007827  loss_rpn_loc: 0.01609  time: 0.6825  data_time: 0.0632  lr: 0.02  max_mem: 11811M
[11/18 15:21:14] d2.utils.events INFO:  eta: 20:13:34  iter: 4299  total_loss: 0.1652  loss_cls: 0.06519  loss_box_reg: 0.07503  loss_rpn_cls: 0.008675  loss_rpn_loc: 0.01726  time: 0.6826  data_time: 0.0673  lr: 0.02  max_mem: 11811M
[11/18 15:21:28] d2.utils.events INFO:  eta: 20:13:35  iter: 4319  total_loss: 0.1644  loss_cls: 0.06897  loss_box_reg: 0.07448  loss_rpn_cls: 0.008214  loss_rpn_loc: 0.01649  time: 0.6826  data_time: 0.0686  lr: 0.02  max_mem: 11811M
[11/18 15:21:42] d2.utils.events INFO:  eta: 20:13:39  iter: 4339  total_loss: 0.1738  loss_cls: 0.07462  loss_box_reg: 0.07651  loss_rpn_cls: 0.007077  loss_rpn_loc: 0.01611  time: 0.6826  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 15:21:55] d2.utils.events INFO:  eta: 20:12:34  iter: 4359  total_loss: 0.1688  loss_cls: 0.06955  loss_box_reg: 0.0766  loss_rpn_cls: 0.008411  loss_rpn_loc: 0.01476  time: 0.6826  data_time: 0.0643  lr: 0.02  max_mem: 11811M
[11/18 15:22:09] d2.utils.events INFO:  eta: 20:13:03  iter: 4379  total_loss: 0.1674  loss_cls: 0.06587  loss_box_reg: 0.0762  loss_rpn_cls: 0.008559  loss_rpn_loc: 0.01715  time: 0.6825  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 15:22:22] d2.utils.events INFO:  eta: 20:12:34  iter: 4399  total_loss: 0.1629  loss_cls: 0.06732  loss_box_reg: 0.0724  loss_rpn_cls: 0.007149  loss_rpn_loc: 0.0154  time: 0.6825  data_time: 0.0726  lr: 0.02  max_mem: 11811M
[11/18 15:22:36] d2.utils.events INFO:  eta: 20:12:35  iter: 4419  total_loss: 0.1568  loss_cls: 0.06415  loss_box_reg: 0.06988  loss_rpn_cls: 0.007797  loss_rpn_loc: 0.01612  time: 0.6826  data_time: 0.0740  lr: 0.02  max_mem: 11811M
[11/18 15:22:50] d2.utils.events INFO:  eta: 20:12:30  iter: 4439  total_loss: 0.1613  loss_cls: 0.06534  loss_box_reg: 0.07325  loss_rpn_cls: 0.008024  loss_rpn_loc: 0.0171  time: 0.6826  data_time: 0.0703  lr: 0.02  max_mem: 11811M
[11/18 15:23:03] d2.utils.events INFO:  eta: 20:12:17  iter: 4459  total_loss: 0.1561  loss_cls: 0.06548  loss_box_reg: 0.07026  loss_rpn_cls: 0.008158  loss_rpn_loc: 0.01743  time: 0.6826  data_time: 0.0712  lr: 0.02  max_mem: 11811M
[11/18 15:23:17] d2.utils.events INFO:  eta: 20:11:54  iter: 4479  total_loss: 0.1656  loss_cls: 0.06804  loss_box_reg: 0.07343  loss_rpn_cls: 0.007561  loss_rpn_loc: 0.01673  time: 0.6825  data_time: 0.0671  lr: 0.02  max_mem: 11811M
[11/18 15:23:31] d2.utils.events INFO:  eta: 20:12:17  iter: 4499  total_loss: 0.1532  loss_cls: 0.06439  loss_box_reg: 0.06652  loss_rpn_cls: 0.007124  loss_rpn_loc: 0.01645  time: 0.6826  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 15:23:44] d2.utils.events INFO:  eta: 20:12:08  iter: 4519  total_loss: 0.1602  loss_cls: 0.0631  loss_box_reg: 0.07362  loss_rpn_cls: 0.00739  loss_rpn_loc: 0.01695  time: 0.6825  data_time: 0.0630  lr: 0.02  max_mem: 11811M
[11/18 15:23:58] d2.utils.events INFO:  eta: 20:11:34  iter: 4539  total_loss: 0.1641  loss_cls: 0.06298  loss_box_reg: 0.0755  loss_rpn_cls: 0.008013  loss_rpn_loc: 0.01581  time: 0.6825  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 15:24:12] d2.utils.events INFO:  eta: 20:11:17  iter: 4559  total_loss: 0.1634  loss_cls: 0.06421  loss_box_reg: 0.07872  loss_rpn_cls: 0.00795  loss_rpn_loc: 0.01685  time: 0.6825  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 15:24:25] d2.utils.events INFO:  eta: 20:11:07  iter: 4579  total_loss: 0.1675  loss_cls: 0.06584  loss_box_reg: 0.0744  loss_rpn_cls: 0.007332  loss_rpn_loc: 0.01674  time: 0.6826  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 15:24:39] d2.utils.events INFO:  eta: 20:11:01  iter: 4599  total_loss: 0.1562  loss_cls: 0.06297  loss_box_reg: 0.07194  loss_rpn_cls: 0.00723  loss_rpn_loc: 0.01677  time: 0.6827  data_time: 0.0867  lr: 0.02  max_mem: 11811M
[11/18 15:24:53] d2.utils.events INFO:  eta: 20:10:55  iter: 4619  total_loss: 0.161  loss_cls: 0.06229  loss_box_reg: 0.07269  loss_rpn_cls: 0.007648  loss_rpn_loc: 0.01593  time: 0.6827  data_time: 0.0687  lr: 0.02  max_mem: 11811M
[11/18 15:25:07] d2.utils.events INFO:  eta: 20:10:33  iter: 4639  total_loss: 0.1609  loss_cls: 0.06263  loss_box_reg: 0.07362  loss_rpn_cls: 0.007685  loss_rpn_loc: 0.01609  time: 0.6827  data_time: 0.0611  lr: 0.02  max_mem: 11811M
[11/18 15:25:20] d2.utils.events INFO:  eta: 20:10:12  iter: 4659  total_loss: 0.1679  loss_cls: 0.06616  loss_box_reg: 0.07847  loss_rpn_cls: 0.008238  loss_rpn_loc: 0.01596  time: 0.6826  data_time: 0.0685  lr: 0.02  max_mem: 11811M
[11/18 15:25:34] d2.utils.events INFO:  eta: 20:09:46  iter: 4679  total_loss: 0.1658  loss_cls: 0.06717  loss_box_reg: 0.07747  loss_rpn_cls: 0.007498  loss_rpn_loc: 0.01622  time: 0.6827  data_time: 0.0606  lr: 0.02  max_mem: 11811M
[11/18 15:25:48] d2.utils.events INFO:  eta: 20:09:16  iter: 4699  total_loss: 0.165  loss_cls: 0.06506  loss_box_reg: 0.07627  loss_rpn_cls: 0.008128  loss_rpn_loc: 0.0164  time: 0.6827  data_time: 0.0747  lr: 0.02  max_mem: 11811M
[11/18 15:26:02] d2.utils.events INFO:  eta: 20:09:56  iter: 4719  total_loss: 0.1602  loss_cls: 0.06342  loss_box_reg: 0.07363  loss_rpn_cls: 0.008352  loss_rpn_loc: 0.01695  time: 0.6827  data_time: 0.0627  lr: 0.02  max_mem: 11811M
[11/18 15:26:15] d2.utils.events INFO:  eta: 20:09:33  iter: 4739  total_loss: 0.161  loss_cls: 0.06319  loss_box_reg: 0.0718  loss_rpn_cls: 0.007624  loss_rpn_loc: 0.01518  time: 0.6827  data_time: 0.0635  lr: 0.02  max_mem: 11811M
[11/18 15:26:29] d2.utils.events INFO:  eta: 20:09:20  iter: 4759  total_loss: 0.1637  loss_cls: 0.06474  loss_box_reg: 0.07335  loss_rpn_cls: 0.007725  loss_rpn_loc: 0.01653  time: 0.6827  data_time: 0.0848  lr: 0.02  max_mem: 11811M
[11/18 15:26:43] d2.utils.events INFO:  eta: 20:08:38  iter: 4779  total_loss: 0.1666  loss_cls: 0.06756  loss_box_reg: 0.07551  loss_rpn_cls: 0.008451  loss_rpn_loc: 0.01604  time: 0.6827  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 15:26:56] d2.utils.events INFO:  eta: 20:06:57  iter: 4799  total_loss: 0.163  loss_cls: 0.06418  loss_box_reg: 0.07741  loss_rpn_cls: 0.00796  loss_rpn_loc: 0.01524  time: 0.6826  data_time: 0.0651  lr: 0.02  max_mem: 11811M
[11/18 15:27:10] d2.utils.events INFO:  eta: 20:06:23  iter: 4819  total_loss: 0.1626  loss_cls: 0.06388  loss_box_reg: 0.07142  loss_rpn_cls: 0.007331  loss_rpn_loc: 0.01694  time: 0.6826  data_time: 0.0758  lr: 0.02  max_mem: 11811M
[11/18 15:27:23] d2.utils.events INFO:  eta: 20:05:57  iter: 4839  total_loss: 0.1614  loss_cls: 0.0649  loss_box_reg: 0.07262  loss_rpn_cls: 0.007595  loss_rpn_loc: 0.01737  time: 0.6826  data_time: 0.0664  lr: 0.02  max_mem: 11811M
[11/18 15:27:37] d2.utils.events INFO:  eta: 20:06:04  iter: 4859  total_loss: 0.1651  loss_cls: 0.06417  loss_box_reg: 0.0732  loss_rpn_cls: 0.008066  loss_rpn_loc: 0.01621  time: 0.6826  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 15:27:51] d2.utils.events INFO:  eta: 20:06:02  iter: 4879  total_loss: 0.1703  loss_cls: 0.07103  loss_box_reg: 0.07278  loss_rpn_cls: 0.008715  loss_rpn_loc: 0.01633  time: 0.6827  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 15:28:04] d2.utils.events INFO:  eta: 20:05:37  iter: 4899  total_loss: 0.162  loss_cls: 0.06637  loss_box_reg: 0.07274  loss_rpn_cls: 0.007983  loss_rpn_loc: 0.01635  time: 0.6826  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 15:28:18] d2.utils.events INFO:  eta: 20:05:35  iter: 4919  total_loss: 0.1719  loss_cls: 0.07187  loss_box_reg: 0.07634  loss_rpn_cls: 0.00877  loss_rpn_loc: 0.01477  time: 0.6827  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 15:28:32] d2.utils.events INFO:  eta: 20:05:10  iter: 4939  total_loss: 0.1594  loss_cls: 0.06774  loss_box_reg: 0.07093  loss_rpn_cls: 0.007081  loss_rpn_loc: 0.015  time: 0.6827  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 15:28:45] d2.utils.events INFO:  eta: 20:04:27  iter: 4959  total_loss: 0.1626  loss_cls: 0.06364  loss_box_reg: 0.07236  loss_rpn_cls: 0.007256  loss_rpn_loc: 0.01644  time: 0.6827  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 15:28:59] d2.utils.events INFO:  eta: 20:03:58  iter: 4979  total_loss: 0.167  loss_cls: 0.06558  loss_box_reg: 0.07391  loss_rpn_cls: 0.00738  loss_rpn_loc: 0.01541  time: 0.6827  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 15:29:12] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0004999.pth
[11/18 15:29:13] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 15:29:13] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 15:29:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 15:29:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 15:29:13] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 15:29:13] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 15:29:14] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 15:29:21] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0431 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:02:28
[11/18 15:29:26] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/18 15:29:31] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/18 15:29:36] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:02
[11/18 15:29:41] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/18 15:29:46] d2.evaluation.evaluator INFO: Inference done 622/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/18 15:29:51] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/18 15:29:56] d2.evaluation.evaluator INFO: Inference done 863/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/18 15:30:01] d2.evaluation.evaluator INFO: Inference done 983/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/18 15:30:06] d2.evaluation.evaluator INFO: Inference done 1103/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/18 15:30:11] d2.evaluation.evaluator INFO: Inference done 1225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/18 15:30:16] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/18 15:30:21] d2.evaluation.evaluator INFO: Inference done 1466/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/18 15:30:26] d2.evaluation.evaluator INFO: Inference done 1584/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/18 15:30:31] d2.evaluation.evaluator INFO: Inference done 1703/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:07
[11/18 15:30:36] d2.evaluation.evaluator INFO: Inference done 1824/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/18 15:30:41] d2.evaluation.evaluator INFO: Inference done 1943/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/18 15:30:46] d2.evaluation.evaluator INFO: Inference done 2065/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/18 15:30:51] d2.evaluation.evaluator INFO: Inference done 2186/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/18 15:30:56] d2.evaluation.evaluator INFO: Inference done 2307/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:42
[11/18 15:31:01] d2.evaluation.evaluator INFO: Inference done 2429/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/18 15:31:06] d2.evaluation.evaluator INFO: Inference done 2546/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/18 15:31:11] d2.evaluation.evaluator INFO: Inference done 2668/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/18 15:31:16] d2.evaluation.evaluator INFO: Inference done 2788/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/18 15:31:21] d2.evaluation.evaluator INFO: Inference done 2911/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/18 15:31:26] d2.evaluation.evaluator INFO: Inference done 3034/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/18 15:31:31] d2.evaluation.evaluator INFO: Inference done 3152/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/18 15:31:36] d2.evaluation.evaluator INFO: Inference done 3273/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/18 15:31:39] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.481969 (0.041599 s / iter per device, on 6 devices)
[11/18 15:31:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039645 s / iter per device, on 6 devices)
[11/18 15:31:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 15:31:40] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 15:31:41] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 15:31:42] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 15:32:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.58 seconds.
[11/18 15:32:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 15:32:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.65 seconds.
[11/18 15:32:06] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.887 | 27.039 | 12.596 | 1.496 | 5.423 | 17.145 |
[11/18 15:32:06] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 10.065 | bird          | 37.270 | hat with a wide brim | 8.984  |
| person                | 9.601  | dog           | 52.699 | lizard               | 11.383 |
| sheep                 | 13.190 | wine bottle   | 7.154  | bowl                 | 13.142 |
| airplane              | 28.014 | domestic cat  | 19.153 | car                  | 37.698 |
| porcupine             | 24.574 | bear          | 20.976 | tape player          | 7.712  |
| ray                   | 2.537  | laptop        | 9.481  | zebra                | 32.566 |
| computer keyboard     | 15.810 | pitcher       | 12.888 | artichoke            | 20.989 |
| tv or monitor         | 11.912 | table         | 11.473 | chair                | 7.034  |
| helmet                | 13.483 | traffic light | 4.976  | red panda            | 20.423 |
| sunglasses            | 3.069  | lamp          | 4.419  | bicycle              | 11.004 |
| backpack              | 9.765  | mushroom      | 5.413  | fox                  | 19.061 |
| otter                 | 8.622  | guitar        | 10.154 | microphone           | 1.334  |
| strawberry            | 7.183  | stove         | 14.174 | violin               | 1.772  |
| bookshelf             | 17.164 | sofa          | 6.414  | bell pepper          | 11.678 |
| bagel                 | 12.921 | lemon         | 9.165  | orange               | 19.076 |
| bench                 | 1.492  | piano         | 26.712 | flower pot           | 3.164  |
| butterfly             | 37.079 | purse         | 5.855  | pomegranate          | 5.389  |
| train                 | 20.954 | drum          | 2.260  | hippopotamus         | 5.729  |
| ski                   | 1.368  | ladybug       | 28.244 | banana               | 1.398  |
| monkey                | 19.895 | bus           | 28.859 | miniskirt            | 5.727  |
| camel                 | 11.086 | cream         | 17.502 | lobster              | 9.452  |
| seal                  | 3.880  | horse         | 14.318 | cart                 | 17.791 |
| elephant              | 25.618 | snake         | 14.530 | fig                  | 1.561  |
| watercraft            | 26.470 | apple         | 15.067 | antelope             | 32.041 |
| cattle                | 7.326  | whale         | 15.764 | coffee maker         | 23.798 |
| baby bed              | 24.429 | frog          | 20.872 | bathing cap          | 9.556  |
| crutch                | 0.113  | koala bear    | 22.682 | tie                  | 3.843  |
| dumbbell              | 1.076  | tiger         | 24.566 | dragonfly            | 13.675 |
| goldfish              | 12.168 | cucumber      | 2.272  | turtle               | 19.714 |
| harp                  | 9.717  | jellyfish     | 13.758 | swine                | 13.400 |
| pretzel               | 6.459  | motorcycle    | 24.747 | beaker               | 15.006 |
| rabbit                | 28.396 | nail          | 0.111  | axe                  | 6.984  |
| salt or pepper shaker | 5.926  | croquet ball  | 17.346 | skunk                | 10.479 |
| starfish              | 13.500 |               |        |                      |        |
[11/18 15:32:08] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 15:32:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 15:32:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 15:32:08] d2.evaluation.testing INFO: copypaste: 13.8870,27.0391,12.5960,1.4956,5.4235,17.1452
[11/18 15:32:08] d2.utils.events INFO:  eta: 20:03:23  iter: 4999  total_loss: 0.1742  loss_cls: 0.07173  loss_box_reg: 0.08027  loss_rpn_cls: 0.009019  loss_rpn_loc: 0.01594  time: 0.6826  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 15:32:22] d2.utils.events INFO:  eta: 20:03:14  iter: 5019  total_loss: 0.1587  loss_cls: 0.0611  loss_box_reg: 0.07411  loss_rpn_cls: 0.006481  loss_rpn_loc: 0.01591  time: 0.6827  data_time: 0.0703  lr: 0.02  max_mem: 11811M
[11/18 15:32:35] d2.utils.events INFO:  eta: 20:03:01  iter: 5039  total_loss: 0.1531  loss_cls: 0.05772  loss_box_reg: 0.07535  loss_rpn_cls: 0.007152  loss_rpn_loc: 0.0155  time: 0.6826  data_time: 0.0620  lr: 0.02  max_mem: 11811M
[11/18 15:32:49] d2.utils.events INFO:  eta: 20:02:47  iter: 5059  total_loss: 0.1536  loss_cls: 0.05809  loss_box_reg: 0.07008  loss_rpn_cls: 0.007948  loss_rpn_loc: 0.0174  time: 0.6826  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 15:33:02] d2.utils.events INFO:  eta: 20:02:43  iter: 5079  total_loss: 0.1595  loss_cls: 0.059  loss_box_reg: 0.07279  loss_rpn_cls: 0.007615  loss_rpn_loc: 0.0162  time: 0.6826  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 15:33:16] d2.utils.events INFO:  eta: 20:03:12  iter: 5099  total_loss: 0.1644  loss_cls: 0.06595  loss_box_reg: 0.07547  loss_rpn_cls: 0.008019  loss_rpn_loc: 0.01583  time: 0.6826  data_time: 0.0747  lr: 0.02  max_mem: 11811M
[11/18 15:33:30] d2.utils.events INFO:  eta: 20:02:42  iter: 5119  total_loss: 0.1636  loss_cls: 0.06358  loss_box_reg: 0.07379  loss_rpn_cls: 0.007773  loss_rpn_loc: 0.01521  time: 0.6826  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 15:33:43] d2.utils.events INFO:  eta: 20:02:53  iter: 5139  total_loss: 0.1587  loss_cls: 0.06337  loss_box_reg: 0.0733  loss_rpn_cls: 0.007568  loss_rpn_loc: 0.01489  time: 0.6826  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 15:33:57] d2.utils.events INFO:  eta: 20:02:25  iter: 5159  total_loss: 0.1493  loss_cls: 0.05931  loss_box_reg: 0.06914  loss_rpn_cls: 0.007314  loss_rpn_loc: 0.01671  time: 0.6827  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:34:11] d2.utils.events INFO:  eta: 20:02:33  iter: 5179  total_loss: 0.1598  loss_cls: 0.0624  loss_box_reg: 0.07494  loss_rpn_cls: 0.008269  loss_rpn_loc: 0.0154  time: 0.6827  data_time: 0.0722  lr: 0.02  max_mem: 11811M
[11/18 15:34:25] d2.utils.events INFO:  eta: 20:02:31  iter: 5199  total_loss: 0.1616  loss_cls: 0.06635  loss_box_reg: 0.07304  loss_rpn_cls: 0.007231  loss_rpn_loc: 0.01452  time: 0.6827  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 15:34:39] d2.utils.events INFO:  eta: 20:03:29  iter: 5219  total_loss: 0.1653  loss_cls: 0.06703  loss_box_reg: 0.07213  loss_rpn_cls: 0.007012  loss_rpn_loc: 0.01681  time: 0.6827  data_time: 0.0632  lr: 0.02  max_mem: 11811M
[11/18 15:34:52] d2.utils.events INFO:  eta: 20:02:51  iter: 5239  total_loss: 0.17  loss_cls: 0.06977  loss_box_reg: 0.07683  loss_rpn_cls: 0.008254  loss_rpn_loc: 0.01556  time: 0.6827  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 15:35:06] d2.utils.events INFO:  eta: 20:03:12  iter: 5259  total_loss: 0.1631  loss_cls: 0.06603  loss_box_reg: 0.07375  loss_rpn_cls: 0.007298  loss_rpn_loc: 0.01509  time: 0.6827  data_time: 0.0711  lr: 0.02  max_mem: 11811M
[11/18 15:35:20] d2.utils.events INFO:  eta: 20:02:58  iter: 5279  total_loss: 0.1648  loss_cls: 0.06375  loss_box_reg: 0.07265  loss_rpn_cls: 0.007781  loss_rpn_loc: 0.0171  time: 0.6827  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 15:35:33] d2.utils.events INFO:  eta: 20:02:28  iter: 5299  total_loss: 0.1682  loss_cls: 0.06745  loss_box_reg: 0.07464  loss_rpn_cls: 0.008966  loss_rpn_loc: 0.01651  time: 0.6827  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 15:35:47] d2.utils.events INFO:  eta: 20:01:38  iter: 5319  total_loss: 0.1652  loss_cls: 0.06467  loss_box_reg: 0.07649  loss_rpn_cls: 0.008043  loss_rpn_loc: 0.01544  time: 0.6827  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 15:36:00] d2.utils.events INFO:  eta: 20:02:07  iter: 5339  total_loss: 0.1607  loss_cls: 0.0668  loss_box_reg: 0.07049  loss_rpn_cls: 0.007791  loss_rpn_loc: 0.01689  time: 0.6827  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 15:36:14] d2.utils.events INFO:  eta: 20:02:08  iter: 5359  total_loss: 0.1596  loss_cls: 0.06367  loss_box_reg: 0.0741  loss_rpn_cls: 0.007261  loss_rpn_loc: 0.01553  time: 0.6827  data_time: 0.0770  lr: 0.02  max_mem: 11811M
[11/18 15:36:28] d2.utils.events INFO:  eta: 20:02:28  iter: 5379  total_loss: 0.1662  loss_cls: 0.06668  loss_box_reg: 0.07165  loss_rpn_cls: 0.007851  loss_rpn_loc: 0.0159  time: 0.6828  data_time: 0.0745  lr: 0.02  max_mem: 11811M
[11/18 15:36:42] d2.utils.events INFO:  eta: 20:02:14  iter: 5399  total_loss: 0.1611  loss_cls: 0.06578  loss_box_reg: 0.07032  loss_rpn_cls: 0.008289  loss_rpn_loc: 0.01587  time: 0.6828  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 15:36:56] d2.utils.events INFO:  eta: 20:01:55  iter: 5419  total_loss: 0.1716  loss_cls: 0.07039  loss_box_reg: 0.07439  loss_rpn_cls: 0.007565  loss_rpn_loc: 0.01603  time: 0.6828  data_time: 0.0738  lr: 0.02  max_mem: 11811M
[11/18 15:37:09] d2.utils.events INFO:  eta: 20:01:35  iter: 5439  total_loss: 0.1572  loss_cls: 0.06268  loss_box_reg: 0.06931  loss_rpn_cls: 0.007528  loss_rpn_loc: 0.01687  time: 0.6828  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 15:37:23] d2.utils.events INFO:  eta: 20:01:12  iter: 5459  total_loss: 0.1689  loss_cls: 0.06844  loss_box_reg: 0.0726  loss_rpn_cls: 0.007443  loss_rpn_loc: 0.01573  time: 0.6828  data_time: 0.0725  lr: 0.02  max_mem: 11811M
[11/18 15:37:36] d2.utils.events INFO:  eta: 20:00:42  iter: 5479  total_loss: 0.1627  loss_cls: 0.06521  loss_box_reg: 0.0711  loss_rpn_cls: 0.009498  loss_rpn_loc: 0.01679  time: 0.6828  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:37:50] d2.utils.events INFO:  eta: 20:00:28  iter: 5499  total_loss: 0.1743  loss_cls: 0.07025  loss_box_reg: 0.07513  loss_rpn_cls: 0.008412  loss_rpn_loc: 0.01687  time: 0.6828  data_time: 0.0736  lr: 0.02  max_mem: 11811M
[11/18 15:38:04] d2.utils.events INFO:  eta: 20:00:14  iter: 5519  total_loss: 0.1637  loss_cls: 0.06232  loss_box_reg: 0.07114  loss_rpn_cls: 0.008189  loss_rpn_loc: 0.01732  time: 0.6828  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 15:38:17] d2.utils.events INFO:  eta: 20:00:28  iter: 5539  total_loss: 0.1597  loss_cls: 0.06219  loss_box_reg: 0.0747  loss_rpn_cls: 0.006263  loss_rpn_loc: 0.0145  time: 0.6828  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 15:38:31] d2.utils.events INFO:  eta: 20:00:39  iter: 5559  total_loss: 0.1662  loss_cls: 0.06743  loss_box_reg: 0.07602  loss_rpn_cls: 0.007676  loss_rpn_loc: 0.01613  time: 0.6828  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 15:38:45] d2.utils.events INFO:  eta: 20:00:12  iter: 5579  total_loss: 0.1612  loss_cls: 0.06577  loss_box_reg: 0.07364  loss_rpn_cls: 0.008457  loss_rpn_loc: 0.01485  time: 0.6828  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 15:38:58] d2.utils.events INFO:  eta: 19:59:29  iter: 5599  total_loss: 0.1623  loss_cls: 0.06544  loss_box_reg: 0.07666  loss_rpn_cls: 0.006851  loss_rpn_loc: 0.01536  time: 0.6828  data_time: 0.0687  lr: 0.02  max_mem: 11811M
[11/18 15:39:12] d2.utils.events INFO:  eta: 19:58:51  iter: 5619  total_loss: 0.1576  loss_cls: 0.06396  loss_box_reg: 0.07265  loss_rpn_cls: 0.008134  loss_rpn_loc: 0.01667  time: 0.6827  data_time: 0.0604  lr: 0.02  max_mem: 11811M
[11/18 15:39:26] d2.utils.events INFO:  eta: 19:58:42  iter: 5639  total_loss: 0.16  loss_cls: 0.0637  loss_box_reg: 0.07353  loss_rpn_cls: 0.008071  loss_rpn_loc: 0.01664  time: 0.6827  data_time: 0.0670  lr: 0.02  max_mem: 11811M
[11/18 15:39:39] d2.utils.events INFO:  eta: 19:58:49  iter: 5659  total_loss: 0.1536  loss_cls: 0.0611  loss_box_reg: 0.06863  loss_rpn_cls: 0.006818  loss_rpn_loc: 0.01635  time: 0.6828  data_time: 0.0675  lr: 0.02  max_mem: 11811M
[11/18 15:39:53] d2.utils.events INFO:  eta: 19:58:28  iter: 5679  total_loss: 0.1596  loss_cls: 0.0605  loss_box_reg: 0.073  loss_rpn_cls: 0.007937  loss_rpn_loc: 0.01572  time: 0.6827  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 15:40:07] d2.utils.events INFO:  eta: 19:58:18  iter: 5699  total_loss: 0.1573  loss_cls: 0.06048  loss_box_reg: 0.07246  loss_rpn_cls: 0.006273  loss_rpn_loc: 0.01684  time: 0.6827  data_time: 0.0620  lr: 0.02  max_mem: 11811M
[11/18 15:40:20] d2.utils.events INFO:  eta: 19:57:43  iter: 5719  total_loss: 0.1604  loss_cls: 0.06312  loss_box_reg: 0.07337  loss_rpn_cls: 0.006952  loss_rpn_loc: 0.0155  time: 0.6827  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 15:40:34] d2.utils.events INFO:  eta: 19:57:26  iter: 5739  total_loss: 0.1579  loss_cls: 0.05933  loss_box_reg: 0.07011  loss_rpn_cls: 0.008533  loss_rpn_loc: 0.01672  time: 0.6827  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 15:40:47] d2.utils.events INFO:  eta: 19:57:06  iter: 5759  total_loss: 0.1621  loss_cls: 0.06224  loss_box_reg: 0.07186  loss_rpn_cls: 0.008215  loss_rpn_loc: 0.01675  time: 0.6827  data_time: 0.0630  lr: 0.02  max_mem: 11811M
[11/18 15:41:01] d2.utils.events INFO:  eta: 19:56:59  iter: 5779  total_loss: 0.1565  loss_cls: 0.06061  loss_box_reg: 0.07146  loss_rpn_cls: 0.008323  loss_rpn_loc: 0.01549  time: 0.6827  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 15:41:14] d2.utils.events INFO:  eta: 19:56:59  iter: 5799  total_loss: 0.1552  loss_cls: 0.06384  loss_box_reg: 0.07142  loss_rpn_cls: 0.006371  loss_rpn_loc: 0.0155  time: 0.6827  data_time: 0.0762  lr: 0.02  max_mem: 11811M
[11/18 15:41:28] d2.utils.events INFO:  eta: 19:57:06  iter: 5819  total_loss: 0.1657  loss_cls: 0.06516  loss_box_reg: 0.07659  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.01468  time: 0.6827  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 15:41:42] d2.utils.events INFO:  eta: 19:56:43  iter: 5839  total_loss: 0.156  loss_cls: 0.06069  loss_box_reg: 0.07108  loss_rpn_cls: 0.00692  loss_rpn_loc: 0.01407  time: 0.6827  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 15:41:55] d2.utils.events INFO:  eta: 19:56:18  iter: 5859  total_loss: 0.1588  loss_cls: 0.06226  loss_box_reg: 0.07477  loss_rpn_cls: 0.007766  loss_rpn_loc: 0.01603  time: 0.6827  data_time: 0.0631  lr: 0.02  max_mem: 11811M
[11/18 15:42:09] d2.utils.events INFO:  eta: 19:55:44  iter: 5879  total_loss: 0.1728  loss_cls: 0.06835  loss_box_reg: 0.0786  loss_rpn_cls: 0.009506  loss_rpn_loc: 0.01723  time: 0.6827  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 15:42:23] d2.utils.events INFO:  eta: 19:55:37  iter: 5899  total_loss: 0.1584  loss_cls: 0.06308  loss_box_reg: 0.07218  loss_rpn_cls: 0.007425  loss_rpn_loc: 0.01538  time: 0.6827  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 15:42:36] d2.utils.events INFO:  eta: 19:55:16  iter: 5919  total_loss: 0.1705  loss_cls: 0.0704  loss_box_reg: 0.07702  loss_rpn_cls: 0.007725  loss_rpn_loc: 0.01651  time: 0.6827  data_time: 0.0645  lr: 0.02  max_mem: 11811M
[11/18 15:42:50] d2.utils.events INFO:  eta: 19:54:29  iter: 5939  total_loss: 0.1656  loss_cls: 0.06839  loss_box_reg: 0.07275  loss_rpn_cls: 0.008051  loss_rpn_loc: 0.01657  time: 0.6827  data_time: 0.0569  lr: 0.02  max_mem: 11811M
[11/18 15:43:04] d2.utils.events INFO:  eta: 19:54:30  iter: 5959  total_loss: 0.1613  loss_cls: 0.06834  loss_box_reg: 0.07114  loss_rpn_cls: 0.007394  loss_rpn_loc: 0.01621  time: 0.6827  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 15:43:17] d2.utils.events INFO:  eta: 19:54:17  iter: 5979  total_loss: 0.1686  loss_cls: 0.06954  loss_box_reg: 0.07717  loss_rpn_cls: 0.008144  loss_rpn_loc: 0.01564  time: 0.6827  data_time: 0.0726  lr: 0.02  max_mem: 11811M
[11/18 15:43:31] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0005999.pth
[11/18 15:43:31] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 15:43:31] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 15:43:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 15:43:32] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 15:43:32] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 15:43:32] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 15:43:32] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 15:43:39] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0464 s/iter. Eval: 0.0002 s/iter. Total: 0.0477 s/iter. ETA=0:02:38
[11/18 15:43:44] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:02:15
[11/18 15:43:49] d2.evaluation.evaluator INFO: Inference done 251/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/18 15:43:54] d2.evaluation.evaluator INFO: Inference done 372/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:03
[11/18 15:43:59] d2.evaluation.evaluator INFO: Inference done 495/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:57
[11/18 15:44:04] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/18 15:44:09] d2.evaluation.evaluator INFO: Inference done 741/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/18 15:44:14] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/18 15:44:19] d2.evaluation.evaluator INFO: Inference done 980/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/18 15:44:24] d2.evaluation.evaluator INFO: Inference done 1106/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:31
[11/18 15:44:29] d2.evaluation.evaluator INFO: Inference done 1229/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/18 15:44:34] d2.evaluation.evaluator INFO: Inference done 1351/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/18 15:44:39] d2.evaluation.evaluator INFO: Inference done 1474/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/18 15:44:44] d2.evaluation.evaluator INFO: Inference done 1597/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/18 15:44:49] d2.evaluation.evaluator INFO: Inference done 1717/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/18 15:44:54] d2.evaluation.evaluator INFO: Inference done 1841/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/18 15:44:59] d2.evaluation.evaluator INFO: Inference done 1965/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/18 15:45:04] d2.evaluation.evaluator INFO: Inference done 2091/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:51
[11/18 15:45:09] d2.evaluation.evaluator INFO: Inference done 2211/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/18 15:45:14] d2.evaluation.evaluator INFO: Inference done 2332/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/18 15:45:19] d2.evaluation.evaluator INFO: Inference done 2452/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/18 15:45:24] d2.evaluation.evaluator INFO: Inference done 2570/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/18 15:45:29] d2.evaluation.evaluator INFO: Inference done 2691/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:26
[11/18 15:45:34] d2.evaluation.evaluator INFO: Inference done 2811/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:21
[11/18 15:45:39] d2.evaluation.evaluator INFO: Inference done 2931/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/18 15:45:44] d2.evaluation.evaluator INFO: Inference done 3054/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:11
[11/18 15:45:49] d2.evaluation.evaluator INFO: Inference done 3175/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/18 15:45:54] d2.evaluation.evaluator INFO: Inference done 3297/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/18 15:45:56] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.337485 (0.041255 s / iter per device, on 6 devices)
[11/18 15:45:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039335 s / iter per device, on 6 devices)
[11/18 15:45:58] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 15:45:58] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 15:45:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 15:46:00] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 15:46:23] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.10 seconds.
[11/18 15:46:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 15:46:26] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.85 seconds.
[11/18 15:46:26] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 12.798 | 25.666 | 11.302 | 1.439 | 5.029 | 15.627 |
[11/18 15:46:26] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 12.038 | bird          | 37.784 | hat with a wide brim | 8.146  |
| person                | 8.963  | dog           | 50.487 | lizard               | 9.142  |
| sheep                 | 14.734 | wine bottle   | 8.351  | bowl                 | 15.014 |
| airplane              | 24.153 | domestic cat  | 15.181 | car                  | 32.833 |
| porcupine             | 17.148 | bear          | 21.186 | tape player          | 8.712  |
| ray                   | 4.522  | laptop        | 10.055 | zebra                | 31.163 |
| computer keyboard     | 14.593 | pitcher       | 9.648  | artichoke            | 22.204 |
| tv or monitor         | 11.976 | table         | 9.902  | chair                | 6.742  |
| helmet                | 13.791 | traffic light | 4.542  | red panda            | 18.504 |
| sunglasses            | 3.036  | lamp          | 2.724  | bicycle              | 12.293 |
| backpack              | 8.631  | mushroom      | 4.465  | fox                  | 15.996 |
| otter                 | 7.819  | guitar        | 9.803  | microphone           | 0.798  |
| strawberry            | 9.308  | stove         | 13.785 | violin               | 1.883  |
| bookshelf             | 18.493 | sofa          | 8.386  | bell pepper          | 10.143 |
| bagel                 | 9.738  | lemon         | 9.618  | orange               | 13.363 |
| bench                 | 3.256  | piano         | 18.739 | flower pot           | 2.940  |
| butterfly             | 36.618 | purse         | 7.234  | pomegranate          | 4.806  |
| train                 | 21.346 | drum          | 3.730  | hippopotamus         | 5.322  |
| ski                   | 1.725  | ladybug       | 23.845 | banana               | 2.536  |
| monkey                | 16.669 | bus           | 28.918 | miniskirt            | 4.100  |
| camel                 | 7.846  | cream         | 17.772 | lobster              | 7.798  |
| seal                  | 2.800  | horse         | 11.590 | cart                 | 15.840 |
| elephant              | 24.732 | snake         | 10.393 | fig                  | 2.699  |
| watercraft            | 25.196 | apple         | 15.187 | antelope             | 26.015 |
| cattle                | 4.130  | whale         | 16.190 | coffee maker         | 28.193 |
| baby bed              | 24.036 | frog          | 16.765 | bathing cap          | 10.722 |
| crutch                | 0.489  | koala bear    | 17.805 | tie                  | 2.845  |
| dumbbell              | 1.078  | tiger         | 15.140 | dragonfly            | 12.358 |
| goldfish              | 13.962 | cucumber      | 1.873  | turtle               | 16.369 |
| harp                  | 9.279  | jellyfish     | 11.158 | swine                | 12.659 |
| pretzel               | 7.480  | motorcycle    | 23.500 | beaker               | 10.655 |
| rabbit                | 24.800 | nail          | 0.231  | axe                  | 2.766  |
| salt or pepper shaker | 3.658  | croquet ball  | 14.310 | skunk                | 11.077 |
| starfish              | 14.859 |               |        |                      |        |
[11/18 15:46:28] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 15:46:28] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 15:46:28] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 15:46:28] d2.evaluation.testing INFO: copypaste: 12.7983,25.6658,11.3021,1.4394,5.0289,15.6268
[11/18 15:46:28] d2.utils.events INFO:  eta: 19:54:22  iter: 5999  total_loss: 0.1714  loss_cls: 0.06997  loss_box_reg: 0.07926  loss_rpn_cls: 0.008808  loss_rpn_loc: 0.01634  time: 0.6827  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 15:46:41] d2.utils.events INFO:  eta: 19:53:29  iter: 6019  total_loss: 0.1629  loss_cls: 0.06141  loss_box_reg: 0.0743  loss_rpn_cls: 0.007557  loss_rpn_loc: 0.01584  time: 0.6826  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 15:46:55] d2.utils.events INFO:  eta: 19:53:54  iter: 6039  total_loss: 0.1597  loss_cls: 0.06299  loss_box_reg: 0.07268  loss_rpn_cls: 0.008217  loss_rpn_loc: 0.01593  time: 0.6827  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:47:09] d2.utils.events INFO:  eta: 19:53:32  iter: 6059  total_loss: 0.1567  loss_cls: 0.06046  loss_box_reg: 0.07171  loss_rpn_cls: 0.007192  loss_rpn_loc: 0.01603  time: 0.6827  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 15:47:22] d2.utils.events INFO:  eta: 19:53:07  iter: 6079  total_loss: 0.1568  loss_cls: 0.0607  loss_box_reg: 0.07172  loss_rpn_cls: 0.007922  loss_rpn_loc: 0.01607  time: 0.6826  data_time: 0.0697  lr: 0.02  max_mem: 11811M
[11/18 15:47:36] d2.utils.events INFO:  eta: 19:52:16  iter: 6099  total_loss: 0.158  loss_cls: 0.06081  loss_box_reg: 0.07369  loss_rpn_cls: 0.008009  loss_rpn_loc: 0.01592  time: 0.6826  data_time: 0.0595  lr: 0.02  max_mem: 11811M
[11/18 15:47:50] d2.utils.events INFO:  eta: 19:52:03  iter: 6119  total_loss: 0.156  loss_cls: 0.05909  loss_box_reg: 0.07044  loss_rpn_cls: 0.008165  loss_rpn_loc: 0.01601  time: 0.6826  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:48:03] d2.utils.events INFO:  eta: 19:51:59  iter: 6139  total_loss: 0.1521  loss_cls: 0.05907  loss_box_reg: 0.06933  loss_rpn_cls: 0.006594  loss_rpn_loc: 0.01532  time: 0.6826  data_time: 0.0630  lr: 0.02  max_mem: 11811M
[11/18 15:48:17] d2.utils.events INFO:  eta: 19:51:35  iter: 6159  total_loss: 0.1616  loss_cls: 0.06207  loss_box_reg: 0.07527  loss_rpn_cls: 0.006674  loss_rpn_loc: 0.01493  time: 0.6826  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 15:48:31] d2.utils.events INFO:  eta: 19:50:50  iter: 6179  total_loss: 0.1604  loss_cls: 0.06244  loss_box_reg: 0.07424  loss_rpn_cls: 0.006436  loss_rpn_loc: 0.01508  time: 0.6826  data_time: 0.0802  lr: 0.02  max_mem: 11811M
[11/18 15:48:44] d2.utils.events INFO:  eta: 19:50:06  iter: 6199  total_loss: 0.1616  loss_cls: 0.06203  loss_box_reg: 0.07418  loss_rpn_cls: 0.007128  loss_rpn_loc: 0.01541  time: 0.6826  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 15:48:58] d2.utils.events INFO:  eta: 19:49:52  iter: 6219  total_loss: 0.1567  loss_cls: 0.06207  loss_box_reg: 0.07256  loss_rpn_cls: 0.00728  loss_rpn_loc: 0.01575  time: 0.6826  data_time: 0.0595  lr: 0.02  max_mem: 11811M
[11/18 15:49:12] d2.utils.events INFO:  eta: 19:49:18  iter: 6239  total_loss: 0.165  loss_cls: 0.06372  loss_box_reg: 0.07463  loss_rpn_cls: 0.008135  loss_rpn_loc: 0.01608  time: 0.6826  data_time: 0.0697  lr: 0.02  max_mem: 11811M
[11/18 15:49:25] d2.utils.events INFO:  eta: 19:48:35  iter: 6259  total_loss: 0.1639  loss_cls: 0.06445  loss_box_reg: 0.07069  loss_rpn_cls: 0.007654  loss_rpn_loc: 0.01548  time: 0.6826  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 15:49:39] d2.utils.events INFO:  eta: 19:48:25  iter: 6279  total_loss: 0.1713  loss_cls: 0.0647  loss_box_reg: 0.07912  loss_rpn_cls: 0.006966  loss_rpn_loc: 0.01675  time: 0.6826  data_time: 0.0757  lr: 0.02  max_mem: 11811M
[11/18 15:49:52] d2.utils.events INFO:  eta: 19:47:54  iter: 6299  total_loss: 0.1615  loss_cls: 0.0648  loss_box_reg: 0.07657  loss_rpn_cls: 0.007544  loss_rpn_loc: 0.01517  time: 0.6826  data_time: 0.0598  lr: 0.02  max_mem: 11811M
[11/18 15:50:06] d2.utils.events INFO:  eta: 19:47:48  iter: 6319  total_loss: 0.1721  loss_cls: 0.06892  loss_box_reg: 0.07895  loss_rpn_cls: 0.009014  loss_rpn_loc: 0.01575  time: 0.6826  data_time: 0.0705  lr: 0.02  max_mem: 11811M
[11/18 15:50:20] d2.utils.events INFO:  eta: 19:47:20  iter: 6339  total_loss: 0.1761  loss_cls: 0.07377  loss_box_reg: 0.07847  loss_rpn_cls: 0.007849  loss_rpn_loc: 0.0161  time: 0.6826  data_time: 0.0701  lr: 0.02  max_mem: 11811M
[11/18 15:50:33] d2.utils.events INFO:  eta: 19:46:41  iter: 6359  total_loss: 0.1643  loss_cls: 0.06589  loss_box_reg: 0.07551  loss_rpn_cls: 0.007573  loss_rpn_loc: 0.01521  time: 0.6826  data_time: 0.0601  lr: 0.02  max_mem: 11811M
[11/18 15:50:47] d2.utils.events INFO:  eta: 19:46:01  iter: 6379  total_loss: 0.1648  loss_cls: 0.06711  loss_box_reg: 0.07592  loss_rpn_cls: 0.008628  loss_rpn_loc: 0.01628  time: 0.6826  data_time: 0.0609  lr: 0.02  max_mem: 11811M
[11/18 15:51:01] d2.utils.events INFO:  eta: 19:46:10  iter: 6399  total_loss: 0.1626  loss_cls: 0.06465  loss_box_reg: 0.07594  loss_rpn_cls: 0.007079  loss_rpn_loc: 0.0164  time: 0.6826  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 15:51:14] d2.utils.events INFO:  eta: 19:45:33  iter: 6419  total_loss: 0.1604  loss_cls: 0.06323  loss_box_reg: 0.07324  loss_rpn_cls: 0.007888  loss_rpn_loc: 0.01715  time: 0.6826  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 15:51:28] d2.utils.events INFO:  eta: 19:45:14  iter: 6439  total_loss: 0.1492  loss_cls: 0.05695  loss_box_reg: 0.06866  loss_rpn_cls: 0.008374  loss_rpn_loc: 0.01706  time: 0.6826  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 15:51:41] d2.utils.events INFO:  eta: 19:45:08  iter: 6459  total_loss: 0.163  loss_cls: 0.06443  loss_box_reg: 0.07541  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.01545  time: 0.6826  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 15:51:55] d2.utils.events INFO:  eta: 19:45:16  iter: 6479  total_loss: 0.1624  loss_cls: 0.06438  loss_box_reg: 0.0727  loss_rpn_cls: 0.007808  loss_rpn_loc: 0.0161  time: 0.6826  data_time: 0.0753  lr: 0.02  max_mem: 11811M
[11/18 15:52:09] d2.utils.events INFO:  eta: 19:44:41  iter: 6499  total_loss: 0.1602  loss_cls: 0.06545  loss_box_reg: 0.07092  loss_rpn_cls: 0.007923  loss_rpn_loc: 0.01749  time: 0.6826  data_time: 0.0712  lr: 0.02  max_mem: 11811M
[11/18 15:52:22] d2.utils.events INFO:  eta: 19:44:26  iter: 6519  total_loss: 0.1606  loss_cls: 0.06303  loss_box_reg: 0.07303  loss_rpn_cls: 0.007158  loss_rpn_loc: 0.01627  time: 0.6826  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 15:52:36] d2.utils.events INFO:  eta: 19:43:57  iter: 6539  total_loss: 0.1647  loss_cls: 0.05962  loss_box_reg: 0.07375  loss_rpn_cls: 0.006874  loss_rpn_loc: 0.01595  time: 0.6825  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 15:52:49] d2.utils.events INFO:  eta: 19:42:34  iter: 6559  total_loss: 0.156  loss_cls: 0.05994  loss_box_reg: 0.07198  loss_rpn_cls: 0.006737  loss_rpn_loc: 0.0144  time: 0.6825  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 15:53:03] d2.utils.events INFO:  eta: 19:42:30  iter: 6579  total_loss: 0.1517  loss_cls: 0.058  loss_box_reg: 0.06856  loss_rpn_cls: 0.00696  loss_rpn_loc: 0.01686  time: 0.6826  data_time: 0.0821  lr: 0.02  max_mem: 11811M
[11/18 15:53:17] d2.utils.events INFO:  eta: 19:42:35  iter: 6599  total_loss: 0.1541  loss_cls: 0.05871  loss_box_reg: 0.07301  loss_rpn_cls: 0.0069  loss_rpn_loc: 0.0144  time: 0.6826  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 15:53:31] d2.utils.events INFO:  eta: 19:43:18  iter: 6619  total_loss: 0.1595  loss_cls: 0.06264  loss_box_reg: 0.07557  loss_rpn_cls: 0.007302  loss_rpn_loc: 0.01563  time: 0.6826  data_time: 0.0728  lr: 0.02  max_mem: 11811M
[11/18 15:53:45] d2.utils.events INFO:  eta: 19:42:49  iter: 6639  total_loss: 0.1554  loss_cls: 0.06  loss_box_reg: 0.07462  loss_rpn_cls: 0.006421  loss_rpn_loc: 0.01549  time: 0.6826  data_time: 0.0650  lr: 0.02  max_mem: 11811M
[11/18 15:53:58] d2.utils.events INFO:  eta: 19:42:12  iter: 6659  total_loss: 0.1513  loss_cls: 0.05954  loss_box_reg: 0.06911  loss_rpn_cls: 0.006447  loss_rpn_loc: 0.01567  time: 0.6826  data_time: 0.0675  lr: 0.02  max_mem: 11811M
[11/18 15:54:12] d2.utils.events INFO:  eta: 19:42:22  iter: 6679  total_loss: 0.1606  loss_cls: 0.06053  loss_box_reg: 0.07452  loss_rpn_cls: 0.006191  loss_rpn_loc: 0.01575  time: 0.6826  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 15:54:25] d2.utils.events INFO:  eta: 19:42:02  iter: 6699  total_loss: 0.1476  loss_cls: 0.06047  loss_box_reg: 0.06628  loss_rpn_cls: 0.007053  loss_rpn_loc: 0.01513  time: 0.6826  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 15:54:39] d2.utils.events INFO:  eta: 19:41:55  iter: 6719  total_loss: 0.1694  loss_cls: 0.06719  loss_box_reg: 0.07662  loss_rpn_cls: 0.008015  loss_rpn_loc: 0.01604  time: 0.6826  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 15:54:53] d2.utils.events INFO:  eta: 19:41:56  iter: 6739  total_loss: 0.1629  loss_cls: 0.06446  loss_box_reg: 0.07579  loss_rpn_cls: 0.007227  loss_rpn_loc: 0.01607  time: 0.6826  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 15:55:06] d2.utils.events INFO:  eta: 19:41:55  iter: 6759  total_loss: 0.1643  loss_cls: 0.06312  loss_box_reg: 0.07755  loss_rpn_cls: 0.007322  loss_rpn_loc: 0.01471  time: 0.6826  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 15:55:20] d2.utils.events INFO:  eta: 19:41:58  iter: 6779  total_loss: 0.1645  loss_cls: 0.06469  loss_box_reg: 0.07381  loss_rpn_cls: 0.007944  loss_rpn_loc: 0.01625  time: 0.6826  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 15:55:33] d2.utils.events INFO:  eta: 19:41:17  iter: 6799  total_loss: 0.1626  loss_cls: 0.06394  loss_box_reg: 0.07385  loss_rpn_cls: 0.007827  loss_rpn_loc: 0.01549  time: 0.6825  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 15:55:47] d2.utils.events INFO:  eta: 19:41:00  iter: 6819  total_loss: 0.1598  loss_cls: 0.0637  loss_box_reg: 0.07288  loss_rpn_cls: 0.007363  loss_rpn_loc: 0.01573  time: 0.6825  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 15:56:01] d2.utils.events INFO:  eta: 19:40:47  iter: 6839  total_loss: 0.1677  loss_cls: 0.06569  loss_box_reg: 0.07441  loss_rpn_cls: 0.007644  loss_rpn_loc: 0.01618  time: 0.6825  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 15:56:14] d2.utils.events INFO:  eta: 19:40:28  iter: 6859  total_loss: 0.1564  loss_cls: 0.06505  loss_box_reg: 0.07005  loss_rpn_cls: 0.007147  loss_rpn_loc: 0.01498  time: 0.6825  data_time: 0.0620  lr: 0.02  max_mem: 11811M
[11/18 15:56:28] d2.utils.events INFO:  eta: 19:40:19  iter: 6879  total_loss: 0.1753  loss_cls: 0.06886  loss_box_reg: 0.08015  loss_rpn_cls: 0.007636  loss_rpn_loc: 0.01655  time: 0.6825  data_time: 0.0720  lr: 0.02  max_mem: 11811M
[11/18 15:56:42] d2.utils.events INFO:  eta: 19:40:06  iter: 6899  total_loss: 0.166  loss_cls: 0.06457  loss_box_reg: 0.07539  loss_rpn_cls: 0.008068  loss_rpn_loc: 0.01742  time: 0.6825  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 15:56:55] d2.utils.events INFO:  eta: 19:39:52  iter: 6919  total_loss: 0.1691  loss_cls: 0.06529  loss_box_reg: 0.0787  loss_rpn_cls: 0.008551  loss_rpn_loc: 0.01597  time: 0.6825  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 15:57:09] d2.utils.events INFO:  eta: 19:39:33  iter: 6939  total_loss: 0.1695  loss_cls: 0.06796  loss_box_reg: 0.07874  loss_rpn_cls: 0.00781  loss_rpn_loc: 0.01524  time: 0.6826  data_time: 0.0852  lr: 0.02  max_mem: 11811M
[11/18 15:57:23] d2.utils.events INFO:  eta: 19:39:02  iter: 6959  total_loss: 0.1602  loss_cls: 0.06447  loss_box_reg: 0.07084  loss_rpn_cls: 0.006899  loss_rpn_loc: 0.01465  time: 0.6826  data_time: 0.0624  lr: 0.02  max_mem: 11811M
[11/18 15:57:36] d2.utils.events INFO:  eta: 19:38:19  iter: 6979  total_loss: 0.1711  loss_cls: 0.07002  loss_box_reg: 0.07478  loss_rpn_cls: 0.008865  loss_rpn_loc: 0.01625  time: 0.6825  data_time: 0.0714  lr: 0.02  max_mem: 11811M
[11/18 15:57:50] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0006999.pth
[11/18 15:57:50] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 15:57:50] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 15:57:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 15:57:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 15:57:51] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 15:57:51] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 15:57:51] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 15:57:58] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:17
[11/18 15:58:03] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/18 15:58:08] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/18 15:58:13] d2.evaluation.evaluator INFO: Inference done 373/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:02:03
[11/18 15:58:18] d2.evaluation.evaluator INFO: Inference done 492/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0003 s/iter. Total: 0.0418 s/iter. ETA=0:01:58
[11/18 15:58:23] d2.evaluation.evaluator INFO: Inference done 615/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0416 s/iter. ETA=0:01:53
[11/18 15:58:28] d2.evaluation.evaluator INFO: Inference done 738/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/18 15:58:33] d2.evaluation.evaluator INFO: Inference done 859/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/18 15:58:38] d2.evaluation.evaluator INFO: Inference done 981/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/18 15:58:43] d2.evaluation.evaluator INFO: Inference done 1099/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:32
[11/18 15:58:48] d2.evaluation.evaluator INFO: Inference done 1220/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:27
[11/18 15:58:53] d2.evaluation.evaluator INFO: Inference done 1342/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:22
[11/18 15:58:58] d2.evaluation.evaluator INFO: Inference done 1462/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/18 15:59:03] d2.evaluation.evaluator INFO: Inference done 1581/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/18 15:59:08] d2.evaluation.evaluator INFO: Inference done 1703/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:07
[11/18 15:59:13] d2.evaluation.evaluator INFO: Inference done 1825/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/18 15:59:18] d2.evaluation.evaluator INFO: Inference done 1945/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/18 15:59:23] d2.evaluation.evaluator INFO: Inference done 2066/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/18 15:59:29] d2.evaluation.evaluator INFO: Inference done 2189/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/18 15:59:34] d2.evaluation.evaluator INFO: Inference done 2309/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:42
[11/18 15:59:39] d2.evaluation.evaluator INFO: Inference done 2431/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/18 15:59:44] d2.evaluation.evaluator INFO: Inference done 2550/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/18 15:59:49] d2.evaluation.evaluator INFO: Inference done 2672/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/18 15:59:54] d2.evaluation.evaluator INFO: Inference done 2791/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/18 15:59:59] d2.evaluation.evaluator INFO: Inference done 2914/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/18 16:00:04] d2.evaluation.evaluator INFO: Inference done 3036/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/18 16:00:09] d2.evaluation.evaluator INFO: Inference done 3157/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/18 16:00:14] d2.evaluation.evaluator INFO: Inference done 3279/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/18 16:00:16] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.185958 (0.041510 s / iter per device, on 6 devices)
[11/18 16:00:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039540 s / iter per device, on 6 devices)
[11/18 16:00:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 16:00:18] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 16:00:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 16:00:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 16:00:42] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.22 seconds.
[11/18 16:00:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 16:00:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.92 seconds.
[11/18 16:00:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.112 | 26.024 | 11.603 | 1.336 | 5.450 | 16.123 |
[11/18 16:00:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 9.626  | bird          | 35.753 | hat with a wide brim | 6.733  |
| person                | 8.320  | dog           | 51.462 | lizard               | 10.364 |
| sheep                 | 13.272 | wine bottle   | 9.733  | bowl                 | 16.471 |
| airplane              | 25.297 | domestic cat  | 17.627 | car                  | 36.850 |
| porcupine             | 18.076 | bear          | 19.011 | tape player          | 10.911 |
| ray                   | 5.186  | laptop        | 10.096 | zebra                | 30.614 |
| computer keyboard     | 10.547 | pitcher       | 14.875 | artichoke            | 24.244 |
| tv or monitor         | 11.926 | table         | 9.452  | chair                | 6.555  |
| helmet                | 12.391 | traffic light | 4.234  | red panda            | 23.098 |
| sunglasses            | 2.026  | lamp          | 3.244  | bicycle              | 11.143 |
| backpack              | 9.158  | mushroom      | 5.455  | fox                  | 20.216 |
| otter                 | 7.538  | guitar        | 8.204  | microphone           | 0.692  |
| strawberry            | 7.479  | stove         | 12.895 | violin               | 2.588  |
| bookshelf             | 12.947 | sofa          | 6.876  | bell pepper          | 12.726 |
| bagel                 | 13.998 | lemon         | 12.003 | orange               | 11.603 |
| bench                 | 2.433  | piano         | 20.876 | flower pot           | 4.106  |
| butterfly             | 37.245 | purse         | 3.342  | pomegranate          | 5.105  |
| train                 | 21.035 | drum          | 3.261  | hippopotamus         | 4.243  |
| ski                   | 1.273  | ladybug       | 29.531 | banana               | 1.561  |
| monkey                | 10.216 | bus           | 34.555 | miniskirt            | 3.962  |
| camel                 | 7.183  | cream         | 20.962 | lobster              | 9.419  |
| seal                  | 4.131  | horse         | 13.213 | cart                 | 17.370 |
| elephant              | 23.990 | snake         | 14.796 | fig                  | 1.771  |
| watercraft            | 26.950 | apple         | 19.784 | antelope             | 28.487 |
| cattle                | 3.960  | whale         | 18.625 | coffee maker         | 24.724 |
| baby bed              | 18.734 | frog          | 19.870 | bathing cap          | 9.749  |
| crutch                | 0.472  | koala bear    | 20.133 | tie                  | 2.241  |
| dumbbell              | 0.273  | tiger         | 20.303 | dragonfly            | 11.738 |
| goldfish              | 3.138  | cucumber      | 2.641  | turtle               | 17.717 |
| harp                  | 5.609  | jellyfish     | 8.673  | swine                | 11.604 |
| pretzel               | 5.402  | motorcycle    | 23.715 | beaker               | 14.102 |
| rabbit                | 28.687 | nail          | 1.195  | axe                  | 5.793  |
| salt or pepper shaker | 5.240  | croquet ball  | 16.012 | skunk                | 11.121 |
| starfish              | 15.448 |               |        |                      |        |
[11/18 16:00:47] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 16:00:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 16:00:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 16:00:47] d2.evaluation.testing INFO: copypaste: 13.1123,26.0237,11.6025,1.3361,5.4500,16.1231
[11/18 16:00:47] d2.utils.events INFO:  eta: 19:38:07  iter: 6999  total_loss: 0.1677  loss_cls: 0.06816  loss_box_reg: 0.07417  loss_rpn_cls: 0.009149  loss_rpn_loc: 0.01706  time: 0.6825  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 16:01:00] d2.utils.events INFO:  eta: 19:37:42  iter: 7019  total_loss: 0.1616  loss_cls: 0.06189  loss_box_reg: 0.07261  loss_rpn_cls: 0.008718  loss_rpn_loc: 0.01661  time: 0.6825  data_time: 0.0685  lr: 0.02  max_mem: 11811M
[11/18 16:01:14] d2.utils.events INFO:  eta: 19:36:11  iter: 7039  total_loss: 0.1647  loss_cls: 0.0631  loss_box_reg: 0.07162  loss_rpn_cls: 0.008535  loss_rpn_loc: 0.0153  time: 0.6824  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 16:01:27] d2.utils.events INFO:  eta: 19:35:36  iter: 7059  total_loss: 0.1585  loss_cls: 0.05811  loss_box_reg: 0.07145  loss_rpn_cls: 0.007952  loss_rpn_loc: 0.01706  time: 0.6824  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 16:01:41] d2.utils.events INFO:  eta: 19:35:08  iter: 7079  total_loss: 0.1614  loss_cls: 0.06212  loss_box_reg: 0.072  loss_rpn_cls: 0.00977  loss_rpn_loc: 0.01617  time: 0.6824  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 16:01:54] d2.utils.events INFO:  eta: 19:35:35  iter: 7099  total_loss: 0.1583  loss_cls: 0.06256  loss_box_reg: 0.07027  loss_rpn_cls: 0.007946  loss_rpn_loc: 0.01743  time: 0.6824  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 16:02:08] d2.utils.events INFO:  eta: 19:34:55  iter: 7119  total_loss: 0.1551  loss_cls: 0.05936  loss_box_reg: 0.07017  loss_rpn_cls: 0.007702  loss_rpn_loc: 0.01485  time: 0.6824  data_time: 0.0623  lr: 0.02  max_mem: 11811M
[11/18 16:02:22] d2.utils.events INFO:  eta: 19:34:42  iter: 7139  total_loss: 0.172  loss_cls: 0.06759  loss_box_reg: 0.07872  loss_rpn_cls: 0.008868  loss_rpn_loc: 0.01568  time: 0.6824  data_time: 0.0711  lr: 0.02  max_mem: 11811M
[11/18 16:02:35] d2.utils.events INFO:  eta: 19:34:28  iter: 7159  total_loss: 0.1656  loss_cls: 0.06621  loss_box_reg: 0.0728  loss_rpn_cls: 0.008796  loss_rpn_loc: 0.01693  time: 0.6824  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 16:02:49] d2.utils.events INFO:  eta: 19:34:40  iter: 7179  total_loss: 0.1573  loss_cls: 0.06086  loss_box_reg: 0.07114  loss_rpn_cls: 0.007827  loss_rpn_loc: 0.01554  time: 0.6824  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 16:03:02] d2.utils.events INFO:  eta: 19:33:52  iter: 7199  total_loss: 0.1574  loss_cls: 0.06196  loss_box_reg: 0.07105  loss_rpn_cls: 0.008147  loss_rpn_loc: 0.01618  time: 0.6824  data_time: 0.0723  lr: 0.02  max_mem: 11811M
[11/18 16:03:16] d2.utils.events INFO:  eta: 19:33:30  iter: 7219  total_loss: 0.154  loss_cls: 0.05978  loss_box_reg: 0.07076  loss_rpn_cls: 0.007065  loss_rpn_loc: 0.01583  time: 0.6824  data_time: 0.0747  lr: 0.02  max_mem: 11811M
[11/18 16:03:30] d2.utils.events INFO:  eta: 19:33:19  iter: 7239  total_loss: 0.1648  loss_cls: 0.06513  loss_box_reg: 0.07449  loss_rpn_cls: 0.007847  loss_rpn_loc: 0.01547  time: 0.6824  data_time: 0.0616  lr: 0.02  max_mem: 11811M
[11/18 16:03:43] d2.utils.events INFO:  eta: 19:34:13  iter: 7259  total_loss: 0.1533  loss_cls: 0.06125  loss_box_reg: 0.06859  loss_rpn_cls: 0.007103  loss_rpn_loc: 0.01698  time: 0.6824  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 16:03:57] d2.utils.events INFO:  eta: 19:33:50  iter: 7279  total_loss: 0.1561  loss_cls: 0.06236  loss_box_reg: 0.07247  loss_rpn_cls: 0.007255  loss_rpn_loc: 0.01526  time: 0.6823  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 16:04:10] d2.utils.events INFO:  eta: 19:34:08  iter: 7299  total_loss: 0.166  loss_cls: 0.065  loss_box_reg: 0.0763  loss_rpn_cls: 0.008333  loss_rpn_loc: 0.01551  time: 0.6824  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 16:04:24] d2.utils.events INFO:  eta: 19:33:59  iter: 7319  total_loss: 0.1636  loss_cls: 0.06544  loss_box_reg: 0.07355  loss_rpn_cls: 0.006687  loss_rpn_loc: 0.01689  time: 0.6824  data_time: 0.0620  lr: 0.02  max_mem: 11811M
[11/18 16:04:38] d2.utils.events INFO:  eta: 19:33:29  iter: 7339  total_loss: 0.164  loss_cls: 0.06287  loss_box_reg: 0.07434  loss_rpn_cls: 0.007416  loss_rpn_loc: 0.01457  time: 0.6823  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 16:04:51] d2.utils.events INFO:  eta: 19:33:14  iter: 7359  total_loss: 0.168  loss_cls: 0.06579  loss_box_reg: 0.07907  loss_rpn_cls: 0.006664  loss_rpn_loc: 0.01549  time: 0.6823  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 16:05:05] d2.utils.events INFO:  eta: 19:33:18  iter: 7379  total_loss: 0.172  loss_cls: 0.06707  loss_box_reg: 0.08005  loss_rpn_cls: 0.00746  loss_rpn_loc: 0.01629  time: 0.6824  data_time: 0.0768  lr: 0.02  max_mem: 11811M
[11/18 16:05:19] d2.utils.events INFO:  eta: 19:32:53  iter: 7399  total_loss: 0.1614  loss_cls: 0.06452  loss_box_reg: 0.07071  loss_rpn_cls: 0.00754  loss_rpn_loc: 0.01697  time: 0.6824  data_time: 0.0701  lr: 0.02  max_mem: 11811M
[11/18 16:05:32] d2.utils.events INFO:  eta: 19:32:40  iter: 7419  total_loss: 0.1587  loss_cls: 0.06185  loss_box_reg: 0.07243  loss_rpn_cls: 0.00851  loss_rpn_loc: 0.0162  time: 0.6824  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 16:05:46] d2.utils.events INFO:  eta: 19:32:39  iter: 7439  total_loss: 0.1703  loss_cls: 0.06807  loss_box_reg: 0.07755  loss_rpn_cls: 0.009307  loss_rpn_loc: 0.01572  time: 0.6824  data_time: 0.0719  lr: 0.02  max_mem: 11811M
[11/18 16:06:00] d2.utils.events INFO:  eta: 19:32:39  iter: 7459  total_loss: 0.1619  loss_cls: 0.0631  loss_box_reg: 0.07227  loss_rpn_cls: 0.007688  loss_rpn_loc: 0.0171  time: 0.6823  data_time: 0.0645  lr: 0.02  max_mem: 11811M
[11/18 16:06:14] d2.utils.events INFO:  eta: 19:33:14  iter: 7479  total_loss: 0.168  loss_cls: 0.06543  loss_box_reg: 0.07502  loss_rpn_cls: 0.007837  loss_rpn_loc: 0.01576  time: 0.6824  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 16:06:27] d2.utils.events INFO:  eta: 19:32:44  iter: 7499  total_loss: 0.1584  loss_cls: 0.06112  loss_box_reg: 0.07331  loss_rpn_cls: 0.008461  loss_rpn_loc: 0.01569  time: 0.6824  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 16:06:41] d2.utils.events INFO:  eta: 19:31:59  iter: 7519  total_loss: 0.1539  loss_cls: 0.05578  loss_box_reg: 0.07245  loss_rpn_cls: 0.007907  loss_rpn_loc: 0.01638  time: 0.6824  data_time: 0.0675  lr: 0.02  max_mem: 11811M
[11/18 16:06:54] d2.utils.events INFO:  eta: 19:31:45  iter: 7539  total_loss: 0.1554  loss_cls: 0.05803  loss_box_reg: 0.07266  loss_rpn_cls: 0.006885  loss_rpn_loc: 0.01586  time: 0.6823  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 16:07:08] d2.utils.events INFO:  eta: 19:32:20  iter: 7559  total_loss: 0.1652  loss_cls: 0.0626  loss_box_reg: 0.0755  loss_rpn_cls: 0.008703  loss_rpn_loc: 0.01734  time: 0.6823  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 16:07:21] d2.utils.events INFO:  eta: 19:31:34  iter: 7579  total_loss: 0.1542  loss_cls: 0.06054  loss_box_reg: 0.07427  loss_rpn_cls: 0.00717  loss_rpn_loc: 0.01461  time: 0.6823  data_time: 0.0635  lr: 0.02  max_mem: 11811M
[11/18 16:07:35] d2.utils.events INFO:  eta: 19:30:48  iter: 7599  total_loss: 0.1581  loss_cls: 0.05942  loss_box_reg: 0.07356  loss_rpn_cls: 0.007879  loss_rpn_loc: 0.0163  time: 0.6823  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 16:07:49] d2.utils.events INFO:  eta: 19:29:59  iter: 7619  total_loss: 0.1472  loss_cls: 0.05727  loss_box_reg: 0.07292  loss_rpn_cls: 0.007202  loss_rpn_loc: 0.01492  time: 0.6823  data_time: 0.0753  lr: 0.02  max_mem: 11811M
[11/18 16:08:03] d2.utils.events INFO:  eta: 19:30:23  iter: 7639  total_loss: 0.1621  loss_cls: 0.06197  loss_box_reg: 0.07481  loss_rpn_cls: 0.007229  loss_rpn_loc: 0.01643  time: 0.6824  data_time: 0.0676  lr: 0.02  max_mem: 11811M
[11/18 16:08:16] d2.utils.events INFO:  eta: 19:30:24  iter: 7659  total_loss: 0.1611  loss_cls: 0.06452  loss_box_reg: 0.07369  loss_rpn_cls: 0.007026  loss_rpn_loc: 0.0165  time: 0.6823  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 16:08:30] d2.utils.events INFO:  eta: 19:30:10  iter: 7679  total_loss: 0.153  loss_cls: 0.06293  loss_box_reg: 0.07054  loss_rpn_cls: 0.007471  loss_rpn_loc: 0.01582  time: 0.6824  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 16:08:44] d2.utils.events INFO:  eta: 19:30:31  iter: 7699  total_loss: 0.1577  loss_cls: 0.05906  loss_box_reg: 0.07597  loss_rpn_cls: 0.008343  loss_rpn_loc: 0.01526  time: 0.6824  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 16:08:57] d2.utils.events INFO:  eta: 19:30:36  iter: 7719  total_loss: 0.1595  loss_cls: 0.06011  loss_box_reg: 0.07276  loss_rpn_cls: 0.008219  loss_rpn_loc: 0.0174  time: 0.6824  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 16:09:11] d2.utils.events INFO:  eta: 19:30:04  iter: 7739  total_loss: 0.1626  loss_cls: 0.06527  loss_box_reg: 0.07394  loss_rpn_cls: 0.006551  loss_rpn_loc: 0.01485  time: 0.6824  data_time: 0.0772  lr: 0.02  max_mem: 11811M
[11/18 16:09:25] d2.utils.events INFO:  eta: 19:29:47  iter: 7759  total_loss: 0.1675  loss_cls: 0.06775  loss_box_reg: 0.07981  loss_rpn_cls: 0.00754  loss_rpn_loc: 0.0165  time: 0.6824  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 16:09:38] d2.utils.events INFO:  eta: 19:29:26  iter: 7779  total_loss: 0.162  loss_cls: 0.0615  loss_box_reg: 0.07493  loss_rpn_cls: 0.007962  loss_rpn_loc: 0.01636  time: 0.6824  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 16:09:52] d2.utils.events INFO:  eta: 19:29:29  iter: 7799  total_loss: 0.1617  loss_cls: 0.0637  loss_box_reg: 0.07395  loss_rpn_cls: 0.007174  loss_rpn_loc: 0.01473  time: 0.6824  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 16:10:06] d2.utils.events INFO:  eta: 19:29:06  iter: 7819  total_loss: 0.1546  loss_cls: 0.05921  loss_box_reg: 0.07119  loss_rpn_cls: 0.007694  loss_rpn_loc: 0.01678  time: 0.6824  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 16:10:19] d2.utils.events INFO:  eta: 19:28:45  iter: 7839  total_loss: 0.1592  loss_cls: 0.06415  loss_box_reg: 0.07497  loss_rpn_cls: 0.008028  loss_rpn_loc: 0.01527  time: 0.6824  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 16:10:33] d2.utils.events INFO:  eta: 19:28:54  iter: 7859  total_loss: 0.1589  loss_cls: 0.06198  loss_box_reg: 0.07318  loss_rpn_cls: 0.007429  loss_rpn_loc: 0.01543  time: 0.6824  data_time: 0.0714  lr: 0.02  max_mem: 11811M
[11/18 16:10:47] d2.utils.events INFO:  eta: 19:28:35  iter: 7879  total_loss: 0.1571  loss_cls: 0.06066  loss_box_reg: 0.07196  loss_rpn_cls: 0.007281  loss_rpn_loc: 0.01533  time: 0.6824  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 16:11:00] d2.utils.events INFO:  eta: 19:28:32  iter: 7899  total_loss: 0.1731  loss_cls: 0.068  loss_box_reg: 0.08155  loss_rpn_cls: 0.00861  loss_rpn_loc: 0.01835  time: 0.6824  data_time: 0.0759  lr: 0.02  max_mem: 11811M
[11/18 16:11:14] d2.utils.events INFO:  eta: 19:28:07  iter: 7919  total_loss: 0.1601  loss_cls: 0.0636  loss_box_reg: 0.07212  loss_rpn_cls: 0.008072  loss_rpn_loc: 0.01503  time: 0.6824  data_time: 0.0613  lr: 0.02  max_mem: 11811M
[11/18 16:11:28] d2.utils.events INFO:  eta: 19:27:45  iter: 7939  total_loss: 0.1614  loss_cls: 0.06776  loss_box_reg: 0.07231  loss_rpn_cls: 0.007186  loss_rpn_loc: 0.01539  time: 0.6824  data_time: 0.0690  lr: 0.02  max_mem: 11811M
[11/18 16:11:41] d2.utils.events INFO:  eta: 19:27:31  iter: 7959  total_loss: 0.1544  loss_cls: 0.0644  loss_box_reg: 0.0709  loss_rpn_cls: 0.007448  loss_rpn_loc: 0.01555  time: 0.6824  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 16:11:55] d2.utils.events INFO:  eta: 19:27:37  iter: 7979  total_loss: 0.1489  loss_cls: 0.05967  loss_box_reg: 0.06662  loss_rpn_cls: 0.006521  loss_rpn_loc: 0.01731  time: 0.6824  data_time: 0.0841  lr: 0.02  max_mem: 11811M
[11/18 16:12:09] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0007999.pth
[11/18 16:12:09] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 16:12:09] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 16:12:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 16:12:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 16:12:10] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 16:12:10] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 16:12:10] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 16:12:17] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0420 s/iter. Eval: 0.0002 s/iter. Total: 0.0435 s/iter. ETA=0:02:24
[11/18 16:12:22] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:10
[11/18 16:12:27] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:06
[11/18 16:12:32] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/18 16:12:37] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/18 16:12:42] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/18 16:12:47] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:46
[11/18 16:12:52] d2.evaluation.evaluator INFO: Inference done 869/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:41
[11/18 16:12:57] d2.evaluation.evaluator INFO: Inference done 992/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/18 16:13:02] d2.evaluation.evaluator INFO: Inference done 1112/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/18 16:13:07] d2.evaluation.evaluator INFO: Inference done 1232/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/18 16:13:12] d2.evaluation.evaluator INFO: Inference done 1355/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/18 16:13:17] d2.evaluation.evaluator INFO: Inference done 1473/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:16
[11/18 16:13:22] d2.evaluation.evaluator INFO: Inference done 1594/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:11
[11/18 16:13:27] d2.evaluation.evaluator INFO: Inference done 1715/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:06
[11/18 16:13:32] d2.evaluation.evaluator INFO: Inference done 1836/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:01
[11/18 16:13:37] d2.evaluation.evaluator INFO: Inference done 1958/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/18 16:13:42] d2.evaluation.evaluator INFO: Inference done 2080/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/18 16:13:47] d2.evaluation.evaluator INFO: Inference done 2201/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/18 16:13:52] d2.evaluation.evaluator INFO: Inference done 2322/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/18 16:13:57] d2.evaluation.evaluator INFO: Inference done 2440/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:36
[11/18 16:14:02] d2.evaluation.evaluator INFO: Inference done 2561/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:31
[11/18 16:14:07] d2.evaluation.evaluator INFO: Inference done 2684/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/18 16:14:12] d2.evaluation.evaluator INFO: Inference done 2807/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/18 16:14:17] d2.evaluation.evaluator INFO: Inference done 2931/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/18 16:14:22] d2.evaluation.evaluator INFO: Inference done 3050/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/18 16:14:27] d2.evaluation.evaluator INFO: Inference done 3172/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/18 16:14:32] d2.evaluation.evaluator INFO: Inference done 3293/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/18 16:14:34] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.894617 (0.041422 s / iter per device, on 6 devices)
[11/18 16:14:34] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039515 s / iter per device, on 6 devices)
[11/18 16:14:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 16:14:37] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 16:14:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 16:14:39] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 16:15:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.87 seconds.
[11/18 16:15:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 16:15:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.82 seconds.
[11/18 16:15:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.759 | 27.247 | 11.984 | 1.154 | 5.496 | 16.905 |
[11/18 16:15:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 13.676 | bird          | 36.905 | hat with a wide brim | 7.178  |
| person                | 7.765  | dog           | 53.475 | lizard               | 11.287 |
| sheep                 | 12.955 | wine bottle   | 11.784 | bowl                 | 16.956 |
| airplane              | 31.922 | domestic cat  | 15.626 | car                  | 37.286 |
| porcupine             | 25.435 | bear          | 20.986 | tape player          | 14.447 |
| ray                   | 5.858  | laptop        | 11.343 | zebra                | 28.929 |
| computer keyboard     | 16.077 | pitcher       | 9.464  | artichoke            | 23.780 |
| tv or monitor         | 12.226 | table         | 11.261 | chair                | 7.277  |
| helmet                | 13.374 | traffic light | 5.244  | red panda            | 24.677 |
| sunglasses            | 2.962  | lamp          | 3.341  | bicycle              | 9.283  |
| backpack              | 10.250 | mushroom      | 4.761  | fox                  | 15.962 |
| otter                 | 6.388  | guitar        | 8.323  | microphone           | 0.931  |
| strawberry            | 7.041  | stove         | 14.908 | violin               | 2.381  |
| bookshelf             | 17.268 | sofa          | 8.352  | bell pepper          | 13.728 |
| bagel                 | 11.360 | lemon         | 13.791 | orange               | 17.166 |
| bench                 | 3.009  | piano         | 22.100 | flower pot           | 2.721  |
| butterfly             | 36.887 | purse         | 6.012  | pomegranate          | 6.849  |
| train                 | 19.964 | drum          | 4.247  | hippopotamus         | 4.441  |
| ski                   | 1.969  | ladybug       | 32.148 | banana               | 3.649  |
| monkey                | 17.055 | bus           | 36.109 | miniskirt            | 5.232  |
| camel                 | 8.866  | cream         | 18.813 | lobster              | 8.142  |
| seal                  | 4.228  | horse         | 11.910 | cart                 | 15.847 |
| elephant              | 19.062 | snake         | 12.457 | fig                  | 2.624  |
| watercraft            | 27.074 | apple         | 17.800 | antelope             | 28.091 |
| cattle                | 3.922  | whale         | 15.729 | coffee maker         | 29.082 |
| baby bed              | 27.010 | frog          | 22.324 | bathing cap          | 8.567  |
| crutch                | 0.267  | koala bear    | 19.124 | tie                  | 2.254  |
| dumbbell              | 0.384  | tiger         | 19.720 | dragonfly            | 13.582 |
| goldfish              | 6.011  | cucumber      | 3.217  | turtle               | 19.293 |
| harp                  | 12.060 | jellyfish     | 12.596 | swine                | 11.291 |
| pretzel               | 6.420  | motorcycle    | 23.990 | beaker               | 11.503 |
| rabbit                | 25.509 | nail          | 0.862  | axe                  | 7.959  |
| salt or pepper shaker | 2.652  | croquet ball  | 14.109 | skunk                | 13.062 |
| starfish              | 10.734 |               |        |                      |        |
[11/18 16:15:08] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 16:15:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 16:15:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 16:15:08] d2.evaluation.testing INFO: copypaste: 13.7593,27.2474,11.9842,1.1537,5.4960,16.9055
[11/18 16:15:08] d2.utils.events INFO:  eta: 19:27:46  iter: 7999  total_loss: 0.1613  loss_cls: 0.0646  loss_box_reg: 0.07349  loss_rpn_cls: 0.007252  loss_rpn_loc: 0.01558  time: 0.6824  data_time: 0.0725  lr: 0.02  max_mem: 11811M
[11/18 16:15:21] d2.utils.events INFO:  eta: 19:27:44  iter: 8019  total_loss: 0.153  loss_cls: 0.05724  loss_box_reg: 0.07091  loss_rpn_cls: 0.00647  loss_rpn_loc: 0.01466  time: 0.6824  data_time: 0.0699  lr: 0.02  max_mem: 11811M
[11/18 16:15:35] d2.utils.events INFO:  eta: 19:27:57  iter: 8039  total_loss: 0.1631  loss_cls: 0.06027  loss_box_reg: 0.07552  loss_rpn_cls: 0.007242  loss_rpn_loc: 0.01623  time: 0.6824  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 16:15:49] d2.utils.events INFO:  eta: 19:27:44  iter: 8059  total_loss: 0.1613  loss_cls: 0.06133  loss_box_reg: 0.07631  loss_rpn_cls: 0.007206  loss_rpn_loc: 0.0159  time: 0.6824  data_time: 0.0623  lr: 0.02  max_mem: 11811M
[11/18 16:16:03] d2.utils.events INFO:  eta: 19:28:26  iter: 8079  total_loss: 0.1556  loss_cls: 0.05783  loss_box_reg: 0.07431  loss_rpn_cls: 0.006544  loss_rpn_loc: 0.01731  time: 0.6824  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 16:16:16] d2.utils.events INFO:  eta: 19:28:54  iter: 8099  total_loss: 0.1593  loss_cls: 0.06091  loss_box_reg: 0.07273  loss_rpn_cls: 0.007406  loss_rpn_loc: 0.01629  time: 0.6825  data_time: 0.0736  lr: 0.02  max_mem: 11811M
[11/18 16:16:30] d2.utils.events INFO:  eta: 19:28:50  iter: 8119  total_loss: 0.1582  loss_cls: 0.05948  loss_box_reg: 0.07478  loss_rpn_cls: 0.006533  loss_rpn_loc: 0.01793  time: 0.6825  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 16:16:44] d2.utils.events INFO:  eta: 19:28:34  iter: 8139  total_loss: 0.1506  loss_cls: 0.05773  loss_box_reg: 0.06767  loss_rpn_cls: 0.00708  loss_rpn_loc: 0.01496  time: 0.6825  data_time: 0.0783  lr: 0.02  max_mem: 11811M
[11/18 16:16:57] d2.utils.events INFO:  eta: 19:27:55  iter: 8159  total_loss: 0.1571  loss_cls: 0.06028  loss_box_reg: 0.07321  loss_rpn_cls: 0.007534  loss_rpn_loc: 0.01483  time: 0.6825  data_time: 0.0722  lr: 0.02  max_mem: 11811M
[11/18 16:17:11] d2.utils.events INFO:  eta: 19:28:05  iter: 8179  total_loss: 0.1582  loss_cls: 0.06042  loss_box_reg: 0.07358  loss_rpn_cls: 0.007512  loss_rpn_loc: 0.01581  time: 0.6825  data_time: 0.0663  lr: 0.02  max_mem: 11811M
[11/18 16:17:25] d2.utils.events INFO:  eta: 19:28:03  iter: 8199  total_loss: 0.1577  loss_cls: 0.05877  loss_box_reg: 0.07377  loss_rpn_cls: 0.007802  loss_rpn_loc: 0.01651  time: 0.6825  data_time: 0.0795  lr: 0.02  max_mem: 11811M
[11/18 16:17:39] d2.utils.events INFO:  eta: 19:27:42  iter: 8219  total_loss: 0.1547  loss_cls: 0.0601  loss_box_reg: 0.07294  loss_rpn_cls: 0.007702  loss_rpn_loc: 0.01663  time: 0.6825  data_time: 0.0687  lr: 0.02  max_mem: 11811M
[11/18 16:17:52] d2.utils.events INFO:  eta: 19:27:24  iter: 8239  total_loss: 0.1527  loss_cls: 0.05919  loss_box_reg: 0.07102  loss_rpn_cls: 0.007959  loss_rpn_loc: 0.01616  time: 0.6825  data_time: 0.0643  lr: 0.02  max_mem: 11811M
[11/18 16:18:06] d2.utils.events INFO:  eta: 19:26:44  iter: 8259  total_loss: 0.1607  loss_cls: 0.06356  loss_box_reg: 0.07675  loss_rpn_cls: 0.007328  loss_rpn_loc: 0.01663  time: 0.6825  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 16:18:19] d2.utils.events INFO:  eta: 19:26:43  iter: 8279  total_loss: 0.16  loss_cls: 0.06035  loss_box_reg: 0.07621  loss_rpn_cls: 0.007606  loss_rpn_loc: 0.01592  time: 0.6825  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 16:18:33] d2.utils.events INFO:  eta: 19:26:03  iter: 8299  total_loss: 0.1507  loss_cls: 0.059  loss_box_reg: 0.06729  loss_rpn_cls: 0.007167  loss_rpn_loc: 0.01794  time: 0.6825  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 16:18:47] d2.utils.events INFO:  eta: 19:25:28  iter: 8319  total_loss: 0.1466  loss_cls: 0.05551  loss_box_reg: 0.06789  loss_rpn_cls: 0.006863  loss_rpn_loc: 0.01604  time: 0.6825  data_time: 0.0645  lr: 0.02  max_mem: 11811M
[11/18 16:19:00] d2.utils.events INFO:  eta: 19:25:34  iter: 8339  total_loss: 0.1556  loss_cls: 0.05927  loss_box_reg: 0.07086  loss_rpn_cls: 0.007715  loss_rpn_loc: 0.01653  time: 0.6824  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 16:19:14] d2.utils.events INFO:  eta: 19:25:29  iter: 8359  total_loss: 0.1575  loss_cls: 0.05714  loss_box_reg: 0.07255  loss_rpn_cls: 0.007557  loss_rpn_loc: 0.01653  time: 0.6825  data_time: 0.0691  lr: 0.02  max_mem: 11811M
[11/18 16:19:28] d2.utils.events INFO:  eta: 19:25:09  iter: 8379  total_loss: 0.1613  loss_cls: 0.06132  loss_box_reg: 0.07571  loss_rpn_cls: 0.007681  loss_rpn_loc: 0.01535  time: 0.6825  data_time: 0.0823  lr: 0.02  max_mem: 11811M
[11/18 16:19:41] d2.utils.events INFO:  eta: 19:25:21  iter: 8399  total_loss: 0.1516  loss_cls: 0.05979  loss_box_reg: 0.07262  loss_rpn_cls: 0.007044  loss_rpn_loc: 0.01535  time: 0.6825  data_time: 0.0702  lr: 0.02  max_mem: 11811M
[11/18 16:19:55] d2.utils.events INFO:  eta: 19:25:26  iter: 8419  total_loss: 0.1582  loss_cls: 0.05981  loss_box_reg: 0.07191  loss_rpn_cls: 0.007538  loss_rpn_loc: 0.01657  time: 0.6825  data_time: 0.0719  lr: 0.02  max_mem: 11811M
[11/18 16:20:09] d2.utils.events INFO:  eta: 19:25:21  iter: 8439  total_loss: 0.1692  loss_cls: 0.06656  loss_box_reg: 0.0749  loss_rpn_cls: 0.008259  loss_rpn_loc: 0.01766  time: 0.6825  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 16:20:22] d2.utils.events INFO:  eta: 19:24:50  iter: 8459  total_loss: 0.1578  loss_cls: 0.06391  loss_box_reg: 0.06996  loss_rpn_cls: 0.007748  loss_rpn_loc: 0.01607  time: 0.6825  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 16:20:36] d2.utils.events INFO:  eta: 19:23:38  iter: 8479  total_loss: 0.1646  loss_cls: 0.06301  loss_box_reg: 0.07482  loss_rpn_cls: 0.008303  loss_rpn_loc: 0.01472  time: 0.6825  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 16:20:50] d2.utils.events INFO:  eta: 19:24:13  iter: 8499  total_loss: 0.1542  loss_cls: 0.05807  loss_box_reg: 0.07192  loss_rpn_cls: 0.006522  loss_rpn_loc: 0.01634  time: 0.6825  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 16:21:03] d2.utils.events INFO:  eta: 19:24:12  iter: 8519  total_loss: 0.1542  loss_cls: 0.059  loss_box_reg: 0.07172  loss_rpn_cls: 0.006826  loss_rpn_loc: 0.01638  time: 0.6825  data_time: 0.0616  lr: 0.02  max_mem: 11811M
[11/18 16:21:17] d2.utils.events INFO:  eta: 19:24:03  iter: 8539  total_loss: 0.1601  loss_cls: 0.06111  loss_box_reg: 0.07827  loss_rpn_cls: 0.006564  loss_rpn_loc: 0.01373  time: 0.6825  data_time: 0.0769  lr: 0.02  max_mem: 11811M
[11/18 16:21:31] d2.utils.events INFO:  eta: 19:24:35  iter: 8559  total_loss: 0.1625  loss_cls: 0.06036  loss_box_reg: 0.07362  loss_rpn_cls: 0.007247  loss_rpn_loc: 0.01754  time: 0.6825  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 16:21:45] d2.utils.events INFO:  eta: 19:24:28  iter: 8579  total_loss: 0.1567  loss_cls: 0.05851  loss_box_reg: 0.07249  loss_rpn_cls: 0.007189  loss_rpn_loc: 0.01483  time: 0.6825  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 16:21:58] d2.utils.events INFO:  eta: 19:24:22  iter: 8599  total_loss: 0.1506  loss_cls: 0.05615  loss_box_reg: 0.07333  loss_rpn_cls: 0.006863  loss_rpn_loc: 0.01621  time: 0.6825  data_time: 0.0763  lr: 0.02  max_mem: 11811M
[11/18 16:22:12] d2.utils.events INFO:  eta: 19:23:47  iter: 8619  total_loss: 0.1481  loss_cls: 0.05706  loss_box_reg: 0.06915  loss_rpn_cls: 0.007146  loss_rpn_loc: 0.01504  time: 0.6825  data_time: 0.0717  lr: 0.02  max_mem: 11811M
[11/18 16:22:25] d2.utils.events INFO:  eta: 19:22:56  iter: 8639  total_loss: 0.1492  loss_cls: 0.0567  loss_box_reg: 0.06949  loss_rpn_cls: 0.006719  loss_rpn_loc: 0.01692  time: 0.6825  data_time: 0.0600  lr: 0.02  max_mem: 11811M
[11/18 16:22:39] d2.utils.events INFO:  eta: 19:23:02  iter: 8659  total_loss: 0.1565  loss_cls: 0.06039  loss_box_reg: 0.07048  loss_rpn_cls: 0.00856  loss_rpn_loc: 0.01676  time: 0.6825  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 16:22:53] d2.utils.events INFO:  eta: 19:22:32  iter: 8679  total_loss: 0.166  loss_cls: 0.06424  loss_box_reg: 0.07734  loss_rpn_cls: 0.008313  loss_rpn_loc: 0.01729  time: 0.6825  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 16:23:06] d2.utils.events INFO:  eta: 19:22:19  iter: 8699  total_loss: 0.154  loss_cls: 0.06041  loss_box_reg: 0.07117  loss_rpn_cls: 0.006489  loss_rpn_loc: 0.01511  time: 0.6825  data_time: 0.0702  lr: 0.02  max_mem: 11811M
[11/18 16:23:20] d2.utils.events INFO:  eta: 19:21:59  iter: 8719  total_loss: 0.1561  loss_cls: 0.05897  loss_box_reg: 0.07217  loss_rpn_cls: 0.007457  loss_rpn_loc: 0.01692  time: 0.6825  data_time: 0.0725  lr: 0.02  max_mem: 11811M
[11/18 16:23:34] d2.utils.events INFO:  eta: 19:21:43  iter: 8739  total_loss: 0.1545  loss_cls: 0.05897  loss_box_reg: 0.06959  loss_rpn_cls: 0.007506  loss_rpn_loc: 0.01516  time: 0.6825  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 16:23:47] d2.utils.events INFO:  eta: 19:21:32  iter: 8759  total_loss: 0.1509  loss_cls: 0.05836  loss_box_reg: 0.06844  loss_rpn_cls: 0.006864  loss_rpn_loc: 0.01514  time: 0.6825  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 16:24:01] d2.utils.events INFO:  eta: 19:21:21  iter: 8779  total_loss: 0.1565  loss_cls: 0.05852  loss_box_reg: 0.07441  loss_rpn_cls: 0.00686  loss_rpn_loc: 0.016  time: 0.6825  data_time: 0.0619  lr: 0.02  max_mem: 11811M
[11/18 16:24:15] d2.utils.events INFO:  eta: 19:21:12  iter: 8799  total_loss: 0.163  loss_cls: 0.06292  loss_box_reg: 0.07251  loss_rpn_cls: 0.008458  loss_rpn_loc: 0.01629  time: 0.6825  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 16:24:29] d2.utils.events INFO:  eta: 19:21:31  iter: 8819  total_loss: 0.1644  loss_cls: 0.06362  loss_box_reg: 0.0717  loss_rpn_cls: 0.007613  loss_rpn_loc: 0.01691  time: 0.6825  data_time: 0.0744  lr: 0.02  max_mem: 11811M
[11/18 16:24:42] d2.utils.events INFO:  eta: 19:21:31  iter: 8839  total_loss: 0.162  loss_cls: 0.06387  loss_box_reg: 0.07515  loss_rpn_cls: 0.007191  loss_rpn_loc: 0.01485  time: 0.6825  data_time: 0.0796  lr: 0.02  max_mem: 11811M
[11/18 16:24:56] d2.utils.events INFO:  eta: 19:21:14  iter: 8859  total_loss: 0.1542  loss_cls: 0.06071  loss_box_reg: 0.0744  loss_rpn_cls: 0.006627  loss_rpn_loc: 0.01534  time: 0.6826  data_time: 0.0700  lr: 0.02  max_mem: 11811M
[11/18 16:25:10] d2.utils.events INFO:  eta: 19:21:18  iter: 8879  total_loss: 0.161  loss_cls: 0.06278  loss_box_reg: 0.07309  loss_rpn_cls: 0.007105  loss_rpn_loc: 0.01721  time: 0.6826  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 16:25:23] d2.utils.events INFO:  eta: 19:20:52  iter: 8899  total_loss: 0.1606  loss_cls: 0.06623  loss_box_reg: 0.07101  loss_rpn_cls: 0.007514  loss_rpn_loc: 0.01617  time: 0.6826  data_time: 0.0611  lr: 0.02  max_mem: 11811M
[11/18 16:25:38] d2.utils.events INFO:  eta: 19:20:50  iter: 8919  total_loss: 0.1524  loss_cls: 0.06136  loss_box_reg: 0.07256  loss_rpn_cls: 0.006223  loss_rpn_loc: 0.01376  time: 0.6826  data_time: 0.0898  lr: 0.02  max_mem: 11811M
[11/18 16:25:51] d2.utils.events INFO:  eta: 19:20:46  iter: 8939  total_loss: 0.163  loss_cls: 0.065  loss_box_reg: 0.07498  loss_rpn_cls: 0.008163  loss_rpn_loc: 0.01619  time: 0.6826  data_time: 0.0574  lr: 0.02  max_mem: 11811M
[11/18 16:26:05] d2.utils.events INFO:  eta: 19:20:39  iter: 8959  total_loss: 0.1605  loss_cls: 0.06086  loss_box_reg: 0.07377  loss_rpn_cls: 0.006693  loss_rpn_loc: 0.0158  time: 0.6826  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 16:26:18] d2.utils.events INFO:  eta: 19:20:26  iter: 8979  total_loss: 0.1708  loss_cls: 0.06533  loss_box_reg: 0.07995  loss_rpn_cls: 0.008071  loss_rpn_loc: 0.01661  time: 0.6826  data_time: 0.0650  lr: 0.02  max_mem: 11811M
[11/18 16:26:32] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0008999.pth
[11/18 16:26:33] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 16:26:33] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 16:26:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 16:26:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 16:26:33] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 16:26:33] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 16:26:33] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 16:26:40] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0378 s/iter. Eval: 0.0002 s/iter. Total: 0.0389 s/iter. ETA=0:02:09
[11/18 16:26:45] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:10
[11/18 16:26:50] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/18 16:26:55] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/18 16:27:00] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/18 16:27:05] d2.evaluation.evaluator INFO: Inference done 618/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:52
[11/18 16:27:11] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/18 16:27:16] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/18 16:27:21] d2.evaluation.evaluator INFO: Inference done 981/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/18 16:27:26] d2.evaluation.evaluator INFO: Inference done 1103/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/18 16:27:31] d2.evaluation.evaluator INFO: Inference done 1226/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:27
[11/18 16:27:36] d2.evaluation.evaluator INFO: Inference done 1348/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:22
[11/18 16:27:41] d2.evaluation.evaluator INFO: Inference done 1468/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/18 16:27:46] d2.evaluation.evaluator INFO: Inference done 1589/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/18 16:27:51] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/18 16:27:56] d2.evaluation.evaluator INFO: Inference done 1830/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/18 16:28:01] d2.evaluation.evaluator INFO: Inference done 1951/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/18 16:28:06] d2.evaluation.evaluator INFO: Inference done 2072/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/18 16:28:11] d2.evaluation.evaluator INFO: Inference done 2192/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/18 16:28:16] d2.evaluation.evaluator INFO: Inference done 2312/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 16:28:21] d2.evaluation.evaluator INFO: Inference done 2433/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/18 16:28:26] d2.evaluation.evaluator INFO: Inference done 2551/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:32
[11/18 16:28:31] d2.evaluation.evaluator INFO: Inference done 2673/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/18 16:28:36] d2.evaluation.evaluator INFO: Inference done 2795/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/18 16:28:41] d2.evaluation.evaluator INFO: Inference done 2916/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/18 16:28:46] d2.evaluation.evaluator INFO: Inference done 3035/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/18 16:28:51] d2.evaluation.evaluator INFO: Inference done 3157/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/18 16:28:56] d2.evaluation.evaluator INFO: Inference done 3279/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/18 16:28:58] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.180930 (0.041508 s / iter per device, on 6 devices)
[11/18 16:28:58] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039605 s / iter per device, on 6 devices)
[11/18 16:29:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 16:29:00] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 16:29:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 16:29:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 16:29:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.17 seconds.
[11/18 16:29:23] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 16:29:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.57 seconds.
[11/18 16:29:24] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.115 | 27.868 | 12.582 | 1.165 | 5.433 | 17.318 |
[11/18 16:29:24] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 11.386 | bird          | 40.186 | hat with a wide brim | 8.266  |
| person                | 8.059  | dog           | 51.719 | lizard               | 12.997 |
| sheep                 | 15.688 | wine bottle   | 6.827  | bowl                 | 15.169 |
| airplane              | 23.822 | domestic cat  | 16.980 | car                  | 38.507 |
| porcupine             | 22.279 | bear          | 23.248 | tape player          | 12.761 |
| ray                   | 6.641  | laptop        | 13.908 | zebra                | 29.508 |
| computer keyboard     | 13.949 | pitcher       | 12.945 | artichoke            | 22.297 |
| tv or monitor         | 13.229 | table         | 11.157 | chair                | 8.088  |
| helmet                | 14.183 | traffic light | 4.577  | red panda            | 22.673 |
| sunglasses            | 2.562  | lamp          | 4.337  | bicycle              | 11.234 |
| backpack              | 8.821  | mushroom      | 6.127  | fox                  | 17.612 |
| otter                 | 5.848  | guitar        | 12.125 | microphone           | 1.453  |
| strawberry            | 8.833  | stove         | 14.188 | violin               | 2.720  |
| bookshelf             | 16.534 | sofa          | 9.738  | bell pepper          | 11.603 |
| bagel                 | 12.287 | lemon         | 15.130 | orange               | 13.140 |
| bench                 | 2.743  | piano         | 24.559 | flower pot           | 3.591  |
| butterfly             | 34.060 | purse         | 6.416  | pomegranate          | 5.205  |
| train                 | 23.924 | drum          | 2.830  | hippopotamus         | 6.028  |
| ski                   | 1.689  | ladybug       | 26.605 | banana               | 2.593  |
| monkey                | 15.560 | bus           | 33.749 | miniskirt            | 4.313  |
| camel                 | 11.591 | cream         | 21.179 | lobster              | 10.205 |
| seal                  | 2.077  | horse         | 10.683 | cart                 | 17.385 |
| elephant              | 25.959 | snake         | 14.736 | fig                  | 4.750  |
| watercraft            | 28.370 | apple         | 16.167 | antelope             | 31.521 |
| cattle                | 6.598  | whale         | 18.918 | coffee maker         | 21.451 |
| baby bed              | 29.104 | frog          | 21.780 | bathing cap          | 10.695 |
| crutch                | 0.390  | koala bear    | 20.319 | tie                  | 1.095  |
| dumbbell              | 1.148  | tiger         | 20.839 | dragonfly            | 16.471 |
| goldfish              | 9.807  | cucumber      | 2.471  | turtle               | 20.472 |
| harp                  | 12.272 | jellyfish     | 11.608 | swine                | 11.916 |
| pretzel               | 8.716  | motorcycle    | 26.442 | beaker               | 12.925 |
| rabbit                | 29.928 | nail          | 1.158  | axe                  | 4.561  |
| salt or pepper shaker | 4.357  | croquet ball  | 13.263 | skunk                | 14.291 |
| starfish              | 14.653 |               |        |                      |        |
[11/18 16:29:26] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 16:29:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 16:29:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 16:29:26] d2.evaluation.testing INFO: copypaste: 14.1148,27.8683,12.5818,1.1648,5.4326,17.3183
[11/18 16:29:26] d2.utils.events INFO:  eta: 19:20:22  iter: 8999  total_loss: 0.1623  loss_cls: 0.06131  loss_box_reg: 0.07309  loss_rpn_cls: 0.007031  loss_rpn_loc: 0.01685  time: 0.6826  data_time: 0.0755  lr: 0.02  max_mem: 11811M
[11/18 16:29:40] d2.utils.events INFO:  eta: 19:20:22  iter: 9019  total_loss: 0.1434  loss_cls: 0.05404  loss_box_reg: 0.06979  loss_rpn_cls: 0.006291  loss_rpn_loc: 0.01487  time: 0.6826  data_time: 0.0734  lr: 0.02  max_mem: 11811M
[11/18 16:29:54] d2.utils.events INFO:  eta: 19:20:15  iter: 9039  total_loss: 0.1531  loss_cls: 0.05746  loss_box_reg: 0.07155  loss_rpn_cls: 0.006575  loss_rpn_loc: 0.01598  time: 0.6826  data_time: 0.0642  lr: 0.02  max_mem: 11811M
[11/18 16:30:08] d2.utils.events INFO:  eta: 19:20:04  iter: 9059  total_loss: 0.1731  loss_cls: 0.06602  loss_box_reg: 0.08267  loss_rpn_cls: 0.00747  loss_rpn_loc: 0.01641  time: 0.6827  data_time: 0.0727  lr: 0.02  max_mem: 11811M
[11/18 16:30:21] d2.utils.events INFO:  eta: 19:19:28  iter: 9079  total_loss: 0.1524  loss_cls: 0.05865  loss_box_reg: 0.07212  loss_rpn_cls: 0.006209  loss_rpn_loc: 0.01754  time: 0.6827  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 16:30:35] d2.utils.events INFO:  eta: 19:18:13  iter: 9099  total_loss: 0.1517  loss_cls: 0.05759  loss_box_reg: 0.06924  loss_rpn_cls: 0.007081  loss_rpn_loc: 0.0148  time: 0.6827  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 16:30:48] d2.utils.events INFO:  eta: 19:17:27  iter: 9119  total_loss: 0.1604  loss_cls: 0.05836  loss_box_reg: 0.07282  loss_rpn_cls: 0.0081  loss_rpn_loc: 0.01659  time: 0.6826  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 16:31:02] d2.utils.events INFO:  eta: 19:17:03  iter: 9139  total_loss: 0.1565  loss_cls: 0.05869  loss_box_reg: 0.07261  loss_rpn_cls: 0.006965  loss_rpn_loc: 0.01634  time: 0.6826  data_time: 0.0613  lr: 0.02  max_mem: 11811M
[11/18 16:31:16] d2.utils.events INFO:  eta: 19:16:57  iter: 9159  total_loss: 0.1639  loss_cls: 0.05884  loss_box_reg: 0.07772  loss_rpn_cls: 0.006392  loss_rpn_loc: 0.0151  time: 0.6826  data_time: 0.0700  lr: 0.02  max_mem: 11811M
[11/18 16:31:29] d2.utils.events INFO:  eta: 19:16:41  iter: 9179  total_loss: 0.155  loss_cls: 0.05994  loss_box_reg: 0.07265  loss_rpn_cls: 0.00784  loss_rpn_loc: 0.01599  time: 0.6826  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 16:31:43] d2.utils.events INFO:  eta: 19:16:31  iter: 9199  total_loss: 0.1641  loss_cls: 0.06285  loss_box_reg: 0.07677  loss_rpn_cls: 0.007479  loss_rpn_loc: 0.01788  time: 0.6826  data_time: 0.0710  lr: 0.02  max_mem: 11811M
[11/18 16:31:57] d2.utils.events INFO:  eta: 19:16:19  iter: 9219  total_loss: 0.1567  loss_cls: 0.06035  loss_box_reg: 0.07142  loss_rpn_cls: 0.007952  loss_rpn_loc: 0.0156  time: 0.6826  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 16:32:10] d2.utils.events INFO:  eta: 19:16:06  iter: 9239  total_loss: 0.1581  loss_cls: 0.06343  loss_box_reg: 0.07257  loss_rpn_cls: 0.007278  loss_rpn_loc: 0.01435  time: 0.6826  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 16:32:24] d2.utils.events INFO:  eta: 19:16:38  iter: 9259  total_loss: 0.162  loss_cls: 0.0627  loss_box_reg: 0.07425  loss_rpn_cls: 0.007442  loss_rpn_loc: 0.0177  time: 0.6827  data_time: 0.0863  lr: 0.02  max_mem: 11811M
[11/18 16:32:38] d2.utils.events INFO:  eta: 19:16:31  iter: 9279  total_loss: 0.161  loss_cls: 0.06118  loss_box_reg: 0.07441  loss_rpn_cls: 0.007631  loss_rpn_loc: 0.01592  time: 0.6827  data_time: 0.0713  lr: 0.02  max_mem: 11811M
[11/18 16:32:52] d2.utils.events INFO:  eta: 19:16:21  iter: 9299  total_loss: 0.1563  loss_cls: 0.05935  loss_box_reg: 0.07529  loss_rpn_cls: 0.007304  loss_rpn_loc: 0.01655  time: 0.6827  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 16:33:05] d2.utils.events INFO:  eta: 19:16:11  iter: 9319  total_loss: 0.1492  loss_cls: 0.05798  loss_box_reg: 0.06988  loss_rpn_cls: 0.006782  loss_rpn_loc: 0.01379  time: 0.6827  data_time: 0.0690  lr: 0.02  max_mem: 11811M
[11/18 16:33:19] d2.utils.events INFO:  eta: 19:15:52  iter: 9339  total_loss: 0.1566  loss_cls: 0.0615  loss_box_reg: 0.07187  loss_rpn_cls: 0.006599  loss_rpn_loc: 0.01585  time: 0.6827  data_time: 0.0689  lr: 0.02  max_mem: 11811M
[11/18 16:33:32] d2.utils.events INFO:  eta: 19:15:33  iter: 9359  total_loss: 0.1517  loss_cls: 0.05753  loss_box_reg: 0.07318  loss_rpn_cls: 0.006635  loss_rpn_loc: 0.01429  time: 0.6826  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 16:33:46] d2.utils.events INFO:  eta: 19:15:19  iter: 9379  total_loss: 0.1706  loss_cls: 0.06581  loss_box_reg: 0.07709  loss_rpn_cls: 0.008009  loss_rpn_loc: 0.01648  time: 0.6827  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 16:34:00] d2.utils.events INFO:  eta: 19:15:00  iter: 9399  total_loss: 0.1635  loss_cls: 0.06352  loss_box_reg: 0.07787  loss_rpn_cls: 0.007257  loss_rpn_loc: 0.01472  time: 0.6827  data_time: 0.0806  lr: 0.02  max_mem: 11811M
[11/18 16:34:13] d2.utils.events INFO:  eta: 19:14:05  iter: 9419  total_loss: 0.1607  loss_cls: 0.06294  loss_box_reg: 0.07244  loss_rpn_cls: 0.008002  loss_rpn_loc: 0.01501  time: 0.6827  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 16:34:27] d2.utils.events INFO:  eta: 19:14:10  iter: 9439  total_loss: 0.1602  loss_cls: 0.06287  loss_box_reg: 0.07312  loss_rpn_cls: 0.006984  loss_rpn_loc: 0.01593  time: 0.6827  data_time: 0.0583  lr: 0.02  max_mem: 11811M
[11/18 16:34:41] d2.utils.events INFO:  eta: 19:14:30  iter: 9459  total_loss: 0.1638  loss_cls: 0.06236  loss_box_reg: 0.07342  loss_rpn_cls: 0.007516  loss_rpn_loc: 0.0164  time: 0.6827  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 16:34:55] d2.utils.events INFO:  eta: 19:14:51  iter: 9479  total_loss: 0.1667  loss_cls: 0.06323  loss_box_reg: 0.07678  loss_rpn_cls: 0.008121  loss_rpn_loc: 0.01641  time: 0.6827  data_time: 0.0731  lr: 0.02  max_mem: 11811M
[11/18 16:35:08] d2.utils.events INFO:  eta: 19:14:03  iter: 9499  total_loss: 0.1613  loss_cls: 0.06228  loss_box_reg: 0.07666  loss_rpn_cls: 0.007374  loss_rpn_loc: 0.01506  time: 0.6827  data_time: 0.0740  lr: 0.02  max_mem: 11811M
[11/18 16:35:22] d2.utils.events INFO:  eta: 19:13:52  iter: 9519  total_loss: 0.1601  loss_cls: 0.05983  loss_box_reg: 0.07319  loss_rpn_cls: 0.007649  loss_rpn_loc: 0.01547  time: 0.6827  data_time: 0.0699  lr: 0.02  max_mem: 11811M
[11/18 16:35:36] d2.utils.events INFO:  eta: 19:13:54  iter: 9539  total_loss: 0.1532  loss_cls: 0.05693  loss_box_reg: 0.07038  loss_rpn_cls: 0.007013  loss_rpn_loc: 0.0157  time: 0.6827  data_time: 0.0629  lr: 0.02  max_mem: 11811M
[11/18 16:35:49] d2.utils.events INFO:  eta: 19:13:18  iter: 9559  total_loss: 0.1599  loss_cls: 0.05891  loss_box_reg: 0.07292  loss_rpn_cls: 0.006145  loss_rpn_loc: 0.01659  time: 0.6827  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 16:36:03] d2.utils.events INFO:  eta: 19:13:08  iter: 9579  total_loss: 0.1625  loss_cls: 0.0613  loss_box_reg: 0.07593  loss_rpn_cls: 0.007189  loss_rpn_loc: 0.01665  time: 0.6827  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 16:36:17] d2.utils.events INFO:  eta: 19:12:46  iter: 9599  total_loss: 0.1468  loss_cls: 0.05675  loss_box_reg: 0.06814  loss_rpn_cls: 0.006847  loss_rpn_loc: 0.0154  time: 0.6827  data_time: 0.0652  lr: 0.02  max_mem: 11811M
[11/18 16:36:30] d2.utils.events INFO:  eta: 19:12:37  iter: 9619  total_loss: 0.1474  loss_cls: 0.05496  loss_box_reg: 0.06912  loss_rpn_cls: 0.006842  loss_rpn_loc: 0.01594  time: 0.6827  data_time: 0.0725  lr: 0.02  max_mem: 11811M
[11/18 16:36:44] d2.utils.events INFO:  eta: 19:13:34  iter: 9639  total_loss: 0.1659  loss_cls: 0.06372  loss_box_reg: 0.07595  loss_rpn_cls: 0.007168  loss_rpn_loc: 0.01438  time: 0.6827  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 16:36:58] d2.utils.events INFO:  eta: 19:13:26  iter: 9659  total_loss: 0.1641  loss_cls: 0.06384  loss_box_reg: 0.07633  loss_rpn_cls: 0.007522  loss_rpn_loc: 0.01546  time: 0.6827  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 16:37:12] d2.utils.events INFO:  eta: 19:13:20  iter: 9679  total_loss: 0.1565  loss_cls: 0.05779  loss_box_reg: 0.07378  loss_rpn_cls: 0.006727  loss_rpn_loc: 0.01569  time: 0.6827  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 16:37:26] d2.utils.events INFO:  eta: 19:13:19  iter: 9699  total_loss: 0.1476  loss_cls: 0.05873  loss_box_reg: 0.07077  loss_rpn_cls: 0.007095  loss_rpn_loc: 0.01466  time: 0.6828  data_time: 0.0710  lr: 0.02  max_mem: 11811M
[11/18 16:37:39] d2.utils.events INFO:  eta: 19:13:05  iter: 9719  total_loss: 0.1592  loss_cls: 0.06028  loss_box_reg: 0.07498  loss_rpn_cls: 0.007836  loss_rpn_loc: 0.01587  time: 0.6827  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 16:37:53] d2.utils.events INFO:  eta: 19:12:39  iter: 9739  total_loss: 0.1561  loss_cls: 0.05828  loss_box_reg: 0.06973  loss_rpn_cls: 0.007544  loss_rpn_loc: 0.01698  time: 0.6827  data_time: 0.0616  lr: 0.02  max_mem: 11811M
[11/18 16:38:06] d2.utils.events INFO:  eta: 19:12:38  iter: 9759  total_loss: 0.1516  loss_cls: 0.06022  loss_box_reg: 0.07007  loss_rpn_cls: 0.007724  loss_rpn_loc: 0.01579  time: 0.6827  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 16:38:20] d2.utils.events INFO:  eta: 19:12:40  iter: 9779  total_loss: 0.1628  loss_cls: 0.05988  loss_box_reg: 0.07509  loss_rpn_cls: 0.008243  loss_rpn_loc: 0.01781  time: 0.6827  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 16:38:34] d2.utils.events INFO:  eta: 19:11:54  iter: 9799  total_loss: 0.1511  loss_cls: 0.05615  loss_box_reg: 0.06864  loss_rpn_cls: 0.007117  loss_rpn_loc: 0.01439  time: 0.6827  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 16:38:47] d2.utils.events INFO:  eta: 19:11:32  iter: 9819  total_loss: 0.1543  loss_cls: 0.05958  loss_box_reg: 0.07252  loss_rpn_cls: 0.007629  loss_rpn_loc: 0.01526  time: 0.6827  data_time: 0.0742  lr: 0.02  max_mem: 11811M
[11/18 16:39:01] d2.utils.events INFO:  eta: 19:11:34  iter: 9839  total_loss: 0.1635  loss_cls: 0.06154  loss_box_reg: 0.07652  loss_rpn_cls: 0.007895  loss_rpn_loc: 0.01582  time: 0.6828  data_time: 0.0607  lr: 0.02  max_mem: 11811M
[11/18 16:39:15] d2.utils.events INFO:  eta: 19:11:45  iter: 9859  total_loss: 0.1504  loss_cls: 0.05773  loss_box_reg: 0.06802  loss_rpn_cls: 0.007242  loss_rpn_loc: 0.01775  time: 0.6828  data_time: 0.0718  lr: 0.02  max_mem: 11811M
[11/18 16:39:29] d2.utils.events INFO:  eta: 19:10:59  iter: 9879  total_loss: 0.1634  loss_cls: 0.06258  loss_box_reg: 0.07398  loss_rpn_cls: 0.007791  loss_rpn_loc: 0.01634  time: 0.6828  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 16:39:42] d2.utils.events INFO:  eta: 19:10:38  iter: 9899  total_loss: 0.1639  loss_cls: 0.06133  loss_box_reg: 0.0785  loss_rpn_cls: 0.008245  loss_rpn_loc: 0.01682  time: 0.6828  data_time: 0.0764  lr: 0.02  max_mem: 11811M
[11/18 16:39:56] d2.utils.events INFO:  eta: 19:09:57  iter: 9919  total_loss: 0.1559  loss_cls: 0.05878  loss_box_reg: 0.07367  loss_rpn_cls: 0.007034  loss_rpn_loc: 0.01616  time: 0.6828  data_time: 0.0673  lr: 0.02  max_mem: 11811M
[11/18 16:40:09] d2.utils.events INFO:  eta: 19:10:15  iter: 9939  total_loss: 0.1524  loss_cls: 0.05865  loss_box_reg: 0.0711  loss_rpn_cls: 0.008182  loss_rpn_loc: 0.01483  time: 0.6828  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 16:40:23] d2.utils.events INFO:  eta: 19:10:12  iter: 9959  total_loss: 0.1586  loss_cls: 0.05977  loss_box_reg: 0.07474  loss_rpn_cls: 0.007298  loss_rpn_loc: 0.01592  time: 0.6828  data_time: 0.0639  lr: 0.02  max_mem: 11811M
[11/18 16:40:37] d2.utils.events INFO:  eta: 19:09:59  iter: 9979  total_loss: 0.1651  loss_cls: 0.06521  loss_box_reg: 0.07487  loss_rpn_cls: 0.0078  loss_rpn_loc: 0.0171  time: 0.6828  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 16:40:51] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0009999.pth
[11/18 16:40:51] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 16:40:51] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 16:40:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 16:40:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 16:40:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 16:40:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 16:40:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 16:40:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:19
[11/18 16:41:04] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:12
[11/18 16:41:09] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/18 16:41:14] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/18 16:41:19] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/18 16:41:24] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/18 16:41:29] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/18 16:41:34] d2.evaluation.evaluator INFO: Inference done 858/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/18 16:41:39] d2.evaluation.evaluator INFO: Inference done 978/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:37
[11/18 16:41:44] d2.evaluation.evaluator INFO: Inference done 1100/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/18 16:41:49] d2.evaluation.evaluator INFO: Inference done 1223/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/18 16:41:54] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/18 16:41:59] d2.evaluation.evaluator INFO: Inference done 1470/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/18 16:42:04] d2.evaluation.evaluator INFO: Inference done 1590/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/18 16:42:09] d2.evaluation.evaluator INFO: Inference done 1710/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/18 16:42:14] d2.evaluation.evaluator INFO: Inference done 1831/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/18 16:42:19] d2.evaluation.evaluator INFO: Inference done 1953/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/18 16:42:24] d2.evaluation.evaluator INFO: Inference done 2075/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/18 16:42:29] d2.evaluation.evaluator INFO: Inference done 2197/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/18 16:42:34] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/18 16:42:39] d2.evaluation.evaluator INFO: Inference done 2443/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/18 16:42:44] d2.evaluation.evaluator INFO: Inference done 2564/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:31
[11/18 16:42:49] d2.evaluation.evaluator INFO: Inference done 2686/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:26
[11/18 16:42:54] d2.evaluation.evaluator INFO: Inference done 2804/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:21
[11/18 16:42:59] d2.evaluation.evaluator INFO: Inference done 2924/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:16
[11/18 16:43:04] d2.evaluation.evaluator INFO: Inference done 3045/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:11
[11/18 16:43:10] d2.evaluation.evaluator INFO: Inference done 3166/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:06
[11/18 16:43:15] d2.evaluation.evaluator INFO: Inference done 3287/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:01
[11/18 16:43:17] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.105738 (0.041486 s / iter per device, on 6 devices)
[11/18 16:43:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039474 s / iter per device, on 6 devices)
[11/18 16:43:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 16:43:19] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 16:43:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 16:43:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 16:43:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.83 seconds.
[11/18 16:43:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 16:43:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.74 seconds.
[11/18 16:43:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.548 | 26.890 | 12.015 | 1.253 | 5.098 | 16.560 |
[11/18 16:43:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 8.994  | bird          | 38.399 | hat with a wide brim | 8.188  |
| person                | 8.292  | dog           | 51.894 | lizard               | 12.223 |
| sheep                 | 12.199 | wine bottle   | 9.604  | bowl                 | 15.442 |
| airplane              | 29.757 | domestic cat  | 18.919 | car                  | 38.582 |
| porcupine             | 20.314 | bear          | 23.554 | tape player          | 12.284 |
| ray                   | 4.928  | laptop        | 10.996 | zebra                | 28.708 |
| computer keyboard     | 11.983 | pitcher       | 12.260 | artichoke            | 25.328 |
| tv or monitor         | 13.713 | table         | 10.917 | chair                | 7.425  |
| helmet                | 13.891 | traffic light | 4.765  | red panda            | 21.774 |
| sunglasses            | 3.045  | lamp          | 4.874  | bicycle              | 9.950  |
| backpack              | 10.397 | mushroom      | 4.131  | fox                  | 15.702 |
| otter                 | 7.062  | guitar        | 14.341 | microphone           | 0.449  |
| strawberry            | 9.348  | stove         | 12.144 | violin               | 2.603  |
| bookshelf             | 18.289 | sofa          | 8.553  | bell pepper          | 11.263 |
| bagel                 | 12.510 | lemon         | 13.641 | orange               | 14.000 |
| bench                 | 3.012  | piano         | 23.797 | flower pot           | 3.921  |
| butterfly             | 37.886 | purse         | 5.315  | pomegranate          | 6.643  |
| train                 | 23.603 | drum          | 2.269  | hippopotamus         | 4.761  |
| ski                   | 2.844  | ladybug       | 26.187 | banana               | 2.306  |
| monkey                | 16.344 | bus           | 32.118 | miniskirt            | 5.015  |
| camel                 | 7.508  | cream         | 16.949 | lobster              | 10.873 |
| seal                  | 4.171  | horse         | 9.632  | cart                 | 16.548 |
| elephant              | 22.069 | snake         | 13.177 | fig                  | 3.946  |
| watercraft            | 26.812 | apple         | 16.917 | antelope             | 28.680 |
| cattle                | 5.655  | whale         | 17.230 | coffee maker         | 26.476 |
| baby bed              | 26.181 | frog          | 23.931 | bathing cap          | 8.889  |
| crutch                | 0.121  | koala bear    | 11.400 | tie                  | 2.097  |
| dumbbell              | 1.440  | tiger         | 17.197 | dragonfly            | 16.093 |
| goldfish              | 9.335  | cucumber      | 0.931  | turtle               | 17.987 |
| harp                  | 8.217  | jellyfish     | 12.531 | swine                | 10.039 |
| pretzel               | 8.514  | motorcycle    | 24.268 | beaker               | 9.974  |
| rabbit                | 24.456 | nail          | 0.292  | axe                  | 4.799  |
| salt or pepper shaker | 4.301  | croquet ball  | 16.550 | skunk                | 13.167 |
| starfish              | 11.770 |               |        |                      |        |
[11/18 16:43:47] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 16:43:47] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 16:43:47] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 16:43:47] d2.evaluation.testing INFO: copypaste: 13.5478,26.8901,12.0147,1.2526,5.0977,16.5596
[11/18 16:43:47] d2.utils.events INFO:  eta: 19:09:37  iter: 9999  total_loss: 0.1528  loss_cls: 0.05957  loss_box_reg: 0.06972  loss_rpn_cls: 0.007183  loss_rpn_loc: 0.0144  time: 0.6828  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 16:44:01] d2.utils.events INFO:  eta: 19:08:37  iter: 10019  total_loss: 0.1544  loss_cls: 0.05651  loss_box_reg: 0.07392  loss_rpn_cls: 0.007063  loss_rpn_loc: 0.01646  time: 0.6828  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 16:44:15] d2.utils.events INFO:  eta: 19:08:41  iter: 10039  total_loss: 0.1526  loss_cls: 0.05559  loss_box_reg: 0.07237  loss_rpn_cls: 0.007681  loss_rpn_loc: 0.01458  time: 0.6828  data_time: 0.0750  lr: 0.02  max_mem: 11811M
[11/18 16:44:28] d2.utils.events INFO:  eta: 19:08:15  iter: 10059  total_loss: 0.1628  loss_cls: 0.05734  loss_box_reg: 0.07633  loss_rpn_cls: 0.006987  loss_rpn_loc: 0.01524  time: 0.6828  data_time: 0.0751  lr: 0.02  max_mem: 11811M
[11/18 16:44:42] d2.utils.events INFO:  eta: 19:08:01  iter: 10079  total_loss: 0.1496  loss_cls: 0.05605  loss_box_reg: 0.06941  loss_rpn_cls: 0.007253  loss_rpn_loc: 0.01572  time: 0.6828  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 16:44:56] d2.utils.events INFO:  eta: 19:08:24  iter: 10099  total_loss: 0.1587  loss_cls: 0.06039  loss_box_reg: 0.07387  loss_rpn_cls: 0.007248  loss_rpn_loc: 0.01628  time: 0.6828  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 16:45:09] d2.utils.events INFO:  eta: 19:08:16  iter: 10119  total_loss: 0.1605  loss_cls: 0.05895  loss_box_reg: 0.07272  loss_rpn_cls: 0.006865  loss_rpn_loc: 0.01713  time: 0.6828  data_time: 0.0612  lr: 0.02  max_mem: 11811M
[11/18 16:45:23] d2.utils.events INFO:  eta: 19:08:31  iter: 10139  total_loss: 0.1547  loss_cls: 0.05701  loss_box_reg: 0.0734  loss_rpn_cls: 0.006935  loss_rpn_loc: 0.01582  time: 0.6828  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 16:45:37] d2.utils.events INFO:  eta: 19:09:10  iter: 10159  total_loss: 0.1543  loss_cls: 0.05862  loss_box_reg: 0.0734  loss_rpn_cls: 0.006752  loss_rpn_loc: 0.01625  time: 0.6828  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 16:45:50] d2.utils.events INFO:  eta: 19:08:34  iter: 10179  total_loss: 0.1507  loss_cls: 0.05822  loss_box_reg: 0.06875  loss_rpn_cls: 0.007054  loss_rpn_loc: 0.0166  time: 0.6828  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 16:46:04] d2.utils.events INFO:  eta: 19:08:43  iter: 10199  total_loss: 0.1514  loss_cls: 0.05883  loss_box_reg: 0.07225  loss_rpn_cls: 0.006237  loss_rpn_loc: 0.01531  time: 0.6828  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 16:46:18] d2.utils.events INFO:  eta: 19:08:33  iter: 10219  total_loss: 0.1467  loss_cls: 0.05512  loss_box_reg: 0.06896  loss_rpn_cls: 0.007907  loss_rpn_loc: 0.01475  time: 0.6828  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 16:46:31] d2.utils.events INFO:  eta: 19:08:16  iter: 10239  total_loss: 0.1518  loss_cls: 0.0591  loss_box_reg: 0.07239  loss_rpn_cls: 0.006636  loss_rpn_loc: 0.01556  time: 0.6828  data_time: 0.0643  lr: 0.02  max_mem: 11811M
[11/18 16:46:45] d2.utils.events INFO:  eta: 19:07:15  iter: 10259  total_loss: 0.1557  loss_cls: 0.0567  loss_box_reg: 0.07309  loss_rpn_cls: 0.008792  loss_rpn_loc: 0.01668  time: 0.6828  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 16:46:59] d2.utils.events INFO:  eta: 19:06:56  iter: 10279  total_loss: 0.1485  loss_cls: 0.05577  loss_box_reg: 0.06851  loss_rpn_cls: 0.006319  loss_rpn_loc: 0.01645  time: 0.6828  data_time: 0.0754  lr: 0.02  max_mem: 11811M
[11/18 16:47:13] d2.utils.events INFO:  eta: 19:07:12  iter: 10299  total_loss: 0.154  loss_cls: 0.05858  loss_box_reg: 0.07164  loss_rpn_cls: 0.006327  loss_rpn_loc: 0.01547  time: 0.6828  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 16:47:26] d2.utils.events INFO:  eta: 19:06:36  iter: 10319  total_loss: 0.1578  loss_cls: 0.06045  loss_box_reg: 0.07427  loss_rpn_cls: 0.006696  loss_rpn_loc: 0.01522  time: 0.6828  data_time: 0.0774  lr: 0.02  max_mem: 11811M
[11/18 16:47:40] d2.utils.events INFO:  eta: 19:07:07  iter: 10339  total_loss: 0.1533  loss_cls: 0.06111  loss_box_reg: 0.07153  loss_rpn_cls: 0.006942  loss_rpn_loc: 0.01605  time: 0.6828  data_time: 0.0619  lr: 0.02  max_mem: 11811M
[11/18 16:47:54] d2.utils.events INFO:  eta: 19:07:18  iter: 10359  total_loss: 0.1613  loss_cls: 0.06213  loss_box_reg: 0.07462  loss_rpn_cls: 0.00768  loss_rpn_loc: 0.01668  time: 0.6828  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 16:48:08] d2.utils.events INFO:  eta: 19:06:16  iter: 10379  total_loss: 0.1551  loss_cls: 0.06053  loss_box_reg: 0.07274  loss_rpn_cls: 0.007498  loss_rpn_loc: 0.01492  time: 0.6828  data_time: 0.0717  lr: 0.02  max_mem: 11811M
[11/18 16:48:21] d2.utils.events INFO:  eta: 19:06:26  iter: 10399  total_loss: 0.1504  loss_cls: 0.05941  loss_box_reg: 0.06981  loss_rpn_cls: 0.006769  loss_rpn_loc: 0.01533  time: 0.6829  data_time: 0.0816  lr: 0.02  max_mem: 11811M
[11/18 16:48:35] d2.utils.events INFO:  eta: 19:07:16  iter: 10419  total_loss: 0.155  loss_cls: 0.05906  loss_box_reg: 0.07267  loss_rpn_cls: 0.006812  loss_rpn_loc: 0.01562  time: 0.6829  data_time: 0.0741  lr: 0.02  max_mem: 11811M
[11/18 16:48:49] d2.utils.events INFO:  eta: 19:06:23  iter: 10439  total_loss: 0.1584  loss_cls: 0.06022  loss_box_reg: 0.07383  loss_rpn_cls: 0.007804  loss_rpn_loc: 0.01528  time: 0.6829  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 16:49:03] d2.utils.events INFO:  eta: 19:04:26  iter: 10459  total_loss: 0.1587  loss_cls: 0.05974  loss_box_reg: 0.07613  loss_rpn_cls: 0.007816  loss_rpn_loc: 0.01552  time: 0.6829  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 16:49:16] d2.utils.events INFO:  eta: 19:04:09  iter: 10479  total_loss: 0.1542  loss_cls: 0.05881  loss_box_reg: 0.07171  loss_rpn_cls: 0.007702  loss_rpn_loc: 0.01501  time: 0.6829  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 16:49:30] d2.utils.events INFO:  eta: 19:03:55  iter: 10499  total_loss: 0.1531  loss_cls: 0.05746  loss_box_reg: 0.07095  loss_rpn_cls: 0.0074  loss_rpn_loc: 0.0175  time: 0.6829  data_time: 0.0628  lr: 0.02  max_mem: 11811M
[11/18 16:49:43] d2.utils.events INFO:  eta: 19:03:45  iter: 10519  total_loss: 0.1573  loss_cls: 0.06033  loss_box_reg: 0.07348  loss_rpn_cls: 0.007786  loss_rpn_loc: 0.01685  time: 0.6829  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 16:49:57] d2.utils.events INFO:  eta: 19:03:47  iter: 10539  total_loss: 0.1571  loss_cls: 0.05716  loss_box_reg: 0.07308  loss_rpn_cls: 0.007246  loss_rpn_loc: 0.01585  time: 0.6829  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 16:50:11] d2.utils.events INFO:  eta: 19:03:10  iter: 10559  total_loss: 0.1693  loss_cls: 0.06076  loss_box_reg: 0.07758  loss_rpn_cls: 0.007993  loss_rpn_loc: 0.01672  time: 0.6829  data_time: 0.0669  lr: 0.02  max_mem: 11811M
[11/18 16:50:24] d2.utils.events INFO:  eta: 19:02:25  iter: 10579  total_loss: 0.1536  loss_cls: 0.05598  loss_box_reg: 0.07221  loss_rpn_cls: 0.007288  loss_rpn_loc: 0.01666  time: 0.6828  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 16:50:38] d2.utils.events INFO:  eta: 19:02:01  iter: 10599  total_loss: 0.1505  loss_cls: 0.05843  loss_box_reg: 0.07213  loss_rpn_cls: 0.006357  loss_rpn_loc: 0.01673  time: 0.6828  data_time: 0.0586  lr: 0.02  max_mem: 11811M
[11/18 16:50:51] d2.utils.events INFO:  eta: 19:01:53  iter: 10619  total_loss: 0.1484  loss_cls: 0.05744  loss_box_reg: 0.07017  loss_rpn_cls: 0.006132  loss_rpn_loc: 0.01477  time: 0.6828  data_time: 0.0597  lr: 0.02  max_mem: 11811M
[11/18 16:51:05] d2.utils.events INFO:  eta: 19:01:06  iter: 10639  total_loss: 0.1501  loss_cls: 0.05589  loss_box_reg: 0.07393  loss_rpn_cls: 0.007327  loss_rpn_loc: 0.01507  time: 0.6829  data_time: 0.0750  lr: 0.02  max_mem: 11811M
[11/18 16:51:19] d2.utils.events INFO:  eta: 19:00:35  iter: 10659  total_loss: 0.1573  loss_cls: 0.06034  loss_box_reg: 0.07618  loss_rpn_cls: 0.007011  loss_rpn_loc: 0.01551  time: 0.6829  data_time: 0.0760  lr: 0.02  max_mem: 11811M
[11/18 16:51:33] d2.utils.events INFO:  eta: 19:00:38  iter: 10679  total_loss: 0.1563  loss_cls: 0.05996  loss_box_reg: 0.07215  loss_rpn_cls: 0.006752  loss_rpn_loc: 0.01395  time: 0.6829  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 16:51:46] d2.utils.events INFO:  eta: 18:59:44  iter: 10699  total_loss: 0.1566  loss_cls: 0.05885  loss_box_reg: 0.07193  loss_rpn_cls: 0.005306  loss_rpn_loc: 0.01477  time: 0.6829  data_time: 0.0695  lr: 0.02  max_mem: 11811M
[11/18 16:52:01] d2.utils.events INFO:  eta: 19:00:11  iter: 10719  total_loss: 0.1602  loss_cls: 0.06095  loss_box_reg: 0.07662  loss_rpn_cls: 0.007731  loss_rpn_loc: 0.01606  time: 0.6829  data_time: 0.0815  lr: 0.02  max_mem: 11811M
[11/18 16:52:14] d2.utils.events INFO:  eta: 19:00:47  iter: 10739  total_loss: 0.1524  loss_cls: 0.05804  loss_box_reg: 0.07209  loss_rpn_cls: 0.007068  loss_rpn_loc: 0.01603  time: 0.6829  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 16:52:28] d2.utils.events INFO:  eta: 19:00:22  iter: 10759  total_loss: 0.1519  loss_cls: 0.05903  loss_box_reg: 0.07158  loss_rpn_cls: 0.006935  loss_rpn_loc: 0.01563  time: 0.6829  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 16:52:41] d2.utils.events INFO:  eta: 19:00:02  iter: 10779  total_loss: 0.1608  loss_cls: 0.06073  loss_box_reg: 0.07645  loss_rpn_cls: 0.00735  loss_rpn_loc: 0.01624  time: 0.6829  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 16:52:55] d2.utils.events INFO:  eta: 19:00:06  iter: 10799  total_loss: 0.1564  loss_cls: 0.05939  loss_box_reg: 0.07382  loss_rpn_cls: 0.006279  loss_rpn_loc: 0.01516  time: 0.6829  data_time: 0.0594  lr: 0.02  max_mem: 11811M
[11/18 16:53:09] d2.utils.events INFO:  eta: 18:59:51  iter: 10819  total_loss: 0.1419  loss_cls: 0.05473  loss_box_reg: 0.06575  loss_rpn_cls: 0.007122  loss_rpn_loc: 0.01628  time: 0.6829  data_time: 0.0673  lr: 0.02  max_mem: 11811M
[11/18 16:53:23] d2.utils.events INFO:  eta: 18:59:34  iter: 10839  total_loss: 0.1662  loss_cls: 0.05984  loss_box_reg: 0.07511  loss_rpn_cls: 0.008245  loss_rpn_loc: 0.01699  time: 0.6829  data_time: 0.0717  lr: 0.02  max_mem: 11811M
[11/18 16:53:36] d2.utils.events INFO:  eta: 18:58:18  iter: 10859  total_loss: 0.1479  loss_cls: 0.05756  loss_box_reg: 0.07127  loss_rpn_cls: 0.006837  loss_rpn_loc: 0.01485  time: 0.6829  data_time: 0.0672  lr: 0.02  max_mem: 11811M
[11/18 16:53:50] d2.utils.events INFO:  eta: 18:58:40  iter: 10879  total_loss: 0.1577  loss_cls: 0.06197  loss_box_reg: 0.07309  loss_rpn_cls: 0.006864  loss_rpn_loc: 0.01653  time: 0.6829  data_time: 0.0663  lr: 0.02  max_mem: 11811M
[11/18 16:54:04] d2.utils.events INFO:  eta: 18:58:56  iter: 10899  total_loss: 0.1536  loss_cls: 0.05915  loss_box_reg: 0.07116  loss_rpn_cls: 0.007179  loss_rpn_loc: 0.0174  time: 0.6829  data_time: 0.0722  lr: 0.02  max_mem: 11811M
[11/18 16:54:17] d2.utils.events INFO:  eta: 18:58:33  iter: 10919  total_loss: 0.1625  loss_cls: 0.06153  loss_box_reg: 0.07452  loss_rpn_cls: 0.007664  loss_rpn_loc: 0.01701  time: 0.6829  data_time: 0.0703  lr: 0.02  max_mem: 11811M
[11/18 16:54:31] d2.utils.events INFO:  eta: 18:58:12  iter: 10939  total_loss: 0.1616  loss_cls: 0.06338  loss_box_reg: 0.0752  loss_rpn_cls: 0.008207  loss_rpn_loc: 0.01501  time: 0.6829  data_time: 0.0768  lr: 0.02  max_mem: 11811M
[11/18 16:54:45] d2.utils.events INFO:  eta: 18:57:11  iter: 10959  total_loss: 0.1634  loss_cls: 0.06146  loss_box_reg: 0.07501  loss_rpn_cls: 0.007784  loss_rpn_loc: 0.01678  time: 0.6830  data_time: 0.1036  lr: 0.02  max_mem: 11811M
[11/18 16:54:59] d2.utils.events INFO:  eta: 18:57:08  iter: 10979  total_loss: 0.1584  loss_cls: 0.06173  loss_box_reg: 0.0747  loss_rpn_cls: 0.007938  loss_rpn_loc: 0.01635  time: 0.6830  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 16:55:12] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0010999.pth
[11/18 16:55:13] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 16:55:13] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 16:55:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 16:55:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 16:55:13] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 16:55:13] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 16:55:13] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 16:55:20] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:14
[11/18 16:55:25] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0014 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/18 16:55:30] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/18 16:55:35] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/18 16:55:40] d2.evaluation.evaluator INFO: Inference done 502/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/18 16:55:45] d2.evaluation.evaluator INFO: Inference done 624/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:50
[11/18 16:55:50] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/18 16:55:55] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:41
[11/18 16:56:00] d2.evaluation.evaluator INFO: Inference done 986/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:36
[11/18 16:56:06] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/18 16:56:11] d2.evaluation.evaluator INFO: Inference done 1231/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/18 16:56:16] d2.evaluation.evaluator INFO: Inference done 1349/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:21
[11/18 16:56:21] d2.evaluation.evaluator INFO: Inference done 1472/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/18 16:56:26] d2.evaluation.evaluator INFO: Inference done 1592/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:11
[11/18 16:56:31] d2.evaluation.evaluator INFO: Inference done 1711/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/18 16:56:36] d2.evaluation.evaluator INFO: Inference done 1834/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:01
[11/18 16:56:41] d2.evaluation.evaluator INFO: Inference done 1954/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:57
[11/18 16:56:46] d2.evaluation.evaluator INFO: Inference done 2075/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:52
[11/18 16:56:51] d2.evaluation.evaluator INFO: Inference done 2196/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/18 16:56:56] d2.evaluation.evaluator INFO: Inference done 2317/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 16:57:01] d2.evaluation.evaluator INFO: Inference done 2435/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/18 16:57:06] d2.evaluation.evaluator INFO: Inference done 2554/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/18 16:57:11] d2.evaluation.evaluator INFO: Inference done 2673/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/18 16:57:16] d2.evaluation.evaluator INFO: Inference done 2795/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/18 16:57:21] d2.evaluation.evaluator INFO: Inference done 2917/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/18 16:57:26] d2.evaluation.evaluator INFO: Inference done 3039/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/18 16:57:31] d2.evaluation.evaluator INFO: Inference done 3161/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/18 16:57:36] d2.evaluation.evaluator INFO: Inference done 3281/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:02
[11/18 16:57:38] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.176920 (0.041507 s / iter per device, on 6 devices)
[11/18 16:57:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039479 s / iter per device, on 6 devices)
[11/18 16:57:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 16:57:40] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 16:57:41] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 16:57:41] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 16:58:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.39 seconds.
[11/18 16:58:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 16:58:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.80 seconds.
[11/18 16:58:07] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.974 | 28.688 | 13.683 | 1.512 | 5.320 | 18.002 |
[11/18 16:58:07] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 13.724 | bird          | 40.341 | hat with a wide brim | 8.939  |
| person                | 8.146  | dog           | 51.794 | lizard               | 14.278 |
| sheep                 | 14.655 | wine bottle   | 9.421  | bowl                 | 17.171 |
| airplane              | 33.143 | domestic cat  | 18.883 | car                  | 39.829 |
| porcupine             | 17.635 | bear          | 19.607 | tape player          | 14.197 |
| ray                   | 6.039  | laptop        | 14.381 | zebra                | 34.415 |
| computer keyboard     | 15.087 | pitcher       | 14.148 | artichoke            | 25.783 |
| tv or monitor         | 13.334 | table         | 11.877 | chair                | 8.276  |
| helmet                | 16.425 | traffic light | 2.436  | red panda            | 26.892 |
| sunglasses            | 2.117  | lamp          | 3.887  | bicycle              | 11.721 |
| backpack              | 10.467 | mushroom      | 6.530  | fox                  | 20.598 |
| otter                 | 8.103  | guitar        | 12.217 | microphone           | 1.373  |
| strawberry            | 10.687 | stove         | 10.773 | violin               | 2.572  |
| bookshelf             | 17.681 | sofa          | 11.922 | bell pepper          | 16.031 |
| bagel                 | 13.789 | lemon         | 14.546 | orange               | 16.702 |
| bench                 | 2.453  | piano         | 23.443 | flower pot           | 4.302  |
| butterfly             | 37.831 | purse         | 5.617  | pomegranate          | 6.677  |
| train                 | 24.551 | drum          | 2.826  | hippopotamus         | 4.769  |
| ski                   | 1.041  | ladybug       | 29.320 | banana               | 3.714  |
| monkey                | 17.750 | bus           | 35.382 | miniskirt            | 5.208  |
| camel                 | 11.011 | cream         | 18.854 | lobster              | 11.474 |
| seal                  | 5.144  | horse         | 12.677 | cart                 | 16.410 |
| elephant              | 25.822 | snake         | 14.259 | fig                  | 3.392  |
| watercraft            | 29.680 | apple         | 16.799 | antelope             | 36.815 |
| cattle                | 6.991  | whale         | 16.883 | coffee maker         | 31.594 |
| baby bed              | 25.936 | frog          | 20.940 | bathing cap          | 9.243  |
| crutch                | 0.621  | koala bear    | 22.861 | tie                  | 3.360  |
| dumbbell              | 1.217  | tiger         | 16.367 | dragonfly            | 13.582 |
| goldfish              | 9.924  | cucumber      | 3.153  | turtle               | 21.542 |
| harp                  | 15.138 | jellyfish     | 15.929 | swine                | 16.323 |
| pretzel               | 8.001  | motorcycle    | 24.836 | beaker               | 13.506 |
| rabbit                | 30.816 | nail          | 0.225  | axe                  | 7.963  |
| salt or pepper shaker | 4.277  | croquet ball  | 16.159 | skunk                | 13.478 |
| starfish              | 16.782 |               |        |                      |        |
[11/18 16:58:09] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 16:58:09] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 16:58:09] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 16:58:09] d2.evaluation.testing INFO: copypaste: 14.9744,28.6885,13.6826,1.5123,5.3201,18.0022
[11/18 16:58:09] d2.utils.events INFO:  eta: 18:56:32  iter: 10999  total_loss: 0.1535  loss_cls: 0.0583  loss_box_reg: 0.07157  loss_rpn_cls: 0.008236  loss_rpn_loc: 0.01669  time: 0.6830  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 16:58:23] d2.utils.events INFO:  eta: 18:56:43  iter: 11019  total_loss: 0.1526  loss_cls: 0.05772  loss_box_reg: 0.0737  loss_rpn_cls: 0.006512  loss_rpn_loc: 0.01565  time: 0.6830  data_time: 0.0671  lr: 0.02  max_mem: 11811M
[11/18 16:58:37] d2.utils.events INFO:  eta: 18:56:16  iter: 11039  total_loss: 0.1585  loss_cls: 0.05807  loss_box_reg: 0.07505  loss_rpn_cls: 0.007052  loss_rpn_loc: 0.01594  time: 0.6830  data_time: 0.0697  lr: 0.02  max_mem: 11811M
[11/18 16:58:50] d2.utils.events INFO:  eta: 18:55:51  iter: 11059  total_loss: 0.1524  loss_cls: 0.05635  loss_box_reg: 0.07361  loss_rpn_cls: 0.007471  loss_rpn_loc: 0.01563  time: 0.6829  data_time: 0.0695  lr: 0.02  max_mem: 11811M
[11/18 16:59:04] d2.utils.events INFO:  eta: 18:55:38  iter: 11079  total_loss: 0.1574  loss_cls: 0.06007  loss_box_reg: 0.0734  loss_rpn_cls: 0.006159  loss_rpn_loc: 0.01737  time: 0.6829  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 16:59:17] d2.utils.events INFO:  eta: 18:54:49  iter: 11099  total_loss: 0.1472  loss_cls: 0.05428  loss_box_reg: 0.06969  loss_rpn_cls: 0.006089  loss_rpn_loc: 0.01604  time: 0.6829  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 16:59:31] d2.utils.events INFO:  eta: 18:54:45  iter: 11119  total_loss: 0.1592  loss_cls: 0.05852  loss_box_reg: 0.07646  loss_rpn_cls: 0.007944  loss_rpn_loc: 0.01628  time: 0.6829  data_time: 0.0653  lr: 0.02  max_mem: 11811M
[11/18 16:59:45] d2.utils.events INFO:  eta: 18:54:31  iter: 11139  total_loss: 0.1571  loss_cls: 0.0592  loss_box_reg: 0.07546  loss_rpn_cls: 0.006331  loss_rpn_loc: 0.01571  time: 0.6829  data_time: 0.0739  lr: 0.02  max_mem: 11811M
[11/18 16:59:58] d2.utils.events INFO:  eta: 18:54:08  iter: 11159  total_loss: 0.1465  loss_cls: 0.05445  loss_box_reg: 0.06891  loss_rpn_cls: 0.006429  loss_rpn_loc: 0.01423  time: 0.6829  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 17:00:12] d2.utils.events INFO:  eta: 18:53:45  iter: 11179  total_loss: 0.149  loss_cls: 0.05282  loss_box_reg: 0.07011  loss_rpn_cls: 0.006391  loss_rpn_loc: 0.01623  time: 0.6829  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 17:00:26] d2.utils.events INFO:  eta: 18:53:32  iter: 11199  total_loss: 0.1573  loss_cls: 0.0592  loss_box_reg: 0.07332  loss_rpn_cls: 0.006913  loss_rpn_loc: 0.01575  time: 0.6829  data_time: 0.0652  lr: 0.02  max_mem: 11811M
[11/18 17:00:39] d2.utils.events INFO:  eta: 18:53:07  iter: 11219  total_loss: 0.1526  loss_cls: 0.05925  loss_box_reg: 0.07252  loss_rpn_cls: 0.008244  loss_rpn_loc: 0.01736  time: 0.6829  data_time: 0.0627  lr: 0.02  max_mem: 11811M
[11/18 17:00:53] d2.utils.events INFO:  eta: 18:52:45  iter: 11239  total_loss: 0.1451  loss_cls: 0.05404  loss_box_reg: 0.06976  loss_rpn_cls: 0.006097  loss_rpn_loc: 0.01517  time: 0.6829  data_time: 0.0677  lr: 0.02  max_mem: 11811M
[11/18 17:01:06] d2.utils.events INFO:  eta: 18:52:22  iter: 11259  total_loss: 0.1454  loss_cls: 0.0536  loss_box_reg: 0.06968  loss_rpn_cls: 0.006741  loss_rpn_loc: 0.01703  time: 0.6829  data_time: 0.0702  lr: 0.02  max_mem: 11811M
[11/18 17:01:20] d2.utils.events INFO:  eta: 18:52:10  iter: 11279  total_loss: 0.1501  loss_cls: 0.05794  loss_box_reg: 0.071  loss_rpn_cls: 0.007093  loss_rpn_loc: 0.01574  time: 0.6829  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 17:01:34] d2.utils.events INFO:  eta: 18:52:04  iter: 11299  total_loss: 0.1527  loss_cls: 0.0568  loss_box_reg: 0.07324  loss_rpn_cls: 0.006875  loss_rpn_loc: 0.01526  time: 0.6829  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 17:01:47] d2.utils.events INFO:  eta: 18:51:51  iter: 11319  total_loss: 0.1517  loss_cls: 0.05965  loss_box_reg: 0.0707  loss_rpn_cls: 0.00687  loss_rpn_loc: 0.01498  time: 0.6829  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 17:02:01] d2.utils.events INFO:  eta: 18:51:33  iter: 11339  total_loss: 0.1535  loss_cls: 0.05864  loss_box_reg: 0.07306  loss_rpn_cls: 0.007157  loss_rpn_loc: 0.01474  time: 0.6829  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 17:02:15] d2.utils.events INFO:  eta: 18:51:14  iter: 11359  total_loss: 0.145  loss_cls: 0.05479  loss_box_reg: 0.06893  loss_rpn_cls: 0.006894  loss_rpn_loc: 0.01557  time: 0.6829  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 17:02:28] d2.utils.events INFO:  eta: 18:51:06  iter: 11379  total_loss: 0.144  loss_cls: 0.05678  loss_box_reg: 0.06524  loss_rpn_cls: 0.006845  loss_rpn_loc: 0.0151  time: 0.6829  data_time: 0.0703  lr: 0.02  max_mem: 11811M
[11/18 17:02:42] d2.utils.events INFO:  eta: 18:50:49  iter: 11399  total_loss: 0.153  loss_cls: 0.05854  loss_box_reg: 0.0726  loss_rpn_cls: 0.006862  loss_rpn_loc: 0.01509  time: 0.6829  data_time: 0.0708  lr: 0.02  max_mem: 11811M
[11/18 17:02:56] d2.utils.events INFO:  eta: 18:50:33  iter: 11419  total_loss: 0.1527  loss_cls: 0.05764  loss_box_reg: 0.06988  loss_rpn_cls: 0.006869  loss_rpn_loc: 0.01652  time: 0.6829  data_time: 0.0627  lr: 0.02  max_mem: 11811M
[11/18 17:03:10] d2.utils.events INFO:  eta: 18:50:36  iter: 11439  total_loss: 0.1598  loss_cls: 0.05983  loss_box_reg: 0.07307  loss_rpn_cls: 0.007735  loss_rpn_loc: 0.01686  time: 0.6829  data_time: 0.0706  lr: 0.02  max_mem: 11811M
[11/18 17:03:23] d2.utils.events INFO:  eta: 18:50:30  iter: 11459  total_loss: 0.167  loss_cls: 0.06709  loss_box_reg: 0.07566  loss_rpn_cls: 0.008006  loss_rpn_loc: 0.01591  time: 0.6829  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 17:03:37] d2.utils.events INFO:  eta: 18:50:02  iter: 11479  total_loss: 0.159  loss_cls: 0.06212  loss_box_reg: 0.07461  loss_rpn_cls: 0.006844  loss_rpn_loc: 0.01525  time: 0.6829  data_time: 0.0692  lr: 0.02  max_mem: 11811M
[11/18 17:03:51] d2.utils.events INFO:  eta: 18:50:10  iter: 11499  total_loss: 0.1543  loss_cls: 0.06128  loss_box_reg: 0.07168  loss_rpn_cls: 0.007309  loss_rpn_loc: 0.01594  time: 0.6829  data_time: 0.0707  lr: 0.02  max_mem: 11811M
[11/18 17:04:04] d2.utils.events INFO:  eta: 18:49:56  iter: 11519  total_loss: 0.1571  loss_cls: 0.05671  loss_box_reg: 0.07249  loss_rpn_cls: 0.006529  loss_rpn_loc: 0.01584  time: 0.6829  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 17:04:18] d2.utils.events INFO:  eta: 18:49:17  iter: 11539  total_loss: 0.1582  loss_cls: 0.05785  loss_box_reg: 0.07192  loss_rpn_cls: 0.008207  loss_rpn_loc: 0.01604  time: 0.6829  data_time: 0.0757  lr: 0.02  max_mem: 11811M
[11/18 17:04:32] d2.utils.events INFO:  eta: 18:49:29  iter: 11559  total_loss: 0.1444  loss_cls: 0.05295  loss_box_reg: 0.06955  loss_rpn_cls: 0.007215  loss_rpn_loc: 0.01511  time: 0.6829  data_time: 0.0612  lr: 0.02  max_mem: 11811M
[11/18 17:04:45] d2.utils.events INFO:  eta: 18:49:39  iter: 11579  total_loss: 0.1514  loss_cls: 0.0569  loss_box_reg: 0.07349  loss_rpn_cls: 0.007293  loss_rpn_loc: 0.01557  time: 0.6829  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 17:04:59] d2.utils.events INFO:  eta: 18:49:32  iter: 11599  total_loss: 0.152  loss_cls: 0.05778  loss_box_reg: 0.07021  loss_rpn_cls: 0.008081  loss_rpn_loc: 0.01609  time: 0.6829  data_time: 0.0720  lr: 0.02  max_mem: 11811M
[11/18 17:05:13] d2.utils.events INFO:  eta: 18:49:20  iter: 11619  total_loss: 0.1489  loss_cls: 0.056  loss_box_reg: 0.07166  loss_rpn_cls: 0.007658  loss_rpn_loc: 0.01584  time: 0.6829  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 17:05:26] d2.utils.events INFO:  eta: 18:49:13  iter: 11639  total_loss: 0.1515  loss_cls: 0.05555  loss_box_reg: 0.07397  loss_rpn_cls: 0.007386  loss_rpn_loc: 0.01595  time: 0.6829  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 17:05:40] d2.utils.events INFO:  eta: 18:48:44  iter: 11659  total_loss: 0.1533  loss_cls: 0.05705  loss_box_reg: 0.07224  loss_rpn_cls: 0.006963  loss_rpn_loc: 0.01745  time: 0.6829  data_time: 0.0643  lr: 0.02  max_mem: 11811M
[11/18 17:05:54] d2.utils.events INFO:  eta: 18:48:22  iter: 11679  total_loss: 0.1475  loss_cls: 0.05481  loss_box_reg: 0.07038  loss_rpn_cls: 0.007383  loss_rpn_loc: 0.01564  time: 0.6829  data_time: 0.0629  lr: 0.02  max_mem: 11811M
[11/18 17:06:07] d2.utils.events INFO:  eta: 18:48:17  iter: 11699  total_loss: 0.1468  loss_cls: 0.05494  loss_box_reg: 0.06847  loss_rpn_cls: 0.007046  loss_rpn_loc: 0.01645  time: 0.6829  data_time: 0.0691  lr: 0.02  max_mem: 11811M
[11/18 17:06:21] d2.utils.events INFO:  eta: 18:47:56  iter: 11719  total_loss: 0.1508  loss_cls: 0.05943  loss_box_reg: 0.07182  loss_rpn_cls: 0.00644  loss_rpn_loc: 0.01462  time: 0.6829  data_time: 0.0630  lr: 0.02  max_mem: 11811M
[11/18 17:06:35] d2.utils.events INFO:  eta: 18:47:26  iter: 11739  total_loss: 0.1491  loss_cls: 0.05602  loss_box_reg: 0.06958  loss_rpn_cls: 0.007115  loss_rpn_loc: 0.01643  time: 0.6829  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 17:06:48] d2.utils.events INFO:  eta: 18:47:15  iter: 11759  total_loss: 0.1569  loss_cls: 0.05955  loss_box_reg: 0.07194  loss_rpn_cls: 0.008031  loss_rpn_loc: 0.01606  time: 0.6829  data_time: 0.0704  lr: 0.02  max_mem: 11811M
[11/18 17:07:02] d2.utils.events INFO:  eta: 18:46:59  iter: 11779  total_loss: 0.1609  loss_cls: 0.0596  loss_box_reg: 0.07396  loss_rpn_cls: 0.00778  loss_rpn_loc: 0.01605  time: 0.6829  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 17:07:16] d2.utils.events INFO:  eta: 18:46:46  iter: 11799  total_loss: 0.1544  loss_cls: 0.05845  loss_box_reg: 0.07254  loss_rpn_cls: 0.006873  loss_rpn_loc: 0.01584  time: 0.6829  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 17:07:30] d2.utils.events INFO:  eta: 18:46:40  iter: 11819  total_loss: 0.1519  loss_cls: 0.05781  loss_box_reg: 0.07115  loss_rpn_cls: 0.006094  loss_rpn_loc: 0.01521  time: 0.6830  data_time: 0.0723  lr: 0.02  max_mem: 11811M
[11/18 17:07:43] d2.utils.events INFO:  eta: 18:46:22  iter: 11839  total_loss: 0.1514  loss_cls: 0.05517  loss_box_reg: 0.07242  loss_rpn_cls: 0.006572  loss_rpn_loc: 0.01535  time: 0.6830  data_time: 0.0742  lr: 0.02  max_mem: 11811M
[11/18 17:07:57] d2.utils.events INFO:  eta: 18:46:13  iter: 11859  total_loss: 0.149  loss_cls: 0.05597  loss_box_reg: 0.07236  loss_rpn_cls: 0.007179  loss_rpn_loc: 0.01598  time: 0.6830  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 17:08:10] d2.utils.events INFO:  eta: 18:45:52  iter: 11879  total_loss: 0.1628  loss_cls: 0.06107  loss_box_reg: 0.07985  loss_rpn_cls: 0.006308  loss_rpn_loc: 0.01592  time: 0.6829  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 17:08:24] d2.utils.events INFO:  eta: 18:45:36  iter: 11899  total_loss: 0.1543  loss_cls: 0.05944  loss_box_reg: 0.06864  loss_rpn_cls: 0.007851  loss_rpn_loc: 0.01568  time: 0.6829  data_time: 0.0594  lr: 0.02  max_mem: 11811M
[11/18 17:08:38] d2.utils.events INFO:  eta: 18:45:18  iter: 11919  total_loss: 0.1465  loss_cls: 0.05478  loss_box_reg: 0.06859  loss_rpn_cls: 0.00621  loss_rpn_loc: 0.01415  time: 0.6829  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 17:08:51] d2.utils.events INFO:  eta: 18:44:44  iter: 11939  total_loss: 0.1497  loss_cls: 0.05623  loss_box_reg: 0.07034  loss_rpn_cls: 0.006378  loss_rpn_loc: 0.01556  time: 0.6829  data_time: 0.0770  lr: 0.02  max_mem: 11811M
[11/18 17:09:05] d2.utils.events INFO:  eta: 18:44:52  iter: 11959  total_loss: 0.1518  loss_cls: 0.05621  loss_box_reg: 0.07008  loss_rpn_cls: 0.009341  loss_rpn_loc: 0.01655  time: 0.6830  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 17:09:19] d2.utils.events INFO:  eta: 18:44:43  iter: 11979  total_loss: 0.158  loss_cls: 0.06329  loss_box_reg: 0.07322  loss_rpn_cls: 0.007235  loss_rpn_loc: 0.01562  time: 0.6830  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 17:09:33] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0011999.pth
[11/18 17:09:33] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 17:09:33] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 17:09:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 17:09:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 17:09:34] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 17:09:34] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 17:09:34] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 17:09:41] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0389 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:02:14
[11/18 17:09:46] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0003 s/iter. Total: 0.0409 s/iter. ETA=0:02:10
[11/18 17:09:51] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/18 17:09:56] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/18 17:10:01] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:57
[11/18 17:10:06] d2.evaluation.evaluator INFO: Inference done 619/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:52
[11/18 17:10:11] d2.evaluation.evaluator INFO: Inference done 738/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/18 17:10:16] d2.evaluation.evaluator INFO: Inference done 861/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/18 17:10:21] d2.evaluation.evaluator INFO: Inference done 983/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/18 17:10:26] d2.evaluation.evaluator INFO: Inference done 1108/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/18 17:10:31] d2.evaluation.evaluator INFO: Inference done 1231/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/18 17:10:36] d2.evaluation.evaluator INFO: Inference done 1352/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/18 17:10:41] d2.evaluation.evaluator INFO: Inference done 1475/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/18 17:10:46] d2.evaluation.evaluator INFO: Inference done 1597/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/18 17:10:51] d2.evaluation.evaluator INFO: Inference done 1716/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:06
[11/18 17:10:56] d2.evaluation.evaluator INFO: Inference done 1834/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:02
[11/18 17:11:01] d2.evaluation.evaluator INFO: Inference done 1953/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/18 17:11:06] d2.evaluation.evaluator INFO: Inference done 2075/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/18 17:11:11] d2.evaluation.evaluator INFO: Inference done 2196/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/18 17:11:16] d2.evaluation.evaluator INFO: Inference done 2315/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 17:11:21] d2.evaluation.evaluator INFO: Inference done 2433/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/18 17:11:26] d2.evaluation.evaluator INFO: Inference done 2554/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:32
[11/18 17:11:31] d2.evaluation.evaluator INFO: Inference done 2673/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/18 17:11:36] d2.evaluation.evaluator INFO: Inference done 2795/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/18 17:11:42] d2.evaluation.evaluator INFO: Inference done 2916/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/18 17:11:47] d2.evaluation.evaluator INFO: Inference done 3035/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/18 17:11:52] d2.evaluation.evaluator INFO: Inference done 3154/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/18 17:11:57] d2.evaluation.evaluator INFO: Inference done 3273/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/18 17:11:59] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.421062 (0.041580 s / iter per device, on 6 devices)
[11/18 17:11:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039681 s / iter per device, on 6 devices)
[11/18 17:12:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 17:12:01] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 17:12:02] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 17:12:03] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 17:12:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.89 seconds.
[11/18 17:12:24] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 17:12:25] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.60 seconds.
[11/18 17:12:25] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.478 | 27.855 | 13.120 | 1.063 | 5.641 | 17.707 |
[11/18 17:12:25] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 11.808 | bird          | 40.353 | hat with a wide brim | 8.281  |
| person                | 8.608  | dog           | 53.981 | lizard               | 12.305 |
| sheep                 | 10.760 | wine bottle   | 10.461 | bowl                 | 17.884 |
| airplane              | 32.021 | domestic cat  | 16.823 | car                  | 36.916 |
| porcupine             | 22.772 | bear          | 23.830 | tape player          | 10.834 |
| ray                   | 6.257  | laptop        | 13.998 | zebra                | 33.480 |
| computer keyboard     | 13.023 | pitcher       | 13.154 | artichoke            | 27.137 |
| tv or monitor         | 13.792 | table         | 10.074 | chair                | 7.777  |
| helmet                | 14.512 | traffic light | 3.177  | red panda            | 24.534 |
| sunglasses            | 2.538  | lamp          | 4.111  | bicycle              | 10.602 |
| backpack              | 8.882  | mushroom      | 7.399  | fox                  | 17.018 |
| otter                 | 6.354  | guitar        | 7.645  | microphone           | 0.591  |
| strawberry            | 11.181 | stove         | 12.045 | violin               | 2.927  |
| bookshelf             | 19.470 | sofa          | 8.504  | bell pepper          | 8.173  |
| bagel                 | 13.056 | lemon         | 18.222 | orange               | 15.924 |
| bench                 | 2.966  | piano         | 24.594 | flower pot           | 3.851  |
| butterfly             | 39.584 | purse         | 7.205  | pomegranate          | 5.558  |
| train                 | 21.626 | drum          | 3.498  | hippopotamus         | 3.238  |
| ski                   | 2.350  | ladybug       | 27.620 | banana               | 2.939  |
| monkey                | 18.769 | bus           | 36.940 | miniskirt            | 5.551  |
| camel                 | 4.688  | cream         | 21.431 | lobster              | 8.962  |
| seal                  | 5.730  | horse         | 13.659 | cart                 | 14.382 |
| elephant              | 22.911 | snake         | 11.528 | fig                  | 2.824  |
| watercraft            | 26.993 | apple         | 18.819 | antelope             | 32.591 |
| cattle                | 5.789  | whale         | 20.712 | coffee maker         | 25.858 |
| baby bed              | 30.655 | frog          | 23.736 | bathing cap          | 10.212 |
| crutch                | 0.330  | koala bear    | 21.049 | tie                  | 2.045  |
| dumbbell              | 1.009  | tiger         | 15.564 | dragonfly            | 13.580 |
| goldfish              | 8.448  | cucumber      | 1.826  | turtle               | 22.220 |
| harp                  | 11.871 | jellyfish     | 16.402 | swine                | 15.185 |
| pretzel               | 9.825  | motorcycle    | 26.299 | beaker               | 14.657 |
| rabbit                | 29.324 | nail          | 0.637  | axe                  | 5.795  |
| salt or pepper shaker | 2.359  | croquet ball  | 17.766 | skunk                | 15.342 |
| starfish              | 15.327 |               |        |                      |        |
[11/18 17:12:27] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 17:12:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 17:12:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 17:12:27] d2.evaluation.testing INFO: copypaste: 14.4783,27.8548,13.1197,1.0631,5.6407,17.7069
[11/18 17:12:27] d2.utils.events INFO:  eta: 18:44:43  iter: 11999  total_loss: 0.1584  loss_cls: 0.06205  loss_box_reg: 0.0731  loss_rpn_cls: 0.007434  loss_rpn_loc: 0.01569  time: 0.6830  data_time: 0.0695  lr: 0.02  max_mem: 11811M
[11/18 17:12:41] d2.utils.events INFO:  eta: 18:44:07  iter: 12019  total_loss: 0.1423  loss_cls: 0.05226  loss_box_reg: 0.0684  loss_rpn_cls: 0.008036  loss_rpn_loc: 0.01648  time: 0.6829  data_time: 0.0628  lr: 0.02  max_mem: 11811M
[11/18 17:12:54] d2.utils.events INFO:  eta: 18:43:36  iter: 12039  total_loss: 0.1449  loss_cls: 0.05438  loss_box_reg: 0.06869  loss_rpn_cls: 0.007102  loss_rpn_loc: 0.0147  time: 0.6829  data_time: 0.0653  lr: 0.02  max_mem: 11811M
[11/18 17:13:08] d2.utils.events INFO:  eta: 18:43:44  iter: 12059  total_loss: 0.1493  loss_cls: 0.0553  loss_box_reg: 0.07217  loss_rpn_cls: 0.006316  loss_rpn_loc: 0.01538  time: 0.6829  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 17:13:21] d2.utils.events INFO:  eta: 18:43:33  iter: 12079  total_loss: 0.1513  loss_cls: 0.0572  loss_box_reg: 0.07606  loss_rpn_cls: 0.006295  loss_rpn_loc: 0.01562  time: 0.6829  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 17:13:35] d2.utils.events INFO:  eta: 18:43:22  iter: 12099  total_loss: 0.1502  loss_cls: 0.05329  loss_box_reg: 0.07107  loss_rpn_cls: 0.006922  loss_rpn_loc: 0.01748  time: 0.6829  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 17:13:48] d2.utils.events INFO:  eta: 18:43:16  iter: 12119  total_loss: 0.147  loss_cls: 0.055  loss_box_reg: 0.07018  loss_rpn_cls: 0.006741  loss_rpn_loc: 0.01746  time: 0.6829  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 17:14:02] d2.utils.events INFO:  eta: 18:42:57  iter: 12139  total_loss: 0.1382  loss_cls: 0.05192  loss_box_reg: 0.06486  loss_rpn_cls: 0.006929  loss_rpn_loc: 0.015  time: 0.6829  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 17:14:16] d2.utils.events INFO:  eta: 18:42:41  iter: 12159  total_loss: 0.1504  loss_cls: 0.05631  loss_box_reg: 0.06857  loss_rpn_cls: 0.006867  loss_rpn_loc: 0.0162  time: 0.6829  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 17:14:30] d2.utils.events INFO:  eta: 18:42:27  iter: 12179  total_loss: 0.1531  loss_cls: 0.05765  loss_box_reg: 0.07306  loss_rpn_cls: 0.00748  loss_rpn_loc: 0.01596  time: 0.6829  data_time: 0.0753  lr: 0.02  max_mem: 11811M
[11/18 17:14:43] d2.utils.events INFO:  eta: 18:42:14  iter: 12199  total_loss: 0.1585  loss_cls: 0.05903  loss_box_reg: 0.07607  loss_rpn_cls: 0.006597  loss_rpn_loc: 0.01617  time: 0.6829  data_time: 0.0709  lr: 0.02  max_mem: 11811M
[11/18 17:14:57] d2.utils.events INFO:  eta: 18:42:16  iter: 12219  total_loss: 0.1539  loss_cls: 0.0574  loss_box_reg: 0.07456  loss_rpn_cls: 0.006532  loss_rpn_loc: 0.01524  time: 0.6829  data_time: 0.0727  lr: 0.02  max_mem: 11811M
[11/18 17:15:11] d2.utils.events INFO:  eta: 18:42:16  iter: 12239  total_loss: 0.1546  loss_cls: 0.05778  loss_box_reg: 0.07425  loss_rpn_cls: 0.006764  loss_rpn_loc: 0.01485  time: 0.6829  data_time: 0.0624  lr: 0.02  max_mem: 11811M
[11/18 17:15:25] d2.utils.events INFO:  eta: 18:42:29  iter: 12259  total_loss: 0.1611  loss_cls: 0.05793  loss_box_reg: 0.07653  loss_rpn_cls: 0.007968  loss_rpn_loc: 0.01798  time: 0.6829  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 17:15:38] d2.utils.events INFO:  eta: 18:42:01  iter: 12279  total_loss: 0.154  loss_cls: 0.05987  loss_box_reg: 0.07246  loss_rpn_cls: 0.008041  loss_rpn_loc: 0.01649  time: 0.6829  data_time: 0.0707  lr: 0.02  max_mem: 11811M
[11/18 17:15:52] d2.utils.events INFO:  eta: 18:41:13  iter: 12299  total_loss: 0.1471  loss_cls: 0.05653  loss_box_reg: 0.07  loss_rpn_cls: 0.008104  loss_rpn_loc: 0.01541  time: 0.6829  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 17:16:06] d2.utils.events INFO:  eta: 18:41:08  iter: 12319  total_loss: 0.1706  loss_cls: 0.06461  loss_box_reg: 0.07754  loss_rpn_cls: 0.008474  loss_rpn_loc: 0.0172  time: 0.6829  data_time: 0.0749  lr: 0.02  max_mem: 11811M
[11/18 17:16:19] d2.utils.events INFO:  eta: 18:40:53  iter: 12339  total_loss: 0.1631  loss_cls: 0.06017  loss_box_reg: 0.07568  loss_rpn_cls: 0.007937  loss_rpn_loc: 0.01589  time: 0.6830  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 17:16:33] d2.utils.events INFO:  eta: 18:40:37  iter: 12359  total_loss: 0.1521  loss_cls: 0.05732  loss_box_reg: 0.07024  loss_rpn_cls: 0.006613  loss_rpn_loc: 0.01509  time: 0.6829  data_time: 0.0657  lr: 0.02  max_mem: 11811M
[11/18 17:16:47] d2.utils.events INFO:  eta: 18:40:18  iter: 12379  total_loss: 0.1541  loss_cls: 0.0567  loss_box_reg: 0.07171  loss_rpn_cls: 0.007448  loss_rpn_loc: 0.01742  time: 0.6829  data_time: 0.0627  lr: 0.02  max_mem: 11811M
[11/18 17:17:00] d2.utils.events INFO:  eta: 18:40:00  iter: 12399  total_loss: 0.1542  loss_cls: 0.05775  loss_box_reg: 0.07095  loss_rpn_cls: 0.007448  loss_rpn_loc: 0.01635  time: 0.6829  data_time: 0.0638  lr: 0.02  max_mem: 11811M
[11/18 17:17:14] d2.utils.events INFO:  eta: 18:39:38  iter: 12419  total_loss: 0.1648  loss_cls: 0.06067  loss_box_reg: 0.07622  loss_rpn_cls: 0.00712  loss_rpn_loc: 0.01442  time: 0.6829  data_time: 0.0710  lr: 0.02  max_mem: 11811M
[11/18 17:17:28] d2.utils.events INFO:  eta: 18:39:16  iter: 12439  total_loss: 0.1482  loss_cls: 0.05614  loss_box_reg: 0.0703  loss_rpn_cls: 0.006135  loss_rpn_loc: 0.014  time: 0.6829  data_time: 0.0690  lr: 0.02  max_mem: 11811M
[11/18 17:17:41] d2.utils.events INFO:  eta: 18:39:06  iter: 12459  total_loss: 0.1533  loss_cls: 0.06006  loss_box_reg: 0.07459  loss_rpn_cls: 0.006852  loss_rpn_loc: 0.01498  time: 0.6829  data_time: 0.0700  lr: 0.02  max_mem: 11811M
[11/18 17:17:55] d2.utils.events INFO:  eta: 18:38:57  iter: 12479  total_loss: 0.1477  loss_cls: 0.05577  loss_box_reg: 0.06979  loss_rpn_cls: 0.006657  loss_rpn_loc: 0.01374  time: 0.6829  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 17:18:09] d2.utils.events INFO:  eta: 18:38:47  iter: 12499  total_loss: 0.1548  loss_cls: 0.05826  loss_box_reg: 0.07128  loss_rpn_cls: 0.006395  loss_rpn_loc: 0.01585  time: 0.6829  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 17:18:22] d2.utils.events INFO:  eta: 18:38:38  iter: 12519  total_loss: 0.1505  loss_cls: 0.05371  loss_box_reg: 0.07054  loss_rpn_cls: 0.006984  loss_rpn_loc: 0.0158  time: 0.6829  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 17:18:36] d2.utils.events INFO:  eta: 18:39:04  iter: 12539  total_loss: 0.1469  loss_cls: 0.05518  loss_box_reg: 0.07184  loss_rpn_cls: 0.006865  loss_rpn_loc: 0.01647  time: 0.6830  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 17:18:49] d2.utils.events INFO:  eta: 18:38:08  iter: 12559  total_loss: 0.1475  loss_cls: 0.0524  loss_box_reg: 0.07208  loss_rpn_cls: 0.006956  loss_rpn_loc: 0.01598  time: 0.6829  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 17:19:03] d2.utils.events INFO:  eta: 18:37:46  iter: 12579  total_loss: 0.1543  loss_cls: 0.05634  loss_box_reg: 0.07579  loss_rpn_cls: 0.007236  loss_rpn_loc: 0.0166  time: 0.6829  data_time: 0.0644  lr: 0.02  max_mem: 11811M
[11/18 17:19:17] d2.utils.events INFO:  eta: 18:37:39  iter: 12599  total_loss: 0.1415  loss_cls: 0.05398  loss_box_reg: 0.06691  loss_rpn_cls: 0.006484  loss_rpn_loc: 0.01708  time: 0.6829  data_time: 0.0710  lr: 0.02  max_mem: 11811M
[11/18 17:19:30] d2.utils.events INFO:  eta: 18:37:25  iter: 12619  total_loss: 0.1478  loss_cls: 0.0555  loss_box_reg: 0.07023  loss_rpn_cls: 0.007176  loss_rpn_loc: 0.01556  time: 0.6829  data_time: 0.0637  lr: 0.02  max_mem: 11811M
[11/18 17:19:44] d2.utils.events INFO:  eta: 18:37:03  iter: 12639  total_loss: 0.1533  loss_cls: 0.05629  loss_box_reg: 0.07144  loss_rpn_cls: 0.006532  loss_rpn_loc: 0.01671  time: 0.6829  data_time: 0.0711  lr: 0.02  max_mem: 11811M
[11/18 17:19:58] d2.utils.events INFO:  eta: 18:36:58  iter: 12659  total_loss: 0.1481  loss_cls: 0.0556  loss_box_reg: 0.07187  loss_rpn_cls: 0.007383  loss_rpn_loc: 0.01528  time: 0.6830  data_time: 0.0731  lr: 0.02  max_mem: 11811M
[11/18 17:20:12] d2.utils.events INFO:  eta: 18:37:25  iter: 12679  total_loss: 0.1571  loss_cls: 0.05669  loss_box_reg: 0.07643  loss_rpn_cls: 0.006776  loss_rpn_loc: 0.01518  time: 0.6830  data_time: 0.0773  lr: 0.02  max_mem: 11811M
[11/18 17:20:26] d2.utils.events INFO:  eta: 18:36:40  iter: 12699  total_loss: 0.1563  loss_cls: 0.05805  loss_box_reg: 0.07249  loss_rpn_cls: 0.007559  loss_rpn_loc: 0.01674  time: 0.6830  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 17:20:39] d2.utils.events INFO:  eta: 18:36:17  iter: 12719  total_loss: 0.1476  loss_cls: 0.05228  loss_box_reg: 0.07134  loss_rpn_cls: 0.006888  loss_rpn_loc: 0.01472  time: 0.6830  data_time: 0.0704  lr: 0.02  max_mem: 11811M
[11/18 17:20:53] d2.utils.events INFO:  eta: 18:36:44  iter: 12739  total_loss: 0.1598  loss_cls: 0.06132  loss_box_reg: 0.07798  loss_rpn_cls: 0.006852  loss_rpn_loc: 0.01559  time: 0.6830  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 17:21:07] d2.utils.events INFO:  eta: 18:36:33  iter: 12759  total_loss: 0.1602  loss_cls: 0.05789  loss_box_reg: 0.07828  loss_rpn_cls: 0.007498  loss_rpn_loc: 0.01625  time: 0.6830  data_time: 0.0749  lr: 0.02  max_mem: 11811M
[11/18 17:21:21] d2.utils.events INFO:  eta: 18:36:12  iter: 12779  total_loss: 0.15  loss_cls: 0.05611  loss_box_reg: 0.07084  loss_rpn_cls: 0.006777  loss_rpn_loc: 0.01586  time: 0.6830  data_time: 0.0680  lr: 0.02  max_mem: 11811M
[11/18 17:21:34] d2.utils.events INFO:  eta: 18:35:58  iter: 12799  total_loss: 0.1502  loss_cls: 0.0558  loss_box_reg: 0.07093  loss_rpn_cls: 0.007623  loss_rpn_loc: 0.01669  time: 0.6830  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 17:21:48] d2.utils.events INFO:  eta: 18:36:01  iter: 12819  total_loss: 0.1581  loss_cls: 0.0611  loss_box_reg: 0.07261  loss_rpn_cls: 0.007388  loss_rpn_loc: 0.01591  time: 0.6830  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 17:22:02] d2.utils.events INFO:  eta: 18:35:55  iter: 12839  total_loss: 0.1555  loss_cls: 0.05846  loss_box_reg: 0.07337  loss_rpn_cls: 0.006846  loss_rpn_loc: 0.01559  time: 0.6830  data_time: 0.0663  lr: 0.02  max_mem: 11811M
[11/18 17:22:15] d2.utils.events INFO:  eta: 18:35:54  iter: 12859  total_loss: 0.1605  loss_cls: 0.0615  loss_box_reg: 0.07429  loss_rpn_cls: 0.007074  loss_rpn_loc: 0.01589  time: 0.6830  data_time: 0.0611  lr: 0.02  max_mem: 11811M
[11/18 17:22:29] d2.utils.events INFO:  eta: 18:35:28  iter: 12879  total_loss: 0.1555  loss_cls: 0.06067  loss_box_reg: 0.07216  loss_rpn_cls: 0.006955  loss_rpn_loc: 0.01494  time: 0.6830  data_time: 0.0608  lr: 0.02  max_mem: 11811M
[11/18 17:22:42] d2.utils.events INFO:  eta: 18:35:14  iter: 12899  total_loss: 0.153  loss_cls: 0.05836  loss_box_reg: 0.07168  loss_rpn_cls: 0.00739  loss_rpn_loc: 0.01668  time: 0.6830  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 17:22:56] d2.utils.events INFO:  eta: 18:35:47  iter: 12919  total_loss: 0.1512  loss_cls: 0.0568  loss_box_reg: 0.07161  loss_rpn_cls: 0.006206  loss_rpn_loc: 0.01516  time: 0.6830  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 17:23:10] d2.utils.events INFO:  eta: 18:36:14  iter: 12939  total_loss: 0.1592  loss_cls: 0.0596  loss_box_reg: 0.07689  loss_rpn_cls: 0.007307  loss_rpn_loc: 0.01492  time: 0.6830  data_time: 0.0733  lr: 0.02  max_mem: 11811M
[11/18 17:23:24] d2.utils.events INFO:  eta: 18:36:00  iter: 12959  total_loss: 0.1601  loss_cls: 0.06202  loss_box_reg: 0.07605  loss_rpn_cls: 0.007315  loss_rpn_loc: 0.01599  time: 0.6830  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 17:23:37] d2.utils.events INFO:  eta: 18:35:14  iter: 12979  total_loss: 0.1582  loss_cls: 0.06191  loss_box_reg: 0.07072  loss_rpn_cls: 0.008534  loss_rpn_loc: 0.01491  time: 0.6830  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:23:51] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0012999.pth
[11/18 17:23:51] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 17:23:51] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 17:23:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 17:23:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 17:23:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 17:23:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 17:23:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 17:23:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0015 s/iter. Inference: 0.0382 s/iter. Eval: 0.0002 s/iter. Total: 0.0399 s/iter. ETA=0:02:12
[11/18 17:24:04] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0019 s/iter. Inference: 0.0394 s/iter. Eval: 0.0003 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/18 17:24:09] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0018 s/iter. Inference: 0.0391 s/iter. Eval: 0.0003 s/iter. Total: 0.0412 s/iter. ETA=0:02:06
[11/18 17:24:14] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/18 17:24:19] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/18 17:24:24] d2.evaluation.evaluator INFO: Inference done 618/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:52
[11/18 17:24:29] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/18 17:24:34] d2.evaluation.evaluator INFO: Inference done 862/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/18 17:24:39] d2.evaluation.evaluator INFO: Inference done 982/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/18 17:24:44] d2.evaluation.evaluator INFO: Inference done 1104/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:32
[11/18 17:24:49] d2.evaluation.evaluator INFO: Inference done 1224/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/18 17:24:54] d2.evaluation.evaluator INFO: Inference done 1344/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/18 17:24:59] d2.evaluation.evaluator INFO: Inference done 1466/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/18 17:25:04] d2.evaluation.evaluator INFO: Inference done 1587/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/18 17:25:09] d2.evaluation.evaluator INFO: Inference done 1706/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/18 17:25:14] d2.evaluation.evaluator INFO: Inference done 1828/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/18 17:25:19] d2.evaluation.evaluator INFO: Inference done 1948/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/18 17:25:24] d2.evaluation.evaluator INFO: Inference done 2068/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/18 17:25:29] d2.evaluation.evaluator INFO: Inference done 2189/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:47
[11/18 17:25:34] d2.evaluation.evaluator INFO: Inference done 2306/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:42
[11/18 17:25:39] d2.evaluation.evaluator INFO: Inference done 2429/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/18 17:25:45] d2.evaluation.evaluator INFO: Inference done 2547/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/18 17:25:50] d2.evaluation.evaluator INFO: Inference done 2665/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/18 17:25:55] d2.evaluation.evaluator INFO: Inference done 2783/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:22
[11/18 17:26:00] d2.evaluation.evaluator INFO: Inference done 2906/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/18 17:26:05] d2.evaluation.evaluator INFO: Inference done 3029/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/18 17:26:10] d2.evaluation.evaluator INFO: Inference done 3150/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/18 17:26:15] d2.evaluation.evaluator INFO: Inference done 3271/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/18 17:26:17] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.414107 (0.041578 s / iter per device, on 6 devices)
[11/18 17:26:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039674 s / iter per device, on 6 devices)
[11/18 17:26:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 17:26:19] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 17:26:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 17:26:21] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 17:26:46] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.90 seconds.
[11/18 17:26:46] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 17:26:48] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.87 seconds.
[11/18 17:26:48] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 13.930 | 27.335 | 12.370 | 1.002 | 5.074 | 17.064 |
[11/18 17:26:48] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 13.780 | bird          | 38.912 | hat with a wide brim | 7.996  |
| person                | 8.230  | dog           | 51.848 | lizard               | 13.197 |
| sheep                 | 12.987 | wine bottle   | 8.624  | bowl                 | 15.548 |
| airplane              | 31.750 | domestic cat  | 18.213 | car                  | 37.720 |
| porcupine             | 23.263 | bear          | 23.980 | tape player          | 14.858 |
| ray                   | 5.485  | laptop        | 12.393 | zebra                | 31.515 |
| computer keyboard     | 14.267 | pitcher       | 12.533 | artichoke            | 19.780 |
| tv or monitor         | 12.045 | table         | 10.238 | chair                | 7.109  |
| helmet                | 15.461 | traffic light | 5.127  | red panda            | 25.577 |
| sunglasses            | 1.947  | lamp          | 4.249  | bicycle              | 12.417 |
| backpack              | 12.154 | mushroom      | 5.817  | fox                  | 18.327 |
| otter                 | 3.719  | guitar        | 9.342  | microphone           | 1.092  |
| strawberry            | 9.396  | stove         | 11.806 | violin               | 2.207  |
| bookshelf             | 14.845 | sofa          | 7.986  | bell pepper          | 11.650 |
| bagel                 | 11.942 | lemon         | 14.086 | orange               | 10.629 |
| bench                 | 2.319  | piano         | 23.528 | flower pot           | 2.087  |
| butterfly             | 38.923 | purse         | 6.379  | pomegranate          | 6.459  |
| train                 | 22.636 | drum          | 2.928  | hippopotamus         | 5.316  |
| ski                   | 2.726  | ladybug       | 26.722 | banana               | 3.709  |
| monkey                | 18.504 | bus           | 34.855 | miniskirt            | 4.610  |
| camel                 | 13.197 | cream         | 21.558 | lobster              | 9.268  |
| seal                  | 5.648  | horse         | 12.977 | cart                 | 14.964 |
| elephant              | 25.396 | snake         | 12.413 | fig                  | 3.194  |
| watercraft            | 27.203 | apple         | 17.907 | antelope             | 28.565 |
| cattle                | 4.562  | whale         | 15.070 | coffee maker         | 27.225 |
| baby bed              | 27.630 | frog          | 24.014 | bathing cap          | 10.715 |
| crutch                | 0.108  | koala bear    | 16.498 | tie                  | 2.366  |
| dumbbell              | 0.462  | tiger         | 10.591 | dragonfly            | 11.747 |
| goldfish              | 10.903 | cucumber      | 1.836  | turtle               | 17.975 |
| harp                  | 11.473 | jellyfish     | 11.209 | swine                | 14.677 |
| pretzel               | 8.622  | motorcycle    | 23.816 | beaker               | 15.091 |
| rabbit                | 27.173 | nail          | 0.851  | axe                  | 6.332  |
| salt or pepper shaker | 3.020  | croquet ball  | 15.004 | skunk                | 12.071 |
| starfish              | 11.906 |               |        |                      |        |
[11/18 17:26:51] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 17:26:51] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 17:26:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 17:26:51] d2.evaluation.testing INFO: copypaste: 13.9299,27.3347,12.3696,1.0022,5.0737,17.0639
[11/18 17:26:51] d2.utils.events INFO:  eta: 18:35:03  iter: 12999  total_loss: 0.1544  loss_cls: 0.06  loss_box_reg: 0.0736  loss_rpn_cls: 0.006553  loss_rpn_loc: 0.01465  time: 0.6830  data_time: 0.0717  lr: 0.02  max_mem: 11811M
[11/18 17:27:04] d2.utils.events INFO:  eta: 18:35:27  iter: 13019  total_loss: 0.1492  loss_cls: 0.05416  loss_box_reg: 0.07181  loss_rpn_cls: 0.006332  loss_rpn_loc: 0.0153  time: 0.6830  data_time: 0.0653  lr: 0.02  max_mem: 11811M
[11/18 17:27:18] d2.utils.events INFO:  eta: 18:35:43  iter: 13039  total_loss: 0.1427  loss_cls: 0.05128  loss_box_reg: 0.06847  loss_rpn_cls: 0.006343  loss_rpn_loc: 0.01369  time: 0.6830  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 17:27:32] d2.utils.events INFO:  eta: 18:35:42  iter: 13059  total_loss: 0.1478  loss_cls: 0.0561  loss_box_reg: 0.07243  loss_rpn_cls: 0.006225  loss_rpn_loc: 0.01483  time: 0.6830  data_time: 0.0626  lr: 0.02  max_mem: 11811M
[11/18 17:27:45] d2.utils.events INFO:  eta: 18:35:30  iter: 13079  total_loss: 0.1422  loss_cls: 0.05221  loss_box_reg: 0.06952  loss_rpn_cls: 0.006064  loss_rpn_loc: 0.01707  time: 0.6830  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:27:59] d2.utils.events INFO:  eta: 18:35:20  iter: 13099  total_loss: 0.1509  loss_cls: 0.05723  loss_box_reg: 0.07267  loss_rpn_cls: 0.006774  loss_rpn_loc: 0.01417  time: 0.6830  data_time: 0.0656  lr: 0.02  max_mem: 11811M
[11/18 17:28:13] d2.utils.events INFO:  eta: 18:35:23  iter: 13119  total_loss: 0.1531  loss_cls: 0.05442  loss_box_reg: 0.07454  loss_rpn_cls: 0.007006  loss_rpn_loc: 0.01538  time: 0.6830  data_time: 0.0668  lr: 0.02  max_mem: 11811M
[11/18 17:28:26] d2.utils.events INFO:  eta: 18:35:24  iter: 13139  total_loss: 0.1462  loss_cls: 0.0529  loss_box_reg: 0.07126  loss_rpn_cls: 0.007236  loss_rpn_loc: 0.01623  time: 0.6830  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 17:28:40] d2.utils.events INFO:  eta: 18:34:58  iter: 13159  total_loss: 0.1457  loss_cls: 0.05381  loss_box_reg: 0.07024  loss_rpn_cls: 0.006275  loss_rpn_loc: 0.01469  time: 0.6830  data_time: 0.0652  lr: 0.02  max_mem: 11811M
[11/18 17:28:54] d2.utils.events INFO:  eta: 18:34:45  iter: 13179  total_loss: 0.1469  loss_cls: 0.05387  loss_box_reg: 0.0716  loss_rpn_cls: 0.0064  loss_rpn_loc: 0.01547  time: 0.6830  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:29:08] d2.utils.events INFO:  eta: 18:34:31  iter: 13199  total_loss: 0.1421  loss_cls: 0.05357  loss_box_reg: 0.06919  loss_rpn_cls: 0.005763  loss_rpn_loc: 0.01503  time: 0.6830  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 17:29:21] d2.utils.events INFO:  eta: 18:33:58  iter: 13219  total_loss: 0.1493  loss_cls: 0.05459  loss_box_reg: 0.07263  loss_rpn_cls: 0.006351  loss_rpn_loc: 0.01455  time: 0.6830  data_time: 0.0760  lr: 0.02  max_mem: 11811M
[11/18 17:29:35] d2.utils.events INFO:  eta: 18:33:44  iter: 13239  total_loss: 0.1566  loss_cls: 0.05918  loss_box_reg: 0.07771  loss_rpn_cls: 0.006358  loss_rpn_loc: 0.01542  time: 0.6830  data_time: 0.0655  lr: 0.02  max_mem: 11811M
[11/18 17:29:49] d2.utils.events INFO:  eta: 18:33:39  iter: 13259  total_loss: 0.1516  loss_cls: 0.05503  loss_box_reg: 0.07323  loss_rpn_cls: 0.00728  loss_rpn_loc: 0.01549  time: 0.6830  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 17:30:03] d2.utils.events INFO:  eta: 18:33:48  iter: 13279  total_loss: 0.1502  loss_cls: 0.05718  loss_box_reg: 0.0705  loss_rpn_cls: 0.005829  loss_rpn_loc: 0.01558  time: 0.6830  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 17:30:16] d2.utils.events INFO:  eta: 18:33:43  iter: 13299  total_loss: 0.1607  loss_cls: 0.06119  loss_box_reg: 0.0774  loss_rpn_cls: 0.006803  loss_rpn_loc: 0.01722  time: 0.6831  data_time: 0.0801  lr: 0.02  max_mem: 11811M
[11/18 17:30:30] d2.utils.events INFO:  eta: 18:33:29  iter: 13319  total_loss: 0.1605  loss_cls: 0.0611  loss_box_reg: 0.07262  loss_rpn_cls: 0.007568  loss_rpn_loc: 0.01691  time: 0.6831  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 17:30:44] d2.utils.events INFO:  eta: 18:33:13  iter: 13339  total_loss: 0.1556  loss_cls: 0.05892  loss_box_reg: 0.07192  loss_rpn_cls: 0.007365  loss_rpn_loc: 0.01601  time: 0.6831  data_time: 0.0734  lr: 0.02  max_mem: 11811M
[11/18 17:30:58] d2.utils.events INFO:  eta: 18:33:32  iter: 13359  total_loss: 0.1583  loss_cls: 0.05946  loss_box_reg: 0.07547  loss_rpn_cls: 0.007036  loss_rpn_loc: 0.01575  time: 0.6831  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 17:31:11] d2.utils.events INFO:  eta: 18:33:18  iter: 13379  total_loss: 0.1701  loss_cls: 0.06386  loss_box_reg: 0.0792  loss_rpn_cls: 0.007147  loss_rpn_loc: 0.01655  time: 0.6831  data_time: 0.0667  lr: 0.02  max_mem: 11811M
[11/18 17:31:25] d2.utils.events INFO:  eta: 18:33:01  iter: 13399  total_loss: 0.1524  loss_cls: 0.05799  loss_box_reg: 0.07085  loss_rpn_cls: 0.00763  loss_rpn_loc: 0.01664  time: 0.6831  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 17:31:38] d2.utils.events INFO:  eta: 18:32:47  iter: 13419  total_loss: 0.1572  loss_cls: 0.06057  loss_box_reg: 0.07453  loss_rpn_cls: 0.007676  loss_rpn_loc: 0.01556  time: 0.6831  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 17:31:52] d2.utils.events INFO:  eta: 18:32:33  iter: 13439  total_loss: 0.1468  loss_cls: 0.05586  loss_box_reg: 0.06845  loss_rpn_cls: 0.006925  loss_rpn_loc: 0.0162  time: 0.6831  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:32:06] d2.utils.events INFO:  eta: 18:31:53  iter: 13459  total_loss: 0.1508  loss_cls: 0.05647  loss_box_reg: 0.0749  loss_rpn_cls: 0.007553  loss_rpn_loc: 0.0167  time: 0.6830  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 17:32:19] d2.utils.events INFO:  eta: 18:31:40  iter: 13479  total_loss: 0.15  loss_cls: 0.05615  loss_box_reg: 0.0728  loss_rpn_cls: 0.006399  loss_rpn_loc: 0.0153  time: 0.6830  data_time: 0.0659  lr: 0.02  max_mem: 11811M
[11/18 17:32:33] d2.utils.events INFO:  eta: 18:31:16  iter: 13499  total_loss: 0.1499  loss_cls: 0.0546  loss_box_reg: 0.0721  loss_rpn_cls: 0.006933  loss_rpn_loc: 0.01625  time: 0.6830  data_time: 0.0722  lr: 0.02  max_mem: 11811M
[11/18 17:32:47] d2.utils.events INFO:  eta: 18:31:06  iter: 13519  total_loss: 0.1543  loss_cls: 0.0572  loss_box_reg: 0.07372  loss_rpn_cls: 0.006203  loss_rpn_loc: 0.01553  time: 0.6831  data_time: 0.0742  lr: 0.02  max_mem: 11811M
[11/18 17:33:00] d2.utils.events INFO:  eta: 18:31:17  iter: 13539  total_loss: 0.1514  loss_cls: 0.05546  loss_box_reg: 0.07338  loss_rpn_cls: 0.005963  loss_rpn_loc: 0.01536  time: 0.6831  data_time: 0.0694  lr: 0.02  max_mem: 11811M
[11/18 17:33:14] d2.utils.events INFO:  eta: 18:31:07  iter: 13559  total_loss: 0.1448  loss_cls: 0.05406  loss_box_reg: 0.07009  loss_rpn_cls: 0.006992  loss_rpn_loc: 0.01482  time: 0.6831  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 17:33:28] d2.utils.events INFO:  eta: 18:30:49  iter: 13579  total_loss: 0.1462  loss_cls: 0.05329  loss_box_reg: 0.07146  loss_rpn_cls: 0.006623  loss_rpn_loc: 0.01581  time: 0.6831  data_time: 0.0760  lr: 0.02  max_mem: 11811M
[11/18 17:33:41] d2.utils.events INFO:  eta: 18:30:27  iter: 13599  total_loss: 0.1479  loss_cls: 0.0536  loss_box_reg: 0.06865  loss_rpn_cls: 0.006189  loss_rpn_loc: 0.01563  time: 0.6831  data_time: 0.0623  lr: 0.02  max_mem: 11811M
[11/18 17:33:55] d2.utils.events INFO:  eta: 18:30:04  iter: 13619  total_loss: 0.1421  loss_cls: 0.05339  loss_box_reg: 0.0664  loss_rpn_cls: 0.00633  loss_rpn_loc: 0.01527  time: 0.6830  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 17:34:09] d2.utils.events INFO:  eta: 18:29:45  iter: 13639  total_loss: 0.164  loss_cls: 0.06086  loss_box_reg: 0.07886  loss_rpn_cls: 0.00909  loss_rpn_loc: 0.01545  time: 0.6831  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 17:34:22] d2.utils.events INFO:  eta: 18:28:52  iter: 13659  total_loss: 0.1496  loss_cls: 0.05641  loss_box_reg: 0.07178  loss_rpn_cls: 0.007628  loss_rpn_loc: 0.01499  time: 0.6831  data_time: 0.0767  lr: 0.02  max_mem: 11811M
[11/18 17:34:36] d2.utils.events INFO:  eta: 18:27:44  iter: 13679  total_loss: 0.1407  loss_cls: 0.05377  loss_box_reg: 0.06691  loss_rpn_cls: 0.00595  loss_rpn_loc: 0.01394  time: 0.6830  data_time: 0.0611  lr: 0.02  max_mem: 11811M
[11/18 17:34:49] d2.utils.events INFO:  eta: 18:27:14  iter: 13699  total_loss: 0.1475  loss_cls: 0.05192  loss_box_reg: 0.07067  loss_rpn_cls: 0.006906  loss_rpn_loc: 0.01701  time: 0.6830  data_time: 0.0717  lr: 0.02  max_mem: 11811M
[11/18 17:35:03] d2.utils.events INFO:  eta: 18:27:01  iter: 13719  total_loss: 0.1549  loss_cls: 0.05625  loss_box_reg: 0.0747  loss_rpn_cls: 0.007457  loss_rpn_loc: 0.01614  time: 0.6830  data_time: 0.0617  lr: 0.02  max_mem: 11811M
[11/18 17:35:17] d2.utils.events INFO:  eta: 18:27:03  iter: 13739  total_loss: 0.1498  loss_cls: 0.05708  loss_box_reg: 0.07114  loss_rpn_cls: 0.006606  loss_rpn_loc: 0.01579  time: 0.6830  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 17:35:30] d2.utils.events INFO:  eta: 18:27:15  iter: 13759  total_loss: 0.1418  loss_cls: 0.0541  loss_box_reg: 0.06532  loss_rpn_cls: 0.006941  loss_rpn_loc: 0.01588  time: 0.6830  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 17:35:44] d2.utils.events INFO:  eta: 18:27:37  iter: 13779  total_loss: 0.1481  loss_cls: 0.05585  loss_box_reg: 0.06699  loss_rpn_cls: 0.0075  loss_rpn_loc: 0.01812  time: 0.6831  data_time: 0.0839  lr: 0.02  max_mem: 11811M
[11/18 17:35:58] d2.utils.events INFO:  eta: 18:26:22  iter: 13799  total_loss: 0.1434  loss_cls: 0.05242  loss_box_reg: 0.06951  loss_rpn_cls: 0.006975  loss_rpn_loc: 0.01542  time: 0.6831  data_time: 0.0806  lr: 0.02  max_mem: 11811M
[11/18 17:36:12] d2.utils.events INFO:  eta: 18:26:08  iter: 13819  total_loss: 0.1498  loss_cls: 0.05595  loss_box_reg: 0.07285  loss_rpn_cls: 0.007061  loss_rpn_loc: 0.01621  time: 0.6831  data_time: 0.0671  lr: 0.02  max_mem: 11811M
[11/18 17:36:26] d2.utils.events INFO:  eta: 18:26:26  iter: 13839  total_loss: 0.1604  loss_cls: 0.05833  loss_box_reg: 0.07441  loss_rpn_cls: 0.007325  loss_rpn_loc: 0.01801  time: 0.6831  data_time: 0.0804  lr: 0.02  max_mem: 11811M
[11/18 17:36:40] d2.utils.events INFO:  eta: 18:26:13  iter: 13859  total_loss: 0.1525  loss_cls: 0.05846  loss_box_reg: 0.07188  loss_rpn_cls: 0.007047  loss_rpn_loc: 0.01599  time: 0.6831  data_time: 0.0718  lr: 0.02  max_mem: 11811M
[11/18 17:36:53] d2.utils.events INFO:  eta: 18:26:43  iter: 13879  total_loss: 0.1548  loss_cls: 0.05762  loss_box_reg: 0.07137  loss_rpn_cls: 0.006458  loss_rpn_loc: 0.01625  time: 0.6831  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:37:07] d2.utils.events INFO:  eta: 18:26:29  iter: 13899  total_loss: 0.1512  loss_cls: 0.05567  loss_box_reg: 0.07111  loss_rpn_cls: 0.007273  loss_rpn_loc: 0.01605  time: 0.6831  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:37:21] d2.utils.events INFO:  eta: 18:26:16  iter: 13919  total_loss: 0.1577  loss_cls: 0.06042  loss_box_reg: 0.07109  loss_rpn_cls: 0.007852  loss_rpn_loc: 0.01511  time: 0.6831  data_time: 0.0635  lr: 0.02  max_mem: 11811M
[11/18 17:37:35] d2.utils.events INFO:  eta: 18:25:04  iter: 13939  total_loss: 0.1535  loss_cls: 0.05568  loss_box_reg: 0.07294  loss_rpn_cls: 0.007486  loss_rpn_loc: 0.01553  time: 0.6831  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:37:48] d2.utils.events INFO:  eta: 18:23:57  iter: 13959  total_loss: 0.152  loss_cls: 0.05697  loss_box_reg: 0.07088  loss_rpn_cls: 0.007292  loss_rpn_loc: 0.01513  time: 0.6831  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 17:38:02] d2.utils.events INFO:  eta: 18:23:32  iter: 13979  total_loss: 0.1487  loss_cls: 0.05672  loss_box_reg: 0.06962  loss_rpn_cls: 0.006902  loss_rpn_loc: 0.01569  time: 0.6831  data_time: 0.0605  lr: 0.02  max_mem: 11811M
[11/18 17:38:15] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0013999.pth
[11/18 17:38:15] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 17:38:15] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 17:38:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 17:38:16] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 17:38:16] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 17:38:16] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 17:38:16] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 17:38:23] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0419 s/iter. Eval: 0.0002 s/iter. Total: 0.0431 s/iter. ETA=0:02:23
[11/18 17:38:28] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:14
[11/18 17:38:33] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/18 17:38:38] d2.evaluation.evaluator INFO: Inference done 372/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:03
[11/18 17:38:43] d2.evaluation.evaluator INFO: Inference done 491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:58
[11/18 17:38:49] d2.evaluation.evaluator INFO: Inference done 611/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:54
[11/18 17:38:54] d2.evaluation.evaluator INFO: Inference done 733/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:48
[11/18 17:38:59] d2.evaluation.evaluator INFO: Inference done 856/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:43
[11/18 17:39:04] d2.evaluation.evaluator INFO: Inference done 976/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/18 17:39:09] d2.evaluation.evaluator INFO: Inference done 1095/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:33
[11/18 17:39:14] d2.evaluation.evaluator INFO: Inference done 1214/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/18 17:39:19] d2.evaluation.evaluator INFO: Inference done 1336/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:23
[11/18 17:39:24] d2.evaluation.evaluator INFO: Inference done 1457/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:18
[11/18 17:39:29] d2.evaluation.evaluator INFO: Inference done 1578/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/18 17:39:34] d2.evaluation.evaluator INFO: Inference done 1698/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:08
[11/18 17:39:39] d2.evaluation.evaluator INFO: Inference done 1819/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:03
[11/18 17:39:44] d2.evaluation.evaluator INFO: Inference done 1938/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:58
[11/18 17:39:49] d2.evaluation.evaluator INFO: Inference done 2057/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:53
[11/18 17:39:54] d2.evaluation.evaluator INFO: Inference done 2176/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:48
[11/18 17:39:59] d2.evaluation.evaluator INFO: Inference done 2296/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:43
[11/18 17:40:04] d2.evaluation.evaluator INFO: Inference done 2414/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:38
[11/18 17:40:09] d2.evaluation.evaluator INFO: Inference done 2532/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:33
[11/18 17:40:14] d2.evaluation.evaluator INFO: Inference done 2649/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:28
[11/18 17:40:19] d2.evaluation.evaluator INFO: Inference done 2770/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:23
[11/18 17:40:24] d2.evaluation.evaluator INFO: Inference done 2890/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:18
[11/18 17:40:29] d2.evaluation.evaluator INFO: Inference done 3009/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:13
[11/18 17:40:34] d2.evaluation.evaluator INFO: Inference done 3132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:08
[11/18 17:40:39] d2.evaluation.evaluator INFO: Inference done 3257/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:03
[11/18 17:40:42] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.901625 (0.041725 s / iter per device, on 6 devices)
[11/18 17:40:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039732 s / iter per device, on 6 devices)
[11/18 17:40:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 17:40:44] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 17:40:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 17:40:45] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 17:41:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 25.30 seconds.
[11/18 17:41:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 17:41:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.92 seconds.
[11/18 17:41:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.794 | 28.618 | 13.580 | 1.096 | 5.551 | 17.920 |
[11/18 17:41:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 12.625 | bird          | 39.964 | hat with a wide brim | 8.995  |
| person                | 9.168  | dog           | 52.236 | lizard               | 13.512 |
| sheep                 | 16.252 | wine bottle   | 13.293 | bowl                 | 14.494 |
| airplane              | 30.852 | domestic cat  | 19.163 | car                  | 38.077 |
| porcupine             | 20.224 | bear          | 23.789 | tape player          | 15.428 |
| ray                   | 5.367  | laptop        | 12.232 | zebra                | 32.833 |
| computer keyboard     | 19.775 | pitcher       | 11.700 | artichoke            | 23.537 |
| tv or monitor         | 10.299 | table         | 11.101 | chair                | 7.098  |
| helmet                | 14.670 | traffic light | 4.649  | red panda            | 23.370 |
| sunglasses            | 2.958  | lamp          | 4.374  | bicycle              | 10.412 |
| backpack              | 11.241 | mushroom      | 5.830  | fox                  | 17.051 |
| otter                 | 11.103 | guitar        | 12.152 | microphone           | 0.458  |
| strawberry            | 9.755  | stove         | 13.938 | violin               | 2.179  |
| bookshelf             | 18.060 | sofa          | 8.751  | bell pepper          | 12.255 |
| bagel                 | 15.144 | lemon         | 15.289 | orange               | 20.442 |
| bench                 | 2.660  | piano         | 25.511 | flower pot           | 3.399  |
| butterfly             | 38.965 | purse         | 7.926  | pomegranate          | 5.909  |
| train                 | 21.819 | drum          | 4.077  | hippopotamus         | 5.515  |
| ski                   | 2.535  | ladybug       | 25.395 | banana               | 3.949  |
| monkey                | 18.714 | bus           | 36.251 | miniskirt            | 3.947  |
| camel                 | 10.971 | cream         | 24.335 | lobster              | 11.589 |
| seal                  | 1.190  | horse         | 13.751 | cart                 | 15.526 |
| elephant              | 25.113 | snake         | 13.163 | fig                  | 4.464  |
| watercraft            | 28.158 | apple         | 20.930 | antelope             | 32.438 |
| cattle                | 6.563  | whale         | 18.947 | coffee maker         | 23.860 |
| baby bed              | 27.316 | frog          | 20.329 | bathing cap          | 9.578  |
| crutch                | 0.595  | koala bear    | 21.568 | tie                  | 4.385  |
| dumbbell              | 0.272  | tiger         | 21.168 | dragonfly            | 12.804 |
| goldfish              | 13.854 | cucumber      | 3.153  | turtle               | 20.649 |
| harp                  | 13.655 | jellyfish     | 13.322 | swine                | 15.097 |
| pretzel               | 7.136  | motorcycle    | 26.598 | beaker               | 12.110 |
| rabbit                | 31.886 | nail          | 0.118  | axe                  | 6.849  |
| salt or pepper shaker | 5.948  | croquet ball  | 9.006  | skunk                | 12.820 |
| starfish              | 15.509 |               |        |                      |        |
[11/18 17:41:16] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 17:41:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 17:41:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 17:41:16] d2.evaluation.testing INFO: copypaste: 14.7939,28.6184,13.5802,1.0961,5.5506,17.9201
[11/18 17:41:16] d2.utils.events INFO:  eta: 18:23:19  iter: 13999  total_loss: 0.1631  loss_cls: 0.05913  loss_box_reg: 0.07561  loss_rpn_cls: 0.008623  loss_rpn_loc: 0.01657  time: 0.6831  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 17:41:29] d2.utils.events INFO:  eta: 18:23:05  iter: 14019  total_loss: 0.145  loss_cls: 0.0523  loss_box_reg: 0.0709  loss_rpn_cls: 0.006717  loss_rpn_loc: 0.01433  time: 0.6831  data_time: 0.0768  lr: 0.02  max_mem: 11811M
[11/18 17:41:43] d2.utils.events INFO:  eta: 18:22:31  iter: 14039  total_loss: 0.1478  loss_cls: 0.05349  loss_box_reg: 0.07393  loss_rpn_cls: 0.006706  loss_rpn_loc: 0.01623  time: 0.6831  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 17:41:56] d2.utils.events INFO:  eta: 18:21:50  iter: 14059  total_loss: 0.1513  loss_cls: 0.05253  loss_box_reg: 0.07378  loss_rpn_cls: 0.006973  loss_rpn_loc: 0.01718  time: 0.6831  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:42:10] d2.utils.events INFO:  eta: 18:21:12  iter: 14079  total_loss: 0.1444  loss_cls: 0.05284  loss_box_reg: 0.07063  loss_rpn_cls: 0.005581  loss_rpn_loc: 0.0164  time: 0.6831  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 17:42:24] d2.utils.events INFO:  eta: 18:21:05  iter: 14099  total_loss: 0.1537  loss_cls: 0.0567  loss_box_reg: 0.07199  loss_rpn_cls: 0.006186  loss_rpn_loc: 0.01684  time: 0.6831  data_time: 0.0650  lr: 0.02  max_mem: 11811M
[11/18 17:42:38] d2.utils.events INFO:  eta: 18:20:52  iter: 14119  total_loss: 0.1489  loss_cls: 0.05432  loss_box_reg: 0.06746  loss_rpn_cls: 0.006614  loss_rpn_loc: 0.01622  time: 0.6831  data_time: 0.0745  lr: 0.02  max_mem: 11811M
[11/18 17:42:51] d2.utils.events INFO:  eta: 18:20:21  iter: 14139  total_loss: 0.1484  loss_cls: 0.05495  loss_box_reg: 0.07159  loss_rpn_cls: 0.006984  loss_rpn_loc: 0.01616  time: 0.6831  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 17:43:05] d2.utils.events INFO:  eta: 18:20:03  iter: 14159  total_loss: 0.1477  loss_cls: 0.05391  loss_box_reg: 0.07177  loss_rpn_cls: 0.006712  loss_rpn_loc: 0.01542  time: 0.6831  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 17:43:18] d2.utils.events INFO:  eta: 18:19:50  iter: 14179  total_loss: 0.1457  loss_cls: 0.05376  loss_box_reg: 0.07014  loss_rpn_cls: 0.006324  loss_rpn_loc: 0.01375  time: 0.6831  data_time: 0.0681  lr: 0.02  max_mem: 11811M
[11/18 17:43:32] d2.utils.events INFO:  eta: 18:19:15  iter: 14199  total_loss: 0.1532  loss_cls: 0.05599  loss_box_reg: 0.07253  loss_rpn_cls: 0.006542  loss_rpn_loc: 0.01595  time: 0.6830  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 17:43:46] d2.utils.events INFO:  eta: 18:19:21  iter: 14219  total_loss: 0.1612  loss_cls: 0.05702  loss_box_reg: 0.07671  loss_rpn_cls: 0.007641  loss_rpn_loc: 0.01747  time: 0.6831  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 17:43:59] d2.utils.events INFO:  eta: 18:19:17  iter: 14239  total_loss: 0.1503  loss_cls: 0.05439  loss_box_reg: 0.07313  loss_rpn_cls: 0.006222  loss_rpn_loc: 0.01489  time: 0.6831  data_time: 0.0617  lr: 0.02  max_mem: 11811M
[11/18 17:44:13] d2.utils.events INFO:  eta: 18:18:40  iter: 14259  total_loss: 0.1466  loss_cls: 0.05432  loss_box_reg: 0.07035  loss_rpn_cls: 0.00644  loss_rpn_loc: 0.01434  time: 0.6830  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 17:44:27] d2.utils.events INFO:  eta: 18:18:02  iter: 14279  total_loss: 0.1501  loss_cls: 0.05408  loss_box_reg: 0.07214  loss_rpn_cls: 0.007093  loss_rpn_loc: 0.01583  time: 0.6831  data_time: 0.0710  lr: 0.02  max_mem: 11811M
[11/18 17:44:40] d2.utils.events INFO:  eta: 18:17:31  iter: 14299  total_loss: 0.1513  loss_cls: 0.05672  loss_box_reg: 0.07518  loss_rpn_cls: 0.007308  loss_rpn_loc: 0.01538  time: 0.6830  data_time: 0.0705  lr: 0.02  max_mem: 11811M
[11/18 17:44:54] d2.utils.events INFO:  eta: 18:17:33  iter: 14319  total_loss: 0.154  loss_cls: 0.05858  loss_box_reg: 0.07209  loss_rpn_cls: 0.008092  loss_rpn_loc: 0.0153  time: 0.6830  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 17:45:08] d2.utils.events INFO:  eta: 18:17:40  iter: 14339  total_loss: 0.1517  loss_cls: 0.05982  loss_box_reg: 0.07311  loss_rpn_cls: 0.006675  loss_rpn_loc: 0.01499  time: 0.6831  data_time: 0.0702  lr: 0.02  max_mem: 11811M
[11/18 17:45:21] d2.utils.events INFO:  eta: 18:17:18  iter: 14359  total_loss: 0.1538  loss_cls: 0.05708  loss_box_reg: 0.07129  loss_rpn_cls: 0.006868  loss_rpn_loc: 0.01662  time: 0.6831  data_time: 0.0698  lr: 0.02  max_mem: 11811M
[11/18 17:45:35] d2.utils.events INFO:  eta: 18:17:28  iter: 14379  total_loss: 0.1577  loss_cls: 0.05809  loss_box_reg: 0.07529  loss_rpn_cls: 0.006784  loss_rpn_loc: 0.01473  time: 0.6831  data_time: 0.0701  lr: 0.02  max_mem: 11811M
[11/18 17:45:49] d2.utils.events INFO:  eta: 18:17:14  iter: 14399  total_loss: 0.1597  loss_cls: 0.05715  loss_box_reg: 0.07582  loss_rpn_cls: 0.007342  loss_rpn_loc: 0.01612  time: 0.6831  data_time: 0.0622  lr: 0.02  max_mem: 11811M
[11/18 17:46:02] d2.utils.events INFO:  eta: 18:17:03  iter: 14419  total_loss: 0.15  loss_cls: 0.05538  loss_box_reg: 0.07256  loss_rpn_cls: 0.006471  loss_rpn_loc: 0.01508  time: 0.6831  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 17:46:16] d2.utils.events INFO:  eta: 18:16:47  iter: 14439  total_loss: 0.1492  loss_cls: 0.05584  loss_box_reg: 0.07063  loss_rpn_cls: 0.006589  loss_rpn_loc: 0.01415  time: 0.6831  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 17:46:30] d2.utils.events INFO:  eta: 18:17:07  iter: 14459  total_loss: 0.1509  loss_cls: 0.055  loss_box_reg: 0.07043  loss_rpn_cls: 0.007061  loss_rpn_loc: 0.016  time: 0.6831  data_time: 0.0792  lr: 0.02  max_mem: 11811M
[11/18 17:46:44] d2.utils.events INFO:  eta: 18:16:52  iter: 14479  total_loss: 0.1515  loss_cls: 0.0553  loss_box_reg: 0.07402  loss_rpn_cls: 0.006334  loss_rpn_loc: 0.01683  time: 0.6831  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 17:46:57] d2.utils.events INFO:  eta: 18:16:48  iter: 14499  total_loss: 0.1507  loss_cls: 0.05421  loss_box_reg: 0.0731  loss_rpn_cls: 0.007117  loss_rpn_loc: 0.015  time: 0.6831  data_time: 0.0696  lr: 0.02  max_mem: 11811M
[11/18 17:47:11] d2.utils.events INFO:  eta: 18:16:01  iter: 14519  total_loss: 0.1524  loss_cls: 0.05362  loss_box_reg: 0.07174  loss_rpn_cls: 0.006798  loss_rpn_loc: 0.01728  time: 0.6831  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 17:47:25] d2.utils.events INFO:  eta: 18:15:39  iter: 14539  total_loss: 0.1481  loss_cls: 0.05217  loss_box_reg: 0.07167  loss_rpn_cls: 0.006281  loss_rpn_loc: 0.01584  time: 0.6831  data_time: 0.0709  lr: 0.02  max_mem: 11811M
[11/18 17:47:38] d2.utils.events INFO:  eta: 18:15:21  iter: 14559  total_loss: 0.1475  loss_cls: 0.05044  loss_box_reg: 0.07169  loss_rpn_cls: 0.006655  loss_rpn_loc: 0.01605  time: 0.6831  data_time: 0.0664  lr: 0.02  max_mem: 11811M
[11/18 17:47:52] d2.utils.events INFO:  eta: 18:15:11  iter: 14579  total_loss: 0.1556  loss_cls: 0.05722  loss_box_reg: 0.07516  loss_rpn_cls: 0.007025  loss_rpn_loc: 0.01629  time: 0.6831  data_time: 0.0640  lr: 0.02  max_mem: 11811M
[11/18 17:48:06] d2.utils.events INFO:  eta: 18:15:01  iter: 14599  total_loss: 0.1379  loss_cls: 0.0519  loss_box_reg: 0.0661  loss_rpn_cls: 0.007202  loss_rpn_loc: 0.0166  time: 0.6831  data_time: 0.0885  lr: 0.02  max_mem: 11811M
[11/18 17:48:20] d2.utils.events INFO:  eta: 18:14:58  iter: 14619  total_loss: 0.1438  loss_cls: 0.05233  loss_box_reg: 0.07057  loss_rpn_cls: 0.006389  loss_rpn_loc: 0.01469  time: 0.6831  data_time: 0.0693  lr: 0.02  max_mem: 11811M
[11/18 17:48:33] d2.utils.events INFO:  eta: 18:15:03  iter: 14639  total_loss: 0.146  loss_cls: 0.05242  loss_box_reg: 0.07357  loss_rpn_cls: 0.0063  loss_rpn_loc: 0.01557  time: 0.6831  data_time: 0.0636  lr: 0.02  max_mem: 11811M
[11/18 17:48:47] d2.utils.events INFO:  eta: 18:15:15  iter: 14659  total_loss: 0.1509  loss_cls: 0.05601  loss_box_reg: 0.07289  loss_rpn_cls: 0.006514  loss_rpn_loc: 0.01608  time: 0.6831  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 17:49:01] d2.utils.events INFO:  eta: 18:15:01  iter: 14679  total_loss: 0.1401  loss_cls: 0.05242  loss_box_reg: 0.06854  loss_rpn_cls: 0.005925  loss_rpn_loc: 0.01461  time: 0.6831  data_time: 0.0671  lr: 0.02  max_mem: 11811M
[11/18 17:49:14] d2.utils.events INFO:  eta: 18:14:28  iter: 14699  total_loss: 0.1433  loss_cls: 0.05189  loss_box_reg: 0.06801  loss_rpn_cls: 0.00601  loss_rpn_loc: 0.01584  time: 0.6831  data_time: 0.0665  lr: 0.02  max_mem: 11811M
[11/18 17:49:28] d2.utils.events INFO:  eta: 18:14:39  iter: 14719  total_loss: 0.1605  loss_cls: 0.06106  loss_box_reg: 0.07509  loss_rpn_cls: 0.00734  loss_rpn_loc: 0.01574  time: 0.6831  data_time: 0.0618  lr: 0.02  max_mem: 11811M
[11/18 17:49:41] d2.utils.events INFO:  eta: 18:13:58  iter: 14739  total_loss: 0.1592  loss_cls: 0.05791  loss_box_reg: 0.07401  loss_rpn_cls: 0.008024  loss_rpn_loc: 0.01638  time: 0.6831  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 17:49:55] d2.utils.events INFO:  eta: 18:13:45  iter: 14759  total_loss: 0.1514  loss_cls: 0.05437  loss_box_reg: 0.07171  loss_rpn_cls: 0.007032  loss_rpn_loc: 0.01658  time: 0.6831  data_time: 0.0699  lr: 0.02  max_mem: 11811M
[11/18 17:50:09] d2.utils.events INFO:  eta: 18:13:53  iter: 14779  total_loss: 0.1491  loss_cls: 0.05526  loss_box_reg: 0.06978  loss_rpn_cls: 0.006206  loss_rpn_loc: 0.01552  time: 0.6831  data_time: 0.0746  lr: 0.02  max_mem: 11811M
[11/18 17:50:23] d2.utils.events INFO:  eta: 18:13:44  iter: 14799  total_loss: 0.1532  loss_cls: 0.05629  loss_box_reg: 0.07405  loss_rpn_cls: 0.007238  loss_rpn_loc: 0.01592  time: 0.6831  data_time: 0.0852  lr: 0.02  max_mem: 11811M
[11/18 17:50:37] d2.utils.events INFO:  eta: 18:13:30  iter: 14819  total_loss: 0.149  loss_cls: 0.05485  loss_box_reg: 0.0714  loss_rpn_cls: 0.007085  loss_rpn_loc: 0.01591  time: 0.6831  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 17:50:51] d2.utils.events INFO:  eta: 18:12:42  iter: 14839  total_loss: 0.1528  loss_cls: 0.05857  loss_box_reg: 0.07205  loss_rpn_cls: 0.006454  loss_rpn_loc: 0.01562  time: 0.6831  data_time: 0.0878  lr: 0.02  max_mem: 11811M
[11/18 17:51:04] d2.utils.events INFO:  eta: 18:12:33  iter: 14859  total_loss: 0.1516  loss_cls: 0.05579  loss_box_reg: 0.07098  loss_rpn_cls: 0.0066  loss_rpn_loc: 0.01485  time: 0.6831  data_time: 0.0675  lr: 0.02  max_mem: 11811M
[11/18 17:51:18] d2.utils.events INFO:  eta: 18:11:51  iter: 14879  total_loss: 0.1385  loss_cls: 0.05304  loss_box_reg: 0.06608  loss_rpn_cls: 0.007032  loss_rpn_loc: 0.01637  time: 0.6831  data_time: 0.0682  lr: 0.02  max_mem: 11811M
[11/18 17:51:32] d2.utils.events INFO:  eta: 18:11:34  iter: 14899  total_loss: 0.1538  loss_cls: 0.058  loss_box_reg: 0.07208  loss_rpn_cls: 0.007177  loss_rpn_loc: 0.0158  time: 0.6832  data_time: 0.0820  lr: 0.02  max_mem: 11811M
[11/18 17:51:45] d2.utils.events INFO:  eta: 18:11:24  iter: 14919  total_loss: 0.1559  loss_cls: 0.05846  loss_box_reg: 0.07041  loss_rpn_cls: 0.008581  loss_rpn_loc: 0.01463  time: 0.6832  data_time: 0.0624  lr: 0.02  max_mem: 11811M
[11/18 17:51:59] d2.utils.events INFO:  eta: 18:11:07  iter: 14939  total_loss: 0.1586  loss_cls: 0.06016  loss_box_reg: 0.07388  loss_rpn_cls: 0.008021  loss_rpn_loc: 0.01602  time: 0.6832  data_time: 0.0622  lr: 0.02  max_mem: 11811M
[11/18 17:52:13] d2.utils.events INFO:  eta: 18:10:53  iter: 14959  total_loss: 0.1595  loss_cls: 0.06282  loss_box_reg: 0.07447  loss_rpn_cls: 0.007327  loss_rpn_loc: 0.01582  time: 0.6832  data_time: 0.0632  lr: 0.02  max_mem: 11811M
[11/18 17:52:27] d2.utils.events INFO:  eta: 18:11:08  iter: 14979  total_loss: 0.1475  loss_cls: 0.05472  loss_box_reg: 0.07066  loss_rpn_cls: 0.006943  loss_rpn_loc: 0.01608  time: 0.6832  data_time: 0.0683  lr: 0.02  max_mem: 11811M
[11/18 17:52:40] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0014999.pth
[11/18 17:52:40] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 17:52:40] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 17:52:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 17:52:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 17:52:41] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 17:52:41] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 17:52:41] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 17:52:49] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:19
[11/18 17:52:54] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0014 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:12
[11/18 17:52:59] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0014 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/18 17:53:04] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0014 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/18 17:53:09] d2.evaluation.evaluator INFO: Inference done 494/3334. Dataloading: 0.0014 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:58
[11/18 17:53:14] d2.evaluation.evaluator INFO: Inference done 610/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:54
[11/18 17:53:19] d2.evaluation.evaluator INFO: Inference done 732/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:48
[11/18 17:53:24] d2.evaluation.evaluator INFO: Inference done 853/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:43
[11/18 17:53:29] d2.evaluation.evaluator INFO: Inference done 973/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/18 17:53:34] d2.evaluation.evaluator INFO: Inference done 1095/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:33
[11/18 17:53:39] d2.evaluation.evaluator INFO: Inference done 1216/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:28
[11/18 17:53:44] d2.evaluation.evaluator INFO: Inference done 1338/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:23
[11/18 17:53:49] d2.evaluation.evaluator INFO: Inference done 1461/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/18 17:53:54] d2.evaluation.evaluator INFO: Inference done 1582/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/18 17:53:59] d2.evaluation.evaluator INFO: Inference done 1701/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:07
[11/18 17:54:04] d2.evaluation.evaluator INFO: Inference done 1819/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:03
[11/18 17:54:09] d2.evaluation.evaluator INFO: Inference done 1942/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/18 17:54:14] d2.evaluation.evaluator INFO: Inference done 2061/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:53
[11/18 17:54:19] d2.evaluation.evaluator INFO: Inference done 2183/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/18 17:54:24] d2.evaluation.evaluator INFO: Inference done 2299/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:43
[11/18 17:54:29] d2.evaluation.evaluator INFO: Inference done 2419/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:38
[11/18 17:54:34] d2.evaluation.evaluator INFO: Inference done 2534/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:33
[11/18 17:54:39] d2.evaluation.evaluator INFO: Inference done 2654/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:28
[11/18 17:54:44] d2.evaluation.evaluator INFO: Inference done 2774/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:23
[11/18 17:54:49] d2.evaluation.evaluator INFO: Inference done 2892/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:18
[11/18 17:54:54] d2.evaluation.evaluator INFO: Inference done 3013/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:13
[11/18 17:54:59] d2.evaluation.evaluator INFO: Inference done 3132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:08
[11/18 17:55:04] d2.evaluation.evaluator INFO: Inference done 3251/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:03
[11/18 17:55:07] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.177001 (0.041807 s / iter per device, on 6 devices)
[11/18 17:55:07] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039871 s / iter per device, on 6 devices)
[11/18 17:55:09] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 17:55:09] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 17:55:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 17:55:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 17:55:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.79 seconds.
[11/18 17:55:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 17:55:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.60 seconds.
[11/18 17:55:33] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.081 | 27.484 | 12.778 | 1.697 | 5.354 | 17.261 |
[11/18 17:55:33] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 13.379 | bird          | 39.906 | hat with a wide brim | 7.594  |
| person                | 7.814  | dog           | 53.870 | lizard               | 9.885  |
| sheep                 | 14.723 | wine bottle   | 11.720 | bowl                 | 15.217 |
| airplane              | 28.323 | domestic cat  | 15.675 | car                  | 36.564 |
| porcupine             | 17.525 | bear          | 20.185 | tape player          | 13.551 |
| ray                   | 7.814  | laptop        | 13.814 | zebra                | 27.982 |
| computer keyboard     | 14.721 | pitcher       | 12.047 | artichoke            | 25.238 |
| tv or monitor         | 11.713 | table         | 10.897 | chair                | 9.103  |
| helmet                | 14.991 | traffic light | 3.672  | red panda            | 20.417 |
| sunglasses            | 2.403  | lamp          | 3.943  | bicycle              | 10.828 |
| backpack              | 10.486 | mushroom      | 5.106  | fox                  | 19.365 |
| otter                 | 7.504  | guitar        | 10.671 | microphone           | 0.814  |
| strawberry            | 9.610  | stove         | 15.528 | violin               | 1.010  |
| bookshelf             | 16.610 | sofa          | 8.181  | bell pepper          | 9.493  |
| bagel                 | 12.024 | lemon         | 16.905 | orange               | 19.554 |
| bench                 | 2.946  | piano         | 23.068 | flower pot           | 4.855  |
| butterfly             | 32.509 | purse         | 6.839  | pomegranate          | 6.073  |
| train                 | 23.562 | drum          | 3.544  | hippopotamus         | 3.608  |
| ski                   | 0.881  | ladybug       | 24.021 | banana               | 2.691  |
| monkey                | 14.960 | bus           | 33.846 | miniskirt            | 5.075  |
| camel                 | 11.507 | cream         | 22.205 | lobster              | 9.962  |
| seal                  | 4.419  | horse         | 10.787 | cart                 | 17.536 |
| elephant              | 25.739 | snake         | 14.061 | fig                  | 2.299  |
| watercraft            | 27.676 | apple         | 16.098 | antelope             | 29.870 |
| cattle                | 6.476  | whale         | 18.883 | coffee maker         | 24.554 |
| baby bed              | 27.191 | frog          | 24.610 | bathing cap          | 10.214 |
| crutch                | 2.232  | koala bear    | 13.657 | tie                  | 1.323  |
| dumbbell              | 1.151  | tiger         | 20.470 | dragonfly            | 13.712 |
| goldfish              | 9.651  | cucumber      | 3.378  | turtle               | 17.112 |
| harp                  | 13.530 | jellyfish     | 14.981 | swine                | 14.966 |
| pretzel               | 7.412  | motorcycle    | 24.668 | beaker               | 13.524 |
| rabbit                | 27.123 | nail          | 0.588  | axe                  | 5.300  |
| salt or pepper shaker | 5.297  | croquet ball  | 17.067 | skunk                | 12.698 |
| starfish              | 17.329 |               |        |                      |        |
[11/18 17:55:35] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 17:55:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 17:55:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 17:55:35] d2.evaluation.testing INFO: copypaste: 14.0811,27.4838,12.7780,1.6965,5.3542,17.2613
[11/18 17:55:35] d2.utils.events INFO:  eta: 18:10:58  iter: 14999  total_loss: 0.1462  loss_cls: 0.05761  loss_box_reg: 0.0674  loss_rpn_cls: 0.007165  loss_rpn_loc: 0.01561  time: 0.6832  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:55:49] d2.utils.events INFO:  eta: 18:10:41  iter: 15019  total_loss: 0.141  loss_cls: 0.05077  loss_box_reg: 0.06781  loss_rpn_cls: 0.006508  loss_rpn_loc: 0.01483  time: 0.6832  data_time: 0.0736  lr: 0.02  max_mem: 11811M
[11/18 17:56:02] d2.utils.events INFO:  eta: 18:10:27  iter: 15039  total_loss: 0.1433  loss_cls: 0.0524  loss_box_reg: 0.0698  loss_rpn_cls: 0.006277  loss_rpn_loc: 0.01558  time: 0.6832  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 17:56:16] d2.utils.events INFO:  eta: 18:10:12  iter: 15059  total_loss: 0.1549  loss_cls: 0.05495  loss_box_reg: 0.07513  loss_rpn_cls: 0.007697  loss_rpn_loc: 0.01607  time: 0.6832  data_time: 0.0691  lr: 0.02  max_mem: 11811M
[11/18 17:56:30] d2.utils.events INFO:  eta: 18:10:33  iter: 15079  total_loss: 0.1441  loss_cls: 0.05381  loss_box_reg: 0.06964  loss_rpn_cls: 0.006307  loss_rpn_loc: 0.01555  time: 0.6832  data_time: 0.0661  lr: 0.02  max_mem: 11811M
[11/18 17:56:43] d2.utils.events INFO:  eta: 18:10:04  iter: 15099  total_loss: 0.1387  loss_cls: 0.05141  loss_box_reg: 0.06887  loss_rpn_cls: 0.006383  loss_rpn_loc: 0.01465  time: 0.6832  data_time: 0.0629  lr: 0.02  max_mem: 11811M
[11/18 17:56:57] d2.utils.events INFO:  eta: 18:09:39  iter: 15119  total_loss: 0.1479  loss_cls: 0.05352  loss_box_reg: 0.07149  loss_rpn_cls: 0.006603  loss_rpn_loc: 0.01546  time: 0.6832  data_time: 0.0763  lr: 0.02  max_mem: 11811M
[11/18 17:57:11] d2.utils.events INFO:  eta: 18:09:52  iter: 15139  total_loss: 0.1521  loss_cls: 0.05514  loss_box_reg: 0.07435  loss_rpn_cls: 0.006668  loss_rpn_loc: 0.01589  time: 0.6832  data_time: 0.0880  lr: 0.02  max_mem: 11811M
[11/18 17:57:25] d2.utils.events INFO:  eta: 18:09:12  iter: 15159  total_loss: 0.1558  loss_cls: 0.05616  loss_box_reg: 0.07385  loss_rpn_cls: 0.006094  loss_rpn_loc: 0.01772  time: 0.6832  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 17:57:38] d2.utils.events INFO:  eta: 18:08:58  iter: 15179  total_loss: 0.1555  loss_cls: 0.05518  loss_box_reg: 0.07401  loss_rpn_cls: 0.00682  loss_rpn_loc: 0.01666  time: 0.6832  data_time: 0.0649  lr: 0.02  max_mem: 11811M
[11/18 17:57:52] d2.utils.events INFO:  eta: 18:09:24  iter: 15199  total_loss: 0.1402  loss_cls: 0.05269  loss_box_reg: 0.06983  loss_rpn_cls: 0.007086  loss_rpn_loc: 0.01562  time: 0.6832  data_time: 0.0624  lr: 0.02  max_mem: 11811M
[11/18 17:58:06] d2.utils.events INFO:  eta: 18:09:11  iter: 15219  total_loss: 0.1546  loss_cls: 0.05566  loss_box_reg: 0.0716  loss_rpn_cls: 0.006764  loss_rpn_loc: 0.01631  time: 0.6832  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:58:19] d2.utils.events INFO:  eta: 18:09:02  iter: 15239  total_loss: 0.1582  loss_cls: 0.05937  loss_box_reg: 0.07755  loss_rpn_cls: 0.007593  loss_rpn_loc: 0.01644  time: 0.6832  data_time: 0.0646  lr: 0.02  max_mem: 11811M
[11/18 17:58:33] d2.utils.events INFO:  eta: 18:08:53  iter: 15259  total_loss: 0.1525  loss_cls: 0.05475  loss_box_reg: 0.0711  loss_rpn_cls: 0.007098  loss_rpn_loc: 0.01555  time: 0.6832  data_time: 0.0633  lr: 0.02  max_mem: 11811M
[11/18 17:58:47] d2.utils.events INFO:  eta: 18:08:30  iter: 15279  total_loss: 0.1542  loss_cls: 0.05503  loss_box_reg: 0.07354  loss_rpn_cls: 0.007558  loss_rpn_loc: 0.01659  time: 0.6832  data_time: 0.0615  lr: 0.02  max_mem: 11811M
[11/18 17:59:00] d2.utils.events INFO:  eta: 18:08:43  iter: 15299  total_loss: 0.1469  loss_cls: 0.05527  loss_box_reg: 0.07174  loss_rpn_cls: 0.007688  loss_rpn_loc: 0.01589  time: 0.6832  data_time: 0.0795  lr: 0.02  max_mem: 11811M
[11/18 17:59:14] d2.utils.events INFO:  eta: 18:08:08  iter: 15319  total_loss: 0.1427  loss_cls: 0.05367  loss_box_reg: 0.06771  loss_rpn_cls: 0.006388  loss_rpn_loc: 0.01545  time: 0.6832  data_time: 0.0753  lr: 0.02  max_mem: 11811M
[11/18 17:59:28] d2.utils.events INFO:  eta: 18:07:45  iter: 15339  total_loss: 0.1457  loss_cls: 0.05513  loss_box_reg: 0.06824  loss_rpn_cls: 0.007013  loss_rpn_loc: 0.01507  time: 0.6832  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 17:59:41] d2.utils.events INFO:  eta: 18:06:49  iter: 15359  total_loss: 0.1474  loss_cls: 0.05408  loss_box_reg: 0.06935  loss_rpn_cls: 0.007244  loss_rpn_loc: 0.01721  time: 0.6832  data_time: 0.0737  lr: 0.02  max_mem: 11811M
[11/18 17:59:55] d2.utils.events INFO:  eta: 18:06:34  iter: 15379  total_loss: 0.1418  loss_cls: 0.05469  loss_box_reg: 0.06863  loss_rpn_cls: 0.006358  loss_rpn_loc: 0.01402  time: 0.6832  data_time: 0.0740  lr: 0.02  max_mem: 11811M
[11/18 18:00:09] d2.utils.events INFO:  eta: 18:06:21  iter: 15399  total_loss: 0.1504  loss_cls: 0.05589  loss_box_reg: 0.07039  loss_rpn_cls: 0.007162  loss_rpn_loc: 0.01538  time: 0.6832  data_time: 0.0817  lr: 0.02  max_mem: 11811M
[11/18 18:00:23] d2.utils.events INFO:  eta: 18:06:07  iter: 15419  total_loss: 0.1427  loss_cls: 0.05141  loss_box_reg: 0.06651  loss_rpn_cls: 0.00729  loss_rpn_loc: 0.01656  time: 0.6832  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 18:00:36] d2.utils.events INFO:  eta: 18:06:01  iter: 15439  total_loss: 0.1382  loss_cls: 0.05223  loss_box_reg: 0.06583  loss_rpn_cls: 0.006145  loss_rpn_loc: 0.01563  time: 0.6832  data_time: 0.0634  lr: 0.02  max_mem: 11811M
[11/18 18:00:50] d2.utils.events INFO:  eta: 18:05:40  iter: 15459  total_loss: 0.153  loss_cls: 0.05633  loss_box_reg: 0.07443  loss_rpn_cls: 0.006671  loss_rpn_loc: 0.01651  time: 0.6832  data_time: 0.0703  lr: 0.02  max_mem: 11811M
[11/18 18:01:04] d2.utils.events INFO:  eta: 18:05:26  iter: 15479  total_loss: 0.1535  loss_cls: 0.05651  loss_box_reg: 0.06887  loss_rpn_cls: 0.008295  loss_rpn_loc: 0.01685  time: 0.6832  data_time: 0.0654  lr: 0.02  max_mem: 11811M
[11/18 18:01:17] d2.utils.events INFO:  eta: 18:05:13  iter: 15499  total_loss: 0.1503  loss_cls: 0.05453  loss_box_reg: 0.07136  loss_rpn_cls: 0.00786  loss_rpn_loc: 0.01585  time: 0.6832  data_time: 0.0730  lr: 0.02  max_mem: 11811M
[11/18 18:01:31] d2.utils.events INFO:  eta: 18:05:09  iter: 15519  total_loss: 0.1404  loss_cls: 0.04991  loss_box_reg: 0.06642  loss_rpn_cls: 0.006963  loss_rpn_loc: 0.01599  time: 0.6832  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 18:01:45] d2.utils.events INFO:  eta: 18:05:32  iter: 15539  total_loss: 0.1345  loss_cls: 0.04992  loss_box_reg: 0.0659  loss_rpn_cls: 0.005965  loss_rpn_loc: 0.01475  time: 0.6832  data_time: 0.0686  lr: 0.02  max_mem: 11811M
[11/18 18:01:58] d2.utils.events INFO:  eta: 18:05:25  iter: 15559  total_loss: 0.1456  loss_cls: 0.05063  loss_box_reg: 0.06954  loss_rpn_cls: 0.006022  loss_rpn_loc: 0.01676  time: 0.6832  data_time: 0.0658  lr: 0.02  max_mem: 11811M
[11/18 18:02:12] d2.utils.events INFO:  eta: 18:04:20  iter: 15579  total_loss: 0.1448  loss_cls: 0.05235  loss_box_reg: 0.06897  loss_rpn_cls: 0.006841  loss_rpn_loc: 0.01544  time: 0.6832  data_time: 0.0679  lr: 0.02  max_mem: 11811M
[11/18 18:02:25] d2.utils.events INFO:  eta: 18:04:06  iter: 15599  total_loss: 0.1498  loss_cls: 0.05538  loss_box_reg: 0.07356  loss_rpn_cls: 0.007062  loss_rpn_loc: 0.01649  time: 0.6832  data_time: 0.0607  lr: 0.02  max_mem: 11811M
[11/18 18:02:39] d2.utils.events INFO:  eta: 18:03:59  iter: 15619  total_loss: 0.1482  loss_cls: 0.05424  loss_box_reg: 0.07216  loss_rpn_cls: 0.00636  loss_rpn_loc: 0.01529  time: 0.6832  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 18:02:53] d2.utils.events INFO:  eta: 18:03:34  iter: 15639  total_loss: 0.1459  loss_cls: 0.05203  loss_box_reg: 0.071  loss_rpn_cls: 0.00698  loss_rpn_loc: 0.01421  time: 0.6832  data_time: 0.0712  lr: 0.02  max_mem: 11811M
[11/18 18:03:06] d2.utils.events INFO:  eta: 18:03:17  iter: 15659  total_loss: 0.1508  loss_cls: 0.05765  loss_box_reg: 0.06946  loss_rpn_cls: 0.006379  loss_rpn_loc: 0.01587  time: 0.6832  data_time: 0.0735  lr: 0.02  max_mem: 11811M
[11/18 18:03:20] d2.utils.events INFO:  eta: 18:03:12  iter: 15679  total_loss: 0.1566  loss_cls: 0.05717  loss_box_reg: 0.0729  loss_rpn_cls: 0.007947  loss_rpn_loc: 0.01671  time: 0.6832  data_time: 0.0814  lr: 0.02  max_mem: 11811M
[11/18 18:03:34] d2.utils.events INFO:  eta: 18:02:58  iter: 15699  total_loss: 0.1468  loss_cls: 0.05301  loss_box_reg: 0.06842  loss_rpn_cls: 0.006183  loss_rpn_loc: 0.01706  time: 0.6832  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 18:03:48] d2.utils.events INFO:  eta: 18:03:01  iter: 15719  total_loss: 0.1505  loss_cls: 0.05676  loss_box_reg: 0.06955  loss_rpn_cls: 0.006242  loss_rpn_loc: 0.01657  time: 0.6832  data_time: 0.0666  lr: 0.02  max_mem: 11811M
[11/18 18:04:02] d2.utils.events INFO:  eta: 18:02:30  iter: 15739  total_loss: 0.1434  loss_cls: 0.05345  loss_box_reg: 0.06969  loss_rpn_cls: 0.006236  loss_rpn_loc: 0.01487  time: 0.6832  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 18:04:15] d2.utils.events INFO:  eta: 18:02:15  iter: 15759  total_loss: 0.1509  loss_cls: 0.05729  loss_box_reg: 0.0701  loss_rpn_cls: 0.006557  loss_rpn_loc: 0.01486  time: 0.6832  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 18:04:29] d2.utils.events INFO:  eta: 18:01:41  iter: 15779  total_loss: 0.1539  loss_cls: 0.05742  loss_box_reg: 0.07244  loss_rpn_cls: 0.006887  loss_rpn_loc: 0.01533  time: 0.6832  data_time: 0.0674  lr: 0.02  max_mem: 11811M
[11/18 18:04:43] d2.utils.events INFO:  eta: 18:01:49  iter: 15799  total_loss: 0.1544  loss_cls: 0.0548  loss_box_reg: 0.07109  loss_rpn_cls: 0.006943  loss_rpn_loc: 0.01589  time: 0.6832  data_time: 0.0625  lr: 0.02  max_mem: 11811M
[11/18 18:04:57] d2.utils.events INFO:  eta: 18:01:36  iter: 15819  total_loss: 0.1529  loss_cls: 0.05764  loss_box_reg: 0.07417  loss_rpn_cls: 0.007392  loss_rpn_loc: 0.01424  time: 0.6832  data_time: 0.0871  lr: 0.02  max_mem: 11811M
[11/18 18:05:10] d2.utils.events INFO:  eta: 18:01:53  iter: 15839  total_loss: 0.1471  loss_cls: 0.05527  loss_box_reg: 0.06896  loss_rpn_cls: 0.007361  loss_rpn_loc: 0.01535  time: 0.6832  data_time: 0.0660  lr: 0.02  max_mem: 11811M
[11/18 18:05:24] d2.utils.events INFO:  eta: 18:01:28  iter: 15859  total_loss: 0.1515  loss_cls: 0.05667  loss_box_reg: 0.07213  loss_rpn_cls: 0.00616  loss_rpn_loc: 0.01524  time: 0.6832  data_time: 0.0662  lr: 0.02  max_mem: 11811M
[11/18 18:05:38] d2.utils.events INFO:  eta: 18:01:15  iter: 15879  total_loss: 0.1407  loss_cls: 0.05162  loss_box_reg: 0.06968  loss_rpn_cls: 0.007289  loss_rpn_loc: 0.01483  time: 0.6832  data_time: 0.0684  lr: 0.02  max_mem: 11811M
[11/18 18:05:51] d2.utils.events INFO:  eta: 18:00:56  iter: 15899  total_loss: 0.1497  loss_cls: 0.05406  loss_box_reg: 0.06933  loss_rpn_cls: 0.007453  loss_rpn_loc: 0.01619  time: 0.6832  data_time: 0.0648  lr: 0.02  max_mem: 11811M
[11/18 18:06:05] d2.utils.events INFO:  eta: 18:00:42  iter: 15919  total_loss: 0.1501  loss_cls: 0.05682  loss_box_reg: 0.07224  loss_rpn_cls: 0.00683  loss_rpn_loc: 0.01618  time: 0.6832  data_time: 0.0678  lr: 0.02  max_mem: 11811M
[11/18 18:06:18] d2.utils.events INFO:  eta: 18:00:20  iter: 15939  total_loss: 0.1523  loss_cls: 0.05528  loss_box_reg: 0.0713  loss_rpn_cls: 0.007524  loss_rpn_loc: 0.01633  time: 0.6832  data_time: 0.0647  lr: 0.02  max_mem: 11811M
[11/18 18:06:32] d2.utils.events INFO:  eta: 18:00:20  iter: 15959  total_loss: 0.1517  loss_cls: 0.05674  loss_box_reg: 0.07255  loss_rpn_cls: 0.007171  loss_rpn_loc: 0.01672  time: 0.6832  data_time: 0.0676  lr: 0.02  max_mem: 11811M
[11/18 18:06:46] d2.utils.events INFO:  eta: 17:59:47  iter: 15979  total_loss: 0.1493  loss_cls: 0.05566  loss_box_reg: 0.07135  loss_rpn_cls: 0.00708  loss_rpn_loc: 0.01416  time: 0.6832  data_time: 0.0688  lr: 0.02  max_mem: 11811M
[11/18 18:07:00] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0015999.pth
[11/18 18:07:00] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 18:07:00] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 18:07:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 18:07:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 18:07:01] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 18:07:01] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 18:07:01] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 18:07:08] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0424 s/iter. Eval: 0.0002 s/iter. Total: 0.0435 s/iter. ETA=0:02:24
[11/18 18:07:13] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0003 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/18 18:07:18] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0003 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/18 18:07:23] d2.evaluation.evaluator INFO: Inference done 369/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0003 s/iter. Total: 0.0421 s/iter. ETA=0:02:04
[11/18 18:07:28] d2.evaluation.evaluator INFO: Inference done 488/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:59
[11/18 18:07:33] d2.evaluation.evaluator INFO: Inference done 608/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:54
[11/18 18:07:38] d2.evaluation.evaluator INFO: Inference done 728/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:49
[11/18 18:07:43] d2.evaluation.evaluator INFO: Inference done 848/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:44
[11/18 18:07:48] d2.evaluation.evaluator INFO: Inference done 966/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:39
[11/18 18:07:53] d2.evaluation.evaluator INFO: Inference done 1086/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:34
[11/18 18:07:58] d2.evaluation.evaluator INFO: Inference done 1205/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:29
[11/18 18:08:03] d2.evaluation.evaluator INFO: Inference done 1325/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:24
[11/18 18:08:08] d2.evaluation.evaluator INFO: Inference done 1447/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:19
[11/18 18:08:13] d2.evaluation.evaluator INFO: Inference done 1566/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:14
[11/18 18:08:18] d2.evaluation.evaluator INFO: Inference done 1688/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:08
[11/18 18:08:23] d2.evaluation.evaluator INFO: Inference done 1809/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:03
[11/18 18:08:28] d2.evaluation.evaluator INFO: Inference done 1928/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:58
[11/18 18:08:33] d2.evaluation.evaluator INFO: Inference done 2047/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:53
[11/18 18:08:38] d2.evaluation.evaluator INFO: Inference done 2165/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:49
[11/18 18:08:43] d2.evaluation.evaluator INFO: Inference done 2284/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:44
[11/18 18:08:48] d2.evaluation.evaluator INFO: Inference done 2407/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:38
[11/18 18:08:53] d2.evaluation.evaluator INFO: Inference done 2525/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:33
[11/18 18:08:58] d2.evaluation.evaluator INFO: Inference done 2642/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:29
[11/18 18:09:03] d2.evaluation.evaluator INFO: Inference done 2761/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:24
[11/18 18:09:08] d2.evaluation.evaluator INFO: Inference done 2882/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:18
[11/18 18:09:13] d2.evaluation.evaluator INFO: Inference done 3002/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:13
[11/18 18:09:18] d2.evaluation.evaluator INFO: Inference done 3123/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:08
[11/18 18:09:23] d2.evaluation.evaluator INFO: Inference done 3243/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:03
[11/18 18:09:27] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.710658 (0.041968 s / iter per device, on 6 devices)
[11/18 18:09:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:13 (0.040007 s / iter per device, on 6 devices)
[11/18 18:09:30] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 18:09:30] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 18:09:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 18:09:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 18:09:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.09 seconds.
[11/18 18:09:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 18:09:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.72 seconds.
[11/18 18:09:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.212 | 27.522 | 12.847 | 1.750 | 5.931 | 17.203 |
[11/18 18:09:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 10.256 | bird          | 39.412 | hat with a wide brim | 7.161  |
| person                | 8.377  | dog           | 51.221 | lizard               | 12.555 |
| sheep                 | 16.898 | wine bottle   | 10.737 | bowl                 | 15.199 |
| airplane              | 29.484 | domestic cat  | 17.187 | car                  | 37.725 |
| porcupine             | 21.436 | bear          | 23.816 | tape player          | 12.596 |
| ray                   | 3.783  | laptop        | 12.435 | zebra                | 34.734 |
| computer keyboard     | 17.196 | pitcher       | 11.797 | artichoke            | 22.832 |
| tv or monitor         | 12.211 | table         | 11.420 | chair                | 6.935  |
| helmet                | 14.672 | traffic light | 5.411  | red panda            | 25.650 |
| sunglasses            | 2.041  | lamp          | 3.442  | bicycle              | 11.211 |
| backpack              | 11.402 | mushroom      | 4.127  | fox                  | 19.528 |
| otter                 | 9.125  | guitar        | 11.132 | microphone           | 0.843  |
| strawberry            | 9.811  | stove         | 15.909 | violin               | 1.981  |
| bookshelf             | 16.484 | sofa          | 8.842  | bell pepper          | 12.757 |
| bagel                 | 13.568 | lemon         | 13.258 | orange               | 10.893 |
| bench                 | 2.739  | piano         | 20.338 | flower pot           | 4.123  |
| butterfly             | 36.418 | purse         | 7.449  | pomegranate          | 7.178  |
| train                 | 21.174 | drum          | 2.807  | hippopotamus         | 4.004  |
| ski                   | 0.662  | ladybug       | 30.733 | banana               | 2.375  |
| monkey                | 17.485 | bus           | 34.733 | miniskirt            | 3.767  |
| camel                 | 12.488 | cream         | 20.340 | lobster              | 8.605  |
| seal                  | 4.350  | horse         | 13.730 | cart                 | 17.274 |
| elephant              | 24.209 | snake         | 13.287 | fig                  | 3.576  |
| watercraft            | 28.109 | apple         | 17.363 | antelope             | 31.225 |
| cattle                | 7.592  | whale         | 14.858 | coffee maker         | 28.258 |
| baby bed              | 27.268 | frog          | 20.286 | bathing cap          | 9.595  |
| crutch                | 0.247  | koala bear    | 21.736 | tie                  | 4.214  |
| dumbbell              | 0.887  | tiger         | 20.285 | dragonfly            | 12.912 |
| goldfish              | 8.135  | cucumber      | 1.389  | turtle               | 18.677 |
| harp                  | 10.839 | jellyfish     | 11.322 | swine                | 14.664 |
| pretzel               | 5.837  | motorcycle    | 22.912 | beaker               | 14.605 |
| rabbit                | 28.908 | nail          | 3.304  | axe                  | 7.472  |
| salt or pepper shaker | 4.782  | croquet ball  | 14.378 | skunk                | 11.842 |
| starfish              | 14.004 |               |        |                      |        |
[11/18 18:09:59] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 18:09:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 18:09:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 18:09:59] d2.evaluation.testing INFO: copypaste: 14.2124,27.5222,12.8469,1.7499,5.9309,17.2026
[11/18 18:09:59] d2.utils.events INFO:  eta: 17:59:48  iter: 15999  total_loss: 0.1634  loss_cls: 0.05801  loss_box_reg: 0.07778  loss_rpn_cls: 0.006509  loss_rpn_loc: 0.01589  time: 0.6832  data_time: 0.0641  lr: 0.02  max_mem: 11811M
[11/18 18:10:05] d2.engine.hooks INFO: Overall training speed: 16007 iterations in 3:02:16 (0.6833 s / it)
[11/18 18:10:05] d2.engine.hooks INFO: Total training time: 3:49:40 (0:47:23 on hooks)
[11/18 18:10:05] d2.utils.events INFO:  eta: 17:59:33  iter: 16009  total_loss: 0.1668  loss_cls: 0.05885  loss_box_reg: 0.07775  loss_rpn_cls: 0.007813  loss_rpn_loc: 0.01593  time: 0.6832  data_time: 0.0734  lr: 0.02  max_mem: 11811M
