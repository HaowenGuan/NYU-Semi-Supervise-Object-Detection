[11/30 01:15:45] detectron2 INFO: Rank of current process: 0. World size: 6
[11/30 01:15:49] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/30 01:15:49] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/semi_to_supervised_evaluation.yaml', resume=False, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/30 01:15:49] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/semi_to_supervised_evaluation.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
OUTPUT_DIR: "../../output/fine_tune"
MODEL:
  WEIGHTS: "../../output/model_semi_to_supervise.pkl"
  # "../../output/model_semi_to_supervise.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (1, 2000)
  MAX_ITER: 10000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.04
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 0
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000

[11/30 01:15:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ../../output/model_semi_to_supervise.pkl
OUTPUT_DIR: ../../output/fine_tune
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.04
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 1
  - 2000
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/30 01:15:49] detectron2 INFO: Full config saved to ../../output/fine_tune/config.yaml
[11/30 01:15:49] d2.utils.env INFO: Using a generated random seed 53956708
[11/30 01:15:50] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/30 01:15:50] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/30 01:15:50] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/30 01:15:50] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/30 01:15:51] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 283          |     bird      | 4331         | hat with a .. | 206          |
|    person     | 4657         |      dog      | 8341         |    lizard     | 640          |
|     sheep     | 196          |  wine bottle  | 154          |     bowl      | 335          |
|   airplane    | 217          | domestic cat  | 395          |      car      | 1171         |
|   porcupine   | 126          |     bear      | 361          |  tape player  | 109          |
|      ray      | 198          |    laptop     | 172          |     zebra     | 135          |
| computer ke.. | 102          |    pitcher    | 120          |   artichoke   | 180          |
| tv or monitor | 212          |     table     | 786          |     chair     | 905          |
|    helmet     | 433          | traffic light | 142          |   red panda   | 108          |
|  sunglasses   | 243          |     lamp      | 319          |    bicycle    | 187          |
|   backpack    | 148          |   mushroom    | 124          |      fox      | 292          |
|     otter     | 127          |    guitar     | 295          |  microphone   | 259          |
|  strawberry   | 232          |     stove     | 156          |    violin     | 118          |
|   bookshelf   | 106          |     sofa      | 160          |  bell pepper  | 146          |
|     bagel     | 125          |     lemon     | 170          |    orange     | 207          |
|     bench     | 150          |     piano     | 199          |  flower pot   | 189          |
|   butterfly   | 453          |     purse     | 130          |  pomegranate  | 188          |
|     train     | 178          |     drum      | 251          | hippopotamus  | 118          |
|      ski      | 109          |    ladybug    | 138          |    banana     | 244          |
|    monkey     | 1004         |      bus      | 322          |   miniskirt   | 118          |
|     camel     | 276          |     cream     | 194          |    lobster    | 253          |
|     seal      | 224          |     horse     | 265          |     cart      | 281          |
|   elephant    | 242          |     snake     | 1001         |      fig      | 133          |
|  watercraft   | 1038         |     apple     | 216          |   antelope    | 288          |
|    cattle     | 148          |     whale     | 155          | coffee maker  | 143          |
|   baby bed    | 185          |     frog      | 245          |  bathing cap  | 163          |
|    crutch     | 138          |  koala bear   | 139          |      tie      | 124          |
|   dumbbell    | 180          |     tiger     | 159          |   dragonfly   | 175          |
|   goldfish    | 228          |   cucumber    | 114          |    turtle     | 313          |
|     harp      | 152          |   jellyfish   | 184          |     swine     | 259          |
|    pretzel    | 124          |  motorcycle   | 278          |    beaker     | 115          |
|    rabbit     | 235          |     nail      | 86           |      axe      | 127          |
| salt or pep.. | 129          | croquet ball  | 135          |     skunk     | 99           |
|   starfish    | 130          |               |              |               |              |
|     total     | 41293        |               |              |               |              |[0m
[11/30 01:15:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/30 01:15:51] d2.data.build INFO: Using training sampler TrainingSampler
[11/30 01:15:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/30 01:15:51] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/30 01:15:51] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/30 01:15:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/model_semi_to_supervise.pkl ...
[11/30 01:15:51] fvcore.common.checkpoint INFO: Reading a file from 'Haowen Guan [haowen@nyu.edu]'
[11/30 01:15:51] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mroi_heads.box_predictor.bbox_pred_std.{bias, weight}[0m
[11/30 01:15:51] d2.engine.train_loop INFO: Starting training from iteration 0
[11/30 01:16:13] d2.utils.events INFO:  eta: 1:54:02  iter: 19  total_loss: 0.1651  loss_cls: 0.06088  loss_box_reg: 0.07526  loss_rpn_cls: 0.006976  loss_rpn_loc: 0.01554  time: 0.6813  data_time: 0.3694  lr: 0.004  max_mem: 11811M
[11/30 01:16:27] d2.utils.events INFO:  eta: 1:53:49  iter: 39  total_loss: 0.15  loss_cls: 0.05619  loss_box_reg: 0.06871  loss_rpn_cls: 0.006933  loss_rpn_loc: 0.01359  time: 0.6817  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/30 01:16:40] d2.utils.events INFO:  eta: 1:53:02  iter: 59  total_loss: 0.1412  loss_cls: 0.05378  loss_box_reg: 0.06448  loss_rpn_cls: 0.007279  loss_rpn_loc: 0.01457  time: 0.6805  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/30 01:16:54] d2.utils.events INFO:  eta: 1:52:32  iter: 79  total_loss: 0.1376  loss_cls: 0.05302  loss_box_reg: 0.06605  loss_rpn_cls: 0.007132  loss_rpn_loc: 0.014  time: 0.6802  data_time: 0.0711  lr: 0.004  max_mem: 11811M
[11/30 01:17:08] d2.utils.events INFO:  eta: 1:51:58  iter: 99  total_loss: 0.1448  loss_cls: 0.05404  loss_box_reg: 0.06774  loss_rpn_cls: 0.007288  loss_rpn_loc: 0.01388  time: 0.6810  data_time: 0.0798  lr: 0.004  max_mem: 11811M
[11/30 01:17:21] d2.utils.events INFO:  eta: 1:51:33  iter: 119  total_loss: 0.1455  loss_cls: 0.05492  loss_box_reg: 0.06867  loss_rpn_cls: 0.006708  loss_rpn_loc: 0.01438  time: 0.6797  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/30 01:17:35] d2.utils.events INFO:  eta: 1:51:15  iter: 139  total_loss: 0.139  loss_cls: 0.05882  loss_box_reg: 0.063  loss_rpn_cls: 0.005864  loss_rpn_loc: 0.0137  time: 0.6787  data_time: 0.0625  lr: 0.004  max_mem: 11811M
[11/30 01:17:48] d2.utils.events INFO:  eta: 1:51:02  iter: 159  total_loss: 0.1506  loss_cls: 0.05897  loss_box_reg: 0.06982  loss_rpn_cls: 0.006657  loss_rpn_loc: 0.01351  time: 0.6791  data_time: 0.0633  lr: 0.004  max_mem: 11811M
[11/30 01:18:02] d2.utils.events INFO:  eta: 1:50:45  iter: 179  total_loss: 0.14  loss_cls: 0.05402  loss_box_reg: 0.06701  loss_rpn_cls: 0.00684  loss_rpn_loc: 0.01414  time: 0.6785  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/30 01:18:15] d2.utils.events INFO:  eta: 1:50:27  iter: 199  total_loss: 0.1395  loss_cls: 0.05304  loss_box_reg: 0.06587  loss_rpn_cls: 0.005967  loss_rpn_loc: 0.01473  time: 0.6783  data_time: 0.0626  lr: 0.004  max_mem: 11811M
[11/30 01:18:29] d2.utils.events INFO:  eta: 1:50:18  iter: 219  total_loss: 0.1312  loss_cls: 0.04915  loss_box_reg: 0.06554  loss_rpn_cls: 0.006044  loss_rpn_loc: 0.01411  time: 0.6784  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/30 01:18:42] d2.utils.events INFO:  eta: 1:50:07  iter: 239  total_loss: 0.1348  loss_cls: 0.05241  loss_box_reg: 0.06356  loss_rpn_cls: 0.006171  loss_rpn_loc: 0.01376  time: 0.6787  data_time: 0.0690  lr: 0.004  max_mem: 11811M
[11/30 01:18:56] d2.utils.events INFO:  eta: 1:49:53  iter: 259  total_loss: 0.1409  loss_cls: 0.05329  loss_box_reg: 0.06658  loss_rpn_cls: 0.006227  loss_rpn_loc: 0.01344  time: 0.6785  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/30 01:19:09] d2.utils.events INFO:  eta: 1:49:33  iter: 279  total_loss: 0.1342  loss_cls: 0.05123  loss_box_reg: 0.06398  loss_rpn_cls: 0.006558  loss_rpn_loc: 0.01375  time: 0.6781  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/30 01:19:23] d2.utils.events INFO:  eta: 1:49:14  iter: 299  total_loss: 0.1284  loss_cls: 0.04776  loss_box_reg: 0.06009  loss_rpn_cls: 0.005889  loss_rpn_loc: 0.01529  time: 0.6780  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/30 01:19:36] d2.utils.events INFO:  eta: 1:48:56  iter: 319  total_loss: 0.1405  loss_cls: 0.05384  loss_box_reg: 0.06529  loss_rpn_cls: 0.006746  loss_rpn_loc: 0.01435  time: 0.6774  data_time: 0.0675  lr: 0.004  max_mem: 11811M
[11/30 01:19:50] d2.utils.events INFO:  eta: 1:48:48  iter: 339  total_loss: 0.1402  loss_cls: 0.05674  loss_box_reg: 0.06759  loss_rpn_cls: 0.006193  loss_rpn_loc: 0.01359  time: 0.6775  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/30 01:20:04] d2.utils.events INFO:  eta: 1:48:44  iter: 359  total_loss: 0.145  loss_cls: 0.05498  loss_box_reg: 0.06792  loss_rpn_cls: 0.006717  loss_rpn_loc: 0.01474  time: 0.6776  data_time: 0.0617  lr: 0.004  max_mem: 11811M
[11/30 01:20:17] d2.utils.events INFO:  eta: 1:48:32  iter: 379  total_loss: 0.147  loss_cls: 0.05487  loss_box_reg: 0.06866  loss_rpn_cls: 0.006363  loss_rpn_loc: 0.0144  time: 0.6779  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/30 01:20:31] d2.utils.events INFO:  eta: 1:48:25  iter: 399  total_loss: 0.1444  loss_cls: 0.05353  loss_box_reg: 0.06373  loss_rpn_cls: 0.005546  loss_rpn_loc: 0.01476  time: 0.6783  data_time: 0.0658  lr: 0.004  max_mem: 11811M
[11/30 01:20:45] d2.utils.events INFO:  eta: 1:48:13  iter: 419  total_loss: 0.1507  loss_cls: 0.05708  loss_box_reg: 0.06408  loss_rpn_cls: 0.006831  loss_rpn_loc: 0.01529  time: 0.6788  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/30 01:20:58] d2.utils.events INFO:  eta: 1:48:02  iter: 439  total_loss: 0.1409  loss_cls: 0.05409  loss_box_reg: 0.06512  loss_rpn_cls: 0.005992  loss_rpn_loc: 0.01417  time: 0.6790  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/30 01:21:12] d2.utils.events INFO:  eta: 1:47:50  iter: 459  total_loss: 0.137  loss_cls: 0.05369  loss_box_reg: 0.06395  loss_rpn_cls: 0.006629  loss_rpn_loc: 0.01549  time: 0.6795  data_time: 0.0700  lr: 0.004  max_mem: 11811M
[11/30 01:21:26] d2.utils.events INFO:  eta: 1:47:37  iter: 479  total_loss: 0.1466  loss_cls: 0.05367  loss_box_reg: 0.06776  loss_rpn_cls: 0.007261  loss_rpn_loc: 0.01443  time: 0.6800  data_time: 0.0805  lr: 0.004  max_mem: 11811M
[11/30 01:21:39] d2.utils.events INFO:  eta: 1:47:22  iter: 499  total_loss: 0.1388  loss_cls: 0.05053  loss_box_reg: 0.06379  loss_rpn_cls: 0.006194  loss_rpn_loc: 0.01503  time: 0.6796  data_time: 0.0552  lr: 0.004  max_mem: 11811M
[11/30 01:21:53] d2.utils.events INFO:  eta: 1:47:05  iter: 519  total_loss: 0.1311  loss_cls: 0.05181  loss_box_reg: 0.06108  loss_rpn_cls: 0.006536  loss_rpn_loc: 0.01358  time: 0.6797  data_time: 0.0722  lr: 0.004  max_mem: 11811M
[11/30 01:22:07] d2.utils.events INFO:  eta: 1:46:52  iter: 539  total_loss: 0.133  loss_cls: 0.04977  loss_box_reg: 0.06177  loss_rpn_cls: 0.005521  loss_rpn_loc: 0.01395  time: 0.6796  data_time: 0.0630  lr: 0.004  max_mem: 11811M
[11/30 01:22:20] d2.utils.events INFO:  eta: 1:46:37  iter: 559  total_loss: 0.1262  loss_cls: 0.04787  loss_box_reg: 0.05996  loss_rpn_cls: 0.005415  loss_rpn_loc: 0.01512  time: 0.6794  data_time: 0.0606  lr: 0.004  max_mem: 11811M
[11/30 01:22:34] d2.utils.events INFO:  eta: 1:46:20  iter: 579  total_loss: 0.1385  loss_cls: 0.05186  loss_box_reg: 0.06555  loss_rpn_cls: 0.006125  loss_rpn_loc: 0.01498  time: 0.6792  data_time: 0.0601  lr: 0.004  max_mem: 11811M
[11/30 01:22:47] d2.utils.events INFO:  eta: 1:46:08  iter: 599  total_loss: 0.1333  loss_cls: 0.05064  loss_box_reg: 0.06091  loss_rpn_cls: 0.006694  loss_rpn_loc: 0.01442  time: 0.6791  data_time: 0.0660  lr: 0.004  max_mem: 11811M
[11/30 01:23:01] d2.utils.events INFO:  eta: 1:45:56  iter: 619  total_loss: 0.1365  loss_cls: 0.04898  loss_box_reg: 0.06263  loss_rpn_cls: 0.006137  loss_rpn_loc: 0.01482  time: 0.6791  data_time: 0.0606  lr: 0.004  max_mem: 11811M
[11/30 01:23:14] d2.utils.events INFO:  eta: 1:45:41  iter: 639  total_loss: 0.1347  loss_cls: 0.05157  loss_box_reg: 0.06324  loss_rpn_cls: 0.005594  loss_rpn_loc: 0.01382  time: 0.6791  data_time: 0.0706  lr: 0.004  max_mem: 11811M
[11/30 01:23:28] d2.utils.events INFO:  eta: 1:45:29  iter: 659  total_loss: 0.1367  loss_cls: 0.05187  loss_box_reg: 0.06427  loss_rpn_cls: 0.006466  loss_rpn_loc: 0.01467  time: 0.6793  data_time: 0.0724  lr: 0.004  max_mem: 11811M
[11/30 01:23:42] d2.utils.events INFO:  eta: 1:45:15  iter: 679  total_loss: 0.1392  loss_cls: 0.05101  loss_box_reg: 0.06576  loss_rpn_cls: 0.00724  loss_rpn_loc: 0.01491  time: 0.6793  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/30 01:23:55] d2.utils.events INFO:  eta: 1:45:01  iter: 699  total_loss: 0.135  loss_cls: 0.05067  loss_box_reg: 0.0646  loss_rpn_cls: 0.006031  loss_rpn_loc: 0.01329  time: 0.6794  data_time: 0.0701  lr: 0.004  max_mem: 11811M
[11/30 01:24:09] d2.utils.events INFO:  eta: 1:44:49  iter: 719  total_loss: 0.1344  loss_cls: 0.05024  loss_box_reg: 0.06453  loss_rpn_cls: 0.006138  loss_rpn_loc: 0.01386  time: 0.6795  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/30 01:24:23] d2.utils.events INFO:  eta: 1:44:38  iter: 739  total_loss: 0.1414  loss_cls: 0.051  loss_box_reg: 0.06706  loss_rpn_cls: 0.005619  loss_rpn_loc: 0.01589  time: 0.6797  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/30 01:24:36] d2.utils.events INFO:  eta: 1:44:22  iter: 759  total_loss: 0.1469  loss_cls: 0.05388  loss_box_reg: 0.07151  loss_rpn_cls: 0.007059  loss_rpn_loc: 0.01622  time: 0.6796  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/30 01:24:50] d2.utils.events INFO:  eta: 1:44:08  iter: 779  total_loss: 0.1274  loss_cls: 0.0477  loss_box_reg: 0.0614  loss_rpn_cls: 0.005782  loss_rpn_loc: 0.01346  time: 0.6793  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/30 01:25:03] d2.utils.events INFO:  eta: 1:43:54  iter: 799  total_loss: 0.1287  loss_cls: 0.04867  loss_box_reg: 0.06205  loss_rpn_cls: 0.005812  loss_rpn_loc: 0.0138  time: 0.6793  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/30 01:25:17] d2.utils.events INFO:  eta: 1:43:43  iter: 819  total_loss: 0.1371  loss_cls: 0.05391  loss_box_reg: 0.06714  loss_rpn_cls: 0.007158  loss_rpn_loc: 0.01353  time: 0.6794  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/30 01:25:31] d2.utils.events INFO:  eta: 1:43:32  iter: 839  total_loss: 0.136  loss_cls: 0.05055  loss_box_reg: 0.06251  loss_rpn_cls: 0.005891  loss_rpn_loc: 0.01419  time: 0.6795  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/30 01:25:44] d2.utils.events INFO:  eta: 1:43:18  iter: 859  total_loss: 0.1404  loss_cls: 0.05186  loss_box_reg: 0.06427  loss_rpn_cls: 0.006644  loss_rpn_loc: 0.01392  time: 0.6797  data_time: 0.0722  lr: 0.004  max_mem: 11811M
[11/30 01:25:58] d2.utils.events INFO:  eta: 1:43:04  iter: 879  total_loss: 0.1311  loss_cls: 0.04819  loss_box_reg: 0.06445  loss_rpn_cls: 0.005912  loss_rpn_loc: 0.01396  time: 0.6795  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/30 01:26:11] d2.utils.events INFO:  eta: 1:42:51  iter: 899  total_loss: 0.1321  loss_cls: 0.04938  loss_box_reg: 0.06299  loss_rpn_cls: 0.005919  loss_rpn_loc: 0.01533  time: 0.6796  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/30 01:26:25] d2.utils.events INFO:  eta: 1:42:38  iter: 919  total_loss: 0.137  loss_cls: 0.0514  loss_box_reg: 0.06565  loss_rpn_cls: 0.006993  loss_rpn_loc: 0.01367  time: 0.6796  data_time: 0.0645  lr: 0.004  max_mem: 11811M
[11/30 01:26:39] d2.utils.events INFO:  eta: 1:42:24  iter: 939  total_loss: 0.132  loss_cls: 0.05053  loss_box_reg: 0.06081  loss_rpn_cls: 0.006511  loss_rpn_loc: 0.01294  time: 0.6797  data_time: 0.0705  lr: 0.004  max_mem: 11811M
[11/30 01:26:52] d2.utils.events INFO:  eta: 1:42:10  iter: 959  total_loss: 0.1396  loss_cls: 0.0504  loss_box_reg: 0.06791  loss_rpn_cls: 0.006736  loss_rpn_loc: 0.01416  time: 0.6796  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/30 01:27:06] d2.utils.events INFO:  eta: 1:41:55  iter: 979  total_loss: 0.1253  loss_cls: 0.04718  loss_box_reg: 0.06049  loss_rpn_cls: 0.005205  loss_rpn_loc: 0.01243  time: 0.6797  data_time: 0.0854  lr: 0.004  max_mem: 11811M
[11/30 01:27:20] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/fine_tune/model_0000999.pth
[11/30 01:27:20] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/30 01:27:20] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/30 01:27:21] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/30 01:27:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/30 01:27:21] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/30 01:27:21] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/30 01:27:21] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/30 01:27:21] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/30 01:27:28] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0362 s/iter. Eval: 0.0002 s/iter. Total: 0.0373 s/iter. ETA=0:02:03
[11/30 01:27:33] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:14
[11/30 01:27:38] d2.evaluation.evaluator INFO: Inference done 249/3334. Dataloading: 0.0016 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:10
[11/30 01:27:43] d2.evaluation.evaluator INFO: Inference done 371/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:03
[11/30 01:27:48] d2.evaluation.evaluator INFO: Inference done 488/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:59
[11/30 01:27:53] d2.evaluation.evaluator INFO: Inference done 605/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:55
[11/30 01:27:58] d2.evaluation.evaluator INFO: Inference done 722/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:50
[11/30 01:28:03] d2.evaluation.evaluator INFO: Inference done 841/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:45
[11/30 01:28:08] d2.evaluation.evaluator INFO: Inference done 961/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:40
[11/30 01:28:13] d2.evaluation.evaluator INFO: Inference done 1079/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:35
[11/30 01:28:18] d2.evaluation.evaluator INFO: Inference done 1194/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:30
[11/30 01:28:23] d2.evaluation.evaluator INFO: Inference done 1310/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:26
[11/30 01:28:28] d2.evaluation.evaluator INFO: Inference done 1431/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:20
[11/30 01:28:33] d2.evaluation.evaluator INFO: Inference done 1551/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:15
[11/30 01:28:38] d2.evaluation.evaluator INFO: Inference done 1669/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:10
[11/30 01:28:43] d2.evaluation.evaluator INFO: Inference done 1788/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:05
[11/30 01:28:48] d2.evaluation.evaluator INFO: Inference done 1906/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:00
[11/30 01:28:53] d2.evaluation.evaluator INFO: Inference done 2024/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:55
[11/30 01:28:58] d2.evaluation.evaluator INFO: Inference done 2141/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:50
[11/30 01:29:03] d2.evaluation.evaluator INFO: Inference done 2258/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:45
[11/30 01:29:09] d2.evaluation.evaluator INFO: Inference done 2376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:40
[11/30 01:29:14] d2.evaluation.evaluator INFO: Inference done 2491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:35
[11/30 01:29:19] d2.evaluation.evaluator INFO: Inference done 2609/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:30
[11/30 01:29:24] d2.evaluation.evaluator INFO: Inference done 2724/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:25
[11/30 01:29:29] d2.evaluation.evaluator INFO: Inference done 2840/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:21
[11/30 01:29:34] d2.evaluation.evaluator INFO: Inference done 2959/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:15
[11/30 01:29:39] d2.evaluation.evaluator INFO: Inference done 3075/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:11
[11/30 01:29:44] d2.evaluation.evaluator INFO: Inference done 3190/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:00:06
[11/30 01:29:49] d2.evaluation.evaluator INFO: Inference done 3317/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:00
[11/30 01:29:50] d2.evaluation.evaluator INFO: Total inference time: 0:02:21.829749 (0.042604 s / iter per device, on 6 devices)
[11/30 01:29:50] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:15 (0.040681 s / iter per device, on 6 devices)
[11/30 01:29:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/30 01:29:52] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/fine_tune/inference/coco_instances_results.json
[11/30 01:29:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/30 01:29:53] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/30 01:30:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.46 seconds.
[11/30 01:30:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/30 01:30:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.47 seconds.
[11/30 01:30:15] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 25.193 | 42.734 | 26.597 | 1.794 | 10.767 | 30.091 |
[11/30 01:30:15] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 28.164 | bird          | 57.980 | hat with a wide brim | 21.385 |
| person                | 15.802 | dog           | 65.336 | lizard               | 28.877 |
| sheep                 | 31.741 | wine bottle   | 20.426 | bowl                 | 28.934 |
| airplane              | 41.808 | domestic cat  | 31.996 | car                  | 50.425 |
| porcupine             | 39.823 | bear          | 41.274 | tape player          | 22.404 |
| ray                   | 17.764 | laptop        | 19.252 | zebra                | 39.166 |
| computer keyboard     | 20.812 | pitcher       | 26.774 | artichoke            | 39.126 |
| tv or monitor         | 17.564 | table         | 18.496 | chair                | 14.235 |
| helmet                | 25.390 | traffic light | 8.483  | red panda            | 38.091 |
| sunglasses            | 8.127  | lamp          | 9.477  | bicycle              | 26.558 |
| backpack              | 14.940 | mushroom      | 11.183 | fox                  | 38.903 |
| otter                 | 17.983 | guitar        | 18.498 | microphone           | 2.738  |
| strawberry            | 16.585 | stove         | 24.549 | violin               | 5.342  |
| bookshelf             | 25.151 | sofa          | 19.851 | bell pepper          | 25.500 |
| bagel                 | 26.895 | lemon         | 22.831 | orange               | 21.553 |
| bench                 | 9.352  | piano         | 34.920 | flower pot           | 9.275  |
| butterfly             | 51.736 | purse         | 17.477 | pomegranate          | 14.530 |
| train                 | 40.996 | drum          | 10.707 | hippopotamus         | 10.097 |
| ski                   | 4.978  | ladybug       | 36.520 | banana               | 7.294  |
| monkey                | 34.660 | bus           | 47.258 | miniskirt            | 11.934 |
| camel                 | 27.190 | cream         | 30.349 | lobster              | 18.649 |
| seal                  | 15.905 | horse         | 25.916 | cart                 | 28.025 |
| elephant              | 39.372 | snake         | 28.006 | fig                  | 12.037 |
| watercraft            | 42.179 | apple         | 28.241 | antelope             | 50.379 |
| cattle                | 9.004  | whale         | 33.007 | coffee maker         | 40.847 |
| baby bed              | 36.726 | frog          | 36.838 | bathing cap          | 19.272 |
| crutch                | 3.289  | koala bear    | 36.532 | tie                  | 8.106  |
| dumbbell              | 6.290  | tiger         | 34.999 | dragonfly            | 26.294 |
| goldfish              | 20.326 | cucumber      | 9.241  | turtle               | 37.873 |
| harp                  | 24.950 | jellyfish     | 27.902 | swine                | 26.040 |
| pretzel               | 15.108 | motorcycle    | 36.447 | beaker               | 30.011 |
| rabbit                | 44.405 | nail          | 3.363  | axe                  | 14.584 |
| salt or pepper shaker | 18.968 | croquet ball  | 23.587 | skunk                | 30.077 |
| starfish              | 29.036 |               |        |                      |        |
[11/30 01:30:17] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/30 01:30:17] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/30 01:30:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/30 01:30:17] d2.evaluation.testing INFO: copypaste: 25.1930,42.7338,26.5965,1.7945,10.7670,30.0910
[11/30 01:30:17] d2.utils.events INFO:  eta: 1:41:43  iter: 999  total_loss: 0.1415  loss_cls: 0.05181  loss_box_reg: 0.06572  loss_rpn_cls: 0.006433  loss_rpn_loc: 0.01453  time: 0.6799  data_time: 0.0726  lr: 0.004  max_mem: 11811M
