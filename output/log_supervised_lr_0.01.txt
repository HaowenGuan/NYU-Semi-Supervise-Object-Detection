[11/17 15:16:13] detectron2 INFO: Rank of current process: 0. World size: 6
[11/17 15:16:17] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 15:16:17] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/17 15:16:17] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "../../output/supervised/model_supervised.pth"
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (102000, 108000)
  MAX_ITER: 111000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.01
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: "../../output/supervised"
[11/17 15:16:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ../../output/supervised/model_supervised.pth
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 111000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 102000
  - 108000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/17 15:16:17] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/17 15:16:18] d2.utils.env INFO: Using a generated random seed 20325642
[11/17 15:16:18] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/17 15:16:18] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 15:16:18] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/17 15:16:18] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/17 15:16:19] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 283          |     bird      | 4331         | hat with a .. | 206          |
|    person     | 4657         |      dog      | 8341         |    lizard     | 640          |
|     sheep     | 196          |  wine bottle  | 154          |     bowl      | 335          |
|   airplane    | 217          | domestic cat  | 395          |      car      | 1171         |
|   porcupine   | 126          |     bear      | 361          |  tape player  | 109          |
|      ray      | 198          |    laptop     | 172          |     zebra     | 135          |
| computer ke.. | 102          |    pitcher    | 120          |   artichoke   | 180          |
| tv or monitor | 212          |     table     | 786          |     chair     | 905          |
|    helmet     | 433          | traffic light | 142          |   red panda   | 108          |
|  sunglasses   | 243          |     lamp      | 319          |    bicycle    | 187          |
|   backpack    | 148          |   mushroom    | 124          |      fox      | 292          |
|     otter     | 127          |    guitar     | 295          |  microphone   | 259          |
|  strawberry   | 232          |     stove     | 156          |    violin     | 118          |
|   bookshelf   | 106          |     sofa      | 160          |  bell pepper  | 146          |
|     bagel     | 125          |     lemon     | 170          |    orange     | 207          |
|     bench     | 150          |     piano     | 199          |  flower pot   | 189          |
|   butterfly   | 453          |     purse     | 130          |  pomegranate  | 188          |
|     train     | 178          |     drum      | 251          | hippopotamus  | 118          |
|      ski      | 109          |    ladybug    | 138          |    banana     | 244          |
|    monkey     | 1004         |      bus      | 322          |   miniskirt   | 118          |
|     camel     | 276          |     cream     | 194          |    lobster    | 253          |
|     seal      | 224          |     horse     | 265          |     cart      | 281          |
|   elephant    | 242          |     snake     | 1001         |      fig      | 133          |
|  watercraft   | 1038         |     apple     | 216          |   antelope    | 288          |
|    cattle     | 148          |     whale     | 155          | coffee maker  | 143          |
|   baby bed    | 185          |     frog      | 245          |  bathing cap  | 163          |
|    crutch     | 138          |  koala bear   | 139          |      tie      | 124          |
|   dumbbell    | 180          |     tiger     | 159          |   dragonfly   | 175          |
|   goldfish    | 228          |   cucumber    | 114          |    turtle     | 313          |
|     harp      | 152          |   jellyfish   | 184          |     swine     | 259          |
|    pretzel    | 124          |  motorcycle   | 278          |    beaker     | 115          |
|    rabbit     | 235          |     nail      | 86           |      axe      | 127          |
| salt or pep.. | 129          | croquet ball  | 135          |     skunk     | 99           |
|   starfish    | 130          |               |              |               |              |
|     total     | 41293        |               |              |               |              |[0m
[11/17 15:16:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/17 15:16:19] d2.data.build INFO: Using training sampler TrainingSampler
[11/17 15:16:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 15:16:19] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/17 15:16:19] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/17 15:16:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_supervised.pth ...
[11/17 15:16:20] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/17 15:16:20] d2.engine.train_loop INFO: Starting training from iteration 0
[11/17 15:16:42] d2.utils.events INFO:  eta: 21:12:23  iter: 19  total_loss: 0.4109  loss_cls: 0.2853  loss_box_reg: 0.09846  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.01603  time: 0.6826  data_time: 0.3791  lr: 0.00019981  max_mem: 11810M
[11/17 15:16:55] d2.utils.events INFO:  eta: 21:12:09  iter: 39  total_loss: 0.3992  loss_cls: 0.2716  loss_box_reg: 0.1011  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.01737  time: 0.6832  data_time: 0.0717  lr: 0.00039961  max_mem: 11811M
[11/17 15:17:09] d2.utils.events INFO:  eta: 21:08:40  iter: 59  total_loss: 0.391  loss_cls: 0.2477  loss_box_reg: 0.1047  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.01678  time: 0.6833  data_time: 0.0755  lr: 0.00059941  max_mem: 11811M
[11/17 15:17:23] d2.utils.events INFO:  eta: 21:04:48  iter: 79  total_loss: 0.3388  loss_cls: 0.2127  loss_box_reg: 0.091  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01666  time: 0.6808  data_time: 0.0646  lr: 0.00079921  max_mem: 11811M
[11/17 15:17:36] d2.utils.events INFO:  eta: 21:04:17  iter: 99  total_loss: 0.3417  loss_cls: 0.2152  loss_box_reg: 0.1006  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.01747  time: 0.6799  data_time: 0.0684  lr: 0.00099901  max_mem: 11811M
[11/17 15:17:50] d2.utils.events INFO:  eta: 20:57:42  iter: 119  total_loss: 0.336  loss_cls: 0.2076  loss_box_reg: 0.09424  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.01655  time: 0.6812  data_time: 0.0737  lr: 0.0011988  max_mem: 11811M
[11/17 15:18:03] d2.utils.events INFO:  eta: 20:56:54  iter: 139  total_loss: 0.3246  loss_cls: 0.2032  loss_box_reg: 0.09696  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.01571  time: 0.6807  data_time: 0.0680  lr: 0.0013986  max_mem: 11811M
[11/17 15:18:17] d2.utils.events INFO:  eta: 20:58:57  iter: 159  total_loss: 0.3403  loss_cls: 0.2135  loss_box_reg: 0.0985  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01665  time: 0.6825  data_time: 0.0832  lr: 0.0015984  max_mem: 11811M
[11/17 15:18:31] d2.utils.events INFO:  eta: 20:54:19  iter: 179  total_loss: 0.3288  loss_cls: 0.2047  loss_box_reg: 0.0956  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01789  time: 0.6815  data_time: 0.0634  lr: 0.0017982  max_mem: 11811M
[11/17 15:18:45] d2.utils.events INFO:  eta: 20:52:59  iter: 199  total_loss: 0.3182  loss_cls: 0.1949  loss_box_reg: 0.0952  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01682  time: 0.6832  data_time: 0.0863  lr: 0.001998  max_mem: 11811M
[11/17 15:18:58] d2.utils.events INFO:  eta: 20:52:46  iter: 219  total_loss: 0.3038  loss_cls: 0.1848  loss_box_reg: 0.09147  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.01725  time: 0.6830  data_time: 0.0631  lr: 0.0021978  max_mem: 11811M
[11/17 15:19:12] d2.utils.events INFO:  eta: 20:52:05  iter: 239  total_loss: 0.3332  loss_cls: 0.2002  loss_box_reg: 0.1035  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01722  time: 0.6823  data_time: 0.0624  lr: 0.0023976  max_mem: 11811M
[11/17 15:19:26] d2.utils.events INFO:  eta: 20:52:19  iter: 259  total_loss: 0.3143  loss_cls: 0.1922  loss_box_reg: 0.09516  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.01689  time: 0.6823  data_time: 0.0653  lr: 0.0025974  max_mem: 11811M
[11/17 15:19:39] d2.utils.events INFO:  eta: 20:51:38  iter: 279  total_loss: 0.324  loss_cls: 0.1941  loss_box_reg: 0.09594  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.01931  time: 0.6821  data_time: 0.0656  lr: 0.0027972  max_mem: 11811M
[11/17 15:19:53] d2.utils.events INFO:  eta: 20:51:25  iter: 299  total_loss: 0.3239  loss_cls: 0.1984  loss_box_reg: 0.09533  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.01521  time: 0.6818  data_time: 0.0649  lr: 0.002997  max_mem: 11811M
[11/17 15:20:06] d2.utils.events INFO:  eta: 20:51:38  iter: 319  total_loss: 0.3325  loss_cls: 0.2014  loss_box_reg: 0.1021  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01656  time: 0.6816  data_time: 0.0644  lr: 0.0031968  max_mem: 11811M
[11/17 15:20:20] d2.utils.events INFO:  eta: 20:51:54  iter: 339  total_loss: 0.3024  loss_cls: 0.1827  loss_box_reg: 0.09324  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01875  time: 0.6819  data_time: 0.0624  lr: 0.0033966  max_mem: 11811M
[11/17 15:20:34] d2.utils.events INFO:  eta: 20:52:48  iter: 359  total_loss: 0.3127  loss_cls: 0.1837  loss_box_reg: 0.09377  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01658  time: 0.6819  data_time: 0.0651  lr: 0.0035964  max_mem: 11811M
[11/17 15:20:47] d2.utils.events INFO:  eta: 20:53:03  iter: 379  total_loss: 0.303  loss_cls: 0.1795  loss_box_reg: 0.09557  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01726  time: 0.6821  data_time: 0.0680  lr: 0.0037962  max_mem: 11811M
[11/17 15:21:01] d2.utils.events INFO:  eta: 20:52:59  iter: 399  total_loss: 0.2931  loss_cls: 0.1788  loss_box_reg: 0.09152  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01614  time: 0.6820  data_time: 0.0681  lr: 0.003996  max_mem: 11811M
[11/17 15:21:15] d2.utils.events INFO:  eta: 20:52:22  iter: 419  total_loss: 0.3274  loss_cls: 0.1945  loss_box_reg: 0.09691  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.01809  time: 0.6820  data_time: 0.0701  lr: 0.0041958  max_mem: 11811M
[11/17 15:21:28] d2.utils.events INFO:  eta: 20:51:54  iter: 439  total_loss: 0.3236  loss_cls: 0.1915  loss_box_reg: 0.09969  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.0159  time: 0.6820  data_time: 0.0739  lr: 0.0043956  max_mem: 11811M
[11/17 15:21:42] d2.utils.events INFO:  eta: 20:53:09  iter: 459  total_loss: 0.3174  loss_cls: 0.1808  loss_box_reg: 0.09456  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.01738  time: 0.6826  data_time: 0.0655  lr: 0.0045954  max_mem: 11811M
[11/17 15:21:56] d2.utils.events INFO:  eta: 20:52:55  iter: 479  total_loss: 0.2961  loss_cls: 0.1735  loss_box_reg: 0.09375  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01687  time: 0.6825  data_time: 0.0614  lr: 0.0047952  max_mem: 11811M
[11/17 15:22:09] d2.utils.events INFO:  eta: 20:52:51  iter: 499  total_loss: 0.3105  loss_cls: 0.1818  loss_box_reg: 0.09581  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.01562  time: 0.6824  data_time: 0.0601  lr: 0.004995  max_mem: 11811M
[11/17 15:22:23] d2.utils.events INFO:  eta: 20:52:01  iter: 519  total_loss: 0.3095  loss_cls: 0.1803  loss_box_reg: 0.09656  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01723  time: 0.6823  data_time: 0.0681  lr: 0.0051948  max_mem: 11811M
[11/17 15:22:37] d2.utils.events INFO:  eta: 20:52:08  iter: 539  total_loss: 0.29  loss_cls: 0.1698  loss_box_reg: 0.09245  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01863  time: 0.6824  data_time: 0.0611  lr: 0.0053946  max_mem: 11811M
[11/17 15:22:50] d2.utils.events INFO:  eta: 20:51:34  iter: 559  total_loss: 0.2925  loss_cls: 0.1702  loss_box_reg: 0.09397  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01662  time: 0.6822  data_time: 0.0661  lr: 0.0055944  max_mem: 11811M
[11/17 15:23:04] d2.utils.events INFO:  eta: 20:51:47  iter: 579  total_loss: 0.2895  loss_cls: 0.1722  loss_box_reg: 0.09032  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01666  time: 0.6822  data_time: 0.0685  lr: 0.0057942  max_mem: 11811M
[11/17 15:23:18] d2.utils.events INFO:  eta: 20:51:43  iter: 599  total_loss: 0.2913  loss_cls: 0.1657  loss_box_reg: 0.09295  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.01859  time: 0.6823  data_time: 0.0711  lr: 0.005994  max_mem: 11811M
[11/17 15:23:31] d2.utils.events INFO:  eta: 20:51:01  iter: 619  total_loss: 0.301  loss_cls: 0.1759  loss_box_reg: 0.09412  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01571  time: 0.6820  data_time: 0.0616  lr: 0.0061938  max_mem: 11811M
[11/17 15:23:45] d2.utils.events INFO:  eta: 20:50:07  iter: 639  total_loss: 0.2871  loss_cls: 0.1652  loss_box_reg: 0.09015  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.01636  time: 0.6818  data_time: 0.0623  lr: 0.0063936  max_mem: 11811M
[11/17 15:23:58] d2.utils.events INFO:  eta: 20:50:08  iter: 659  total_loss: 0.2842  loss_cls: 0.1657  loss_box_reg: 0.09644  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.01846  time: 0.6818  data_time: 0.0641  lr: 0.0065934  max_mem: 11811M
[11/17 15:24:12] d2.utils.events INFO:  eta: 20:50:33  iter: 679  total_loss: 0.3076  loss_cls: 0.1764  loss_box_reg: 0.09974  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.01985  time: 0.6819  data_time: 0.0687  lr: 0.0067932  max_mem: 11811M
[11/17 15:24:26] d2.utils.events INFO:  eta: 20:49:32  iter: 699  total_loss: 0.2866  loss_cls: 0.1674  loss_box_reg: 0.09127  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01889  time: 0.6817  data_time: 0.0601  lr: 0.006993  max_mem: 11811M
[11/17 15:24:39] d2.utils.events INFO:  eta: 20:50:01  iter: 719  total_loss: 0.3129  loss_cls: 0.1768  loss_box_reg: 0.0995  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01762  time: 0.6819  data_time: 0.0651  lr: 0.0071928  max_mem: 11811M
[11/17 15:24:53] d2.utils.events INFO:  eta: 20:49:25  iter: 739  total_loss: 0.2748  loss_cls: 0.1512  loss_box_reg: 0.0914  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.01727  time: 0.6817  data_time: 0.0675  lr: 0.0073926  max_mem: 11811M
[11/17 15:25:06] d2.utils.events INFO:  eta: 20:48:51  iter: 759  total_loss: 0.3052  loss_cls: 0.1717  loss_box_reg: 0.09915  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01734  time: 0.6816  data_time: 0.0666  lr: 0.0075924  max_mem: 11811M
[11/17 15:25:20] d2.utils.events INFO:  eta: 20:48:57  iter: 779  total_loss: 0.2917  loss_cls: 0.162  loss_box_reg: 0.0942  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.01794  time: 0.6816  data_time: 0.0664  lr: 0.0077922  max_mem: 11811M
[11/17 15:25:33] d2.utils.events INFO:  eta: 20:48:18  iter: 799  total_loss: 0.2809  loss_cls: 0.1584  loss_box_reg: 0.09048  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01666  time: 0.6814  data_time: 0.0672  lr: 0.007992  max_mem: 11811M
[11/17 15:25:47] d2.utils.events INFO:  eta: 20:48:10  iter: 819  total_loss: 0.2869  loss_cls: 0.1646  loss_box_reg: 0.09079  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.0187  time: 0.6815  data_time: 0.0658  lr: 0.0081918  max_mem: 11811M
[11/17 15:26:01] d2.utils.events INFO:  eta: 20:47:57  iter: 839  total_loss: 0.2877  loss_cls: 0.1629  loss_box_reg: 0.09054  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01755  time: 0.6814  data_time: 0.0582  lr: 0.0083916  max_mem: 11811M
[11/17 15:26:15] d2.utils.events INFO:  eta: 20:48:17  iter: 859  total_loss: 0.2961  loss_cls: 0.1689  loss_box_reg: 0.09575  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.01945  time: 0.6817  data_time: 0.0714  lr: 0.0085914  max_mem: 11811M
[11/17 15:26:28] d2.utils.events INFO:  eta: 20:48:42  iter: 879  total_loss: 0.2869  loss_cls: 0.1655  loss_box_reg: 0.09129  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01936  time: 0.6819  data_time: 0.0692  lr: 0.0087912  max_mem: 11811M
[11/17 15:26:42] d2.utils.events INFO:  eta: 20:48:28  iter: 899  total_loss: 0.2787  loss_cls: 0.1591  loss_box_reg: 0.09124  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.01835  time: 0.6819  data_time: 0.0621  lr: 0.008991  max_mem: 11811M
[11/17 15:26:56] d2.utils.events INFO:  eta: 20:48:15  iter: 919  total_loss: 0.2773  loss_cls: 0.1571  loss_box_reg: 0.09063  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.01688  time: 0.6819  data_time: 0.0658  lr: 0.0091908  max_mem: 11811M
[11/17 15:27:09] d2.utils.events INFO:  eta: 20:48:08  iter: 939  total_loss: 0.2771  loss_cls: 0.1582  loss_box_reg: 0.09353  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.01668  time: 0.6820  data_time: 0.0712  lr: 0.0093906  max_mem: 11811M
[11/17 15:27:23] d2.utils.events INFO:  eta: 20:47:54  iter: 959  total_loss: 0.2572  loss_cls: 0.142  loss_box_reg: 0.08181  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01873  time: 0.6821  data_time: 0.0775  lr: 0.0095904  max_mem: 11811M
[11/17 15:27:37] d2.utils.events INFO:  eta: 20:47:34  iter: 979  total_loss: 0.2719  loss_cls: 0.1522  loss_box_reg: 0.0895  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.01774  time: 0.6820  data_time: 0.0678  lr: 0.0097902  max_mem: 11811M
[11/17 15:27:50] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0000999.pth
[11/17 15:27:51] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 15:27:51] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 15:27:52] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/17 15:27:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 15:27:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 15:27:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 15:27:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 15:27:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 15:27:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0382 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:02:11
[11/17 15:28:04] d2.evaluation.evaluator INFO: Inference done 137/3334. Dataloading: 0.0015 s/iter. Inference: 0.0381 s/iter. Eval: 0.0002 s/iter. Total: 0.0398 s/iter. ETA=0:02:07
[11/17 15:28:09] d2.evaluation.evaluator INFO: Inference done 260/3334. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:04
[11/17 15:28:14] d2.evaluation.evaluator INFO: Inference done 383/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:59
[11/17 15:28:19] d2.evaluation.evaluator INFO: Inference done 506/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/17 15:28:24] d2.evaluation.evaluator INFO: Inference done 630/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:49
[11/17 15:28:29] d2.evaluation.evaluator INFO: Inference done 754/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:44
[11/17 15:28:34] d2.evaluation.evaluator INFO: Inference done 876/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:39
[11/17 15:28:39] d2.evaluation.evaluator INFO: Inference done 998/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:35
[11/17 15:28:44] d2.evaluation.evaluator INFO: Inference done 1123/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:29
[11/17 15:28:49] d2.evaluation.evaluator INFO: Inference done 1244/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:25
[11/17 15:28:54] d2.evaluation.evaluator INFO: Inference done 1366/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:20
[11/17 15:28:59] d2.evaluation.evaluator INFO: Inference done 1488/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/17 15:29:04] d2.evaluation.evaluator INFO: Inference done 1615/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:09
[11/17 15:29:09] d2.evaluation.evaluator INFO: Inference done 1739/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:04
[11/17 15:29:14] d2.evaluation.evaluator INFO: Inference done 1860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:00
[11/17 15:29:19] d2.evaluation.evaluator INFO: Inference done 1984/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:54
[11/17 15:29:24] d2.evaluation.evaluator INFO: Inference done 2107/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:49
[11/17 15:29:29] d2.evaluation.evaluator INFO: Inference done 2230/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:44
[11/17 15:29:34] d2.evaluation.evaluator INFO: Inference done 2351/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/17 15:29:39] d2.evaluation.evaluator INFO: Inference done 2475/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/17 15:29:45] d2.evaluation.evaluator INFO: Inference done 2594/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/17 15:29:50] d2.evaluation.evaluator INFO: Inference done 2720/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:25
[11/17 15:29:55] d2.evaluation.evaluator INFO: Inference done 2844/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:19
[11/17 15:30:00] d2.evaluation.evaluator INFO: Inference done 2968/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:14
[11/17 15:30:05] d2.evaluation.evaluator INFO: Inference done 3086/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:10
[11/17 15:30:10] d2.evaluation.evaluator INFO: Inference done 3207/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/17 15:30:15] d2.evaluation.evaluator INFO: Inference done 3331/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:00
[11/17 15:30:15] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.405067 (0.040975 s / iter per device, on 6 devices)
[11/17 15:30:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038976 s / iter per device, on 6 devices)
[11/17 15:30:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 15:30:18] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 15:30:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 15:30:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 15:30:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.89 seconds.
[11/17 15:30:41] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 15:30:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.61 seconds.
[11/17 15:30:43] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.071 | 6.888  | 2.243  | 0.370 | 1.278 | 3.577 |
[11/17 15:30:43] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 0.320  | bird          | 20.338 | hat with a wide brim | 0.255  |
| person                | 5.022  | dog           | 37.156 | lizard               | 3.752  |
| sheep                 | 0.502  | wine bottle   | 0.594  | bowl                 | 5.408  |
| airplane              | 9.138  | domestic cat  | 1.900  | car                  | 22.173 |
| porcupine             | 2.888  | bear          | 4.077  | tape player          | 0.594  |
| ray                   | 0.910  | laptop        | 2.090  | zebra                | 8.795  |
| computer keyboard     | 0.000  | pitcher       | 0.000  | artichoke            | 4.147  |
| tv or monitor         | 9.042  | table         | 2.964  | chair                | 1.820  |
| helmet                | 2.274  | traffic light | 0.282  | red panda            | 0.000  |
| sunglasses            | 0.198  | lamp          | 0.182  | bicycle              | 1.455  |
| backpack              | 0.104  | mushroom      | 0.000  | fox                  | 1.080  |
| otter                 | 0.000  | guitar        | 0.000  | microphone           | 0.000  |
| strawberry            | 2.215  | stove         | 0.764  | violin               | 0.000  |
| bookshelf             | 2.065  | sofa          | 0.033  | bell pepper          | 2.655  |
| bagel                 | 0.342  | lemon         | 3.029  | orange               | 6.874  |
| bench                 | 0.000  | piano         | 5.528  | flower pot           | 0.037  |
| butterfly             | 13.078 | purse         | 0.357  | pomegranate          | 0.586  |
| train                 | 0.650  | drum          | 0.469  | hippopotamus         | 0.085  |
| ski                   | 0.000  | ladybug       | 16.256 | banana               | 0.128  |
| monkey                | 4.857  | bus           | 14.852 | miniskirt            | 0.000  |
| camel                 | 0.072  | cream         | 0.172  | lobster              | 0.670  |
| seal                  | 0.000  | horse         | 1.454  | cart                 | 3.798  |
| elephant              | 5.053  | snake         | 5.028  | fig                  | 0.392  |
| watercraft            | 15.392 | apple         | 7.213  | antelope             | 1.852  |
| cattle                | 1.700  | whale         | 1.391  | coffee maker         | 5.253  |
| baby bed              | 4.017  | frog          | 3.617  | bathing cap          | 0.318  |
| crutch                | 0.000  | koala bear    | 0.940  | tie                  | 0.015  |
| dumbbell              | 0.000  | tiger         | 0.000  | dragonfly            | 0.439  |
| goldfish              | 0.119  | cucumber      | 0.037  | turtle               | 2.473  |
| harp                  | 3.219  | jellyfish     | 4.201  | swine                | 1.338  |
| pretzel               | 0.116  | motorcycle    | 4.460  | beaker               | 3.757  |
| rabbit                | 1.795  | nail          | 0.000  | axe                  | 0.000  |
| salt or pepper shaker | 0.000  | croquet ball  | 2.414  | skunk                | 0.032  |
| starfish              | 0.000  |               |        |                      |        |
[11/17 15:30:45] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 15:30:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 15:30:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 15:30:45] d2.evaluation.testing INFO: copypaste: 3.0706,6.8876,2.2430,0.3698,1.2776,3.5768
[11/17 15:30:45] d2.utils.events INFO:  eta: 20:46:57  iter: 999  total_loss: 0.2952  loss_cls: 0.1645  loss_box_reg: 0.09648  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.0179  time: 0.6820  data_time: 0.0654  lr: 0.00999  max_mem: 11811M
[11/17 15:30:59] d2.utils.events INFO:  eta: 20:46:37  iter: 1019  total_loss: 0.2842  loss_cls: 0.1527  loss_box_reg: 0.094  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.01927  time: 0.6819  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/17 15:31:12] d2.utils.events INFO:  eta: 20:46:30  iter: 1039  total_loss: 0.2777  loss_cls: 0.1566  loss_box_reg: 0.08965  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.0182  time: 0.6820  data_time: 0.0619  lr: 0.01  max_mem: 11811M
[11/17 15:31:26] d2.utils.events INFO:  eta: 20:46:30  iter: 1059  total_loss: 0.286  loss_cls: 0.1659  loss_box_reg: 0.09364  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01925  time: 0.6821  data_time: 0.0649  lr: 0.01  max_mem: 11811M
[11/17 15:31:40] d2.utils.events INFO:  eta: 20:46:23  iter: 1079  total_loss: 0.2809  loss_cls: 0.1524  loss_box_reg: 0.0934  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.0179  time: 0.6821  data_time: 0.0790  lr: 0.01  max_mem: 11811M
[11/17 15:31:53] d2.utils.events INFO:  eta: 20:46:00  iter: 1099  total_loss: 0.2732  loss_cls: 0.1508  loss_box_reg: 0.09249  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01728  time: 0.6821  data_time: 0.0660  lr: 0.01  max_mem: 11811M
[11/17 15:32:07] d2.utils.events INFO:  eta: 20:45:35  iter: 1119  total_loss: 0.2758  loss_cls: 0.154  loss_box_reg: 0.09128  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.0176  time: 0.6820  data_time: 0.0630  lr: 0.01  max_mem: 11811M
[11/17 15:32:20] d2.utils.events INFO:  eta: 20:45:07  iter: 1139  total_loss: 0.2806  loss_cls: 0.1544  loss_box_reg: 0.09323  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.01885  time: 0.6818  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/17 15:32:34] d2.utils.events INFO:  eta: 20:44:53  iter: 1159  total_loss: 0.2873  loss_cls: 0.1532  loss_box_reg: 0.09324  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.01889  time: 0.6819  data_time: 0.0670  lr: 0.01  max_mem: 11811M
[11/17 15:32:48] d2.utils.events INFO:  eta: 20:44:49  iter: 1179  total_loss: 0.2697  loss_cls: 0.1513  loss_box_reg: 0.08727  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.0167  time: 0.6819  data_time: 0.0653  lr: 0.01  max_mem: 11811M
[11/17 15:33:02] d2.utils.events INFO:  eta: 20:45:01  iter: 1199  total_loss: 0.292  loss_cls: 0.1627  loss_box_reg: 0.09121  loss_rpn_cls: 0.013  loss_rpn_loc: 0.01817  time: 0.6821  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 15:33:15] d2.utils.events INFO:  eta: 20:44:47  iter: 1219  total_loss: 0.2777  loss_cls: 0.1525  loss_box_reg: 0.09065  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01788  time: 0.6821  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/17 15:33:29] d2.utils.events INFO:  eta: 20:45:48  iter: 1239  total_loss: 0.2862  loss_cls: 0.1579  loss_box_reg: 0.09047  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.01681  time: 0.6821  data_time: 0.0665  lr: 0.01  max_mem: 11811M
[11/17 15:33:42] d2.utils.events INFO:  eta: 20:44:57  iter: 1259  total_loss: 0.2731  loss_cls: 0.1499  loss_box_reg: 0.09223  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.01689  time: 0.6820  data_time: 0.0601  lr: 0.01  max_mem: 11811M
[11/17 15:33:56] d2.utils.events INFO:  eta: 20:45:21  iter: 1279  total_loss: 0.2729  loss_cls: 0.1517  loss_box_reg: 0.08879  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01893  time: 0.6820  data_time: 0.0611  lr: 0.01  max_mem: 11811M
[11/17 15:34:09] d2.utils.events INFO:  eta: 20:44:29  iter: 1299  total_loss: 0.2741  loss_cls: 0.1479  loss_box_reg: 0.09219  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.0192  time: 0.6819  data_time: 0.0636  lr: 0.01  max_mem: 11811M
[11/17 15:34:23] d2.utils.events INFO:  eta: 20:44:33  iter: 1319  total_loss: 0.2706  loss_cls: 0.1471  loss_box_reg: 0.09245  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01759  time: 0.6819  data_time: 0.0684  lr: 0.01  max_mem: 11811M
[11/17 15:34:37] d2.utils.events INFO:  eta: 20:43:50  iter: 1339  total_loss: 0.2666  loss_cls: 0.144  loss_box_reg: 0.09037  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.01848  time: 0.6818  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/17 15:34:51] d2.utils.events INFO:  eta: 20:44:22  iter: 1359  total_loss: 0.2727  loss_cls: 0.1503  loss_box_reg: 0.09221  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01741  time: 0.6820  data_time: 0.0655  lr: 0.01  max_mem: 11811M
[11/17 15:35:04] d2.utils.events INFO:  eta: 20:43:22  iter: 1379  total_loss: 0.2773  loss_cls: 0.1575  loss_box_reg: 0.09535  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01694  time: 0.6819  data_time: 0.0624  lr: 0.01  max_mem: 11811M
[11/17 15:35:18] d2.utils.events INFO:  eta: 20:42:31  iter: 1399  total_loss: 0.2783  loss_cls: 0.1498  loss_box_reg: 0.09053  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.01795  time: 0.6818  data_time: 0.0655  lr: 0.01  max_mem: 11811M
[11/17 15:35:31] d2.utils.events INFO:  eta: 20:42:55  iter: 1419  total_loss: 0.2958  loss_cls: 0.1617  loss_box_reg: 0.09345  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.01733  time: 0.6818  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 15:35:45] d2.utils.events INFO:  eta: 20:43:12  iter: 1439  total_loss: 0.2901  loss_cls: 0.1596  loss_box_reg: 0.09226  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01811  time: 0.6819  data_time: 0.0705  lr: 0.01  max_mem: 11811M
[11/17 15:35:59] d2.utils.events INFO:  eta: 20:42:04  iter: 1459  total_loss: 0.2731  loss_cls: 0.1452  loss_box_reg: 0.08945  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.01757  time: 0.6820  data_time: 0.0783  lr: 0.01  max_mem: 11811M
[11/17 15:36:12] d2.utils.events INFO:  eta: 20:41:51  iter: 1479  total_loss: 0.2698  loss_cls: 0.1499  loss_box_reg: 0.08856  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.0162  time: 0.6820  data_time: 0.0655  lr: 0.01  max_mem: 11811M
[11/17 15:36:26] d2.utils.events INFO:  eta: 20:42:01  iter: 1499  total_loss: 0.2676  loss_cls: 0.149  loss_box_reg: 0.09148  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.01747  time: 0.6821  data_time: 0.0692  lr: 0.01  max_mem: 11811M
[11/17 15:36:40] d2.utils.events INFO:  eta: 20:42:00  iter: 1519  total_loss: 0.2761  loss_cls: 0.1523  loss_box_reg: 0.09407  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.01706  time: 0.6821  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/17 15:36:53] d2.utils.events INFO:  eta: 20:41:34  iter: 1539  total_loss: 0.2741  loss_cls: 0.1538  loss_box_reg: 0.0869  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01604  time: 0.6820  data_time: 0.0598  lr: 0.01  max_mem: 11811M
[11/17 15:37:07] d2.utils.events INFO:  eta: 20:40:46  iter: 1559  total_loss: 0.2659  loss_cls: 0.1448  loss_box_reg: 0.08727  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.01689  time: 0.6819  data_time: 0.0615  lr: 0.01  max_mem: 11811M
[11/17 15:37:21] d2.utils.events INFO:  eta: 20:40:48  iter: 1579  total_loss: 0.267  loss_cls: 0.1459  loss_box_reg: 0.08844  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.01846  time: 0.6819  data_time: 0.0640  lr: 0.01  max_mem: 11811M
[11/17 15:37:34] d2.utils.events INFO:  eta: 20:40:02  iter: 1599  total_loss: 0.2832  loss_cls: 0.1529  loss_box_reg: 0.09499  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01627  time: 0.6821  data_time: 0.0853  lr: 0.01  max_mem: 11811M
[11/17 15:37:48] d2.utils.events INFO:  eta: 20:39:54  iter: 1619  total_loss: 0.2713  loss_cls: 0.1432  loss_box_reg: 0.09278  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01855  time: 0.6820  data_time: 0.0674  lr: 0.01  max_mem: 11811M
[11/17 15:38:02] d2.utils.events INFO:  eta: 20:40:22  iter: 1639  total_loss: 0.2709  loss_cls: 0.1494  loss_box_reg: 0.08886  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01834  time: 0.6820  data_time: 0.0665  lr: 0.01  max_mem: 11811M
[11/17 15:38:15] d2.utils.events INFO:  eta: 20:40:09  iter: 1659  total_loss: 0.266  loss_cls: 0.1452  loss_box_reg: 0.08827  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01686  time: 0.6821  data_time: 0.0735  lr: 0.01  max_mem: 11811M
[11/17 15:38:29] d2.utils.events INFO:  eta: 20:39:24  iter: 1679  total_loss: 0.2664  loss_cls: 0.1453  loss_box_reg: 0.09133  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.01654  time: 0.6821  data_time: 0.0676  lr: 0.01  max_mem: 11811M
[11/17 15:38:43] d2.utils.events INFO:  eta: 20:40:22  iter: 1699  total_loss: 0.2799  loss_cls: 0.152  loss_box_reg: 0.0951  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01811  time: 0.6822  data_time: 0.0635  lr: 0.01  max_mem: 11811M
[11/17 15:38:57] d2.utils.events INFO:  eta: 20:40:14  iter: 1719  total_loss: 0.2628  loss_cls: 0.1382  loss_box_reg: 0.09028  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.01674  time: 0.6823  data_time: 0.0691  lr: 0.01  max_mem: 11811M
[11/17 15:39:10] d2.utils.events INFO:  eta: 20:40:19  iter: 1739  total_loss: 0.2677  loss_cls: 0.1442  loss_box_reg: 0.09014  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.018  time: 0.6823  data_time: 0.0713  lr: 0.01  max_mem: 11811M
[11/17 15:39:24] d2.utils.events INFO:  eta: 20:40:35  iter: 1759  total_loss: 0.2696  loss_cls: 0.1409  loss_box_reg: 0.09201  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.01797  time: 0.6823  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/17 15:39:38] d2.utils.events INFO:  eta: 20:40:07  iter: 1779  total_loss: 0.2809  loss_cls: 0.1507  loss_box_reg: 0.09313  loss_rpn_cls: 0.014  loss_rpn_loc: 0.01745  time: 0.6822  data_time: 0.0610  lr: 0.01  max_mem: 11811M
[11/17 15:39:51] d2.utils.events INFO:  eta: 20:40:02  iter: 1799  total_loss: 0.2578  loss_cls: 0.142  loss_box_reg: 0.09027  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.01934  time: 0.6822  data_time: 0.0642  lr: 0.01  max_mem: 11811M
[11/17 15:40:05] d2.utils.events INFO:  eta: 20:39:48  iter: 1819  total_loss: 0.2588  loss_cls: 0.1386  loss_box_reg: 0.08792  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.01932  time: 0.6822  data_time: 0.0687  lr: 0.01  max_mem: 11811M
[11/17 15:40:18] d2.utils.events INFO:  eta: 20:39:28  iter: 1839  total_loss: 0.269  loss_cls: 0.148  loss_box_reg: 0.08815  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01813  time: 0.6822  data_time: 0.0736  lr: 0.01  max_mem: 11811M
[11/17 15:40:32] d2.utils.events INFO:  eta: 20:38:02  iter: 1859  total_loss: 0.2614  loss_cls: 0.1426  loss_box_reg: 0.08785  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01671  time: 0.6821  data_time: 0.0637  lr: 0.01  max_mem: 11811M
[11/17 15:40:46] d2.utils.events INFO:  eta: 20:37:08  iter: 1879  total_loss: 0.276  loss_cls: 0.1497  loss_box_reg: 0.09133  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01835  time: 0.6821  data_time: 0.0597  lr: 0.01  max_mem: 11811M
[11/17 15:40:59] d2.utils.events INFO:  eta: 20:36:20  iter: 1899  total_loss: 0.2677  loss_cls: 0.1422  loss_box_reg: 0.08647  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.01854  time: 0.6821  data_time: 0.0802  lr: 0.01  max_mem: 11811M
[11/17 15:41:13] d2.utils.events INFO:  eta: 20:36:01  iter: 1919  total_loss: 0.269  loss_cls: 0.148  loss_box_reg: 0.09304  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01927  time: 0.6822  data_time: 0.0670  lr: 0.01  max_mem: 11811M
[11/17 15:41:26] d2.utils.events INFO:  eta: 20:35:24  iter: 1939  total_loss: 0.2552  loss_cls: 0.1382  loss_box_reg: 0.08759  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.01849  time: 0.6820  data_time: 0.0593  lr: 0.01  max_mem: 11811M
[11/17 15:41:40] d2.utils.events INFO:  eta: 20:35:02  iter: 1959  total_loss: 0.2514  loss_cls: 0.1382  loss_box_reg: 0.08727  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.01799  time: 0.6820  data_time: 0.0711  lr: 0.01  max_mem: 11811M
[11/17 15:41:54] d2.utils.events INFO:  eta: 20:34:48  iter: 1979  total_loss: 0.2568  loss_cls: 0.1388  loss_box_reg: 0.08855  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01834  time: 0.6820  data_time: 0.0663  lr: 0.01  max_mem: 11811M
[11/17 15:42:07] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0001999.pth
[11/17 15:42:08] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 15:42:08] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 15:42:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 15:42:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 15:42:08] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 15:42:08] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 15:42:08] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 15:42:15] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:15
[11/17 15:42:20] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:10
[11/17 15:42:25] d2.evaluation.evaluator INFO: Inference done 260/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:04
[11/17 15:42:30] d2.evaluation.evaluator INFO: Inference done 385/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:59
[11/17 15:42:35] d2.evaluation.evaluator INFO: Inference done 508/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/17 15:42:40] d2.evaluation.evaluator INFO: Inference done 627/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:50
[11/17 15:42:45] d2.evaluation.evaluator INFO: Inference done 753/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:44
[11/17 15:42:50] d2.evaluation.evaluator INFO: Inference done 878/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:39
[11/17 15:42:55] d2.evaluation.evaluator INFO: Inference done 1000/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:34
[11/17 15:43:00] d2.evaluation.evaluator INFO: Inference done 1123/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:29
[11/17 15:43:05] d2.evaluation.evaluator INFO: Inference done 1246/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:24
[11/17 15:43:10] d2.evaluation.evaluator INFO: Inference done 1370/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:19
[11/17 15:43:15] d2.evaluation.evaluator INFO: Inference done 1493/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:14
[11/17 15:43:20] d2.evaluation.evaluator INFO: Inference done 1614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:10
[11/17 15:43:25] d2.evaluation.evaluator INFO: Inference done 1735/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/17 15:43:30] d2.evaluation.evaluator INFO: Inference done 1857/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:00
[11/17 15:43:36] d2.evaluation.evaluator INFO: Inference done 1977/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/17 15:43:41] d2.evaluation.evaluator INFO: Inference done 2098/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:50
[11/17 15:43:46] d2.evaluation.evaluator INFO: Inference done 2220/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:45
[11/17 15:43:51] d2.evaluation.evaluator INFO: Inference done 2340/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/17 15:43:56] d2.evaluation.evaluator INFO: Inference done 2460/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/17 15:44:01] d2.evaluation.evaluator INFO: Inference done 2582/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/17 15:44:06] d2.evaluation.evaluator INFO: Inference done 2706/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/17 15:44:11] d2.evaluation.evaluator INFO: Inference done 2825/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:20
[11/17 15:44:16] d2.evaluation.evaluator INFO: Inference done 2945/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:15
[11/17 15:44:21] d2.evaluation.evaluator INFO: Inference done 3065/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/17 15:44:26] d2.evaluation.evaluator INFO: Inference done 3188/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/17 15:44:31] d2.evaluation.evaluator INFO: Inference done 3313/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:00
[11/17 15:44:32] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.130669 (0.041193 s / iter per device, on 6 devices)
[11/17 15:44:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039287 s / iter per device, on 6 devices)
[11/17 15:44:34] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 15:44:34] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 15:44:35] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 15:44:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 15:44:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.46 seconds.
[11/17 15:44:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 15:44:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.61 seconds.
[11/17 15:44:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.003 | 10.880 | 3.791  | 1.164 | 2.370 | 5.880 |
[11/17 15:44:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 2.496  | bird          | 22.132 | hat with a wide brim | 1.819  |
| person                | 6.044  | dog           | 41.524 | lizard               | 3.023  |
| sheep                 | 1.815  | wine bottle   | 1.220  | bowl                 | 6.194  |
| airplane              | 14.089 | domestic cat  | 4.740  | car                  | 25.170 |
| porcupine             | 10.024 | bear          | 6.695  | tape player          | 3.824  |
| ray                   | 1.424  | laptop        | 3.917  | zebra                | 12.893 |
| computer keyboard     | 0.332  | pitcher       | 1.466  | artichoke            | 8.949  |
| tv or monitor         | 11.297 | table         | 4.482  | chair                | 3.307  |
| helmet                | 4.544  | traffic light | 1.727  | red panda            | 0.413  |
| sunglasses            | 0.031  | lamp          | 1.296  | bicycle              | 2.612  |
| backpack              | 0.719  | mushroom      | 1.875  | fox                  | 3.364  |
| otter                 | 0.393  | guitar        | 2.899  | microphone           | 0.000  |
| strawberry            | 4.864  | stove         | 3.736  | violin               | 0.050  |
| bookshelf             | 8.566  | sofa          | 1.086  | bell pepper          | 5.244  |
| bagel                 | 3.274  | lemon         | 5.715  | orange               | 9.584  |
| bench                 | 0.281  | piano         | 6.456  | flower pot           | 0.301  |
| butterfly             | 18.263 | purse         | 1.570  | pomegranate          | 1.566  |
| train                 | 4.672  | drum          | 0.789  | hippopotamus         | 0.438  |
| ski                   | 0.000  | ladybug       | 22.556 | banana               | 0.298  |
| monkey                | 6.838  | bus           | 14.718 | miniskirt            | 0.350  |
| camel                 | 0.467  | cream         | 4.876  | lobster              | 1.445  |
| seal                  | 0.749  | horse         | 3.539  | cart                 | 7.220  |
| elephant              | 7.262  | snake         | 6.101  | fig                  | 1.569  |
| watercraft            | 17.130 | apple         | 10.090 | antelope             | 11.756 |
| cattle                | 1.231  | whale         | 5.978  | coffee maker         | 11.533 |
| baby bed              | 6.646  | frog          | 6.255  | bathing cap          | 1.601  |
| crutch                | 0.053  | koala bear    | 1.585  | tie                  | 0.122  |
| dumbbell              | 0.139  | tiger         | 0.622  | dragonfly            | 2.562  |
| goldfish              | 1.368  | cucumber      | 0.170  | turtle               | 3.313  |
| harp                  | 1.322  | jellyfish     | 6.065  | swine                | 4.117  |
| pretzel               | 2.199  | motorcycle    | 9.877  | beaker               | 4.905  |
| rabbit                | 7.666  | nail          | 0.102  | axe                  | 0.000  |
| salt or pepper shaker | 0.000  | croquet ball  | 5.175  | skunk                | 1.455  |
| starfish              | 2.110  |               |        |                      |        |
[11/17 15:44:59] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 15:44:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 15:44:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 15:44:59] d2.evaluation.testing INFO: copypaste: 5.0034,10.8801,3.7907,1.1638,2.3705,5.8804
[11/17 15:44:59] d2.utils.events INFO:  eta: 20:34:48  iter: 1999  total_loss: 0.252  loss_cls: 0.1407  loss_box_reg: 0.08931  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.0169  time: 0.6820  data_time: 0.0689  lr: 0.01  max_mem: 11811M
[11/17 15:45:12] d2.utils.events INFO:  eta: 20:34:08  iter: 2019  total_loss: 0.2663  loss_cls: 0.1438  loss_box_reg: 0.09448  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01702  time: 0.6820  data_time: 0.0651  lr: 0.01  max_mem: 11811M
[11/17 15:45:26] d2.utils.events INFO:  eta: 20:33:54  iter: 2039  total_loss: 0.264  loss_cls: 0.1424  loss_box_reg: 0.09123  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.01685  time: 0.6822  data_time: 0.0838  lr: 0.01  max_mem: 11811M
[11/17 15:45:40] d2.utils.events INFO:  eta: 20:33:40  iter: 2059  total_loss: 0.2596  loss_cls: 0.1401  loss_box_reg: 0.09336  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.01762  time: 0.6822  data_time: 0.0647  lr: 0.01  max_mem: 11811M
[11/17 15:45:54] d2.utils.events INFO:  eta: 20:33:54  iter: 2079  total_loss: 0.2575  loss_cls: 0.1348  loss_box_reg: 0.08645  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.01916  time: 0.6823  data_time: 0.0743  lr: 0.01  max_mem: 11811M
[11/17 15:46:07] d2.utils.events INFO:  eta: 20:33:27  iter: 2099  total_loss: 0.2694  loss_cls: 0.1439  loss_box_reg: 0.09156  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01977  time: 0.6823  data_time: 0.0745  lr: 0.01  max_mem: 11811M
[11/17 15:46:21] d2.utils.events INFO:  eta: 20:33:41  iter: 2119  total_loss: 0.2736  loss_cls: 0.1484  loss_box_reg: 0.09232  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.01632  time: 0.6822  data_time: 0.0675  lr: 0.01  max_mem: 11811M
[11/17 15:46:35] d2.utils.events INFO:  eta: 20:33:32  iter: 2139  total_loss: 0.2701  loss_cls: 0.1406  loss_box_reg: 0.09375  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01778  time: 0.6822  data_time: 0.0626  lr: 0.01  max_mem: 11811M
[11/17 15:46:48] d2.utils.events INFO:  eta: 20:32:33  iter: 2159  total_loss: 0.2651  loss_cls: 0.1453  loss_box_reg: 0.08876  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.01806  time: 0.6821  data_time: 0.0620  lr: 0.01  max_mem: 11811M
[11/17 15:47:02] d2.utils.events INFO:  eta: 20:32:44  iter: 2179  total_loss: 0.2518  loss_cls: 0.1373  loss_box_reg: 0.08417  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01791  time: 0.6821  data_time: 0.0630  lr: 0.01  max_mem: 11811M
[11/17 15:47:15] d2.utils.events INFO:  eta: 20:32:05  iter: 2199  total_loss: 0.251  loss_cls: 0.1344  loss_box_reg: 0.08397  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01595  time: 0.6821  data_time: 0.0660  lr: 0.01  max_mem: 11811M
[11/17 15:47:29] d2.utils.events INFO:  eta: 20:31:39  iter: 2219  total_loss: 0.2558  loss_cls: 0.1362  loss_box_reg: 0.08778  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.01602  time: 0.6820  data_time: 0.0698  lr: 0.01  max_mem: 11811M
[11/17 15:47:42] d2.utils.events INFO:  eta: 20:31:20  iter: 2239  total_loss: 0.2582  loss_cls: 0.1385  loss_box_reg: 0.08823  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.01837  time: 0.6820  data_time: 0.0733  lr: 0.01  max_mem: 11811M
[11/17 15:47:56] d2.utils.events INFO:  eta: 20:31:06  iter: 2259  total_loss: 0.2601  loss_cls: 0.1378  loss_box_reg: 0.08976  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01742  time: 0.6821  data_time: 0.0707  lr: 0.01  max_mem: 11811M
[11/17 15:48:10] d2.utils.events INFO:  eta: 20:30:53  iter: 2279  total_loss: 0.2669  loss_cls: 0.1421  loss_box_reg: 0.09196  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.01803  time: 0.6821  data_time: 0.0652  lr: 0.01  max_mem: 11811M
[11/17 15:48:24] d2.utils.events INFO:  eta: 20:31:53  iter: 2299  total_loss: 0.2657  loss_cls: 0.1447  loss_box_reg: 0.08925  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.01755  time: 0.6822  data_time: 0.0667  lr: 0.01  max_mem: 11811M
[11/17 15:48:37] d2.utils.events INFO:  eta: 20:31:25  iter: 2319  total_loss: 0.255  loss_cls: 0.1358  loss_box_reg: 0.08773  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01675  time: 0.6822  data_time: 0.0653  lr: 0.01  max_mem: 11811M
[11/17 15:48:51] d2.utils.events INFO:  eta: 20:31:16  iter: 2339  total_loss: 0.2631  loss_cls: 0.1418  loss_box_reg: 0.08943  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.01785  time: 0.6822  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/17 15:49:05] d2.utils.events INFO:  eta: 20:30:58  iter: 2359  total_loss: 0.2683  loss_cls: 0.1448  loss_box_reg: 0.09117  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01792  time: 0.6822  data_time: 0.0653  lr: 0.01  max_mem: 11811M
[11/17 15:49:19] d2.utils.events INFO:  eta: 20:30:36  iter: 2379  total_loss: 0.2752  loss_cls: 0.146  loss_box_reg: 0.09227  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.01873  time: 0.6823  data_time: 0.0891  lr: 0.01  max_mem: 11811M
[11/17 15:49:32] d2.utils.events INFO:  eta: 20:30:45  iter: 2399  total_loss: 0.2517  loss_cls: 0.1313  loss_box_reg: 0.08695  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01825  time: 0.6823  data_time: 0.0692  lr: 0.01  max_mem: 11811M
[11/17 15:49:46] d2.utils.events INFO:  eta: 20:30:27  iter: 2419  total_loss: 0.2633  loss_cls: 0.1418  loss_box_reg: 0.08925  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01745  time: 0.6823  data_time: 0.0737  lr: 0.01  max_mem: 11811M
[11/17 15:50:00] d2.utils.events INFO:  eta: 20:30:08  iter: 2439  total_loss: 0.2542  loss_cls: 0.1394  loss_box_reg: 0.08878  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.01648  time: 0.6823  data_time: 0.0740  lr: 0.01  max_mem: 11811M
[11/17 15:50:13] d2.utils.events INFO:  eta: 20:30:08  iter: 2459  total_loss: 0.2616  loss_cls: 0.1406  loss_box_reg: 0.08736  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.01675  time: 0.6824  data_time: 0.0680  lr: 0.01  max_mem: 11811M
[11/17 15:50:27] d2.utils.events INFO:  eta: 20:30:19  iter: 2479  total_loss: 0.2681  loss_cls: 0.1469  loss_box_reg: 0.09018  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01744  time: 0.6825  data_time: 0.0702  lr: 0.01  max_mem: 11811M
[11/17 15:50:41] d2.utils.events INFO:  eta: 20:29:32  iter: 2499  total_loss: 0.2575  loss_cls: 0.1368  loss_box_reg: 0.08508  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.0177  time: 0.6824  data_time: 0.0630  lr: 0.01  max_mem: 11811M
[11/17 15:50:54] d2.utils.events INFO:  eta: 20:29:01  iter: 2519  total_loss: 0.2536  loss_cls: 0.1354  loss_box_reg: 0.08607  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.0173  time: 0.6823  data_time: 0.0679  lr: 0.01  max_mem: 11811M
[11/17 15:51:08] d2.utils.events INFO:  eta: 20:28:47  iter: 2539  total_loss: 0.264  loss_cls: 0.1383  loss_box_reg: 0.09132  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01783  time: 0.6823  data_time: 0.0657  lr: 0.01  max_mem: 11811M
[11/17 15:51:21] d2.utils.events INFO:  eta: 20:28:41  iter: 2559  total_loss: 0.2557  loss_cls: 0.1366  loss_box_reg: 0.08372  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.01735  time: 0.6823  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/17 15:51:35] d2.utils.events INFO:  eta: 20:28:20  iter: 2579  total_loss: 0.2504  loss_cls: 0.1329  loss_box_reg: 0.09087  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.016  time: 0.6823  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/17 15:51:48] d2.utils.events INFO:  eta: 20:27:47  iter: 2599  total_loss: 0.2568  loss_cls: 0.1419  loss_box_reg: 0.08671  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.01697  time: 0.6822  data_time: 0.0624  lr: 0.01  max_mem: 11811M
[11/17 15:52:02] d2.utils.events INFO:  eta: 20:27:45  iter: 2619  total_loss: 0.2626  loss_cls: 0.1418  loss_box_reg: 0.0894  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.01702  time: 0.6822  data_time: 0.0609  lr: 0.01  max_mem: 11811M
[11/17 15:52:15] d2.utils.events INFO:  eta: 20:26:52  iter: 2639  total_loss: 0.2598  loss_cls: 0.136  loss_box_reg: 0.08808  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.01701  time: 0.6821  data_time: 0.0659  lr: 0.01  max_mem: 11811M
[11/17 15:52:29] d2.utils.events INFO:  eta: 20:26:38  iter: 2659  total_loss: 0.2742  loss_cls: 0.1444  loss_box_reg: 0.09389  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.01694  time: 0.6820  data_time: 0.0579  lr: 0.01  max_mem: 11811M
[11/17 15:52:42] d2.utils.events INFO:  eta: 20:25:40  iter: 2679  total_loss: 0.2587  loss_cls: 0.14  loss_box_reg: 0.09213  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.0184  time: 0.6820  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 15:52:56] d2.utils.events INFO:  eta: 20:25:17  iter: 2699  total_loss: 0.2602  loss_cls: 0.1404  loss_box_reg: 0.08819  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.01793  time: 0.6820  data_time: 0.0689  lr: 0.01  max_mem: 11811M
[11/17 15:53:10] d2.utils.events INFO:  eta: 20:24:48  iter: 2719  total_loss: 0.255  loss_cls: 0.1405  loss_box_reg: 0.09303  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01767  time: 0.6820  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 15:53:23] d2.utils.events INFO:  eta: 20:24:41  iter: 2739  total_loss: 0.2526  loss_cls: 0.1368  loss_box_reg: 0.08585  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.0174  time: 0.6820  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/17 15:53:37] d2.utils.events INFO:  eta: 20:24:27  iter: 2759  total_loss: 0.2653  loss_cls: 0.1364  loss_box_reg: 0.09041  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.01934  time: 0.6820  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/17 15:53:51] d2.utils.events INFO:  eta: 20:24:23  iter: 2779  total_loss: 0.2652  loss_cls: 0.1439  loss_box_reg: 0.09297  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01739  time: 0.6820  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/17 15:54:04] d2.utils.events INFO:  eta: 20:24:38  iter: 2799  total_loss: 0.2541  loss_cls: 0.134  loss_box_reg: 0.08857  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.0186  time: 0.6820  data_time: 0.0627  lr: 0.01  max_mem: 11811M
[11/17 15:54:18] d2.utils.events INFO:  eta: 20:24:39  iter: 2819  total_loss: 0.2507  loss_cls: 0.1324  loss_box_reg: 0.08725  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.01616  time: 0.6820  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/17 15:54:32] d2.utils.events INFO:  eta: 20:24:17  iter: 2839  total_loss: 0.248  loss_cls: 0.128  loss_box_reg: 0.08462  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01624  time: 0.6820  data_time: 0.0805  lr: 0.01  max_mem: 11811M
[11/17 15:54:46] d2.utils.events INFO:  eta: 20:25:10  iter: 2859  total_loss: 0.2707  loss_cls: 0.1398  loss_box_reg: 0.0935  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.018  time: 0.6821  data_time: 0.0703  lr: 0.01  max_mem: 11811M
[11/17 15:54:59] d2.utils.events INFO:  eta: 20:23:59  iter: 2879  total_loss: 0.2647  loss_cls: 0.1445  loss_box_reg: 0.08903  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.01726  time: 0.6821  data_time: 0.0678  lr: 0.01  max_mem: 11811M
[11/17 15:55:13] d2.utils.events INFO:  eta: 20:24:34  iter: 2899  total_loss: 0.2346  loss_cls: 0.1257  loss_box_reg: 0.08096  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01778  time: 0.6821  data_time: 0.0686  lr: 0.01  max_mem: 11811M
[11/17 15:55:26] d2.utils.events INFO:  eta: 20:23:47  iter: 2919  total_loss: 0.2472  loss_cls: 0.1301  loss_box_reg: 0.08476  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.01663  time: 0.6820  data_time: 0.0669  lr: 0.01  max_mem: 11811M
[11/17 15:55:40] d2.utils.events INFO:  eta: 20:24:12  iter: 2939  total_loss: 0.2489  loss_cls: 0.1342  loss_box_reg: 0.08805  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.01737  time: 0.6821  data_time: 0.0743  lr: 0.01  max_mem: 11811M
[11/17 15:55:54] d2.utils.events INFO:  eta: 20:23:59  iter: 2959  total_loss: 0.2534  loss_cls: 0.1367  loss_box_reg: 0.08645  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01858  time: 0.6821  data_time: 0.0694  lr: 0.01  max_mem: 11811M
[11/17 15:56:08] d2.utils.events INFO:  eta: 20:23:20  iter: 2979  total_loss: 0.2515  loss_cls: 0.1345  loss_box_reg: 0.08763  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.01627  time: 0.6821  data_time: 0.0769  lr: 0.01  max_mem: 11811M
[11/17 15:56:21] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0002999.pth
[11/17 15:56:22] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 15:56:22] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 15:56:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 15:56:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 15:56:22] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 15:56:22] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 15:56:23] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 15:56:30] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0417 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:02:22
[11/17 15:56:35] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/17 15:56:40] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/17 15:56:45] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/17 15:56:50] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/17 15:56:55] d2.evaluation.evaluator INFO: Inference done 621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/17 15:57:00] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/17 15:57:05] d2.evaluation.evaluator INFO: Inference done 869/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:41
[11/17 15:57:10] d2.evaluation.evaluator INFO: Inference done 989/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/17 15:57:15] d2.evaluation.evaluator INFO: Inference done 1111/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/17 15:57:20] d2.evaluation.evaluator INFO: Inference done 1234/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/17 15:57:25] d2.evaluation.evaluator INFO: Inference done 1358/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:21
[11/17 15:57:30] d2.evaluation.evaluator INFO: Inference done 1479/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:16
[11/17 15:57:35] d2.evaluation.evaluator INFO: Inference done 1598/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:11
[11/17 15:57:40] d2.evaluation.evaluator INFO: Inference done 1720/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/17 15:57:45] d2.evaluation.evaluator INFO: Inference done 1841/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/17 15:57:50] d2.evaluation.evaluator INFO: Inference done 1962/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/17 15:57:55] d2.evaluation.evaluator INFO: Inference done 2085/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/17 15:58:00] d2.evaluation.evaluator INFO: Inference done 2209/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/17 15:58:05] d2.evaluation.evaluator INFO: Inference done 2332/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/17 15:58:10] d2.evaluation.evaluator INFO: Inference done 2455/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/17 15:58:15] d2.evaluation.evaluator INFO: Inference done 2583/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/17 15:58:20] d2.evaluation.evaluator INFO: Inference done 2707/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/17 15:58:25] d2.evaluation.evaluator INFO: Inference done 2830/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 15:58:30] d2.evaluation.evaluator INFO: Inference done 2950/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/17 15:58:35] d2.evaluation.evaluator INFO: Inference done 3072/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/17 15:58:40] d2.evaluation.evaluator INFO: Inference done 3195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 15:58:45] d2.evaluation.evaluator INFO: Inference done 3314/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 15:58:46] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.086315 (0.041179 s / iter per device, on 6 devices)
[11/17 15:58:46] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039219 s / iter per device, on 6 devices)
[11/17 15:58:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 15:58:49] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 15:58:50] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 15:58:51] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 15:59:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.59 seconds.
[11/17 15:59:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 15:59:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.75 seconds.
[11/17 15:59:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.700 | 12.447 | 4.276  | 0.986 | 3.125 | 6.870 |
[11/17 15:59:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 4.415  | bird          | 21.012 | hat with a wide brim | 3.258  |
| person                | 5.840  | dog           | 41.045 | lizard               | 3.535  |
| sheep                 | 2.312  | wine bottle   | 4.006  | bowl                 | 6.724  |
| airplane              | 13.222 | domestic cat  | 5.512  | car                  | 25.290 |
| porcupine             | 6.973  | bear          | 7.120  | tape player          | 4.702  |
| ray                   | 1.487  | laptop        | 5.980  | zebra                | 16.392 |
| computer keyboard     | 1.176  | pitcher       | 0.592  | artichoke            | 9.571  |
| tv or monitor         | 11.875 | table         | 4.400  | chair                | 4.240  |
| helmet                | 5.416  | traffic light | 2.879  | red panda            | 4.246  |
| sunglasses            | 0.043  | lamp          | 1.651  | bicycle              | 3.448  |
| backpack              | 2.077  | mushroom      | 1.823  | fox                  | 2.058  |
| otter                 | 1.031  | guitar        | 3.268  | microphone           | 0.000  |
| strawberry            | 4.626  | stove         | 6.377  | violin               | 0.008  |
| bookshelf             | 10.806 | sofa          | 2.068  | bell pepper          | 2.997  |
| bagel                 | 2.452  | lemon         | 5.715  | orange               | 12.105 |
| bench                 | 0.928  | piano         | 5.860  | flower pot           | 0.835  |
| butterfly             | 21.138 | purse         | 2.393  | pomegranate          | 1.606  |
| train                 | 4.007  | drum          | 0.540  | hippopotamus         | 0.306  |
| ski                   | 0.545  | ladybug       | 19.935 | banana               | 0.564  |
| monkey                | 4.898  | bus           | 20.244 | miniskirt            | 1.358  |
| camel                 | 0.978  | cream         | 8.575  | lobster              | 2.195  |
| seal                  | 0.755  | horse         | 5.389  | cart                 | 7.204  |
| elephant              | 13.687 | snake         | 5.883  | fig                  | 0.733  |
| watercraft            | 18.015 | apple         | 8.764  | antelope             | 10.167 |
| cattle                | 0.805  | whale         | 5.430  | coffee maker         | 17.339 |
| baby bed              | 7.973  | frog          | 6.928  | bathing cap          | 3.430  |
| crutch                | 0.073  | koala bear    | 3.207  | tie                  | 0.118  |
| dumbbell              | 0.108  | tiger         | 1.998  | dragonfly            | 3.385  |
| goldfish              | 3.851  | cucumber      | 0.134  | turtle               | 3.650  |
| harp                  | 4.061  | jellyfish     | 5.331  | swine                | 3.258  |
| pretzel               | 3.569  | motorcycle    | 12.937 | beaker               | 5.611  |
| rabbit                | 7.928  | nail          | 0.000  | axe                  | 0.040  |
| salt or pepper shaker | 0.779  | croquet ball  | 9.918  | skunk                | 0.476  |
| starfish              | 4.416  |               |        |                      |        |
[11/17 15:59:16] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 15:59:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 15:59:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 15:59:16] d2.evaluation.testing INFO: copypaste: 5.7003,12.4470,4.2757,0.9863,3.1252,6.8696
[11/17 15:59:17] d2.utils.events INFO:  eta: 20:23:26  iter: 2999  total_loss: 0.2551  loss_cls: 0.1323  loss_box_reg: 0.08715  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.01913  time: 0.6821  data_time: 0.0733  lr: 0.01  max_mem: 11811M
[11/17 15:59:30] d2.utils.events INFO:  eta: 20:23:21  iter: 3019  total_loss: 0.2408  loss_cls: 0.1268  loss_box_reg: 0.08501  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.01665  time: 0.6821  data_time: 0.0711  lr: 0.01  max_mem: 11811M
[11/17 15:59:44] d2.utils.events INFO:  eta: 20:23:08  iter: 3039  total_loss: 0.2621  loss_cls: 0.1384  loss_box_reg: 0.08878  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.01875  time: 0.6822  data_time: 0.0789  lr: 0.01  max_mem: 11811M
[11/17 15:59:58] d2.utils.events INFO:  eta: 20:22:26  iter: 3059  total_loss: 0.2484  loss_cls: 0.1283  loss_box_reg: 0.08895  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.01822  time: 0.6822  data_time: 0.0646  lr: 0.01  max_mem: 11811M
[11/17 16:00:11] d2.utils.events INFO:  eta: 20:22:32  iter: 3079  total_loss: 0.262  loss_cls: 0.1395  loss_box_reg: 0.08987  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.01767  time: 0.6822  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/17 16:00:25] d2.utils.events INFO:  eta: 20:23:12  iter: 3099  total_loss: 0.254  loss_cls: 0.1346  loss_box_reg: 0.08884  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01654  time: 0.6822  data_time: 0.0746  lr: 0.01  max_mem: 11811M
[11/17 16:00:38] d2.utils.events INFO:  eta: 20:22:58  iter: 3119  total_loss: 0.2506  loss_cls: 0.1328  loss_box_reg: 0.08221  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01813  time: 0.6821  data_time: 0.0703  lr: 0.01  max_mem: 11811M
[11/17 16:00:52] d2.utils.events INFO:  eta: 20:22:58  iter: 3139  total_loss: 0.2572  loss_cls: 0.1367  loss_box_reg: 0.09155  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.0178  time: 0.6822  data_time: 0.0649  lr: 0.01  max_mem: 11811M
[11/17 16:01:06] d2.utils.events INFO:  eta: 20:22:38  iter: 3159  total_loss: 0.2453  loss_cls: 0.1334  loss_box_reg: 0.08436  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.01818  time: 0.6821  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/17 16:01:19] d2.utils.events INFO:  eta: 20:22:25  iter: 3179  total_loss: 0.253  loss_cls: 0.1349  loss_box_reg: 0.08582  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.01617  time: 0.6821  data_time: 0.0781  lr: 0.01  max_mem: 11811M
[11/17 16:01:33] d2.utils.events INFO:  eta: 20:22:01  iter: 3199  total_loss: 0.2407  loss_cls: 0.1287  loss_box_reg: 0.08313  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.01757  time: 0.6821  data_time: 0.0690  lr: 0.01  max_mem: 11811M
[11/17 16:01:47] d2.utils.events INFO:  eta: 20:21:42  iter: 3219  total_loss: 0.2594  loss_cls: 0.1392  loss_box_reg: 0.0873  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01774  time: 0.6821  data_time: 0.0624  lr: 0.01  max_mem: 11811M
[11/17 16:02:00] d2.utils.events INFO:  eta: 20:21:42  iter: 3239  total_loss: 0.238  loss_cls: 0.1285  loss_box_reg: 0.08488  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.01688  time: 0.6821  data_time: 0.0697  lr: 0.01  max_mem: 11811M
[11/17 16:02:14] d2.utils.events INFO:  eta: 20:21:44  iter: 3259  total_loss: 0.2696  loss_cls: 0.1405  loss_box_reg: 0.09317  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01875  time: 0.6821  data_time: 0.0651  lr: 0.01  max_mem: 11811M
[11/17 16:02:28] d2.utils.events INFO:  eta: 20:22:09  iter: 3279  total_loss: 0.2607  loss_cls: 0.1384  loss_box_reg: 0.09098  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01655  time: 0.6822  data_time: 0.0697  lr: 0.01  max_mem: 11811M
[11/17 16:02:42] d2.utils.events INFO:  eta: 20:21:42  iter: 3299  total_loss: 0.259  loss_cls: 0.1406  loss_box_reg: 0.09114  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.01661  time: 0.6823  data_time: 0.0669  lr: 0.01  max_mem: 11811M
[11/17 16:02:55] d2.utils.events INFO:  eta: 20:21:35  iter: 3319  total_loss: 0.2625  loss_cls: 0.1402  loss_box_reg: 0.08709  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.01653  time: 0.6823  data_time: 0.0743  lr: 0.01  max_mem: 11811M
[11/17 16:03:09] d2.utils.events INFO:  eta: 20:21:11  iter: 3339  total_loss: 0.2534  loss_cls: 0.1341  loss_box_reg: 0.0896  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.01706  time: 0.6822  data_time: 0.0633  lr: 0.01  max_mem: 11811M
[11/17 16:03:22] d2.utils.events INFO:  eta: 20:20:13  iter: 3359  total_loss: 0.2551  loss_cls: 0.1368  loss_box_reg: 0.08443  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.01801  time: 0.6821  data_time: 0.0606  lr: 0.01  max_mem: 11811M
[11/17 16:03:36] d2.utils.events INFO:  eta: 20:20:48  iter: 3379  total_loss: 0.2516  loss_cls: 0.1309  loss_box_reg: 0.08798  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.01672  time: 0.6822  data_time: 0.0768  lr: 0.01  max_mem: 11811M
[11/17 16:03:50] d2.utils.events INFO:  eta: 20:19:58  iter: 3399  total_loss: 0.2516  loss_cls: 0.1362  loss_box_reg: 0.08923  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.01778  time: 0.6821  data_time: 0.0663  lr: 0.01  max_mem: 11811M
[11/17 16:04:03] d2.utils.events INFO:  eta: 20:18:53  iter: 3419  total_loss: 0.242  loss_cls: 0.129  loss_box_reg: 0.0832  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.01552  time: 0.6821  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/17 16:04:17] d2.utils.events INFO:  eta: 20:19:11  iter: 3439  total_loss: 0.2604  loss_cls: 0.1397  loss_box_reg: 0.09161  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.017  time: 0.6821  data_time: 0.0685  lr: 0.01  max_mem: 11811M
[11/17 16:04:31] d2.utils.events INFO:  eta: 20:18:59  iter: 3459  total_loss: 0.2513  loss_cls: 0.1373  loss_box_reg: 0.08896  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01641  time: 0.6822  data_time: 0.0751  lr: 0.01  max_mem: 11811M
[11/17 16:04:44] d2.utils.events INFO:  eta: 20:18:45  iter: 3479  total_loss: 0.2596  loss_cls: 0.1416  loss_box_reg: 0.09082  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.01798  time: 0.6822  data_time: 0.0672  lr: 0.01  max_mem: 11811M
[11/17 16:04:58] d2.utils.events INFO:  eta: 20:18:37  iter: 3499  total_loss: 0.2715  loss_cls: 0.1409  loss_box_reg: 0.09656  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.01876  time: 0.6822  data_time: 0.0637  lr: 0.01  max_mem: 11811M
[11/17 16:05:12] d2.utils.events INFO:  eta: 20:19:13  iter: 3519  total_loss: 0.2503  loss_cls: 0.1334  loss_box_reg: 0.08779  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01606  time: 0.6822  data_time: 0.0693  lr: 0.01  max_mem: 11811M
[11/17 16:05:25] d2.utils.events INFO:  eta: 20:18:33  iter: 3539  total_loss: 0.2547  loss_cls: 0.1374  loss_box_reg: 0.08716  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01852  time: 0.6821  data_time: 0.0632  lr: 0.01  max_mem: 11811M
[11/17 16:05:39] d2.utils.events INFO:  eta: 20:18:56  iter: 3559  total_loss: 0.259  loss_cls: 0.1367  loss_box_reg: 0.08883  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.01736  time: 0.6822  data_time: 0.0707  lr: 0.01  max_mem: 11811M
[11/17 16:05:52] d2.utils.events INFO:  eta: 20:18:32  iter: 3579  total_loss: 0.248  loss_cls: 0.1323  loss_box_reg: 0.08691  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01781  time: 0.6821  data_time: 0.0668  lr: 0.01  max_mem: 11811M
[11/17 16:06:06] d2.utils.events INFO:  eta: 20:18:32  iter: 3599  total_loss: 0.2544  loss_cls: 0.1349  loss_box_reg: 0.08832  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01712  time: 0.6821  data_time: 0.0696  lr: 0.01  max_mem: 11811M
[11/17 16:06:20] d2.utils.events INFO:  eta: 20:18:23  iter: 3619  total_loss: 0.2491  loss_cls: 0.1305  loss_box_reg: 0.08941  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.01757  time: 0.6821  data_time: 0.0694  lr: 0.01  max_mem: 11811M
[11/17 16:06:33] d2.utils.events INFO:  eta: 20:18:23  iter: 3639  total_loss: 0.2443  loss_cls: 0.1336  loss_box_reg: 0.08463  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01746  time: 0.6821  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/17 16:06:47] d2.utils.events INFO:  eta: 20:17:56  iter: 3659  total_loss: 0.2427  loss_cls: 0.1301  loss_box_reg: 0.08578  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01588  time: 0.6821  data_time: 0.0716  lr: 0.01  max_mem: 11811M
[11/17 16:07:00] d2.utils.events INFO:  eta: 20:18:15  iter: 3679  total_loss: 0.2365  loss_cls: 0.1272  loss_box_reg: 0.08231  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01832  time: 0.6821  data_time: 0.0701  lr: 0.01  max_mem: 11811M
[11/17 16:07:14] d2.utils.events INFO:  eta: 20:17:46  iter: 3699  total_loss: 0.248  loss_cls: 0.127  loss_box_reg: 0.08379  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.01755  time: 0.6821  data_time: 0.0625  lr: 0.01  max_mem: 11811M
[11/17 16:07:28] d2.utils.events INFO:  eta: 20:17:48  iter: 3719  total_loss: 0.2492  loss_cls: 0.1354  loss_box_reg: 0.08594  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.01581  time: 0.6821  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/17 16:07:41] d2.utils.events INFO:  eta: 20:17:01  iter: 3739  total_loss: 0.237  loss_cls: 0.1234  loss_box_reg: 0.08493  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.01767  time: 0.6821  data_time: 0.0597  lr: 0.01  max_mem: 11811M
[11/17 16:07:55] d2.utils.events INFO:  eta: 20:16:55  iter: 3759  total_loss: 0.2433  loss_cls: 0.1264  loss_box_reg: 0.08436  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01999  time: 0.6821  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/17 16:08:09] d2.utils.events INFO:  eta: 20:16:16  iter: 3779  total_loss: 0.241  loss_cls: 0.1267  loss_box_reg: 0.08488  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.01847  time: 0.6821  data_time: 0.0793  lr: 0.01  max_mem: 11811M
[11/17 16:08:22] d2.utils.events INFO:  eta: 20:16:09  iter: 3799  total_loss: 0.2381  loss_cls: 0.1239  loss_box_reg: 0.0868  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01549  time: 0.6821  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/17 16:08:36] d2.utils.events INFO:  eta: 20:15:55  iter: 3819  total_loss: 0.2527  loss_cls: 0.1321  loss_box_reg: 0.08859  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01754  time: 0.6822  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 16:08:50] d2.utils.events INFO:  eta: 20:15:41  iter: 3839  total_loss: 0.2557  loss_cls: 0.1376  loss_box_reg: 0.08914  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01697  time: 0.6821  data_time: 0.0637  lr: 0.01  max_mem: 11811M
[11/17 16:09:03] d2.utils.events INFO:  eta: 20:14:56  iter: 3859  total_loss: 0.2428  loss_cls: 0.1293  loss_box_reg: 0.08555  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.01746  time: 0.6821  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/17 16:09:17] d2.utils.events INFO:  eta: 20:15:09  iter: 3879  total_loss: 0.2649  loss_cls: 0.1364  loss_box_reg: 0.09209  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.01547  time: 0.6821  data_time: 0.0681  lr: 0.01  max_mem: 11811M
[11/17 16:09:31] d2.utils.events INFO:  eta: 20:14:36  iter: 3899  total_loss: 0.2586  loss_cls: 0.1372  loss_box_reg: 0.08651  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01643  time: 0.6821  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 16:09:44] d2.utils.events INFO:  eta: 20:14:33  iter: 3919  total_loss: 0.2462  loss_cls: 0.1324  loss_box_reg: 0.08482  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01717  time: 0.6821  data_time: 0.0706  lr: 0.01  max_mem: 11811M
[11/17 16:09:57] d2.utils.events INFO:  eta: 20:14:05  iter: 3939  total_loss: 0.263  loss_cls: 0.142  loss_box_reg: 0.09005  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01708  time: 0.6820  data_time: 0.0665  lr: 0.01  max_mem: 11811M
[11/17 16:10:11] d2.utils.events INFO:  eta: 20:14:09  iter: 3959  total_loss: 0.2478  loss_cls: 0.1285  loss_box_reg: 0.08418  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.0176  time: 0.6820  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/17 16:10:25] d2.utils.events INFO:  eta: 20:14:36  iter: 3979  total_loss: 0.2442  loss_cls: 0.1297  loss_box_reg: 0.08784  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01662  time: 0.6821  data_time: 0.0705  lr: 0.01  max_mem: 11811M
[11/17 16:10:39] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0003999.pth
[11/17 16:10:39] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 16:10:39] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 16:10:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 16:10:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 16:10:40] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 16:10:40] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 16:10:40] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 16:10:47] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0434 s/iter. ETA=0:02:24
[11/17 16:10:52] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:15
[11/17 16:10:57] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:08
[11/17 16:11:02] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/17 16:11:07] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/17 16:11:12] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/17 16:11:17] d2.evaluation.evaluator INFO: Inference done 746/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/17 16:11:22] d2.evaluation.evaluator INFO: Inference done 871/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:40
[11/17 16:11:27] d2.evaluation.evaluator INFO: Inference done 994/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/17 16:11:32] d2.evaluation.evaluator INFO: Inference done 1117/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/17 16:11:37] d2.evaluation.evaluator INFO: Inference done 1235/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:26
[11/17 16:11:42] d2.evaluation.evaluator INFO: Inference done 1359/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:20
[11/17 16:11:47] d2.evaluation.evaluator INFO: Inference done 1479/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/17 16:11:52] d2.evaluation.evaluator INFO: Inference done 1603/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:10
[11/17 16:11:57] d2.evaluation.evaluator INFO: Inference done 1727/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:05
[11/17 16:12:02] d2.evaluation.evaluator INFO: Inference done 1849/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:00
[11/17 16:12:07] d2.evaluation.evaluator INFO: Inference done 1973/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:55
[11/17 16:12:12] d2.evaluation.evaluator INFO: Inference done 2094/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:50
[11/17 16:12:17] d2.evaluation.evaluator INFO: Inference done 2219/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:45
[11/17 16:12:22] d2.evaluation.evaluator INFO: Inference done 2338/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/17 16:12:27] d2.evaluation.evaluator INFO: Inference done 2459/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/17 16:12:32] d2.evaluation.evaluator INFO: Inference done 2583/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/17 16:12:37] d2.evaluation.evaluator INFO: Inference done 2707/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/17 16:12:42] d2.evaluation.evaluator INFO: Inference done 2829/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:20
[11/17 16:12:47] d2.evaluation.evaluator INFO: Inference done 2952/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/17 16:12:52] d2.evaluation.evaluator INFO: Inference done 3071/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/17 16:12:57] d2.evaluation.evaluator INFO: Inference done 3194/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 16:13:02] d2.evaluation.evaluator INFO: Inference done 3317/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 16:13:03] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.992222 (0.041151 s / iter per device, on 6 devices)
[11/17 16:13:03] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039198 s / iter per device, on 6 devices)
[11/17 16:13:06] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 16:13:06] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 16:13:07] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 16:13:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 16:13:28] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.05 seconds.
[11/17 16:13:28] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 16:13:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.69 seconds.
[11/17 16:13:30] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.369 | 13.803 | 4.902  | 1.176 | 3.231 | 7.736 |
[11/17 16:13:30] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 5.002  | bird          | 24.092 | hat with a wide brim | 2.543  |
| person                | 6.831  | dog           | 38.975 | lizard               | 4.562  |
| sheep                 | 3.206  | wine bottle   | 3.187  | bowl                 | 7.664  |
| airplane              | 15.368 | domestic cat  | 6.861  | car                  | 28.149 |
| porcupine             | 7.056  | bear          | 8.697  | tape player          | 6.313  |
| ray                   | 1.788  | laptop        | 6.859  | zebra                | 15.936 |
| computer keyboard     | 1.766  | pitcher       | 2.081  | artichoke            | 13.081 |
| tv or monitor         | 11.576 | table         | 5.707  | chair                | 5.262  |
| helmet                | 7.975  | traffic light | 2.416  | red panda            | 2.233  |
| sunglasses            | 0.133  | lamp          | 1.495  | bicycle              | 3.212  |
| backpack              | 2.885  | mushroom      | 2.878  | fox                  | 5.110  |
| otter                 | 1.459  | guitar        | 3.779  | microphone           | 0.000  |
| strawberry            | 5.545  | stove         | 6.624  | violin               | 0.066  |
| bookshelf             | 11.990 | sofa          | 1.810  | bell pepper          | 5.225  |
| bagel                 | 3.800  | lemon         | 5.932  | orange               | 12.220 |
| bench                 | 0.825  | piano         | 9.711  | flower pot           | 1.108  |
| butterfly             | 23.693 | purse         | 2.261  | pomegranate          | 1.446  |
| train                 | 8.740  | drum          | 0.820  | hippopotamus         | 0.391  |
| ski                   | 0.000  | ladybug       | 16.897 | banana               | 0.728  |
| monkey                | 8.695  | bus           | 20.885 | miniskirt            | 0.735  |
| camel                 | 1.025  | cream         | 6.525  | lobster              | 3.512  |
| seal                  | 1.249  | horse         | 4.058  | cart                 | 7.164  |
| elephant              | 9.700  | snake         | 7.601  | fig                  | 2.360  |
| watercraft            | 18.361 | apple         | 8.560  | antelope             | 12.932 |
| cattle                | 1.367  | whale         | 9.091  | coffee maker         | 16.503 |
| baby bed              | 10.458 | frog          | 8.653  | bathing cap          | 3.086  |
| crutch                | 0.033  | koala bear    | 5.936  | tie                  | 0.195  |
| dumbbell              | 0.035  | tiger         | 0.996  | dragonfly            | 3.989  |
| goldfish              | 4.589  | cucumber      | 0.414  | turtle               | 5.780  |
| harp                  | 3.579  | jellyfish     | 4.560  | swine                | 5.246  |
| pretzel               | 5.653  | motorcycle    | 10.683 | beaker               | 8.496  |
| rabbit                | 12.495 | nail          | 0.528  | axe                  | 0.289  |
| salt or pepper shaker | 0.913  | croquet ball  | 7.549  | skunk                | 0.994  |
| starfish              | 5.466  |               |        |                      |        |
[11/17 16:13:32] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 16:13:32] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 16:13:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 16:13:32] d2.evaluation.testing INFO: copypaste: 6.3691,13.8034,4.9017,1.1764,3.2306,7.7362
[11/17 16:13:32] d2.utils.events INFO:  eta: 20:14:04  iter: 3999  total_loss: 0.2478  loss_cls: 0.1325  loss_box_reg: 0.08351  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.01532  time: 0.6821  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/17 16:13:46] d2.utils.events INFO:  eta: 20:13:51  iter: 4019  total_loss: 0.2592  loss_cls: 0.1382  loss_box_reg: 0.08864  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.01699  time: 0.6821  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/17 16:13:59] d2.utils.events INFO:  eta: 20:13:11  iter: 4039  total_loss: 0.244  loss_cls: 0.1273  loss_box_reg: 0.08689  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01697  time: 0.6820  data_time: 0.0636  lr: 0.01  max_mem: 11811M
[11/17 16:14:13] d2.utils.events INFO:  eta: 20:12:47  iter: 4059  total_loss: 0.2379  loss_cls: 0.1234  loss_box_reg: 0.08207  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.01687  time: 0.6820  data_time: 0.0644  lr: 0.01  max_mem: 11811M
[11/17 16:14:27] d2.utils.events INFO:  eta: 20:12:30  iter: 4079  total_loss: 0.248  loss_cls: 0.1328  loss_box_reg: 0.08616  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.01759  time: 0.6820  data_time: 0.0636  lr: 0.01  max_mem: 11811M
[11/17 16:14:41] d2.utils.events INFO:  eta: 20:12:20  iter: 4099  total_loss: 0.2608  loss_cls: 0.1353  loss_box_reg: 0.08863  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01905  time: 0.6821  data_time: 0.0707  lr: 0.01  max_mem: 11811M
[11/17 16:14:54] d2.utils.events INFO:  eta: 20:12:21  iter: 4119  total_loss: 0.2614  loss_cls: 0.1358  loss_box_reg: 0.08977  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.01836  time: 0.6821  data_time: 0.0636  lr: 0.01  max_mem: 11811M
[11/17 16:15:08] d2.utils.events INFO:  eta: 20:11:55  iter: 4139  total_loss: 0.2406  loss_cls: 0.1272  loss_box_reg: 0.08514  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.01715  time: 0.6820  data_time: 0.0656  lr: 0.01  max_mem: 11811M
[11/17 16:15:21] d2.utils.events INFO:  eta: 20:12:04  iter: 4159  total_loss: 0.2496  loss_cls: 0.1293  loss_box_reg: 0.08611  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01639  time: 0.6820  data_time: 0.0654  lr: 0.01  max_mem: 11811M
[11/17 16:15:35] d2.utils.events INFO:  eta: 20:11:55  iter: 4179  total_loss: 0.2622  loss_cls: 0.1353  loss_box_reg: 0.08949  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01719  time: 0.6821  data_time: 0.0693  lr: 0.01  max_mem: 11811M
[11/17 16:15:49] d2.utils.events INFO:  eta: 20:12:15  iter: 4199  total_loss: 0.2566  loss_cls: 0.1362  loss_box_reg: 0.08817  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.01638  time: 0.6821  data_time: 0.0668  lr: 0.01  max_mem: 11811M
[11/17 16:16:02] d2.utils.events INFO:  eta: 20:12:01  iter: 4219  total_loss: 0.2363  loss_cls: 0.1226  loss_box_reg: 0.08429  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01799  time: 0.6820  data_time: 0.0668  lr: 0.01  max_mem: 11811M
[11/17 16:16:16] d2.utils.events INFO:  eta: 20:11:13  iter: 4239  total_loss: 0.2572  loss_cls: 0.1338  loss_box_reg: 0.0884  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01785  time: 0.6820  data_time: 0.0648  lr: 0.01  max_mem: 11811M
[11/17 16:16:29] d2.utils.events INFO:  eta: 20:11:01  iter: 4259  total_loss: 0.2543  loss_cls: 0.1318  loss_box_reg: 0.08673  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01599  time: 0.6820  data_time: 0.0679  lr: 0.01  max_mem: 11811M
[11/17 16:16:43] d2.utils.events INFO:  eta: 20:10:07  iter: 4279  total_loss: 0.247  loss_cls: 0.1284  loss_box_reg: 0.08207  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01812  time: 0.6820  data_time: 0.0690  lr: 0.01  max_mem: 11811M
[11/17 16:16:57] d2.utils.events INFO:  eta: 20:09:11  iter: 4299  total_loss: 0.2366  loss_cls: 0.126  loss_box_reg: 0.08222  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.01654  time: 0.6819  data_time: 0.0627  lr: 0.01  max_mem: 11811M
[11/17 16:17:10] d2.utils.events INFO:  eta: 20:08:34  iter: 4319  total_loss: 0.2495  loss_cls: 0.1288  loss_box_reg: 0.08821  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01677  time: 0.6819  data_time: 0.0734  lr: 0.01  max_mem: 11811M
[11/17 16:17:24] d2.utils.events INFO:  eta: 20:08:29  iter: 4339  total_loss: 0.2284  loss_cls: 0.122  loss_box_reg: 0.08069  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.01776  time: 0.6819  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/17 16:17:37] d2.utils.events INFO:  eta: 20:08:27  iter: 4359  total_loss: 0.2551  loss_cls: 0.1348  loss_box_reg: 0.08553  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.01817  time: 0.6819  data_time: 0.0692  lr: 0.01  max_mem: 11811M
[11/17 16:17:51] d2.utils.events INFO:  eta: 20:08:31  iter: 4379  total_loss: 0.2533  loss_cls: 0.1323  loss_box_reg: 0.08629  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01824  time: 0.6820  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/17 16:18:05] d2.utils.events INFO:  eta: 20:08:40  iter: 4399  total_loss: 0.2663  loss_cls: 0.1425  loss_box_reg: 0.09404  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01816  time: 0.6820  data_time: 0.0682  lr: 0.01  max_mem: 11811M
[11/17 16:18:18] d2.utils.events INFO:  eta: 20:08:55  iter: 4419  total_loss: 0.2421  loss_cls: 0.124  loss_box_reg: 0.08568  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.018  time: 0.6820  data_time: 0.0653  lr: 0.01  max_mem: 11811M
[11/17 16:18:32] d2.utils.events INFO:  eta: 20:08:41  iter: 4439  total_loss: 0.2318  loss_cls: 0.1172  loss_box_reg: 0.08  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01776  time: 0.6820  data_time: 0.0730  lr: 0.01  max_mem: 11811M
[11/17 16:18:46] d2.utils.events INFO:  eta: 20:07:37  iter: 4459  total_loss: 0.243  loss_cls: 0.128  loss_box_reg: 0.08754  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01635  time: 0.6820  data_time: 0.0642  lr: 0.01  max_mem: 11811M
[11/17 16:18:59] d2.utils.events INFO:  eta: 20:07:13  iter: 4479  total_loss: 0.2358  loss_cls: 0.1263  loss_box_reg: 0.08118  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01629  time: 0.6820  data_time: 0.0710  lr: 0.01  max_mem: 11811M
[11/17 16:19:13] d2.utils.events INFO:  eta: 20:06:34  iter: 4499  total_loss: 0.2662  loss_cls: 0.1382  loss_box_reg: 0.08886  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01731  time: 0.6819  data_time: 0.0606  lr: 0.01  max_mem: 11811M
[11/17 16:19:27] d2.utils.events INFO:  eta: 20:06:21  iter: 4519  total_loss: 0.2421  loss_cls: 0.1264  loss_box_reg: 0.08291  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01834  time: 0.6820  data_time: 0.0711  lr: 0.01  max_mem: 11811M
[11/17 16:19:40] d2.utils.events INFO:  eta: 20:06:43  iter: 4539  total_loss: 0.244  loss_cls: 0.1246  loss_box_reg: 0.08802  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.01819  time: 0.6819  data_time: 0.0620  lr: 0.01  max_mem: 11811M
[11/17 16:19:54] d2.utils.events INFO:  eta: 20:05:51  iter: 4559  total_loss: 0.2485  loss_cls: 0.1282  loss_box_reg: 0.09056  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.0165  time: 0.6819  data_time: 0.0699  lr: 0.01  max_mem: 11811M
[11/17 16:20:07] d2.utils.events INFO:  eta: 20:05:16  iter: 4579  total_loss: 0.2432  loss_cls: 0.1252  loss_box_reg: 0.0869  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.01799  time: 0.6818  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/17 16:20:21] d2.utils.events INFO:  eta: 20:04:56  iter: 4599  total_loss: 0.2474  loss_cls: 0.1241  loss_box_reg: 0.08788  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.01723  time: 0.6818  data_time: 0.0622  lr: 0.01  max_mem: 11811M
[11/17 16:20:34] d2.utils.events INFO:  eta: 20:04:35  iter: 4619  total_loss: 0.2306  loss_cls: 0.1237  loss_box_reg: 0.08034  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.01514  time: 0.6818  data_time: 0.0609  lr: 0.01  max_mem: 11811M
[11/17 16:20:48] d2.utils.events INFO:  eta: 20:04:29  iter: 4639  total_loss: 0.2529  loss_cls: 0.1286  loss_box_reg: 0.0886  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01926  time: 0.6818  data_time: 0.0743  lr: 0.01  max_mem: 11811M
[11/17 16:21:01] d2.utils.events INFO:  eta: 20:04:22  iter: 4659  total_loss: 0.2427  loss_cls: 0.1291  loss_box_reg: 0.08551  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01705  time: 0.6818  data_time: 0.0609  lr: 0.01  max_mem: 11811M
[11/17 16:21:15] d2.utils.events INFO:  eta: 20:04:06  iter: 4679  total_loss: 0.2516  loss_cls: 0.137  loss_box_reg: 0.08946  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01603  time: 0.6818  data_time: 0.0737  lr: 0.01  max_mem: 11811M
[11/17 16:21:29] d2.utils.events INFO:  eta: 20:03:45  iter: 4699  total_loss: 0.2376  loss_cls: 0.1257  loss_box_reg: 0.08664  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.01556  time: 0.6818  data_time: 0.0633  lr: 0.01  max_mem: 11811M
[11/17 16:21:42] d2.utils.events INFO:  eta: 20:03:38  iter: 4719  total_loss: 0.2581  loss_cls: 0.1322  loss_box_reg: 0.08907  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.01735  time: 0.6818  data_time: 0.0635  lr: 0.01  max_mem: 11811M
[11/17 16:21:56] d2.utils.events INFO:  eta: 20:03:31  iter: 4739  total_loss: 0.2407  loss_cls: 0.1276  loss_box_reg: 0.08398  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.01802  time: 0.6818  data_time: 0.0603  lr: 0.01  max_mem: 11811M
[11/17 16:22:10] d2.utils.events INFO:  eta: 20:03:27  iter: 4759  total_loss: 0.2317  loss_cls: 0.1224  loss_box_reg: 0.08253  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01684  time: 0.6818  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/17 16:22:23] d2.utils.events INFO:  eta: 20:03:26  iter: 4779  total_loss: 0.2422  loss_cls: 0.1254  loss_box_reg: 0.08486  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.01695  time: 0.6818  data_time: 0.0700  lr: 0.01  max_mem: 11811M
[11/17 16:22:37] d2.utils.events INFO:  eta: 20:03:07  iter: 4799  total_loss: 0.2496  loss_cls: 0.1327  loss_box_reg: 0.08626  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01833  time: 0.6818  data_time: 0.0742  lr: 0.01  max_mem: 11811M
[11/17 16:22:51] d2.utils.events INFO:  eta: 20:02:47  iter: 4819  total_loss: 0.2572  loss_cls: 0.1357  loss_box_reg: 0.089  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01687  time: 0.6819  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/17 16:23:04] d2.utils.events INFO:  eta: 20:02:23  iter: 4839  total_loss: 0.2585  loss_cls: 0.1335  loss_box_reg: 0.09243  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01711  time: 0.6818  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/17 16:23:18] d2.utils.events INFO:  eta: 20:02:55  iter: 4859  total_loss: 0.2546  loss_cls: 0.132  loss_box_reg: 0.09014  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01804  time: 0.6819  data_time: 0.0808  lr: 0.01  max_mem: 11811M
[11/17 16:23:32] d2.utils.events INFO:  eta: 20:02:16  iter: 4879  total_loss: 0.2386  loss_cls: 0.1246  loss_box_reg: 0.0853  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.01596  time: 0.6818  data_time: 0.0680  lr: 0.01  max_mem: 11811M
[11/17 16:23:45] d2.utils.events INFO:  eta: 20:02:19  iter: 4899  total_loss: 0.2401  loss_cls: 0.1279  loss_box_reg: 0.08452  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.01607  time: 0.6818  data_time: 0.0734  lr: 0.01  max_mem: 11811M
[11/17 16:23:59] d2.utils.events INFO:  eta: 20:02:52  iter: 4919  total_loss: 0.2557  loss_cls: 0.1366  loss_box_reg: 0.09019  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.01732  time: 0.6819  data_time: 0.0655  lr: 0.01  max_mem: 11811M
[11/17 16:24:13] d2.utils.events INFO:  eta: 20:02:59  iter: 4939  total_loss: 0.2447  loss_cls: 0.1309  loss_box_reg: 0.08711  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.01626  time: 0.6819  data_time: 0.0616  lr: 0.01  max_mem: 11811M
[11/17 16:24:26] d2.utils.events INFO:  eta: 20:02:25  iter: 4959  total_loss: 0.2437  loss_cls: 0.1288  loss_box_reg: 0.08739  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01509  time: 0.6818  data_time: 0.0623  lr: 0.01  max_mem: 11811M
[11/17 16:24:40] d2.utils.events INFO:  eta: 20:01:08  iter: 4979  total_loss: 0.2539  loss_cls: 0.1309  loss_box_reg: 0.08822  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.01877  time: 0.6818  data_time: 0.0600  lr: 0.01  max_mem: 11811M
[11/17 16:24:53] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0004999.pth
[11/17 16:24:54] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/17 16:24:54] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 16:24:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 16:24:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 16:24:54] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 16:24:55] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 16:24:55] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 16:25:02] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:18
[11/17 16:25:07] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/17 16:25:12] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/17 16:25:17] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/17 16:25:22] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/17 16:25:27] d2.evaluation.evaluator INFO: Inference done 617/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:52
[11/17 16:25:32] d2.evaluation.evaluator INFO: Inference done 738/3334. Dataloading: 0.0014 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/17 16:25:37] d2.evaluation.evaluator INFO: Inference done 861/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/17 16:25:42] d2.evaluation.evaluator INFO: Inference done 978/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/17 16:25:47] d2.evaluation.evaluator INFO: Inference done 1099/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/17 16:25:52] d2.evaluation.evaluator INFO: Inference done 1221/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/17 16:25:57] d2.evaluation.evaluator INFO: Inference done 1343/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/17 16:26:02] d2.evaluation.evaluator INFO: Inference done 1460/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/17 16:26:07] d2.evaluation.evaluator INFO: Inference done 1584/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/17 16:26:12] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/17 16:26:17] d2.evaluation.evaluator INFO: Inference done 1829/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/17 16:26:22] d2.evaluation.evaluator INFO: Inference done 1953/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/17 16:26:27] d2.evaluation.evaluator INFO: Inference done 2074/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/17 16:26:32] d2.evaluation.evaluator INFO: Inference done 2195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/17 16:26:37] d2.evaluation.evaluator INFO: Inference done 2317/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:42
[11/17 16:26:42] d2.evaluation.evaluator INFO: Inference done 2437/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/17 16:26:47] d2.evaluation.evaluator INFO: Inference done 2560/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/17 16:26:52] d2.evaluation.evaluator INFO: Inference done 2681/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/17 16:26:57] d2.evaluation.evaluator INFO: Inference done 2803/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/17 16:27:02] d2.evaluation.evaluator INFO: Inference done 2925/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/17 16:27:07] d2.evaluation.evaluator INFO: Inference done 3042/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/17 16:27:12] d2.evaluation.evaluator INFO: Inference done 3161/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/17 16:27:17] d2.evaluation.evaluator INFO: Inference done 3284/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:02
[11/17 16:27:20] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.120672 (0.041490 s / iter per device, on 6 devices)
[11/17 16:27:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039580 s / iter per device, on 6 devices)
[11/17 16:27:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 16:27:22] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 16:27:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 16:27:23] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 16:27:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.30 seconds.
[11/17 16:27:45] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 16:27:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.12 seconds.
[11/17 16:27:47] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.270 | 15.699 | 5.699  | 0.885 | 3.580 | 8.782 |
[11/17 16:27:47] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 4.068  | bird          | 26.321 | hat with a wide brim | 4.728  |
| person                | 6.772  | dog           | 39.508 | lizard               | 4.896  |
| sheep                 | 4.288  | wine bottle   | 2.081  | bowl                 | 9.519  |
| airplane              | 18.368 | domestic cat  | 6.927  | car                  | 28.161 |
| porcupine             | 9.602  | bear          | 8.801  | tape player          | 8.086  |
| ray                   | 1.802  | laptop        | 5.177  | zebra                | 20.424 |
| computer keyboard     | 2.353  | pitcher       | 2.575  | artichoke            | 12.575 |
| tv or monitor         | 10.175 | table         | 6.691  | chair                | 4.389  |
| helmet                | 9.131  | traffic light | 2.205  | red panda            | 6.010  |
| sunglasses            | 0.367  | lamp          | 2.269  | bicycle              | 4.888  |
| backpack              | 4.559  | mushroom      | 4.240  | fox                  | 5.661  |
| otter                 | 2.436  | guitar        | 2.032  | microphone           | 0.011  |
| strawberry            | 6.984  | stove         | 7.386  | violin               | 0.674  |
| bookshelf             | 9.576  | sofa          | 1.549  | bell pepper          | 2.383  |
| bagel                 | 4.202  | lemon         | 6.869  | orange               | 12.039 |
| bench                 | 1.577  | piano         | 9.379  | flower pot           | 1.054  |
| butterfly             | 24.153 | purse         | 4.314  | pomegranate          | 2.376  |
| train                 | 5.712  | drum          | 1.493  | hippopotamus         | 0.787  |
| ski                   | 0.905  | ladybug       | 26.110 | banana               | 1.131  |
| monkey                | 8.831  | bus           | 21.250 | miniskirt            | 2.441  |
| camel                 | 1.501  | cream         | 8.224  | lobster              | 2.709  |
| seal                  | 1.572  | horse         | 5.777  | cart                 | 9.678  |
| elephant              | 12.424 | snake         | 7.890  | fig                  | 3.817  |
| watercraft            | 20.187 | apple         | 13.847 | antelope             | 18.640 |
| cattle                | 1.433  | whale         | 10.891 | coffee maker         | 17.161 |
| baby bed              | 10.392 | frog          | 10.235 | bathing cap          | 4.581  |
| crutch                | 0.118  | koala bear    | 5.872  | tie                  | 0.265  |
| dumbbell              | 0.074  | tiger         | 2.196  | dragonfly            | 6.196  |
| goldfish              | 4.947  | cucumber      | 0.853  | turtle               | 6.049  |
| harp                  | 3.777  | jellyfish     | 5.441  | swine                | 5.887  |
| pretzel               | 4.182  | motorcycle    | 13.086 | beaker               | 9.186  |
| rabbit                | 15.095 | nail          | 0.780  | axe                  | 1.994  |
| salt or pepper shaker | 3.346  | croquet ball  | 9.928  | skunk                | 1.741  |
| starfish              | 9.732  |               |        |                      |        |
[11/17 16:27:49] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 16:27:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 16:27:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 16:27:49] d2.evaluation.testing INFO: copypaste: 7.2698,15.6988,5.6992,0.8851,3.5798,8.7817
[11/18 00:44:37] detectron2 INFO: Rank of current process: 0. World size: 6
[11/18 00:44:42] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 00:44:42] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=True, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/18 00:44:42] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "../../output/supervised/model_supervised.pth"
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (102000, 108000)
  MAX_ITER: 111000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.01
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: "../../output/supervised"
[11/18 00:44:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ../../output/supervised/model_supervised.pth
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 111000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 102000
  - 108000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/18 00:44:42] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/18 00:44:42] d2.utils.env INFO: Using a generated random seed 44502515
[11/18 00:44:42] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/18 00:44:42] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 00:44:42] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/18 00:44:43] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/18 00:44:43] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 283          |     bird      | 4331         | hat with a .. | 206          |
|    person     | 4657         |      dog      | 8341         |    lizard     | 640          |
|     sheep     | 196          |  wine bottle  | 154          |     bowl      | 335          |
|   airplane    | 217          | domestic cat  | 395          |      car      | 1171         |
|   porcupine   | 126          |     bear      | 361          |  tape player  | 109          |
|      ray      | 198          |    laptop     | 172          |     zebra     | 135          |
| computer ke.. | 102          |    pitcher    | 120          |   artichoke   | 180          |
| tv or monitor | 212          |     table     | 786          |     chair     | 905          |
|    helmet     | 433          | traffic light | 142          |   red panda   | 108          |
|  sunglasses   | 243          |     lamp      | 319          |    bicycle    | 187          |
|   backpack    | 148          |   mushroom    | 124          |      fox      | 292          |
|     otter     | 127          |    guitar     | 295          |  microphone   | 259          |
|  strawberry   | 232          |     stove     | 156          |    violin     | 118          |
|   bookshelf   | 106          |     sofa      | 160          |  bell pepper  | 146          |
|     bagel     | 125          |     lemon     | 170          |    orange     | 207          |
|     bench     | 150          |     piano     | 199          |  flower pot   | 189          |
|   butterfly   | 453          |     purse     | 130          |  pomegranate  | 188          |
|     train     | 178          |     drum      | 251          | hippopotamus  | 118          |
|      ski      | 109          |    ladybug    | 138          |    banana     | 244          |
|    monkey     | 1004         |      bus      | 322          |   miniskirt   | 118          |
|     camel     | 276          |     cream     | 194          |    lobster    | 253          |
|     seal      | 224          |     horse     | 265          |     cart      | 281          |
|   elephant    | 242          |     snake     | 1001         |      fig      | 133          |
|  watercraft   | 1038         |     apple     | 216          |   antelope    | 288          |
|    cattle     | 148          |     whale     | 155          | coffee maker  | 143          |
|   baby bed    | 185          |     frog      | 245          |  bathing cap  | 163          |
|    crutch     | 138          |  koala bear   | 139          |      tie      | 124          |
|   dumbbell    | 180          |     tiger     | 159          |   dragonfly   | 175          |
|   goldfish    | 228          |   cucumber    | 114          |    turtle     | 313          |
|     harp      | 152          |   jellyfish   | 184          |     swine     | 259          |
|    pretzel    | 124          |  motorcycle   | 278          |    beaker     | 115          |
|    rabbit     | 235          |     nail      | 86           |      axe      | 127          |
| salt or pep.. | 129          | croquet ball  | 135          |     skunk     | 99           |
|   starfish    | 130          |               |              |               |              |
|     total     | 41293        |               |              |               |              |[0m
[11/18 00:44:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/18 00:44:43] d2.data.build INFO: Using training sampler TrainingSampler
[11/18 00:44:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 00:44:43] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/18 00:44:44] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/18 00:44:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_0004999.pth ...
[11/18 00:44:44] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/18 00:44:44] fvcore.common.checkpoint INFO: Loading trainer from ../../output/supervised/model_0004999.pth ...
[11/18 00:44:44] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/18 00:44:45] d2.engine.train_loop INFO: Starting training from iteration 5000
[11/18 00:45:07] d2.utils.events INFO:  eta: 19:42:23  iter: 5019  total_loss: 0.235  loss_cls: 0.1212  loss_box_reg: 0.08409  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01789  time: 0.6735  data_time: 0.4119  lr: 0.01  max_mem: 11812M
[11/18 00:45:20] d2.utils.events INFO:  eta: 19:42:09  iter: 5039  total_loss: 0.2503  loss_cls: 0.1324  loss_box_reg: 0.08757  loss_rpn_cls: 0.014  loss_rpn_loc: 0.01609  time: 0.6749  data_time: 0.0668  lr: 0.01  max_mem: 11812M
[11/18 00:45:34] d2.utils.events INFO:  eta: 19:41:34  iter: 5059  total_loss: 0.2425  loss_cls: 0.1304  loss_box_reg: 0.08501  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.01729  time: 0.6748  data_time: 0.0694  lr: 0.01  max_mem: 11812M
[11/18 00:45:48] d2.utils.events INFO:  eta: 19:55:58  iter: 5079  total_loss: 0.2494  loss_cls: 0.1328  loss_box_reg: 0.09148  loss_rpn_cls: 0.0107  loss_rpn_loc: 0.01862  time: 0.6778  data_time: 0.0728  lr: 0.01  max_mem: 11812M
[11/18 00:46:02] d2.utils.events INFO:  eta: 20:02:55  iter: 5099  total_loss: 0.2313  loss_cls: 0.123  loss_box_reg: 0.07962  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01701  time: 0.6822  data_time: 0.0714  lr: 0.01  max_mem: 11813M
[11/18 00:46:15] d2.utils.events INFO:  eta: 19:59:15  iter: 5119  total_loss: 0.2478  loss_cls: 0.1208  loss_box_reg: 0.08708  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01693  time: 0.6818  data_time: 0.0703  lr: 0.01  max_mem: 11813M
[11/18 00:46:29] d2.utils.events INFO:  eta: 19:59:01  iter: 5139  total_loss: 0.2553  loss_cls: 0.1319  loss_box_reg: 0.09073  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.01721  time: 0.6808  data_time: 0.0661  lr: 0.01  max_mem: 11813M
[11/18 00:46:42] d2.utils.events INFO:  eta: 19:58:20  iter: 5159  total_loss: 0.2375  loss_cls: 0.1242  loss_box_reg: 0.08354  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01666  time: 0.6807  data_time: 0.0669  lr: 0.01  max_mem: 11813M
[11/18 00:46:56] d2.utils.events INFO:  eta: 20:05:03  iter: 5179  total_loss: 0.2511  loss_cls: 0.1284  loss_box_reg: 0.08969  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.0183  time: 0.6817  data_time: 0.0646  lr: 0.01  max_mem: 11813M
[11/18 00:47:10] d2.utils.events INFO:  eta: 20:05:26  iter: 5199  total_loss: 0.2435  loss_cls: 0.1252  loss_box_reg: 0.08755  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01719  time: 0.6821  data_time: 0.0673  lr: 0.01  max_mem: 11813M
[11/18 00:47:24] d2.utils.events INFO:  eta: 20:04:35  iter: 5219  total_loss: 0.2441  loss_cls: 0.1289  loss_box_reg: 0.08877  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01627  time: 0.6821  data_time: 0.0707  lr: 0.01  max_mem: 11813M
[11/18 00:47:37] d2.utils.events INFO:  eta: 20:05:42  iter: 5239  total_loss: 0.2447  loss_cls: 0.1313  loss_box_reg: 0.08393  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.01743  time: 0.6829  data_time: 0.0687  lr: 0.01  max_mem: 11813M
[11/18 00:47:51] d2.utils.events INFO:  eta: 20:02:09  iter: 5259  total_loss: 0.2336  loss_cls: 0.1262  loss_box_reg: 0.08168  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.01703  time: 0.6822  data_time: 0.0708  lr: 0.01  max_mem: 11813M
[11/18 00:48:04] d2.utils.events INFO:  eta: 19:59:33  iter: 5279  total_loss: 0.2343  loss_cls: 0.1255  loss_box_reg: 0.08178  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01747  time: 0.6817  data_time: 0.0632  lr: 0.01  max_mem: 11813M
[11/18 00:48:18] d2.utils.events INFO:  eta: 19:59:47  iter: 5299  total_loss: 0.2415  loss_cls: 0.1282  loss_box_reg: 0.08346  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.01647  time: 0.6818  data_time: 0.0678  lr: 0.01  max_mem: 11813M
[11/18 00:48:32] d2.utils.events INFO:  eta: 19:59:10  iter: 5319  total_loss: 0.239  loss_cls: 0.1261  loss_box_reg: 0.08676  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.01704  time: 0.6817  data_time: 0.0684  lr: 0.01  max_mem: 11813M
[11/18 00:48:45] d2.utils.events INFO:  eta: 19:58:31  iter: 5339  total_loss: 0.2416  loss_cls: 0.1248  loss_box_reg: 0.08641  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.01673  time: 0.6816  data_time: 0.0720  lr: 0.01  max_mem: 11813M
[11/18 00:48:59] d2.utils.events INFO:  eta: 19:57:03  iter: 5359  total_loss: 0.2321  loss_cls: 0.1202  loss_box_reg: 0.08305  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01786  time: 0.6813  data_time: 0.0592  lr: 0.01  max_mem: 11813M
[11/18 00:49:12] d2.utils.events INFO:  eta: 19:56:43  iter: 5379  total_loss: 0.2413  loss_cls: 0.129  loss_box_reg: 0.08636  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01684  time: 0.6813  data_time: 0.0670  lr: 0.01  max_mem: 11813M
[11/18 00:49:26] d2.utils.events INFO:  eta: 19:57:22  iter: 5399  total_loss: 0.2512  loss_cls: 0.1368  loss_box_reg: 0.08522  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.0196  time: 0.6820  data_time: 0.0826  lr: 0.01  max_mem: 11813M
[11/18 00:49:40] d2.utils.events INFO:  eta: 19:56:13  iter: 5419  total_loss: 0.235  loss_cls: 0.1191  loss_box_reg: 0.08175  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.01858  time: 0.6816  data_time: 0.0716  lr: 0.01  max_mem: 11813M
[11/18 00:49:53] d2.utils.events INFO:  eta: 19:55:48  iter: 5439  total_loss: 0.2354  loss_cls: 0.1205  loss_box_reg: 0.0825  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01744  time: 0.6814  data_time: 0.0690  lr: 0.01  max_mem: 11813M
[11/18 00:50:07] d2.utils.events INFO:  eta: 19:55:46  iter: 5459  total_loss: 0.2291  loss_cls: 0.1195  loss_box_reg: 0.08427  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01599  time: 0.6815  data_time: 0.0713  lr: 0.01  max_mem: 11813M
[11/18 00:50:21] d2.utils.events INFO:  eta: 19:55:35  iter: 5479  total_loss: 0.2405  loss_cls: 0.1275  loss_box_reg: 0.08758  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.01723  time: 0.6821  data_time: 0.0779  lr: 0.01  max_mem: 11813M
[11/18 00:50:34] d2.utils.events INFO:  eta: 19:54:51  iter: 5499  total_loss: 0.2406  loss_cls: 0.1261  loss_box_reg: 0.08682  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01579  time: 0.6818  data_time: 0.0643  lr: 0.01  max_mem: 11813M
[11/18 00:50:48] d2.utils.events INFO:  eta: 19:54:20  iter: 5519  total_loss: 0.2429  loss_cls: 0.1269  loss_box_reg: 0.08407  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.01737  time: 0.6816  data_time: 0.0649  lr: 0.01  max_mem: 11813M
[11/18 00:51:02] d2.utils.events INFO:  eta: 19:53:58  iter: 5539  total_loss: 0.2362  loss_cls: 0.122  loss_box_reg: 0.08264  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.01566  time: 0.6814  data_time: 0.0720  lr: 0.01  max_mem: 11813M
[11/18 00:51:15] d2.utils.events INFO:  eta: 19:53:54  iter: 5559  total_loss: 0.2438  loss_cls: 0.1259  loss_box_reg: 0.08383  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.01815  time: 0.6812  data_time: 0.0638  lr: 0.01  max_mem: 11813M
[11/18 00:51:29] d2.utils.events INFO:  eta: 19:53:45  iter: 5579  total_loss: 0.2392  loss_cls: 0.121  loss_box_reg: 0.0846  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.01714  time: 0.6813  data_time: 0.0668  lr: 0.01  max_mem: 11813M
[11/18 00:51:42] d2.utils.events INFO:  eta: 19:53:18  iter: 5599  total_loss: 0.2539  loss_cls: 0.1295  loss_box_reg: 0.08906  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.01827  time: 0.6810  data_time: 0.0654  lr: 0.01  max_mem: 11813M
[11/18 00:51:56] d2.utils.events INFO:  eta: 19:53:18  iter: 5619  total_loss: 0.2302  loss_cls: 0.1212  loss_box_reg: 0.08141  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01703  time: 0.6809  data_time: 0.0654  lr: 0.01  max_mem: 11813M
[11/18 00:52:09] d2.utils.events INFO:  eta: 19:53:10  iter: 5639  total_loss: 0.2437  loss_cls: 0.125  loss_box_reg: 0.08578  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01784  time: 0.6809  data_time: 0.0663  lr: 0.01  max_mem: 11813M
[11/18 00:52:23] d2.utils.events INFO:  eta: 19:52:51  iter: 5659  total_loss: 0.243  loss_cls: 0.1275  loss_box_reg: 0.08517  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.01763  time: 0.6808  data_time: 0.0648  lr: 0.01  max_mem: 11813M
[11/18 00:52:36] d2.utils.events INFO:  eta: 19:52:11  iter: 5679  total_loss: 0.2513  loss_cls: 0.1293  loss_box_reg: 0.0861  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.01604  time: 0.6804  data_time: 0.0618  lr: 0.01  max_mem: 11813M
[11/18 00:52:50] d2.utils.events INFO:  eta: 19:52:03  iter: 5699  total_loss: 0.2419  loss_cls: 0.1232  loss_box_reg: 0.08181  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01732  time: 0.6807  data_time: 0.0794  lr: 0.01  max_mem: 11813M
[11/18 00:53:04] d2.utils.events INFO:  eta: 19:51:26  iter: 5719  total_loss: 0.2289  loss_cls: 0.119  loss_box_reg: 0.07933  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01831  time: 0.6805  data_time: 0.0705  lr: 0.01  max_mem: 11813M
[11/18 00:53:17] d2.utils.events INFO:  eta: 19:51:07  iter: 5739  total_loss: 0.2348  loss_cls: 0.1206  loss_box_reg: 0.08261  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.01569  time: 0.6804  data_time: 0.0661  lr: 0.01  max_mem: 11813M
[11/18 00:53:31] d2.utils.events INFO:  eta: 19:51:10  iter: 5759  total_loss: 0.231  loss_cls: 0.1203  loss_box_reg: 0.08593  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01637  time: 0.6805  data_time: 0.0657  lr: 0.01  max_mem: 11813M
[11/18 00:53:44] d2.utils.events INFO:  eta: 19:51:03  iter: 5779  total_loss: 0.2477  loss_cls: 0.1281  loss_box_reg: 0.08566  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01792  time: 0.6804  data_time: 0.0658  lr: 0.01  max_mem: 11813M
[11/18 00:53:58] d2.utils.events INFO:  eta: 19:50:49  iter: 5799  total_loss: 0.2324  loss_cls: 0.1202  loss_box_reg: 0.08387  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.01736  time: 0.6803  data_time: 0.0671  lr: 0.01  max_mem: 11813M
[11/18 00:54:12] d2.utils.events INFO:  eta: 19:50:36  iter: 5819  total_loss: 0.244  loss_cls: 0.128  loss_box_reg: 0.09021  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.01669  time: 0.6803  data_time: 0.0639  lr: 0.01  max_mem: 11813M
[11/18 00:54:25] d2.utils.events INFO:  eta: 19:50:16  iter: 5839  total_loss: 0.2458  loss_cls: 0.1316  loss_box_reg: 0.08905  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01763  time: 0.6802  data_time: 0.0607  lr: 0.01  max_mem: 11813M
[11/18 00:54:39] d2.utils.events INFO:  eta: 19:50:02  iter: 5859  total_loss: 0.2466  loss_cls: 0.128  loss_box_reg: 0.08605  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01617  time: 0.6801  data_time: 0.0645  lr: 0.01  max_mem: 11813M
[11/18 00:54:52] d2.utils.events INFO:  eta: 19:49:34  iter: 5879  total_loss: 0.2378  loss_cls: 0.124  loss_box_reg: 0.08812  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01474  time: 0.6799  data_time: 0.0700  lr: 0.01  max_mem: 11813M
[11/18 00:55:05] d2.utils.events INFO:  eta: 19:49:01  iter: 5899  total_loss: 0.2499  loss_cls: 0.1291  loss_box_reg: 0.08973  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.0167  time: 0.6797  data_time: 0.0617  lr: 0.01  max_mem: 11813M
[11/18 00:55:19] d2.utils.events INFO:  eta: 19:49:03  iter: 5919  total_loss: 0.2367  loss_cls: 0.1209  loss_box_reg: 0.0846  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01744  time: 0.6799  data_time: 0.0617  lr: 0.01  max_mem: 11813M
[11/18 00:55:33] d2.utils.events INFO:  eta: 19:48:50  iter: 5939  total_loss: 0.2406  loss_cls: 0.1276  loss_box_reg: 0.0862  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.01591  time: 0.6800  data_time: 0.0726  lr: 0.01  max_mem: 11813M
[11/18 00:55:46] d2.utils.events INFO:  eta: 19:48:36  iter: 5959  total_loss: 0.247  loss_cls: 0.129  loss_box_reg: 0.0872  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01667  time: 0.6799  data_time: 0.0609  lr: 0.01  max_mem: 11813M
[11/18 00:56:00] d2.utils.events INFO:  eta: 19:48:15  iter: 5979  total_loss: 0.2391  loss_cls: 0.126  loss_box_reg: 0.08212  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.01647  time: 0.6799  data_time: 0.0682  lr: 0.01  max_mem: 11813M
[11/18 00:56:14] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0005999.pth
[11/18 00:56:14] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 00:56:14] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 00:56:15] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/18 00:56:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 00:56:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 00:56:15] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 00:56:15] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 00:56:15] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 00:56:22] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0016 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:19
[11/18 00:56:27] d2.evaluation.evaluator INFO: Inference done 137/3334. Dataloading: 0.0016 s/iter. Inference: 0.0382 s/iter. Eval: 0.0002 s/iter. Total: 0.0400 s/iter. ETA=0:02:08
[11/18 00:56:32] d2.evaluation.evaluator INFO: Inference done 266/3334. Dataloading: 0.0015 s/iter. Inference: 0.0377 s/iter. Eval: 0.0002 s/iter. Total: 0.0395 s/iter. ETA=0:02:01
[11/18 00:56:37] d2.evaluation.evaluator INFO: Inference done 389/3334. Dataloading: 0.0016 s/iter. Inference: 0.0381 s/iter. Eval: 0.0002 s/iter. Total: 0.0399 s/iter. ETA=0:01:57
[11/18 00:56:42] d2.evaluation.evaluator INFO: Inference done 512/3334. Dataloading: 0.0016 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0401 s/iter. ETA=0:01:53
[11/18 00:56:47] d2.evaluation.evaluator INFO: Inference done 635/3334. Dataloading: 0.0015 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:48
[11/18 00:56:52] d2.evaluation.evaluator INFO: Inference done 758/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:44
[11/18 00:56:57] d2.evaluation.evaluator INFO: Inference done 882/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:39
[11/18 00:57:02] d2.evaluation.evaluator INFO: Inference done 1005/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:34
[11/18 00:57:07] d2.evaluation.evaluator INFO: Inference done 1129/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:29
[11/18 00:57:12] d2.evaluation.evaluator INFO: Inference done 1255/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:24
[11/18 00:57:17] d2.evaluation.evaluator INFO: Inference done 1378/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:19
[11/18 00:57:22] d2.evaluation.evaluator INFO: Inference done 1502/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:14
[11/18 00:57:27] d2.evaluation.evaluator INFO: Inference done 1623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:09
[11/18 00:57:32] d2.evaluation.evaluator INFO: Inference done 1745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:04
[11/18 00:57:37] d2.evaluation.evaluator INFO: Inference done 1865/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:59
[11/18 00:57:42] d2.evaluation.evaluator INFO: Inference done 1987/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:54
[11/18 00:57:47] d2.evaluation.evaluator INFO: Inference done 2107/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/18 00:57:52] d2.evaluation.evaluator INFO: Inference done 2228/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/18 00:57:57] d2.evaluation.evaluator INFO: Inference done 2351/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/18 00:58:02] d2.evaluation.evaluator INFO: Inference done 2474/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/18 00:58:07] d2.evaluation.evaluator INFO: Inference done 2597/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/18 00:58:12] d2.evaluation.evaluator INFO: Inference done 2720/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:25
[11/18 00:58:18] d2.evaluation.evaluator INFO: Inference done 2842/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:20
[11/18 00:58:23] d2.evaluation.evaluator INFO: Inference done 2967/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:14
[11/18 00:58:28] d2.evaluation.evaluator INFO: Inference done 3085/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/18 00:58:33] d2.evaluation.evaluator INFO: Inference done 3208/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/18 00:58:38] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.377972 (0.040967 s / iter per device, on 6 devices)
[11/18 00:58:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038943 s / iter per device, on 6 devices)
[11/18 00:58:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 00:58:40] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 00:58:41] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 00:58:42] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 00:59:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.69 seconds.
[11/18 00:59:06] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 00:59:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.83 seconds.
[11/18 00:59:07] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 8.006 | 16.663 | 6.537  | 1.103 | 3.806 | 9.601 |
[11/18 00:59:07] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 6.260  | bird          | 27.071 | hat with a wide brim | 4.614  |
| person                | 8.039  | dog           | 43.569 | lizard               | 4.804  |
| sheep                 | 5.575  | wine bottle   | 3.067  | bowl                 | 9.046  |
| airplane              | 17.999 | domestic cat  | 7.140  | car                  | 31.807 |
| porcupine             | 11.056 | bear          | 10.835 | tape player          | 8.166  |
| ray                   | 1.842  | laptop        | 6.621  | zebra                | 21.229 |
| computer keyboard     | 2.958  | pitcher       | 3.593  | artichoke            | 10.975 |
| tv or monitor         | 9.814  | table         | 6.696  | chair                | 5.368  |
| helmet                | 9.896  | traffic light | 1.903  | red panda            | 10.284 |
| sunglasses            | 0.214  | lamp          | 2.124  | bicycle              | 5.807  |
| backpack              | 4.451  | mushroom      | 4.852  | fox                  | 7.087  |
| otter                 | 2.150  | guitar        | 3.947  | microphone           | 0.001  |
| strawberry            | 5.996  | stove         | 7.108  | violin               | 0.714  |
| bookshelf             | 12.103 | sofa          | 2.373  | bell pepper          | 6.317  |
| bagel                 | 4.694  | lemon         | 9.579  | orange               | 10.861 |
| bench                 | 1.503  | piano         | 11.773 | flower pot           | 1.593  |
| butterfly             | 24.308 | purse         | 3.843  | pomegranate          | 3.973  |
| train                 | 10.546 | drum          | 1.225  | hippopotamus         | 1.564  |
| ski                   | 0.838  | ladybug       | 17.970 | banana               | 0.349  |
| monkey                | 9.496  | bus           | 25.591 | miniskirt            | 2.693  |
| camel                 | 2.468  | cream         | 7.268  | lobster              | 3.742  |
| seal                  | 1.745  | horse         | 6.331  | cart                 | 11.565 |
| elephant              | 14.876 | snake         | 8.155  | fig                  | 4.168  |
| watercraft            | 20.932 | apple         | 12.649 | antelope             | 15.924 |
| cattle                | 2.452  | whale         | 11.703 | coffee maker         | 16.640 |
| baby bed              | 13.760 | frog          | 9.209  | bathing cap          | 5.998  |
| crutch                | 0.009  | koala bear    | 9.856  | tie                  | 0.434  |
| dumbbell              | 0.094  | tiger         | 9.353  | dragonfly            | 6.165  |
| goldfish              | 7.089  | cucumber      | 0.216  | turtle               | 8.924  |
| harp                  | 4.542  | jellyfish     | 8.042  | swine                | 6.805  |
| pretzel               | 3.073  | motorcycle    | 17.321 | beaker               | 10.677 |
| rabbit                | 13.508 | nail          | 0.703  | axe                  | 1.759  |
| salt or pepper shaker | 1.083  | croquet ball  | 9.561  | skunk                | 4.144  |
| starfish              | 9.776  |               |        |                      |        |
[11/18 00:59:10] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 00:59:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 00:59:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 00:59:10] d2.evaluation.testing INFO: copypaste: 8.0059,16.6631,6.5373,1.1033,3.8055,9.6014
[11/18 00:59:10] d2.utils.events INFO:  eta: 19:48:09  iter: 5999  total_loss: 0.2553  loss_cls: 0.134  loss_box_reg: 0.08703  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.01781  time: 0.6799  data_time: 0.0648  lr: 0.01  max_mem: 11813M
[11/18 00:59:23] d2.utils.events INFO:  eta: 19:47:58  iter: 6019  total_loss: 0.2288  loss_cls: 0.1205  loss_box_reg: 0.0807  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01654  time: 0.6798  data_time: 0.0702  lr: 0.01  max_mem: 11813M
[11/18 00:59:37] d2.utils.events INFO:  eta: 19:47:42  iter: 6039  total_loss: 0.2322  loss_cls: 0.1202  loss_box_reg: 0.08389  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01647  time: 0.6796  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 00:59:50] d2.utils.events INFO:  eta: 19:47:31  iter: 6059  total_loss: 0.2517  loss_cls: 0.1317  loss_box_reg: 0.08892  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01765  time: 0.6794  data_time: 0.0656  lr: 0.01  max_mem: 11813M
[11/18 01:00:04] d2.utils.events INFO:  eta: 19:46:24  iter: 6079  total_loss: 0.2359  loss_cls: 0.1222  loss_box_reg: 0.08568  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01768  time: 0.6793  data_time: 0.0635  lr: 0.01  max_mem: 11813M
[11/18 01:00:17] d2.utils.events INFO:  eta: 19:45:44  iter: 6099  total_loss: 0.2361  loss_cls: 0.1224  loss_box_reg: 0.08215  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.0164  time: 0.6794  data_time: 0.0696  lr: 0.01  max_mem: 11813M
[11/18 01:00:31] d2.utils.events INFO:  eta: 19:45:39  iter: 6119  total_loss: 0.2392  loss_cls: 0.1211  loss_box_reg: 0.08922  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01682  time: 0.6797  data_time: 0.0794  lr: 0.01  max_mem: 11813M
[11/18 01:00:45] d2.utils.events INFO:  eta: 19:45:25  iter: 6139  total_loss: 0.2519  loss_cls: 0.1308  loss_box_reg: 0.08863  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01659  time: 0.6798  data_time: 0.0711  lr: 0.01  max_mem: 11813M
[11/18 01:00:59] d2.utils.events INFO:  eta: 19:45:34  iter: 6159  total_loss: 0.2423  loss_cls: 0.1276  loss_box_reg: 0.08645  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01681  time: 0.6799  data_time: 0.0674  lr: 0.01  max_mem: 11813M
[11/18 01:01:12] d2.utils.events INFO:  eta: 19:44:45  iter: 6179  total_loss: 0.2483  loss_cls: 0.1281  loss_box_reg: 0.08772  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.0165  time: 0.6799  data_time: 0.0712  lr: 0.01  max_mem: 11813M
[11/18 01:01:26] d2.utils.events INFO:  eta: 19:44:31  iter: 6199  total_loss: 0.2159  loss_cls: 0.1137  loss_box_reg: 0.07674  loss_rpn_cls: 0.009847  loss_rpn_loc: 0.01571  time: 0.6800  data_time: 0.0599  lr: 0.01  max_mem: 11813M
[11/18 01:01:40] d2.utils.events INFO:  eta: 19:43:39  iter: 6219  total_loss: 0.242  loss_cls: 0.1272  loss_box_reg: 0.08656  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.01697  time: 0.6798  data_time: 0.0662  lr: 0.01  max_mem: 11813M
[11/18 01:01:53] d2.utils.events INFO:  eta: 19:42:45  iter: 6239  total_loss: 0.2377  loss_cls: 0.1232  loss_box_reg: 0.08206  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01658  time: 0.6798  data_time: 0.0654  lr: 0.01  max_mem: 11813M
[11/18 01:02:07] d2.utils.events INFO:  eta: 19:43:12  iter: 6259  total_loss: 0.2416  loss_cls: 0.1221  loss_box_reg: 0.08624  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.01844  time: 0.6799  data_time: 0.0778  lr: 0.01  max_mem: 11813M
[11/18 01:02:20] d2.utils.events INFO:  eta: 19:42:56  iter: 6279  total_loss: 0.2469  loss_cls: 0.1282  loss_box_reg: 0.08871  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.01641  time: 0.6799  data_time: 0.0657  lr: 0.01  max_mem: 11813M
[11/18 01:02:34] d2.utils.events INFO:  eta: 19:42:25  iter: 6299  total_loss: 0.2459  loss_cls: 0.1301  loss_box_reg: 0.0911  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.01718  time: 0.6800  data_time: 0.0677  lr: 0.01  max_mem: 11813M
[11/18 01:02:48] d2.utils.events INFO:  eta: 19:42:25  iter: 6319  total_loss: 0.2338  loss_cls: 0.1234  loss_box_reg: 0.08474  loss_rpn_cls: 0.011  loss_rpn_loc: 0.01534  time: 0.6800  data_time: 0.0742  lr: 0.01  max_mem: 11813M
[11/18 01:03:01] d2.utils.events INFO:  eta: 19:41:37  iter: 6339  total_loss: 0.2306  loss_cls: 0.1203  loss_box_reg: 0.08375  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01675  time: 0.6800  data_time: 0.0665  lr: 0.01  max_mem: 11813M
[11/18 01:03:15] d2.utils.events INFO:  eta: 19:41:44  iter: 6359  total_loss: 0.2407  loss_cls: 0.1249  loss_box_reg: 0.08514  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.0165  time: 0.6800  data_time: 0.0646  lr: 0.01  max_mem: 11813M
[11/18 01:03:28] d2.utils.events INFO:  eta: 19:41:43  iter: 6379  total_loss: 0.2377  loss_cls: 0.122  loss_box_reg: 0.08443  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.0175  time: 0.6800  data_time: 0.0672  lr: 0.01  max_mem: 11813M
[11/18 01:03:42] d2.utils.events INFO:  eta: 19:40:16  iter: 6399  total_loss: 0.2381  loss_cls: 0.1238  loss_box_reg: 0.08384  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01915  time: 0.6799  data_time: 0.0659  lr: 0.01  max_mem: 11813M
[11/18 01:03:56] d2.utils.events INFO:  eta: 19:42:00  iter: 6419  total_loss: 0.2378  loss_cls: 0.1257  loss_box_reg: 0.0819  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.0169  time: 0.6800  data_time: 0.0674  lr: 0.01  max_mem: 11813M
[11/18 01:04:10] d2.utils.events INFO:  eta: 19:41:46  iter: 6439  total_loss: 0.2389  loss_cls: 0.1243  loss_box_reg: 0.08513  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.0178  time: 0.6801  data_time: 0.0726  lr: 0.01  max_mem: 11813M
[11/18 01:04:23] d2.utils.events INFO:  eta: 19:41:57  iter: 6459  total_loss: 0.2511  loss_cls: 0.1309  loss_box_reg: 0.08771  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.01782  time: 0.6802  data_time: 0.0671  lr: 0.01  max_mem: 11813M
[11/18 01:04:37] d2.utils.events INFO:  eta: 19:41:43  iter: 6479  total_loss: 0.2318  loss_cls: 0.1205  loss_box_reg: 0.08228  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01725  time: 0.6804  data_time: 0.0731  lr: 0.01  max_mem: 11813M
[11/18 01:04:51] d2.utils.events INFO:  eta: 19:42:06  iter: 6499  total_loss: 0.2403  loss_cls: 0.1229  loss_box_reg: 0.08599  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.01682  time: 0.6805  data_time: 0.0792  lr: 0.01  max_mem: 11813M
[11/18 01:05:05] d2.utils.events INFO:  eta: 19:42:18  iter: 6519  total_loss: 0.2454  loss_cls: 0.1275  loss_box_reg: 0.08405  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.01729  time: 0.6806  data_time: 0.0654  lr: 0.01  max_mem: 11813M
[11/18 01:05:18] d2.utils.events INFO:  eta: 19:42:12  iter: 6539  total_loss: 0.2335  loss_cls: 0.1241  loss_box_reg: 0.0854  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.01525  time: 0.6805  data_time: 0.0666  lr: 0.01  max_mem: 11813M
[11/18 01:05:32] d2.utils.events INFO:  eta: 19:41:20  iter: 6559  total_loss: 0.2351  loss_cls: 0.1175  loss_box_reg: 0.08567  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01913  time: 0.6804  data_time: 0.0679  lr: 0.01  max_mem: 11813M
[11/18 01:05:45] d2.utils.events INFO:  eta: 19:41:06  iter: 6579  total_loss: 0.2343  loss_cls: 0.1192  loss_box_reg: 0.08221  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.01637  time: 0.6804  data_time: 0.0646  lr: 0.01  max_mem: 11813M
[11/18 01:05:59] d2.utils.events INFO:  eta: 19:40:41  iter: 6599  total_loss: 0.2343  loss_cls: 0.1202  loss_box_reg: 0.0841  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01755  time: 0.6802  data_time: 0.0627  lr: 0.01  max_mem: 11813M
[11/18 01:06:12] d2.utils.events INFO:  eta: 19:39:56  iter: 6619  total_loss: 0.2356  loss_cls: 0.1214  loss_box_reg: 0.0822  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.01702  time: 0.6801  data_time: 0.0645  lr: 0.01  max_mem: 11813M
[11/18 01:06:25] d2.utils.events INFO:  eta: 19:38:53  iter: 6639  total_loss: 0.2413  loss_cls: 0.1233  loss_box_reg: 0.08896  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01546  time: 0.6800  data_time: 0.0658  lr: 0.01  max_mem: 11813M
[11/18 01:06:39] d2.utils.events INFO:  eta: 19:39:17  iter: 6659  total_loss: 0.2332  loss_cls: 0.1199  loss_box_reg: 0.08428  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.01662  time: 0.6800  data_time: 0.0727  lr: 0.01  max_mem: 11813M
[11/18 01:06:53] d2.utils.events INFO:  eta: 19:39:42  iter: 6679  total_loss: 0.237  loss_cls: 0.1242  loss_box_reg: 0.08327  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.01593  time: 0.6800  data_time: 0.0617  lr: 0.01  max_mem: 11813M
[11/18 01:07:06] d2.utils.events INFO:  eta: 19:38:52  iter: 6699  total_loss: 0.2359  loss_cls: 0.1211  loss_box_reg: 0.08973  loss_rpn_cls: 0.009315  loss_rpn_loc: 0.01636  time: 0.6799  data_time: 0.0616  lr: 0.01  max_mem: 11813M
[11/18 01:07:20] d2.utils.events INFO:  eta: 19:39:00  iter: 6719  total_loss: 0.2477  loss_cls: 0.1299  loss_box_reg: 0.0869  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01667  time: 0.6799  data_time: 0.0587  lr: 0.01  max_mem: 11813M
[11/18 01:07:33] d2.utils.events INFO:  eta: 19:39:06  iter: 6739  total_loss: 0.2479  loss_cls: 0.1263  loss_box_reg: 0.08889  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01742  time: 0.6799  data_time: 0.0724  lr: 0.01  max_mem: 11813M
[11/18 01:07:47] d2.utils.events INFO:  eta: 19:38:21  iter: 6759  total_loss: 0.2387  loss_cls: 0.1234  loss_box_reg: 0.08765  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01766  time: 0.6799  data_time: 0.0647  lr: 0.01  max_mem: 11813M
[11/18 01:08:01] d2.utils.events INFO:  eta: 19:38:19  iter: 6779  total_loss: 0.2355  loss_cls: 0.1216  loss_box_reg: 0.08145  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01796  time: 0.6799  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 01:08:14] d2.utils.events INFO:  eta: 19:37:45  iter: 6799  total_loss: 0.228  loss_cls: 0.1188  loss_box_reg: 0.07971  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.01766  time: 0.6799  data_time: 0.0699  lr: 0.01  max_mem: 11813M
[11/18 01:08:28] d2.utils.events INFO:  eta: 19:37:39  iter: 6819  total_loss: 0.239  loss_cls: 0.1252  loss_box_reg: 0.08522  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01708  time: 0.6799  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 01:08:41] d2.utils.events INFO:  eta: 19:37:18  iter: 6839  total_loss: 0.2327  loss_cls: 0.1222  loss_box_reg: 0.08187  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01672  time: 0.6799  data_time: 0.0648  lr: 0.01  max_mem: 11813M
[11/18 01:08:55] d2.utils.events INFO:  eta: 19:36:42  iter: 6859  total_loss: 0.2386  loss_cls: 0.121  loss_box_reg: 0.08608  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.01725  time: 0.6799  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 01:09:09] d2.utils.events INFO:  eta: 19:37:11  iter: 6879  total_loss: 0.2477  loss_cls: 0.1271  loss_box_reg: 0.09089  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01811  time: 0.6799  data_time: 0.0679  lr: 0.01  max_mem: 11813M
[11/18 01:09:22] d2.utils.events INFO:  eta: 19:37:15  iter: 6899  total_loss: 0.2326  loss_cls: 0.1188  loss_box_reg: 0.08279  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01761  time: 0.6799  data_time: 0.0613  lr: 0.01  max_mem: 11813M
[11/18 01:09:36] d2.utils.events INFO:  eta: 19:36:44  iter: 6919  total_loss: 0.2329  loss_cls: 0.1173  loss_box_reg: 0.08231  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01613  time: 0.6799  data_time: 0.0617  lr: 0.01  max_mem: 11813M
[11/18 01:09:50] d2.utils.events INFO:  eta: 19:37:18  iter: 6939  total_loss: 0.2527  loss_cls: 0.1356  loss_box_reg: 0.09103  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.0172  time: 0.6800  data_time: 0.0785  lr: 0.01  max_mem: 11813M
[11/18 01:10:03] d2.utils.events INFO:  eta: 19:37:46  iter: 6959  total_loss: 0.2527  loss_cls: 0.1314  loss_box_reg: 0.09021  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01739  time: 0.6801  data_time: 0.0630  lr: 0.01  max_mem: 11813M
[11/18 01:10:17] d2.utils.events INFO:  eta: 19:37:43  iter: 6979  total_loss: 0.2408  loss_cls: 0.1225  loss_box_reg: 0.08464  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01975  time: 0.6801  data_time: 0.0740  lr: 0.01  max_mem: 11813M
[11/18 01:10:30] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0006999.pth
[11/18 01:10:31] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 01:10:31] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 01:10:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 01:10:31] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 01:10:31] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 01:10:32] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 01:10:32] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 01:10:39] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:17
[11/18 01:10:44] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:09
[11/18 01:10:49] d2.evaluation.evaluator INFO: Inference done 259/3334. Dataloading: 0.0016 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:04
[11/18 01:10:54] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/18 01:10:59] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/18 01:11:04] d2.evaluation.evaluator INFO: Inference done 622/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/18 01:11:09] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/18 01:11:14] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:41
[11/18 01:11:19] d2.evaluation.evaluator INFO: Inference done 986/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:36
[11/18 01:11:24] d2.evaluation.evaluator INFO: Inference done 1105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:31
[11/18 01:11:29] d2.evaluation.evaluator INFO: Inference done 1227/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:26
[11/18 01:11:34] d2.evaluation.evaluator INFO: Inference done 1349/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:21
[11/18 01:11:39] d2.evaluation.evaluator INFO: Inference done 1472/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/18 01:11:44] d2.evaluation.evaluator INFO: Inference done 1595/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/18 01:11:49] d2.evaluation.evaluator INFO: Inference done 1717/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/18 01:11:54] d2.evaluation.evaluator INFO: Inference done 1839/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/18 01:11:59] d2.evaluation.evaluator INFO: Inference done 1958/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/18 01:12:04] d2.evaluation.evaluator INFO: Inference done 2077/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/18 01:12:09] d2.evaluation.evaluator INFO: Inference done 2197/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/18 01:12:14] d2.evaluation.evaluator INFO: Inference done 2319/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/18 01:12:19] d2.evaluation.evaluator INFO: Inference done 2441/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/18 01:12:24] d2.evaluation.evaluator INFO: Inference done 2563/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/18 01:12:29] d2.evaluation.evaluator INFO: Inference done 2684/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/18 01:12:34] d2.evaluation.evaluator INFO: Inference done 2804/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:21
[11/18 01:12:39] d2.evaluation.evaluator INFO: Inference done 2925/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:16
[11/18 01:12:44] d2.evaluation.evaluator INFO: Inference done 3045/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:11
[11/18 01:12:49] d2.evaluation.evaluator INFO: Inference done 3163/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/18 01:12:54] d2.evaluation.evaluator INFO: Inference done 3284/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:02
[11/18 01:12:56] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.133143 (0.041494 s / iter per device, on 6 devices)
[11/18 01:12:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039477 s / iter per device, on 6 devices)
[11/18 01:12:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 01:12:59] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 01:13:00] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 01:13:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 01:13:25] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.54 seconds.
[11/18 01:13:25] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 01:13:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.03 seconds.
[11/18 01:13:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.840 | 16.703 | 6.261  | 1.266 | 3.930 | 9.647 |
[11/18 01:13:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 4.948  | bird          | 27.023 | hat with a wide brim | 5.364  |
| person                | 6.972  | dog           | 43.024 | lizard               | 5.096  |
| sheep                 | 4.678  | wine bottle   | 3.417  | bowl                 | 8.552  |
| airplane              | 19.437 | domestic cat  | 7.337  | car                  | 27.407 |
| porcupine             | 8.288  | bear          | 9.510  | tape player          | 7.023  |
| ray                   | 1.757  | laptop        | 6.605  | zebra                | 20.272 |
| computer keyboard     | 2.652  | pitcher       | 3.411  | artichoke            | 10.968 |
| tv or monitor         | 10.332 | table         | 6.178  | chair                | 5.485  |
| helmet                | 10.798 | traffic light | 2.179  | red panda            | 7.355  |
| sunglasses            | 0.837  | lamp          | 2.154  | bicycle              | 5.683  |
| backpack              | 6.366  | mushroom      | 4.789  | fox                  | 6.122  |
| otter                 | 1.580  | guitar        | 4.070  | microphone           | 0.034  |
| strawberry            | 7.330  | stove         | 5.767  | violin               | 0.945  |
| bookshelf             | 12.733 | sofa          | 1.837  | bell pepper          | 6.461  |
| bagel                 | 7.450  | lemon         | 9.325  | orange               | 14.351 |
| bench                 | 1.362  | piano         | 10.999 | flower pot           | 1.607  |
| butterfly             | 25.941 | purse         | 4.834  | pomegranate          | 2.389  |
| train                 | 8.177  | drum          | 0.764  | hippopotamus         | 0.869  |
| ski                   | 1.970  | ladybug       | 22.339 | banana               | 1.931  |
| monkey                | 8.135  | bus           | 18.792 | miniskirt            | 2.548  |
| camel                 | 1.913  | cream         | 11.874 | lobster              | 3.542  |
| seal                  | 1.898  | horse         | 7.295  | cart                 | 9.370  |
| elephant              | 12.691 | snake         | 8.090  | fig                  | 3.891  |
| watercraft            | 20.679 | apple         | 14.919 | antelope             | 17.383 |
| cattle                | 3.973  | whale         | 9.362  | coffee maker         | 16.467 |
| baby bed              | 13.302 | frog          | 8.406  | bathing cap          | 4.535  |
| crutch                | 0.136  | koala bear    | 7.853  | tie                  | 0.758  |
| dumbbell              | 0.059  | tiger         | 6.795  | dragonfly            | 7.264  |
| goldfish              | 4.220  | cucumber      | 1.166  | turtle               | 6.886  |
| harp                  | 4.979  | jellyfish     | 7.462  | swine                | 9.387  |
| pretzel               | 6.350  | motorcycle    | 12.288 | beaker               | 7.844  |
| rabbit                | 13.681 | nail          | 0.411  | axe                  | 2.190  |
| salt or pepper shaker | 1.383  | croquet ball  | 12.814 | skunk                | 4.588  |
| starfish              | 9.381  |               |        |                      |        |
[11/18 01:13:30] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 01:13:30] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 01:13:30] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 01:13:30] d2.evaluation.testing INFO: copypaste: 7.8404,16.7030,6.2612,1.2656,3.9295,9.6474
[11/18 01:13:30] d2.utils.events INFO:  eta: 19:37:18  iter: 6999  total_loss: 0.2507  loss_cls: 0.1286  loss_box_reg: 0.08939  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.01587  time: 0.6801  data_time: 0.0650  lr: 0.01  max_mem: 11813M
[11/18 01:13:43] d2.utils.events INFO:  eta: 19:37:13  iter: 7019  total_loss: 0.2316  loss_cls: 0.1183  loss_box_reg: 0.08164  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01732  time: 0.6800  data_time: 0.0652  lr: 0.01  max_mem: 11813M
[11/18 01:13:57] d2.utils.events INFO:  eta: 19:37:34  iter: 7039  total_loss: 0.2506  loss_cls: 0.1262  loss_box_reg: 0.08815  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01779  time: 0.6800  data_time: 0.0641  lr: 0.01  max_mem: 11813M
[11/18 01:14:10] d2.utils.events INFO:  eta: 19:37:03  iter: 7059  total_loss: 0.2365  loss_cls: 0.1193  loss_box_reg: 0.08526  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01775  time: 0.6800  data_time: 0.0678  lr: 0.01  max_mem: 11813M
[11/18 01:14:24] d2.utils.events INFO:  eta: 19:37:41  iter: 7079  total_loss: 0.2313  loss_cls: 0.1204  loss_box_reg: 0.08482  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01548  time: 0.6800  data_time: 0.0623  lr: 0.01  max_mem: 11813M
[11/18 01:14:38] d2.utils.events INFO:  eta: 19:37:27  iter: 7099  total_loss: 0.2353  loss_cls: 0.1203  loss_box_reg: 0.08418  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01611  time: 0.6800  data_time: 0.0713  lr: 0.01  max_mem: 11813M
[11/18 01:14:52] d2.utils.events INFO:  eta: 19:37:19  iter: 7119  total_loss: 0.2437  loss_cls: 0.1231  loss_box_reg: 0.08674  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.01685  time: 0.6801  data_time: 0.0645  lr: 0.01  max_mem: 11813M
[11/18 01:15:05] d2.utils.events INFO:  eta: 19:37:29  iter: 7139  total_loss: 0.2203  loss_cls: 0.1112  loss_box_reg: 0.08433  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.01567  time: 0.6801  data_time: 0.0592  lr: 0.01  max_mem: 11813M
[11/18 01:15:19] d2.utils.events INFO:  eta: 19:36:50  iter: 7159  total_loss: 0.2344  loss_cls: 0.1201  loss_box_reg: 0.0845  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01721  time: 0.6801  data_time: 0.0712  lr: 0.01  max_mem: 11813M
[11/18 01:15:33] d2.utils.events INFO:  eta: 19:36:44  iter: 7179  total_loss: 0.2449  loss_cls: 0.1306  loss_box_reg: 0.08953  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01776  time: 0.6802  data_time: 0.0688  lr: 0.01  max_mem: 11813M
[11/18 01:15:46] d2.utils.events INFO:  eta: 19:36:25  iter: 7199  total_loss: 0.2548  loss_cls: 0.1341  loss_box_reg: 0.08956  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01834  time: 0.6801  data_time: 0.0694  lr: 0.01  max_mem: 11813M
[11/18 01:16:00] d2.utils.events INFO:  eta: 19:36:41  iter: 7219  total_loss: 0.2241  loss_cls: 0.1177  loss_box_reg: 0.08326  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.016  time: 0.6802  data_time: 0.0637  lr: 0.01  max_mem: 11813M
[11/18 01:16:13] d2.utils.events INFO:  eta: 19:36:58  iter: 7239  total_loss: 0.2367  loss_cls: 0.1199  loss_box_reg: 0.08219  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.01733  time: 0.6802  data_time: 0.0653  lr: 0.01  max_mem: 11813M
[11/18 01:16:27] d2.utils.events INFO:  eta: 19:36:30  iter: 7259  total_loss: 0.2483  loss_cls: 0.1289  loss_box_reg: 0.08596  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.01719  time: 0.6802  data_time: 0.0619  lr: 0.01  max_mem: 11813M
[11/18 01:16:41] d2.utils.events INFO:  eta: 19:36:22  iter: 7279  total_loss: 0.2471  loss_cls: 0.1272  loss_box_reg: 0.08691  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.01629  time: 0.6803  data_time: 0.0828  lr: 0.01  max_mem: 11813M
[11/18 01:16:54] d2.utils.events INFO:  eta: 19:35:39  iter: 7299  total_loss: 0.2289  loss_cls: 0.1203  loss_box_reg: 0.07989  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.01693  time: 0.6802  data_time: 0.0651  lr: 0.01  max_mem: 11813M
[11/18 01:17:08] d2.utils.events INFO:  eta: 19:35:41  iter: 7319  total_loss: 0.2201  loss_cls: 0.114  loss_box_reg: 0.07643  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.01899  time: 0.6803  data_time: 0.0688  lr: 0.01  max_mem: 11813M
[11/18 01:17:22] d2.utils.events INFO:  eta: 19:35:35  iter: 7339  total_loss: 0.2431  loss_cls: 0.127  loss_box_reg: 0.08585  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01825  time: 0.6803  data_time: 0.0689  lr: 0.01  max_mem: 11813M
[11/18 01:17:35] d2.utils.events INFO:  eta: 19:34:53  iter: 7359  total_loss: 0.2492  loss_cls: 0.1272  loss_box_reg: 0.08738  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01727  time: 0.6802  data_time: 0.0665  lr: 0.01  max_mem: 11813M
[11/18 01:17:49] d2.utils.events INFO:  eta: 19:34:36  iter: 7379  total_loss: 0.2342  loss_cls: 0.1179  loss_box_reg: 0.08425  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01742  time: 0.6802  data_time: 0.0669  lr: 0.01  max_mem: 11813M
[11/18 01:18:02] d2.utils.events INFO:  eta: 19:34:31  iter: 7399  total_loss: 0.2337  loss_cls: 0.122  loss_box_reg: 0.08374  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.01669  time: 0.6802  data_time: 0.0656  lr: 0.01  max_mem: 11813M
[11/18 01:18:16] d2.utils.events INFO:  eta: 19:34:03  iter: 7419  total_loss: 0.2245  loss_cls: 0.1144  loss_box_reg: 0.07767  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.01733  time: 0.6802  data_time: 0.0693  lr: 0.01  max_mem: 11813M
[11/18 01:18:30] d2.utils.events INFO:  eta: 19:33:56  iter: 7439  total_loss: 0.2385  loss_cls: 0.1224  loss_box_reg: 0.08568  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.01608  time: 0.6803  data_time: 0.0613  lr: 0.01  max_mem: 11813M
[11/18 01:18:43] d2.utils.events INFO:  eta: 19:33:42  iter: 7459  total_loss: 0.2483  loss_cls: 0.1268  loss_box_reg: 0.0864  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.0196  time: 0.6803  data_time: 0.0862  lr: 0.01  max_mem: 11813M
[11/18 01:18:57] d2.utils.events INFO:  eta: 19:33:52  iter: 7479  total_loss: 0.2274  loss_cls: 0.118  loss_box_reg: 0.08  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.01654  time: 0.6805  data_time: 0.0711  lr: 0.01  max_mem: 11813M
[11/18 01:19:11] d2.utils.events INFO:  eta: 19:33:30  iter: 7499  total_loss: 0.2441  loss_cls: 0.1258  loss_box_reg: 0.08737  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01826  time: 0.6805  data_time: 0.0712  lr: 0.01  max_mem: 11813M
[11/18 01:19:25] d2.utils.events INFO:  eta: 19:33:01  iter: 7519  total_loss: 0.2262  loss_cls: 0.1155  loss_box_reg: 0.08357  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.0162  time: 0.6805  data_time: 0.0621  lr: 0.01  max_mem: 11813M
[11/18 01:19:38] d2.utils.events INFO:  eta: 19:32:55  iter: 7539  total_loss: 0.2448  loss_cls: 0.1275  loss_box_reg: 0.08744  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.01773  time: 0.6805  data_time: 0.0648  lr: 0.01  max_mem: 11813M
[11/18 01:19:52] d2.utils.events INFO:  eta: 19:32:42  iter: 7559  total_loss: 0.23  loss_cls: 0.1185  loss_box_reg: 0.08308  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.01674  time: 0.6804  data_time: 0.0665  lr: 0.01  max_mem: 11813M
[11/18 01:20:05] d2.utils.events INFO:  eta: 19:32:24  iter: 7579  total_loss: 0.2377  loss_cls: 0.1171  loss_box_reg: 0.08652  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.01731  time: 0.6805  data_time: 0.0663  lr: 0.01  max_mem: 11813M
[11/18 01:20:19] d2.utils.events INFO:  eta: 19:32:53  iter: 7599  total_loss: 0.2276  loss_cls: 0.1238  loss_box_reg: 0.08109  loss_rpn_cls: 0.01081  loss_rpn_loc: 0.01701  time: 0.6804  data_time: 0.0673  lr: 0.01  max_mem: 11813M
[11/18 01:20:33] d2.utils.events INFO:  eta: 19:33:07  iter: 7619  total_loss: 0.2301  loss_cls: 0.1178  loss_box_reg: 0.08414  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01643  time: 0.6805  data_time: 0.0697  lr: 0.01  max_mem: 11813M
[11/18 01:20:46] d2.utils.events INFO:  eta: 19:33:03  iter: 7639  total_loss: 0.2225  loss_cls: 0.1116  loss_box_reg: 0.08269  loss_rpn_cls: 0.009479  loss_rpn_loc: 0.01647  time: 0.6804  data_time: 0.0695  lr: 0.01  max_mem: 11813M
[11/18 01:21:00] d2.utils.events INFO:  eta: 19:33:02  iter: 7659  total_loss: 0.2257  loss_cls: 0.1127  loss_box_reg: 0.08359  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.01644  time: 0.6804  data_time: 0.0645  lr: 0.01  max_mem: 11813M
[11/18 01:21:13] d2.utils.events INFO:  eta: 19:32:20  iter: 7679  total_loss: 0.2312  loss_cls: 0.1174  loss_box_reg: 0.08755  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01739  time: 0.6804  data_time: 0.0679  lr: 0.01  max_mem: 11813M
[11/18 01:21:27] d2.utils.events INFO:  eta: 19:32:52  iter: 7699  total_loss: 0.2293  loss_cls: 0.1179  loss_box_reg: 0.08284  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.0172  time: 0.6804  data_time: 0.0656  lr: 0.01  max_mem: 11813M
[11/18 01:21:40] d2.utils.events INFO:  eta: 19:32:54  iter: 7719  total_loss: 0.2354  loss_cls: 0.1202  loss_box_reg: 0.08099  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.01729  time: 0.6804  data_time: 0.0649  lr: 0.01  max_mem: 11813M
[11/18 01:21:54] d2.utils.events INFO:  eta: 19:32:54  iter: 7739  total_loss: 0.2313  loss_cls: 0.1189  loss_box_reg: 0.08233  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.01754  time: 0.6805  data_time: 0.0710  lr: 0.01  max_mem: 11813M
[11/18 01:22:08] d2.utils.events INFO:  eta: 19:32:54  iter: 7759  total_loss: 0.2344  loss_cls: 0.1185  loss_box_reg: 0.08696  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.0192  time: 0.6804  data_time: 0.0587  lr: 0.01  max_mem: 11813M
[11/18 01:22:22] d2.utils.events INFO:  eta: 19:32:29  iter: 7779  total_loss: 0.2428  loss_cls: 0.1289  loss_box_reg: 0.08769  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01789  time: 0.6804  data_time: 0.0650  lr: 0.01  max_mem: 11813M
[11/18 01:22:35] d2.utils.events INFO:  eta: 19:32:13  iter: 7799  total_loss: 0.2261  loss_cls: 0.1133  loss_box_reg: 0.08606  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01752  time: 0.6804  data_time: 0.0609  lr: 0.01  max_mem: 11813M
[11/18 01:22:49] d2.utils.events INFO:  eta: 19:31:49  iter: 7819  total_loss: 0.2352  loss_cls: 0.1173  loss_box_reg: 0.08196  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.01659  time: 0.6804  data_time: 0.0713  lr: 0.01  max_mem: 11813M
[11/18 01:23:02] d2.utils.events INFO:  eta: 19:31:35  iter: 7839  total_loss: 0.2298  loss_cls: 0.1215  loss_box_reg: 0.0815  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.01689  time: 0.6803  data_time: 0.0705  lr: 0.01  max_mem: 11813M
[11/18 01:23:16] d2.utils.events INFO:  eta: 19:31:33  iter: 7859  total_loss: 0.2382  loss_cls: 0.124  loss_box_reg: 0.08456  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.0167  time: 0.6805  data_time: 0.0863  lr: 0.01  max_mem: 11813M
[11/18 01:23:30] d2.utils.events INFO:  eta: 19:31:18  iter: 7879  total_loss: 0.23  loss_cls: 0.121  loss_box_reg: 0.08121  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.01623  time: 0.6804  data_time: 0.0685  lr: 0.01  max_mem: 11813M
[11/18 01:23:43] d2.utils.events INFO:  eta: 19:31:08  iter: 7899  total_loss: 0.234  loss_cls: 0.1201  loss_box_reg: 0.0828  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01606  time: 0.6804  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 01:23:57] d2.utils.events INFO:  eta: 19:30:54  iter: 7919  total_loss: 0.2376  loss_cls: 0.1237  loss_box_reg: 0.08478  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01764  time: 0.6804  data_time: 0.0663  lr: 0.01  max_mem: 11813M
[11/18 01:24:10] d2.utils.events INFO:  eta: 19:30:23  iter: 7939  total_loss: 0.2461  loss_cls: 0.1344  loss_box_reg: 0.08582  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01731  time: 0.6804  data_time: 0.0716  lr: 0.01  max_mem: 11813M
[11/18 01:24:24] d2.utils.events INFO:  eta: 19:29:39  iter: 7959  total_loss: 0.2421  loss_cls: 0.1265  loss_box_reg: 0.08768  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01636  time: 0.6804  data_time: 0.0611  lr: 0.01  max_mem: 11813M
[11/18 01:24:37] d2.utils.events INFO:  eta: 19:28:56  iter: 7979  total_loss: 0.2324  loss_cls: 0.1188  loss_box_reg: 0.08392  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.01661  time: 0.6804  data_time: 0.0669  lr: 0.01  max_mem: 11813M
[11/18 01:24:51] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0007999.pth
[11/18 01:24:51] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 01:24:51] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 01:24:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 01:24:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 01:24:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 01:24:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 01:24:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 01:24:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0456 s/iter. Eval: 0.0002 s/iter. Total: 0.0469 s/iter. ETA=0:02:35
[11/18 01:25:04] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:15
[11/18 01:25:09] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:08
[11/18 01:25:14] d2.evaluation.evaluator INFO: Inference done 369/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:05
[11/18 01:25:19] d2.evaluation.evaluator INFO: Inference done 491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:59
[11/18 01:25:24] d2.evaluation.evaluator INFO: Inference done 615/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/18 01:25:29] d2.evaluation.evaluator INFO: Inference done 735/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:48
[11/18 01:25:34] d2.evaluation.evaluator INFO: Inference done 855/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:43
[11/18 01:25:39] d2.evaluation.evaluator INFO: Inference done 976/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/18 01:25:44] d2.evaluation.evaluator INFO: Inference done 1098/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:33
[11/18 01:25:49] d2.evaluation.evaluator INFO: Inference done 1222/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/18 01:25:54] d2.evaluation.evaluator INFO: Inference done 1343/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/18 01:25:59] d2.evaluation.evaluator INFO: Inference done 1465/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/18 01:26:05] d2.evaluation.evaluator INFO: Inference done 1586/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/18 01:26:10] d2.evaluation.evaluator INFO: Inference done 1704/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/18 01:26:15] d2.evaluation.evaluator INFO: Inference done 1827/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/18 01:26:20] d2.evaluation.evaluator INFO: Inference done 1948/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/18 01:26:25] d2.evaluation.evaluator INFO: Inference done 2072/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/18 01:26:30] d2.evaluation.evaluator INFO: Inference done 2193/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:47
[11/18 01:26:35] d2.evaluation.evaluator INFO: Inference done 2317/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 01:26:40] d2.evaluation.evaluator INFO: Inference done 2438/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/18 01:26:45] d2.evaluation.evaluator INFO: Inference done 2558/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/18 01:26:50] d2.evaluation.evaluator INFO: Inference done 2678/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/18 01:26:55] d2.evaluation.evaluator INFO: Inference done 2798/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/18 01:27:00] d2.evaluation.evaluator INFO: Inference done 2919/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/18 01:27:05] d2.evaluation.evaluator INFO: Inference done 3041/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/18 01:27:10] d2.evaluation.evaluator INFO: Inference done 3161/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/18 01:27:15] d2.evaluation.evaluator INFO: Inference done 3281/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/18 01:27:17] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.260464 (0.041532 s / iter per device, on 6 devices)
[11/18 01:27:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039523 s / iter per device, on 6 devices)
[11/18 01:27:20] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 01:27:20] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 01:27:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 01:27:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 01:27:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.55 seconds.
[11/18 01:27:45] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 01:27:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.82 seconds.
[11/18 01:27:47] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 8.372 | 17.737 | 6.790  | 1.178 | 3.627 | 10.399 |
[11/18 01:27:47] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 3.346  | bird          | 27.236 | hat with a wide brim | 3.900  |
| person                | 7.973  | dog           | 43.510 | lizard               | 6.063  |
| sheep                 | 3.316  | wine bottle   | 5.355  | bowl                 | 7.784  |
| airplane              | 18.709 | domestic cat  | 7.170  | car                  | 30.472 |
| porcupine             | 10.848 | bear          | 12.029 | tape player          | 8.402  |
| ray                   | 2.245  | laptop        | 8.648  | zebra                | 21.779 |
| computer keyboard     | 3.475  | pitcher       | 3.894  | artichoke            | 12.066 |
| tv or monitor         | 9.765  | table         | 7.355  | chair                | 4.539  |
| helmet                | 8.526  | traffic light | 2.398  | red panda            | 9.362  |
| sunglasses            | 0.985  | lamp          | 2.150  | bicycle              | 6.271  |
| backpack              | 7.541  | mushroom      | 4.126  | fox                  | 6.842  |
| otter                 | 2.000  | guitar        | 5.036  | microphone           | 0.011  |
| strawberry            | 6.445  | stove         | 9.683  | violin               | 0.794  |
| bookshelf             | 13.295 | sofa          | 2.953  | bell pepper          | 7.301  |
| bagel                 | 3.331  | lemon         | 5.290  | orange               | 14.195 |
| bench                 | 1.948  | piano         | 12.619 | flower pot           | 1.483  |
| butterfly             | 22.141 | purse         | 5.349  | pomegranate          | 3.898  |
| train                 | 14.318 | drum          | 0.734  | hippopotamus         | 0.948  |
| ski                   | 1.502  | ladybug       | 16.436 | banana               | 0.918  |
| monkey                | 10.132 | bus           | 24.779 | miniskirt            | 3.309  |
| camel                 | 2.525  | cream         | 10.130 | lobster              | 6.434  |
| seal                  | 2.016  | horse         | 7.020  | cart                 | 13.269 |
| elephant              | 17.134 | snake         | 8.074  | fig                  | 2.334  |
| watercraft            | 22.035 | apple         | 15.992 | antelope             | 19.018 |
| cattle                | 3.385  | whale         | 11.763 | coffee maker         | 21.054 |
| baby bed              | 14.275 | frog          | 7.949  | bathing cap          | 5.751  |
| crutch                | 0.054  | koala bear    | 9.433  | tie                  | 1.502  |
| dumbbell              | 0.129  | tiger         | 5.734  | dragonfly            | 6.163  |
| goldfish              | 4.715  | cucumber      | 0.692  | turtle               | 9.697  |
| harp                  | 4.697  | jellyfish     | 6.663  | swine                | 10.075 |
| pretzel               | 6.537  | motorcycle    | 17.519 | beaker               | 7.382  |
| rabbit                | 14.794 | nail          | 0.484  | axe                  | 1.865  |
| salt or pepper shaker | 2.181  | croquet ball  | 11.112 | skunk                | 5.426  |
| starfish              | 11.227 |               |        |                      |        |
[11/18 01:27:49] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 01:27:49] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 01:27:49] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 01:27:49] d2.evaluation.testing INFO: copypaste: 8.3717,17.7375,6.7897,1.1780,3.6267,10.3995
[11/18 01:27:49] d2.utils.events INFO:  eta: 19:28:25  iter: 7999  total_loss: 0.2284  loss_cls: 0.1171  loss_box_reg: 0.08483  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.01559  time: 0.6804  data_time: 0.0701  lr: 0.01  max_mem: 11813M
[11/18 01:28:03] d2.utils.events INFO:  eta: 19:28:11  iter: 8019  total_loss: 0.2317  loss_cls: 0.1171  loss_box_reg: 0.08347  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.01676  time: 0.6804  data_time: 0.0805  lr: 0.01  max_mem: 11813M
[11/18 01:28:16] d2.utils.events INFO:  eta: 19:27:11  iter: 8039  total_loss: 0.228  loss_cls: 0.1187  loss_box_reg: 0.08418  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.01688  time: 0.6803  data_time: 0.0587  lr: 0.01  max_mem: 11813M
[11/18 01:28:30] d2.utils.events INFO:  eta: 19:27:06  iter: 8059  total_loss: 0.2329  loss_cls: 0.1183  loss_box_reg: 0.08334  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.0166  time: 0.6803  data_time: 0.0717  lr: 0.01  max_mem: 11813M
[11/18 01:28:43] d2.utils.events INFO:  eta: 19:26:44  iter: 8079  total_loss: 0.2441  loss_cls: 0.1282  loss_box_reg: 0.09014  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.01569  time: 0.6803  data_time: 0.0684  lr: 0.01  max_mem: 11813M
[11/18 01:28:57] d2.utils.events INFO:  eta: 19:26:26  iter: 8099  total_loss: 0.2294  loss_cls: 0.1192  loss_box_reg: 0.08327  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01597  time: 0.6803  data_time: 0.0670  lr: 0.01  max_mem: 11813M
[11/18 01:29:10] d2.utils.events INFO:  eta: 19:25:29  iter: 8119  total_loss: 0.2324  loss_cls: 0.1179  loss_box_reg: 0.08472  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.01693  time: 0.6803  data_time: 0.0699  lr: 0.01  max_mem: 11813M
[11/18 01:29:24] d2.utils.events INFO:  eta: 19:24:38  iter: 8139  total_loss: 0.2321  loss_cls: 0.1197  loss_box_reg: 0.0832  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.01746  time: 0.6803  data_time: 0.0719  lr: 0.01  max_mem: 11813M
[11/18 01:29:38] d2.utils.events INFO:  eta: 19:24:35  iter: 8159  total_loss: 0.2309  loss_cls: 0.1183  loss_box_reg: 0.0865  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.01596  time: 0.6803  data_time: 0.0665  lr: 0.01  max_mem: 11813M
[11/18 01:29:51] d2.utils.events INFO:  eta: 19:24:18  iter: 8179  total_loss: 0.2402  loss_cls: 0.1239  loss_box_reg: 0.08552  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.01536  time: 0.6804  data_time: 0.0642  lr: 0.01  max_mem: 11813M
[11/18 01:30:05] d2.utils.events INFO:  eta: 19:24:07  iter: 8199  total_loss: 0.2413  loss_cls: 0.1271  loss_box_reg: 0.08791  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01539  time: 0.6804  data_time: 0.0774  lr: 0.01  max_mem: 11813M
[11/18 01:30:19] d2.utils.events INFO:  eta: 19:23:51  iter: 8219  total_loss: 0.24  loss_cls: 0.1247  loss_box_reg: 0.08787  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.01675  time: 0.6805  data_time: 0.0644  lr: 0.01  max_mem: 11813M
[11/18 01:30:32] d2.utils.events INFO:  eta: 19:23:37  iter: 8239  total_loss: 0.2259  loss_cls: 0.1142  loss_box_reg: 0.08079  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.01539  time: 0.6804  data_time: 0.0644  lr: 0.01  max_mem: 11813M
[11/18 01:30:46] d2.utils.events INFO:  eta: 19:23:26  iter: 8259  total_loss: 0.2239  loss_cls: 0.115  loss_box_reg: 0.08106  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01639  time: 0.6804  data_time: 0.0643  lr: 0.01  max_mem: 11813M
[11/18 01:31:00] d2.utils.events INFO:  eta: 19:24:44  iter: 8279  total_loss: 0.2225  loss_cls: 0.1141  loss_box_reg: 0.08171  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.01725  time: 0.6804  data_time: 0.0722  lr: 0.01  max_mem: 11813M
[11/18 01:31:13] d2.utils.events INFO:  eta: 19:26:09  iter: 8299  total_loss: 0.2322  loss_cls: 0.1186  loss_box_reg: 0.08391  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.01732  time: 0.6805  data_time: 0.0743  lr: 0.01  max_mem: 11813M
[11/18 01:31:27] d2.utils.events INFO:  eta: 19:24:34  iter: 8319  total_loss: 0.2147  loss_cls: 0.1092  loss_box_reg: 0.07873  loss_rpn_cls: 0.00999  loss_rpn_loc: 0.01728  time: 0.6805  data_time: 0.0654  lr: 0.01  max_mem: 11813M
[11/18 01:31:40] d2.utils.events INFO:  eta: 19:23:01  iter: 8339  total_loss: 0.2324  loss_cls: 0.1184  loss_box_reg: 0.08442  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.01779  time: 0.6804  data_time: 0.0629  lr: 0.01  max_mem: 11813M
[11/18 01:31:54] d2.utils.events INFO:  eta: 19:24:07  iter: 8359  total_loss: 0.223  loss_cls: 0.1154  loss_box_reg: 0.07815  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01773  time: 0.6803  data_time: 0.0615  lr: 0.01  max_mem: 11813M
[11/18 01:32:07] d2.utils.events INFO:  eta: 19:23:36  iter: 8379  total_loss: 0.238  loss_cls: 0.1189  loss_box_reg: 0.08667  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.01715  time: 0.6803  data_time: 0.0620  lr: 0.01  max_mem: 11813M
[11/18 01:32:21] d2.utils.events INFO:  eta: 19:23:11  iter: 8399  total_loss: 0.2427  loss_cls: 0.1252  loss_box_reg: 0.08735  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.01761  time: 0.6803  data_time: 0.0709  lr: 0.01  max_mem: 11813M
[11/18 01:32:35] d2.utils.events INFO:  eta: 19:22:58  iter: 8419  total_loss: 0.2395  loss_cls: 0.1234  loss_box_reg: 0.08569  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.01639  time: 0.6803  data_time: 0.0669  lr: 0.01  max_mem: 11813M
[11/18 01:32:48] d2.utils.events INFO:  eta: 19:22:29  iter: 8439  total_loss: 0.2414  loss_cls: 0.1255  loss_box_reg: 0.08758  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.0162  time: 0.6804  data_time: 0.0623  lr: 0.01  max_mem: 11813M
[11/18 01:33:02] d2.utils.events INFO:  eta: 19:21:02  iter: 8459  total_loss: 0.2381  loss_cls: 0.1208  loss_box_reg: 0.08466  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.01698  time: 0.6804  data_time: 0.0657  lr: 0.01  max_mem: 11813M
[11/18 01:33:16] d2.utils.events INFO:  eta: 19:20:25  iter: 8479  total_loss: 0.2352  loss_cls: 0.1223  loss_box_reg: 0.08376  loss_rpn_cls: 0.014  loss_rpn_loc: 0.01814  time: 0.6804  data_time: 0.0754  lr: 0.01  max_mem: 11813M
[11/18 01:33:29] d2.utils.events INFO:  eta: 19:20:00  iter: 8499  total_loss: 0.221  loss_cls: 0.1167  loss_box_reg: 0.07894  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.01616  time: 0.6804  data_time: 0.0638  lr: 0.01  max_mem: 11813M
[11/18 01:33:43] d2.utils.events INFO:  eta: 19:20:28  iter: 8519  total_loss: 0.2172  loss_cls: 0.1132  loss_box_reg: 0.07905  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.01608  time: 0.6804  data_time: 0.0634  lr: 0.01  max_mem: 11813M
[11/18 01:33:57] d2.utils.events INFO:  eta: 19:20:11  iter: 8539  total_loss: 0.2355  loss_cls: 0.1211  loss_box_reg: 0.08746  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.01688  time: 0.6804  data_time: 0.0659  lr: 0.01  max_mem: 11813M
[11/18 01:34:10] d2.utils.events INFO:  eta: 19:20:02  iter: 8559  total_loss: 0.2158  loss_cls: 0.11  loss_box_reg: 0.07853  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01574  time: 0.6804  data_time: 0.0682  lr: 0.01  max_mem: 11813M
[11/18 01:34:24] d2.utils.events INFO:  eta: 19:20:36  iter: 8579  total_loss: 0.2569  loss_cls: 0.1295  loss_box_reg: 0.09023  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01742  time: 0.6804  data_time: 0.0774  lr: 0.01  max_mem: 11813M
[11/18 01:34:38] d2.utils.events INFO:  eta: 19:20:40  iter: 8599  total_loss: 0.2354  loss_cls: 0.1199  loss_box_reg: 0.08798  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01657  time: 0.6805  data_time: 0.0765  lr: 0.01  max_mem: 11813M
[11/18 01:34:51] d2.utils.events INFO:  eta: 19:19:39  iter: 8619  total_loss: 0.2225  loss_cls: 0.1141  loss_box_reg: 0.08088  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01609  time: 0.6805  data_time: 0.0621  lr: 0.01  max_mem: 11813M
[11/18 01:35:05] d2.utils.events INFO:  eta: 19:19:55  iter: 8639  total_loss: 0.2226  loss_cls: 0.1158  loss_box_reg: 0.08493  loss_rpn_cls: 0.00935  loss_rpn_loc: 0.01665  time: 0.6805  data_time: 0.0682  lr: 0.01  max_mem: 11813M
[11/18 01:35:19] d2.utils.events INFO:  eta: 19:19:28  iter: 8659  total_loss: 0.2457  loss_cls: 0.1247  loss_box_reg: 0.08761  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.01897  time: 0.6805  data_time: 0.0720  lr: 0.01  max_mem: 11813M
[11/18 01:35:32] d2.utils.events INFO:  eta: 19:19:00  iter: 8679  total_loss: 0.2438  loss_cls: 0.1309  loss_box_reg: 0.08482  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.01601  time: 0.6805  data_time: 0.0670  lr: 0.01  max_mem: 11813M
[11/18 01:35:46] d2.utils.events INFO:  eta: 19:18:18  iter: 8699  total_loss: 0.235  loss_cls: 0.1211  loss_box_reg: 0.07971  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01724  time: 0.6805  data_time: 0.0652  lr: 0.01  max_mem: 11813M
[11/18 01:35:59] d2.utils.events INFO:  eta: 19:17:55  iter: 8719  total_loss: 0.2371  loss_cls: 0.1175  loss_box_reg: 0.08308  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.01502  time: 0.6805  data_time: 0.0618  lr: 0.01  max_mem: 11813M
[11/18 01:36:13] d2.utils.events INFO:  eta: 19:17:20  iter: 8739  total_loss: 0.2302  loss_cls: 0.1198  loss_box_reg: 0.08143  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.01755  time: 0.6805  data_time: 0.0674  lr: 0.01  max_mem: 11813M
[11/18 01:36:26] d2.utils.events INFO:  eta: 19:16:53  iter: 8759  total_loss: 0.2245  loss_cls: 0.1128  loss_box_reg: 0.08118  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.01714  time: 0.6804  data_time: 0.0608  lr: 0.01  max_mem: 11813M
[11/18 01:36:40] d2.utils.events INFO:  eta: 19:16:11  iter: 8779  total_loss: 0.2258  loss_cls: 0.1188  loss_box_reg: 0.07992  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01759  time: 0.6803  data_time: 0.0666  lr: 0.01  max_mem: 11813M
[11/18 01:36:53] d2.utils.events INFO:  eta: 19:16:24  iter: 8799  total_loss: 0.2383  loss_cls: 0.1263  loss_box_reg: 0.08205  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.0166  time: 0.6804  data_time: 0.0626  lr: 0.01  max_mem: 11813M
[11/18 01:37:07] d2.utils.events INFO:  eta: 19:16:26  iter: 8819  total_loss: 0.232  loss_cls: 0.1169  loss_box_reg: 0.08174  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01783  time: 0.6803  data_time: 0.0650  lr: 0.01  max_mem: 11813M
[11/18 01:37:20] d2.utils.events INFO:  eta: 19:16:04  iter: 8839  total_loss: 0.2282  loss_cls: 0.1186  loss_box_reg: 0.08154  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01661  time: 0.6803  data_time: 0.0721  lr: 0.01  max_mem: 11813M
[11/18 01:37:34] d2.utils.events INFO:  eta: 19:15:17  iter: 8859  total_loss: 0.2324  loss_cls: 0.1149  loss_box_reg: 0.08647  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.01605  time: 0.6803  data_time: 0.0627  lr: 0.01  max_mem: 11813M
[11/18 01:37:47] d2.utils.events INFO:  eta: 19:14:58  iter: 8879  total_loss: 0.2361  loss_cls: 0.1219  loss_box_reg: 0.08173  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.01597  time: 0.6802  data_time: 0.0633  lr: 0.01  max_mem: 11813M
[11/18 01:38:01] d2.utils.events INFO:  eta: 19:14:50  iter: 8899  total_loss: 0.2404  loss_cls: 0.1262  loss_box_reg: 0.08711  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.01641  time: 0.6803  data_time: 0.0727  lr: 0.01  max_mem: 11813M
[11/18 01:38:15] d2.utils.events INFO:  eta: 19:14:43  iter: 8919  total_loss: 0.242  loss_cls: 0.1222  loss_box_reg: 0.08908  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.01544  time: 0.6803  data_time: 0.0682  lr: 0.01  max_mem: 11813M
[11/18 01:38:28] d2.utils.events INFO:  eta: 19:14:41  iter: 8939  total_loss: 0.2392  loss_cls: 0.1188  loss_box_reg: 0.0872  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01722  time: 0.6803  data_time: 0.0725  lr: 0.01  max_mem: 11813M
[11/18 01:38:42] d2.utils.events INFO:  eta: 19:14:16  iter: 8959  total_loss: 0.2201  loss_cls: 0.1138  loss_box_reg: 0.08175  loss_rpn_cls: 0.009324  loss_rpn_loc: 0.01614  time: 0.6803  data_time: 0.0655  lr: 0.01  max_mem: 11813M
[11/18 01:38:56] d2.utils.events INFO:  eta: 19:14:44  iter: 8979  total_loss: 0.2323  loss_cls: 0.1169  loss_box_reg: 0.08171  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01708  time: 0.6803  data_time: 0.0689  lr: 0.01  max_mem: 11813M
[11/18 01:39:09] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0008999.pth
[11/18 01:39:10] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 01:39:10] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 01:39:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 01:39:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 01:39:10] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 01:39:10] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 01:39:11] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 01:39:17] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:19
[11/18 01:39:22] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/18 01:39:27] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:07
[11/18 01:39:33] d2.evaluation.evaluator INFO: Inference done 372/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:03
[11/18 01:39:38] d2.evaluation.evaluator INFO: Inference done 494/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:58
[11/18 01:39:43] d2.evaluation.evaluator INFO: Inference done 613/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/18 01:39:48] d2.evaluation.evaluator INFO: Inference done 735/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:48
[11/18 01:39:53] d2.evaluation.evaluator INFO: Inference done 859/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/18 01:39:58] d2.evaluation.evaluator INFO: Inference done 980/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/18 01:40:03] d2.evaluation.evaluator INFO: Inference done 1100/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/18 01:40:08] d2.evaluation.evaluator INFO: Inference done 1220/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/18 01:40:13] d2.evaluation.evaluator INFO: Inference done 1343/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/18 01:40:18] d2.evaluation.evaluator INFO: Inference done 1463/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/18 01:40:23] d2.evaluation.evaluator INFO: Inference done 1588/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/18 01:40:28] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/18 01:40:33] d2.evaluation.evaluator INFO: Inference done 1828/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/18 01:40:38] d2.evaluation.evaluator INFO: Inference done 1950/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/18 01:40:43] d2.evaluation.evaluator INFO: Inference done 2074/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/18 01:40:48] d2.evaluation.evaluator INFO: Inference done 2195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/18 01:40:53] d2.evaluation.evaluator INFO: Inference done 2316/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/18 01:40:58] d2.evaluation.evaluator INFO: Inference done 2437/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/18 01:41:03] d2.evaluation.evaluator INFO: Inference done 2560/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/18 01:41:08] d2.evaluation.evaluator INFO: Inference done 2682/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:26
[11/18 01:41:13] d2.evaluation.evaluator INFO: Inference done 2804/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/18 01:41:18] d2.evaluation.evaluator INFO: Inference done 2927/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/18 01:41:23] d2.evaluation.evaluator INFO: Inference done 3048/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/18 01:41:28] d2.evaluation.evaluator INFO: Inference done 3169/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/18 01:41:33] d2.evaluation.evaluator INFO: Inference done 3290/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/18 01:41:35] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.849066 (0.041409 s / iter per device, on 6 devices)
[11/18 01:41:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039419 s / iter per device, on 6 devices)
[11/18 01:41:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 01:41:37] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 01:41:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 01:41:39] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 01:42:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.43 seconds.
[11/18 01:42:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 01:42:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.04 seconds.
[11/18 01:42:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 8.559 | 18.023 | 6.954  | 1.136 | 4.103 | 10.555 |
[11/18 01:42:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 3.545  | bird          | 28.688 | hat with a wide brim | 5.284  |
| person                | 7.232  | dog           | 42.642 | lizard               | 5.889  |
| sheep                 | 5.451  | wine bottle   | 5.166  | bowl                 | 8.214  |
| airplane              | 20.326 | domestic cat  | 9.274  | car                  | 29.981 |
| porcupine             | 9.986  | bear          | 10.565 | tape player          | 6.597  |
| ray                   | 2.466  | laptop        | 6.653  | zebra                | 22.387 |
| computer keyboard     | 3.953  | pitcher       | 2.265  | artichoke            | 13.409 |
| tv or monitor         | 11.513 | table         | 7.264  | chair                | 4.700  |
| helmet                | 9.133  | traffic light | 2.799  | red panda            | 12.559 |
| sunglasses            | 0.699  | lamp          | 2.232  | bicycle              | 6.550  |
| backpack              | 7.991  | mushroom      | 5.464  | fox                  | 8.267  |
| otter                 | 2.809  | guitar        | 2.940  | microphone           | 0.191  |
| strawberry            | 6.666  | stove         | 9.923  | violin               | 1.172  |
| bookshelf             | 12.550 | sofa          | 2.768  | bell pepper          | 4.434  |
| bagel                 | 4.865  | lemon         | 9.644  | orange               | 9.399  |
| bench                 | 2.127  | piano         | 11.404 | flower pot           | 2.422  |
| butterfly             | 23.880 | purse         | 4.494  | pomegranate          | 3.672  |
| train                 | 12.286 | drum          | 0.557  | hippopotamus         | 0.980  |
| ski                   | 2.111  | ladybug       | 24.393 | banana               | 1.029  |
| monkey                | 10.908 | bus           | 24.031 | miniskirt            | 3.595  |
| camel                 | 4.204  | cream         | 10.711 | lobster              | 4.387  |
| seal                  | 1.733  | horse         | 8.511  | cart                 | 11.651 |
| elephant              | 13.436 | snake         | 8.635  | fig                  | 2.497  |
| watercraft            | 20.339 | apple         | 14.806 | antelope             | 17.042 |
| cattle                | 2.158  | whale         | 11.548 | coffee maker         | 21.723 |
| baby bed              | 13.831 | frog          | 8.406  | bathing cap          | 7.154  |
| crutch                | 0.138  | koala bear    | 11.065 | tie                  | 1.149  |
| dumbbell              | 0.198  | tiger         | 6.579  | dragonfly            | 7.650  |
| goldfish              | 5.229  | cucumber      | 0.325  | turtle               | 11.668 |
| harp                  | 5.782  | jellyfish     | 7.960  | swine                | 9.139  |
| pretzel               | 3.527  | motorcycle    | 16.785 | beaker               | 10.888 |
| rabbit                | 18.286 | nail          | 0.354  | axe                  | 3.027  |
| salt or pepper shaker | 1.293  | croquet ball  | 14.153 | skunk                | 6.263  |
| starfish              | 7.293  |               |        |                      |        |
[11/18 01:42:08] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 01:42:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 01:42:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 01:42:08] d2.evaluation.testing INFO: copypaste: 8.5592,18.0232,6.9545,1.1363,4.1026,10.5547
[11/18 02:22:11] d2.utils.events INFO:  eta: 19:16:40  iter: 9019  total_loss: 0.2377  loss_cls: 0.1231  loss_box_reg: 0.08568  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.01647  time: 0.6796  data_time: 0.4309  lr: 0.01  max_mem: 11810M
[11/18 02:22:24] d2.utils.events INFO:  eta: 19:08:33  iter: 9039  total_loss: 0.2245  loss_cls: 0.1137  loss_box_reg: 0.08107  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.01795  time: 0.6783  data_time: 0.0684  lr: 0.01  max_mem: 11810M
[11/18 02:22:37] d2.utils.events INFO:  eta: 19:08:20  iter: 9059  total_loss: 0.2212  loss_cls: 0.1118  loss_box_reg: 0.0799  loss_rpn_cls: 0.01144  loss_rpn_loc: 0.0156  time: 0.6754  data_time: 0.0691  lr: 0.01  max_mem: 11810M
[11/18 02:22:51] d2.utils.events INFO:  eta: 19:09:44  iter: 9079  total_loss: 0.217  loss_cls: 0.1117  loss_box_reg: 0.07726  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.01807  time: 0.6749  data_time: 0.0675  lr: 0.01  max_mem: 11811M
[11/18 02:23:05] d2.utils.events INFO:  eta: 19:09:17  iter: 9099  total_loss: 0.2257  loss_cls: 0.1133  loss_box_reg: 0.08367  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.016  time: 0.6757  data_time: 0.0657  lr: 0.01  max_mem: 11811M
[11/18 02:23:18] d2.utils.events INFO:  eta: 19:09:01  iter: 9119  total_loss: 0.2278  loss_cls: 0.1183  loss_box_reg: 0.08313  loss_rpn_cls: 0.009807  loss_rpn_loc: 0.01655  time: 0.6760  data_time: 0.0646  lr: 0.01  max_mem: 11811M
[11/18 02:23:32] d2.utils.events INFO:  eta: 19:08:47  iter: 9139  total_loss: 0.2248  loss_cls: 0.1114  loss_box_reg: 0.08517  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01689  time: 0.6757  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/18 02:23:45] d2.utils.events INFO:  eta: 19:09:59  iter: 9159  total_loss: 0.2386  loss_cls: 0.1243  loss_box_reg: 0.08074  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01793  time: 0.6764  data_time: 0.0734  lr: 0.01  max_mem: 11811M
[11/18 02:23:59] d2.utils.events INFO:  eta: 19:09:46  iter: 9179  total_loss: 0.2212  loss_cls: 0.114  loss_box_reg: 0.08213  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.01672  time: 0.6767  data_time: 0.0671  lr: 0.01  max_mem: 11811M
[11/18 02:24:12] d2.utils.events INFO:  eta: 19:10:40  iter: 9199  total_loss: 0.2287  loss_cls: 0.1214  loss_box_reg: 0.0821  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01601  time: 0.6768  data_time: 0.0686  lr: 0.01  max_mem: 11811M
[11/18 02:24:26] d2.utils.events INFO:  eta: 19:11:38  iter: 9219  total_loss: 0.2399  loss_cls: 0.1228  loss_box_reg: 0.08796  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.01744  time: 0.6779  data_time: 0.0716  lr: 0.01  max_mem: 11811M
[11/18 02:24:40] d2.utils.events INFO:  eta: 19:11:05  iter: 9239  total_loss: 0.2285  loss_cls: 0.1158  loss_box_reg: 0.08262  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.0154  time: 0.6782  data_time: 0.0717  lr: 0.01  max_mem: 11811M
[11/18 02:24:53] d2.utils.events INFO:  eta: 19:10:09  iter: 9259  total_loss: 0.2261  loss_cls: 0.112  loss_box_reg: 0.08511  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.01651  time: 0.6778  data_time: 0.0685  lr: 0.01  max_mem: 11811M
[11/18 02:25:07] d2.utils.events INFO:  eta: 19:12:19  iter: 9279  total_loss: 0.2309  loss_cls: 0.118  loss_box_reg: 0.08318  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01823  time: 0.6795  data_time: 0.0739  lr: 0.01  max_mem: 11811M
[11/18 02:25:21] d2.utils.events INFO:  eta: 19:13:05  iter: 9299  total_loss: 0.2485  loss_cls: 0.1237  loss_box_reg: 0.0893  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.01593  time: 0.6799  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/18 02:25:35] d2.utils.events INFO:  eta: 19:12:44  iter: 9319  total_loss: 0.2277  loss_cls: 0.1142  loss_box_reg: 0.0801  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.01771  time: 0.6800  data_time: 0.0660  lr: 0.01  max_mem: 11811M
[11/18 02:25:48] d2.utils.events INFO:  eta: 19:11:49  iter: 9339  total_loss: 0.24  loss_cls: 0.1195  loss_box_reg: 0.08631  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01707  time: 0.6799  data_time: 0.0628  lr: 0.01  max_mem: 11811M
[11/18 02:26:02] d2.utils.events INFO:  eta: 19:11:35  iter: 9359  total_loss: 0.2329  loss_cls: 0.1206  loss_box_reg: 0.08431  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.01744  time: 0.6796  data_time: 0.0603  lr: 0.01  max_mem: 11811M
[11/18 02:26:15] d2.utils.events INFO:  eta: 19:10:02  iter: 9379  total_loss: 0.2253  loss_cls: 0.118  loss_box_reg: 0.08027  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.01721  time: 0.6793  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/18 02:26:29] d2.utils.events INFO:  eta: 19:11:26  iter: 9399  total_loss: 0.24  loss_cls: 0.1237  loss_box_reg: 0.08772  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01786  time: 0.6795  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/18 02:26:42] d2.utils.events INFO:  eta: 19:11:25  iter: 9419  total_loss: 0.2279  loss_cls: 0.1132  loss_box_reg: 0.08298  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01688  time: 0.6796  data_time: 0.0663  lr: 0.01  max_mem: 11811M
[11/18 02:26:56] d2.utils.events INFO:  eta: 19:10:53  iter: 9439  total_loss: 0.2392  loss_cls: 0.1241  loss_box_reg: 0.08602  loss_rpn_cls: 0.01091  loss_rpn_loc: 0.01572  time: 0.6794  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/18 02:27:10] d2.utils.events INFO:  eta: 19:11:08  iter: 9459  total_loss: 0.2169  loss_cls: 0.1099  loss_box_reg: 0.0765  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.0177  time: 0.6799  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/18 02:27:24] d2.utils.events INFO:  eta: 19:11:03  iter: 9479  total_loss: 0.2289  loss_cls: 0.1172  loss_box_reg: 0.08042  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.01659  time: 0.6803  data_time: 0.0662  lr: 0.01  max_mem: 11811M
[11/18 02:27:37] d2.utils.events INFO:  eta: 19:10:41  iter: 9499  total_loss: 0.2459  loss_cls: 0.1253  loss_box_reg: 0.08834  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.01653  time: 0.6801  data_time: 0.0616  lr: 0.01  max_mem: 11811M
[11/18 02:27:51] d2.utils.events INFO:  eta: 19:10:28  iter: 9519  total_loss: 0.2277  loss_cls: 0.1134  loss_box_reg: 0.08525  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.01819  time: 0.6802  data_time: 0.0650  lr: 0.01  max_mem: 11811M
[11/18 02:28:04] d2.utils.events INFO:  eta: 19:08:57  iter: 9539  total_loss: 0.2226  loss_cls: 0.1115  loss_box_reg: 0.08029  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01553  time: 0.6798  data_time: 0.0594  lr: 0.01  max_mem: 11811M
[11/18 02:28:18] d2.utils.events INFO:  eta: 19:08:43  iter: 9559  total_loss: 0.2444  loss_cls: 0.1245  loss_box_reg: 0.08744  loss_rpn_cls: 0.009588  loss_rpn_loc: 0.01661  time: 0.6800  data_time: 0.0645  lr: 0.01  max_mem: 11811M
[11/18 02:28:31] d2.utils.events INFO:  eta: 19:09:06  iter: 9579  total_loss: 0.2257  loss_cls: 0.1152  loss_box_reg: 0.08331  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.01698  time: 0.6799  data_time: 0.0676  lr: 0.01  max_mem: 11811M
[11/18 02:28:45] d2.utils.events INFO:  eta: 19:08:16  iter: 9599  total_loss: 0.2411  loss_cls: 0.1263  loss_box_reg: 0.08741  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.01668  time: 0.6799  data_time: 0.0786  lr: 0.01  max_mem: 11811M
[11/18 02:28:58] d2.utils.events INFO:  eta: 19:07:28  iter: 9619  total_loss: 0.239  loss_cls: 0.1247  loss_box_reg: 0.08607  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.01736  time: 0.6797  data_time: 0.0604  lr: 0.01  max_mem: 11811M
[11/18 02:29:12] d2.utils.events INFO:  eta: 19:07:06  iter: 9639  total_loss: 0.2165  loss_cls: 0.1113  loss_box_reg: 0.07857  loss_rpn_cls: 0.01029  loss_rpn_loc: 0.01605  time: 0.6795  data_time: 0.0821  lr: 0.01  max_mem: 11811M
[11/18 02:29:26] d2.utils.events INFO:  eta: 19:06:46  iter: 9659  total_loss: 0.2357  loss_cls: 0.1196  loss_box_reg: 0.08601  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.01596  time: 0.6799  data_time: 0.0799  lr: 0.01  max_mem: 11811M
[11/18 02:29:39] d2.utils.events INFO:  eta: 19:06:39  iter: 9679  total_loss: 0.236  loss_cls: 0.1153  loss_box_reg: 0.08565  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01628  time: 0.6798  data_time: 0.0668  lr: 0.01  max_mem: 11811M
[11/18 02:29:53] d2.utils.events INFO:  eta: 19:06:34  iter: 9699  total_loss: 0.2399  loss_cls: 0.1205  loss_box_reg: 0.08458  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01638  time: 0.6799  data_time: 0.0619  lr: 0.01  max_mem: 11811M
[11/18 02:30:07] d2.utils.events INFO:  eta: 19:06:33  iter: 9719  total_loss: 0.2158  loss_cls: 0.1097  loss_box_reg: 0.08081  loss_rpn_cls: 0.009617  loss_rpn_loc: 0.01687  time: 0.6800  data_time: 0.0657  lr: 0.01  max_mem: 11811M
[11/18 02:30:20] d2.utils.events INFO:  eta: 19:06:19  iter: 9739  total_loss: 0.2407  loss_cls: 0.1235  loss_box_reg: 0.08603  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.01843  time: 0.6799  data_time: 0.0657  lr: 0.01  max_mem: 11811M
[11/18 02:30:34] d2.utils.events INFO:  eta: 19:05:53  iter: 9759  total_loss: 0.2269  loss_cls: 0.1164  loss_box_reg: 0.08545  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.01483  time: 0.6798  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/18 02:30:47] d2.utils.events INFO:  eta: 19:06:10  iter: 9779  total_loss: 0.2345  loss_cls: 0.1209  loss_box_reg: 0.08821  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.01772  time: 0.6800  data_time: 0.0614  lr: 0.01  max_mem: 11811M
[11/18 02:31:01] d2.utils.events INFO:  eta: 19:06:17  iter: 9799  total_loss: 0.2198  loss_cls: 0.1099  loss_box_reg: 0.07897  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.01593  time: 0.6800  data_time: 0.0687  lr: 0.01  max_mem: 11811M
[11/18 02:31:15] d2.utils.events INFO:  eta: 19:06:01  iter: 9819  total_loss: 0.2287  loss_cls: 0.1154  loss_box_reg: 0.08382  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.01623  time: 0.6799  data_time: 0.0625  lr: 0.01  max_mem: 11811M
[11/18 02:31:28] d2.utils.events INFO:  eta: 19:06:01  iter: 9839  total_loss: 0.2332  loss_cls: 0.1171  loss_box_reg: 0.08665  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.01741  time: 0.6799  data_time: 0.0710  lr: 0.01  max_mem: 11811M
[11/18 02:31:42] d2.utils.events INFO:  eta: 19:05:59  iter: 9859  total_loss: 0.2183  loss_cls: 0.1093  loss_box_reg: 0.07656  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01579  time: 0.6800  data_time: 0.0650  lr: 0.01  max_mem: 11811M
[11/18 02:31:56] d2.utils.events INFO:  eta: 19:06:02  iter: 9879  total_loss: 0.2203  loss_cls: 0.1144  loss_box_reg: 0.07559  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.01705  time: 0.6800  data_time: 0.0682  lr: 0.01  max_mem: 11811M
[11/18 02:32:09] d2.utils.events INFO:  eta: 19:05:49  iter: 9899  total_loss: 0.2272  loss_cls: 0.1149  loss_box_reg: 0.08174  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01681  time: 0.6802  data_time: 0.0751  lr: 0.01  max_mem: 11811M
[11/18 02:32:23] d2.utils.events INFO:  eta: 19:05:18  iter: 9919  total_loss: 0.2268  loss_cls: 0.1178  loss_box_reg: 0.08202  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.01646  time: 0.6800  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/18 02:32:36] d2.utils.events INFO:  eta: 19:05:05  iter: 9939  total_loss: 0.2305  loss_cls: 0.1199  loss_box_reg: 0.08468  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01798  time: 0.6801  data_time: 0.0718  lr: 0.01  max_mem: 11811M
[11/18 02:32:50] d2.utils.events INFO:  eta: 19:05:01  iter: 9959  total_loss: 0.2224  loss_cls: 0.1122  loss_box_reg: 0.0824  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01641  time: 0.6801  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/18 02:33:04] d2.utils.events INFO:  eta: 19:04:38  iter: 9979  total_loss: 0.2246  loss_cls: 0.1139  loss_box_reg: 0.08073  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.01778  time: 0.6799  data_time: 0.0596  lr: 0.01  max_mem: 11811M
[11/18 02:33:17] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0009999.pth
[11/18 02:33:17] d2.data.datasets.coco WARNING:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 02:33:17] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 02:33:18] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/18 02:33:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 02:33:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 02:33:18] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 02:33:18] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 02:33:18] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 02:33:25] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:13
[11/18 02:33:30] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:12
[11/18 02:33:35] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/18 02:33:40] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/18 02:33:46] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/18 02:33:51] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0014 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/18 02:33:56] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/18 02:34:01] d2.evaluation.evaluator INFO: Inference done 864/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/18 02:34:06] d2.evaluation.evaluator INFO: Inference done 985/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:36
[11/18 02:34:11] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/18 02:34:16] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:26
[11/18 02:34:21] d2.evaluation.evaluator INFO: Inference done 1350/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/18 02:34:26] d2.evaluation.evaluator INFO: Inference done 1476/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/18 02:34:31] d2.evaluation.evaluator INFO: Inference done 1598/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:11
[11/18 02:34:36] d2.evaluation.evaluator INFO: Inference done 1719/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/18 02:34:41] d2.evaluation.evaluator INFO: Inference done 1843/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/18 02:34:46] d2.evaluation.evaluator INFO: Inference done 1968/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:56
[11/18 02:34:51] d2.evaluation.evaluator INFO: Inference done 2092/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:50
[11/18 02:34:56] d2.evaluation.evaluator INFO: Inference done 2212/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/18 02:35:01] d2.evaluation.evaluator INFO: Inference done 2334/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/18 02:35:06] d2.evaluation.evaluator INFO: Inference done 2453/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/18 02:35:11] d2.evaluation.evaluator INFO: Inference done 2577/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/18 02:35:16] d2.evaluation.evaluator INFO: Inference done 2702/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/18 02:35:21] d2.evaluation.evaluator INFO: Inference done 2822/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/18 02:35:26] d2.evaluation.evaluator INFO: Inference done 2942/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/18 02:35:31] d2.evaluation.evaluator INFO: Inference done 3064/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/18 02:35:36] d2.evaluation.evaluator INFO: Inference done 3185/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/18 02:35:41] d2.evaluation.evaluator INFO: Inference done 3312/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:00
[11/18 02:35:42] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.831790 (0.041103 s / iter per device, on 6 devices)
[11/18 02:35:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039194 s / iter per device, on 6 devices)
[11/18 02:35:44] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 02:35:44] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 02:35:45] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 02:35:46] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 02:36:09] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.13 seconds.
[11/18 02:36:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 02:36:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.79 seconds.
[11/18 02:36:11] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.325 | 19.680 | 7.309  | 1.357 | 4.272 | 11.307 |
[11/18 02:36:11] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 4.724  | bird          | 29.549 | hat with a wide brim | 6.204  |
| person                | 8.028  | dog           | 43.594 | lizard               | 6.899  |
| sheep                 | 4.495  | wine bottle   | 6.823  | bowl                 | 13.140 |
| airplane              | 19.050 | domestic cat  | 8.915  | car                  | 31.194 |
| porcupine             | 12.433 | bear          | 13.897 | tape player          | 6.569  |
| ray                   | 2.528  | laptop        | 6.857  | zebra                | 25.302 |
| computer keyboard     | 3.761  | pitcher       | 6.370  | artichoke            | 17.112 |
| tv or monitor         | 10.191 | table         | 6.508  | chair                | 3.975  |
| helmet                | 10.909 | traffic light | 3.275  | red panda            | 12.596 |
| sunglasses            | 0.501  | lamp          | 2.897  | bicycle              | 7.067  |
| backpack              | 8.091  | mushroom      | 5.880  | fox                  | 10.213 |
| otter                 | 2.970  | guitar        | 3.783  | microphone           | 0.161  |
| strawberry            | 7.967  | stove         | 8.533  | violin               | 1.424  |
| bookshelf             | 11.719 | sofa          | 2.713  | bell pepper          | 6.888  |
| bagel                 | 6.218  | lemon         | 8.606  | orange               | 12.071 |
| bench                 | 1.365  | piano         | 11.709 | flower pot           | 3.104  |
| butterfly             | 28.581 | purse         | 5.182  | pomegranate          | 2.651  |
| train                 | 12.721 | drum          | 1.512  | hippopotamus         | 1.061  |
| ski                   | 1.239  | ladybug       | 26.773 | banana               | 1.297  |
| monkey                | 11.706 | bus           | 26.833 | miniskirt            | 3.984  |
| camel                 | 3.502  | cream         | 9.842  | lobster              | 7.053  |
| seal                  | 4.767  | horse         | 6.818  | cart                 | 11.471 |
| elephant              | 15.571 | snake         | 9.571  | fig                  | 4.367  |
| watercraft            | 23.753 | apple         | 14.881 | antelope             | 19.580 |
| cattle                | 2.021  | whale         | 13.621 | coffee maker         | 18.934 |
| baby bed              | 15.552 | frog          | 12.719 | bathing cap          | 7.512  |
| crutch                | 0.045  | koala bear    | 10.746 | tie                  | 0.881  |
| dumbbell              | 0.243  | tiger         | 5.911  | dragonfly            | 8.034  |
| goldfish              | 5.298  | cucumber      | 1.790  | turtle               | 10.997 |
| harp                  | 7.340  | jellyfish     | 9.212  | swine                | 8.385  |
| pretzel               | 6.062  | motorcycle    | 21.360 | beaker               | 10.401 |
| rabbit                | 17.804 | nail          | 1.556  | axe                  | 2.716  |
| salt or pepper shaker | 1.996  | croquet ball  | 10.828 | skunk                | 5.194  |
| starfish              | 11.827 |               |        |                      |        |
[11/18 02:36:14] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 02:36:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 02:36:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 02:36:14] d2.evaluation.testing INFO: copypaste: 9.3248,19.6800,7.3090,1.3574,4.2722,11.3072
[11/18 02:36:14] d2.utils.events INFO:  eta: 19:03:59  iter: 9999  total_loss: 0.2299  loss_cls: 0.1189  loss_box_reg: 0.08492  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01705  time: 0.6798  data_time: 0.0584  lr: 0.01  max_mem: 11811M
[11/18 02:36:27] d2.utils.events INFO:  eta: 19:03:58  iter: 10019  total_loss: 0.2279  loss_cls: 0.1141  loss_box_reg: 0.0818  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.01856  time: 0.6797  data_time: 0.0696  lr: 0.01  max_mem: 11811M
[11/18 02:36:41] d2.utils.events INFO:  eta: 19:03:57  iter: 10039  total_loss: 0.2251  loss_cls: 0.1137  loss_box_reg: 0.08171  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.01658  time: 0.6797  data_time: 0.0684  lr: 0.01  max_mem: 11811M
[11/18 02:36:54] d2.utils.events INFO:  eta: 19:03:31  iter: 10059  total_loss: 0.209  loss_cls: 0.1042  loss_box_reg: 0.07624  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.01528  time: 0.6796  data_time: 0.0738  lr: 0.01  max_mem: 11811M
[11/18 02:37:08] d2.utils.events INFO:  eta: 19:03:29  iter: 10079  total_loss: 0.2216  loss_cls: 0.1135  loss_box_reg: 0.08111  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.01601  time: 0.6796  data_time: 0.0695  lr: 0.01  max_mem: 11811M
[11/18 02:37:21] d2.utils.events INFO:  eta: 19:03:16  iter: 10099  total_loss: 0.2118  loss_cls: 0.1062  loss_box_reg: 0.07745  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.01622  time: 0.6795  data_time: 0.0672  lr: 0.01  max_mem: 11811M
[11/18 02:37:35] d2.utils.events INFO:  eta: 19:02:37  iter: 10119  total_loss: 0.2213  loss_cls: 0.1092  loss_box_reg: 0.08016  loss_rpn_cls: 0.01047  loss_rpn_loc: 0.01658  time: 0.6795  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/18 02:37:49] d2.utils.events INFO:  eta: 19:02:26  iter: 10139  total_loss: 0.2154  loss_cls: 0.1109  loss_box_reg: 0.08084  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01649  time: 0.6795  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/18 02:38:02] d2.utils.events INFO:  eta: 19:02:08  iter: 10159  total_loss: 0.2285  loss_cls: 0.114  loss_box_reg: 0.08256  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.01725  time: 0.6795  data_time: 0.0694  lr: 0.01  max_mem: 11811M
[11/18 02:38:16] d2.utils.events INFO:  eta: 19:01:51  iter: 10179  total_loss: 0.2175  loss_cls: 0.112  loss_box_reg: 0.08134  loss_rpn_cls: 0.009485  loss_rpn_loc: 0.01673  time: 0.6796  data_time: 0.0844  lr: 0.01  max_mem: 11811M
[11/18 02:38:30] d2.utils.events INFO:  eta: 19:01:41  iter: 10199  total_loss: 0.2242  loss_cls: 0.1096  loss_box_reg: 0.08121  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.01827  time: 0.6798  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/18 02:38:43] d2.utils.events INFO:  eta: 19:01:24  iter: 10219  total_loss: 0.2295  loss_cls: 0.1146  loss_box_reg: 0.08397  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01657  time: 0.6798  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/18 02:38:57] d2.utils.events INFO:  eta: 19:00:52  iter: 10239  total_loss: 0.2237  loss_cls: 0.1149  loss_box_reg: 0.08482  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.01733  time: 0.6797  data_time: 0.0647  lr: 0.01  max_mem: 11811M
[11/18 02:39:11] d2.utils.events INFO:  eta: 19:01:01  iter: 10259  total_loss: 0.2242  loss_cls: 0.1121  loss_box_reg: 0.08053  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.01716  time: 0.6799  data_time: 0.0716  lr: 0.01  max_mem: 11811M
[11/18 02:39:24] d2.utils.events INFO:  eta: 18:59:21  iter: 10279  total_loss: 0.2372  loss_cls: 0.121  loss_box_reg: 0.08407  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01667  time: 0.6799  data_time: 0.0736  lr: 0.01  max_mem: 11811M
[11/18 02:39:38] d2.utils.events INFO:  eta: 18:59:07  iter: 10299  total_loss: 0.2278  loss_cls: 0.1138  loss_box_reg: 0.07889  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.01583  time: 0.6800  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/18 02:39:51] d2.utils.events INFO:  eta: 18:58:38  iter: 10319  total_loss: 0.2286  loss_cls: 0.1151  loss_box_reg: 0.08179  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.01694  time: 0.6798  data_time: 0.0606  lr: 0.01  max_mem: 11811M
[11/18 02:40:05] d2.utils.events INFO:  eta: 18:58:20  iter: 10339  total_loss: 0.2104  loss_cls: 0.1072  loss_box_reg: 0.07634  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.01576  time: 0.6799  data_time: 0.0787  lr: 0.01  max_mem: 11811M
[11/18 02:40:19] d2.utils.events INFO:  eta: 18:57:52  iter: 10359  total_loss: 0.2267  loss_cls: 0.1143  loss_box_reg: 0.08361  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01754  time: 0.6798  data_time: 0.0659  lr: 0.01  max_mem: 11811M
[11/18 02:40:32] d2.utils.events INFO:  eta: 18:58:00  iter: 10379  total_loss: 0.2166  loss_cls: 0.1117  loss_box_reg: 0.08106  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01881  time: 0.6799  data_time: 0.0675  lr: 0.01  max_mem: 11811M
[11/18 02:40:46] d2.utils.events INFO:  eta: 18:56:57  iter: 10399  total_loss: 0.2314  loss_cls: 0.1148  loss_box_reg: 0.08393  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.01667  time: 0.6798  data_time: 0.0668  lr: 0.01  max_mem: 11811M
[11/18 02:41:00] d2.utils.events INFO:  eta: 18:56:49  iter: 10419  total_loss: 0.2311  loss_cls: 0.1218  loss_box_reg: 0.08445  loss_rpn_cls: 0.009307  loss_rpn_loc: 0.017  time: 0.6800  data_time: 0.0656  lr: 0.01  max_mem: 11811M
[11/18 02:41:13] d2.utils.events INFO:  eta: 18:56:58  iter: 10439  total_loss: 0.2286  loss_cls: 0.1117  loss_box_reg: 0.08418  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.01538  time: 0.6800  data_time: 0.0631  lr: 0.01  max_mem: 11811M
[11/18 02:41:27] d2.utils.events INFO:  eta: 18:57:13  iter: 10459  total_loss: 0.2147  loss_cls: 0.1072  loss_box_reg: 0.08116  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01829  time: 0.6803  data_time: 0.0721  lr: 0.01  max_mem: 11811M
[11/18 02:41:41] d2.utils.events INFO:  eta: 18:57:19  iter: 10479  total_loss: 0.2377  loss_cls: 0.1178  loss_box_reg: 0.08614  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.01767  time: 0.6803  data_time: 0.0702  lr: 0.01  max_mem: 11811M
[11/18 02:41:54] d2.utils.events INFO:  eta: 18:56:53  iter: 10499  total_loss: 0.2411  loss_cls: 0.1218  loss_box_reg: 0.08803  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01836  time: 0.6803  data_time: 0.0700  lr: 0.01  max_mem: 11811M
[11/18 02:42:08] d2.utils.events INFO:  eta: 18:56:52  iter: 10519  total_loss: 0.216  loss_cls: 0.1086  loss_box_reg: 0.07993  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.01451  time: 0.6803  data_time: 0.0674  lr: 0.01  max_mem: 11811M
[11/18 02:42:22] d2.utils.events INFO:  eta: 18:57:12  iter: 10539  total_loss: 0.23  loss_cls: 0.1147  loss_box_reg: 0.08724  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.01771  time: 0.6802  data_time: 0.0633  lr: 0.01  max_mem: 11811M
[11/18 02:42:35] d2.utils.events INFO:  eta: 18:57:37  iter: 10559  total_loss: 0.2209  loss_cls: 0.1125  loss_box_reg: 0.08155  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.0156  time: 0.6803  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/18 02:42:49] d2.utils.events INFO:  eta: 18:57:30  iter: 10579  total_loss: 0.2363  loss_cls: 0.1198  loss_box_reg: 0.08601  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01624  time: 0.6803  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/18 02:43:03] d2.utils.events INFO:  eta: 18:57:48  iter: 10599  total_loss: 0.2207  loss_cls: 0.1129  loss_box_reg: 0.0819  loss_rpn_cls: 0.011  loss_rpn_loc: 0.01682  time: 0.6805  data_time: 0.0785  lr: 0.01  max_mem: 11811M
[11/18 02:43:16] d2.utils.events INFO:  eta: 18:57:25  iter: 10619  total_loss: 0.2143  loss_cls: 0.1066  loss_box_reg: 0.08301  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.01532  time: 0.6804  data_time: 0.0626  lr: 0.01  max_mem: 11811M
[11/18 02:43:30] d2.utils.events INFO:  eta: 18:57:21  iter: 10639  total_loss: 0.233  loss_cls: 0.117  loss_box_reg: 0.08689  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.01588  time: 0.6804  data_time: 0.0672  lr: 0.01  max_mem: 11811M
[11/18 02:43:44] d2.utils.events INFO:  eta: 18:57:30  iter: 10659  total_loss: 0.2278  loss_cls: 0.118  loss_box_reg: 0.08437  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.01571  time: 0.6804  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/18 02:43:57] d2.utils.events INFO:  eta: 18:57:54  iter: 10679  total_loss: 0.2316  loss_cls: 0.1186  loss_box_reg: 0.08259  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.01691  time: 0.6804  data_time: 0.0641  lr: 0.01  max_mem: 11811M
[11/18 02:44:11] d2.utils.events INFO:  eta: 18:57:47  iter: 10699  total_loss: 0.2288  loss_cls: 0.1153  loss_box_reg: 0.08487  loss_rpn_cls: 0.009675  loss_rpn_loc: 0.01633  time: 0.6805  data_time: 0.0688  lr: 0.01  max_mem: 11811M
[11/18 02:44:25] d2.utils.events INFO:  eta: 18:57:34  iter: 10719  total_loss: 0.2342  loss_cls: 0.117  loss_box_reg: 0.08247  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01818  time: 0.6805  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/18 02:44:38] d2.utils.events INFO:  eta: 18:57:57  iter: 10739  total_loss: 0.2237  loss_cls: 0.1126  loss_box_reg: 0.08371  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.01586  time: 0.6805  data_time: 0.0617  lr: 0.01  max_mem: 11811M
[11/18 02:44:51] d2.utils.events INFO:  eta: 18:56:52  iter: 10759  total_loss: 0.2304  loss_cls: 0.1126  loss_box_reg: 0.0823  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.0173  time: 0.6803  data_time: 0.0663  lr: 0.01  max_mem: 11811M
[11/18 02:45:05] d2.utils.events INFO:  eta: 18:56:09  iter: 10779  total_loss: 0.2266  loss_cls: 0.1116  loss_box_reg: 0.08439  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.01691  time: 0.6803  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/18 02:45:19] d2.utils.events INFO:  eta: 18:55:40  iter: 10799  total_loss: 0.2246  loss_cls: 0.1139  loss_box_reg: 0.08252  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.01583  time: 0.6803  data_time: 0.0631  lr: 0.01  max_mem: 11811M
[11/18 02:45:33] d2.utils.events INFO:  eta: 18:56:10  iter: 10819  total_loss: 0.2426  loss_cls: 0.1214  loss_box_reg: 0.08661  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01836  time: 0.6805  data_time: 0.0726  lr: 0.01  max_mem: 11811M
[11/18 02:45:46] d2.utils.events INFO:  eta: 18:56:05  iter: 10839  total_loss: 0.2203  loss_cls: 0.1129  loss_box_reg: 0.08153  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.01685  time: 0.6805  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/18 02:46:00] d2.utils.events INFO:  eta: 18:55:05  iter: 10859  total_loss: 0.2343  loss_cls: 0.1225  loss_box_reg: 0.08512  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.01667  time: 0.6805  data_time: 0.0681  lr: 0.01  max_mem: 11811M
[11/18 02:46:13] d2.utils.events INFO:  eta: 18:54:37  iter: 10879  total_loss: 0.2133  loss_cls: 0.1094  loss_box_reg: 0.07965  loss_rpn_cls: 0.009358  loss_rpn_loc: 0.01655  time: 0.6804  data_time: 0.0589  lr: 0.01  max_mem: 11811M
[11/18 02:46:27] d2.utils.events INFO:  eta: 18:54:27  iter: 10899  total_loss: 0.2221  loss_cls: 0.1119  loss_box_reg: 0.08229  loss_rpn_cls: 0.009943  loss_rpn_loc: 0.01608  time: 0.6804  data_time: 0.0679  lr: 0.01  max_mem: 11811M
[11/18 02:46:40] d2.utils.events INFO:  eta: 18:54:16  iter: 10919  total_loss: 0.2374  loss_cls: 0.1239  loss_box_reg: 0.08539  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.01499  time: 0.6804  data_time: 0.0673  lr: 0.01  max_mem: 11811M
[11/18 02:46:54] d2.utils.events INFO:  eta: 18:54:20  iter: 10939  total_loss: 0.2191  loss_cls: 0.1162  loss_box_reg: 0.08033  loss_rpn_cls: 0.01139  loss_rpn_loc: 0.01662  time: 0.6804  data_time: 0.0687  lr: 0.01  max_mem: 11811M
[11/18 02:47:08] d2.utils.events INFO:  eta: 18:53:49  iter: 10959  total_loss: 0.231  loss_cls: 0.1183  loss_box_reg: 0.08144  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.01526  time: 0.6803  data_time: 0.0632  lr: 0.01  max_mem: 11811M
[11/18 02:47:21] d2.utils.events INFO:  eta: 18:53:35  iter: 10979  total_loss: 0.2274  loss_cls: 0.1122  loss_box_reg: 0.08309  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01866  time: 0.6803  data_time: 0.0607  lr: 0.01  max_mem: 11811M
[11/18 02:47:35] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0010999.pth
[11/18 02:47:35] d2.data.datasets.coco WARNING:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 02:47:35] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 02:47:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 02:47:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 02:47:36] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 02:47:36] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 02:47:36] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 02:47:43] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0442 s/iter. Eval: 0.0002 s/iter. Total: 0.0453 s/iter. ETA=0:02:30
[11/18 02:47:48] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:15
[11/18 02:47:53] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/18 02:47:58] d2.evaluation.evaluator INFO: Inference done 373/3334. Dataloading: 0.0014 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/18 02:48:03] d2.evaluation.evaluator INFO: Inference done 491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:58
[11/18 02:48:08] d2.evaluation.evaluator INFO: Inference done 615/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:53
[11/18 02:48:13] d2.evaluation.evaluator INFO: Inference done 736/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:48
[11/18 02:48:18] d2.evaluation.evaluator INFO: Inference done 858/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:42
[11/18 02:48:23] d2.evaluation.evaluator INFO: Inference done 978/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:37
[11/18 02:48:28] d2.evaluation.evaluator INFO: Inference done 1099/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:32
[11/18 02:48:33] d2.evaluation.evaluator INFO: Inference done 1219/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:27
[11/18 02:48:38] d2.evaluation.evaluator INFO: Inference done 1340/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:22
[11/18 02:48:43] d2.evaluation.evaluator INFO: Inference done 1460/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/18 02:48:48] d2.evaluation.evaluator INFO: Inference done 1579/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:13
[11/18 02:48:53] d2.evaluation.evaluator INFO: Inference done 1705/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/18 02:48:58] d2.evaluation.evaluator INFO: Inference done 1825/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/18 02:49:03] d2.evaluation.evaluator INFO: Inference done 1945/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/18 02:49:08] d2.evaluation.evaluator INFO: Inference done 2064/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/18 02:49:13] d2.evaluation.evaluator INFO: Inference done 2186/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/18 02:49:18] d2.evaluation.evaluator INFO: Inference done 2308/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/18 02:49:23] d2.evaluation.evaluator INFO: Inference done 2430/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/18 02:49:28] d2.evaluation.evaluator INFO: Inference done 2550/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:32
[11/18 02:49:33] d2.evaluation.evaluator INFO: Inference done 2673/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/18 02:49:38] d2.evaluation.evaluator INFO: Inference done 2795/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/18 02:49:43] d2.evaluation.evaluator INFO: Inference done 2918/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/18 02:49:48] d2.evaluation.evaluator INFO: Inference done 3040/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/18 02:49:53] d2.evaluation.evaluator INFO: Inference done 3160/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/18 02:49:58] d2.evaluation.evaluator INFO: Inference done 3283/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/18 02:50:01] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.094479 (0.041482 s / iter per device, on 6 devices)
[11/18 02:50:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039553 s / iter per device, on 6 devices)
[11/18 02:50:02] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 02:50:02] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 02:50:03] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 02:50:04] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 02:50:25] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.14 seconds.
[11/18 02:50:25] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 02:50:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.69 seconds.
[11/18 02:50:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.887 | 20.370 | 8.306  | 1.310 | 4.716 | 12.065 |
[11/18 02:50:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 7.997  | bird          | 30.955 | hat with a wide brim | 4.580  |
| person                | 8.469  | dog           | 46.049 | lizard               | 5.867  |
| sheep                 | 4.228  | wine bottle   | 5.827  | bowl                 | 11.026 |
| airplane              | 22.848 | domestic cat  | 8.759  | car                  | 33.370 |
| porcupine             | 13.070 | bear          | 12.776 | tape player          | 9.568  |
| ray                   | 3.148  | laptop        | 9.090  | zebra                | 25.514 |
| computer keyboard     | 5.047  | pitcher       | 6.745  | artichoke            | 15.154 |
| tv or monitor         | 13.348 | table         | 9.120  | chair                | 6.406  |
| helmet                | 12.996 | traffic light | 3.748  | red panda            | 14.185 |
| sunglasses            | 0.613  | lamp          | 3.331  | bicycle              | 7.158  |
| backpack              | 6.800  | mushroom      | 4.996  | fox                  | 7.442  |
| otter                 | 3.051  | guitar        | 5.361  | microphone           | 0.113  |
| strawberry            | 9.425  | stove         | 11.408 | violin               | 0.563  |
| bookshelf             | 14.407 | sofa          | 3.121  | bell pepper          | 7.876  |
| bagel                 | 8.119  | lemon         | 14.172 | orange               | 15.804 |
| bench                 | 2.810  | piano         | 12.057 | flower pot           | 4.034  |
| butterfly             | 25.761 | purse         | 4.493  | pomegranate          | 2.987  |
| train                 | 16.304 | drum          | 0.908  | hippopotamus         | 1.315  |
| ski                   | 2.204  | ladybug       | 25.357 | banana               | 1.158  |
| monkey                | 11.481 | bus           | 27.536 | miniskirt            | 3.456  |
| camel                 | 4.571  | cream         | 14.592 | lobster              | 7.096  |
| seal                  | 3.417  | horse         | 7.600  | cart                 | 13.897 |
| elephant              | 16.874 | snake         | 8.967  | fig                  | 3.393  |
| watercraft            | 23.634 | apple         | 17.528 | antelope             | 19.801 |
| cattle                | 4.006  | whale         | 13.684 | coffee maker         | 22.424 |
| baby bed              | 14.542 | frog          | 12.160 | bathing cap          | 7.900  |
| crutch                | 0.048  | koala bear    | 10.378 | tie                  | 0.920  |
| dumbbell              | 0.378  | tiger         | 8.440  | dragonfly            | 7.666  |
| goldfish              | 5.186  | cucumber      | 2.342  | turtle               | 11.584 |
| harp                  | 5.860  | jellyfish     | 10.001 | swine                | 8.877  |
| pretzel               | 6.844  | motorcycle    | 18.958 | beaker               | 10.001 |
| rabbit                | 18.291 | nail          | 0.114  | axe                  | 2.835  |
| salt or pepper shaker | 2.019  | croquet ball  | 12.343 | skunk                | 4.739  |
| starfish              | 9.312  |               |        |                      |        |
[11/18 02:50:29] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 02:50:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 02:50:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 02:50:29] d2.evaluation.testing INFO: copypaste: 9.8873,20.3703,8.3065,1.3099,4.7165,12.0645
[11/18 02:50:29] d2.utils.events INFO:  eta: 18:54:16  iter: 10999  total_loss: 0.2254  loss_cls: 0.113  loss_box_reg: 0.08523  loss_rpn_cls: 0.009654  loss_rpn_loc: 0.01824  time: 0.6804  data_time: 0.0736  lr: 0.01  max_mem: 11811M
[11/18 02:50:43] d2.utils.events INFO:  eta: 18:53:38  iter: 11019  total_loss: 0.2279  loss_cls: 0.1177  loss_box_reg: 0.08341  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.0154  time: 0.6804  data_time: 0.0627  lr: 0.01  max_mem: 11811M
[11/18 02:50:56] d2.utils.events INFO:  eta: 18:53:12  iter: 11039  total_loss: 0.217  loss_cls: 0.1048  loss_box_reg: 0.08113  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.0172  time: 0.6804  data_time: 0.0721  lr: 0.01  max_mem: 11811M
[11/18 02:51:10] d2.utils.events INFO:  eta: 18:52:59  iter: 11059  total_loss: 0.2231  loss_cls: 0.1109  loss_box_reg: 0.08478  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.01491  time: 0.6804  data_time: 0.0674  lr: 0.01  max_mem: 11811M
[11/18 02:51:23] d2.utils.events INFO:  eta: 18:52:45  iter: 11079  total_loss: 0.2252  loss_cls: 0.1153  loss_box_reg: 0.08388  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.0172  time: 0.6804  data_time: 0.0654  lr: 0.01  max_mem: 11811M
[11/18 02:51:37] d2.utils.events INFO:  eta: 18:52:59  iter: 11099  total_loss: 0.2172  loss_cls: 0.1113  loss_box_reg: 0.08451  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.01448  time: 0.6805  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/18 02:51:51] d2.utils.events INFO:  eta: 18:53:37  iter: 11119  total_loss: 0.2213  loss_cls: 0.1099  loss_box_reg: 0.08256  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.01561  time: 0.6805  data_time: 0.0630  lr: 0.01  max_mem: 11811M
[11/18 02:52:05] d2.utils.events INFO:  eta: 18:53:27  iter: 11139  total_loss: 0.228  loss_cls: 0.1177  loss_box_reg: 0.08306  loss_rpn_cls: 0.009307  loss_rpn_loc: 0.01643  time: 0.6805  data_time: 0.0619  lr: 0.01  max_mem: 11811M
[11/18 02:52:18] d2.utils.events INFO:  eta: 18:53:21  iter: 11159  total_loss: 0.2133  loss_cls: 0.1057  loss_box_reg: 0.07982  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.01825  time: 0.6805  data_time: 0.0617  lr: 0.01  max_mem: 11811M
[11/18 02:52:32] d2.utils.events INFO:  eta: 18:53:22  iter: 11179  total_loss: 0.2177  loss_cls: 0.1093  loss_box_reg: 0.0807  loss_rpn_cls: 0.01155  loss_rpn_loc: 0.01681  time: 0.6805  data_time: 0.0648  lr: 0.01  max_mem: 11811M
[11/18 02:52:45] d2.utils.events INFO:  eta: 18:52:46  iter: 11199  total_loss: 0.2209  loss_cls: 0.1119  loss_box_reg: 0.08224  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.01723  time: 0.6805  data_time: 0.0718  lr: 0.01  max_mem: 11811M
[11/18 02:52:59] d2.utils.events INFO:  eta: 18:52:40  iter: 11219  total_loss: 0.2252  loss_cls: 0.1122  loss_box_reg: 0.08413  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.01698  time: 0.6806  data_time: 0.0656  lr: 0.01  max_mem: 11811M
[11/18 02:53:13] d2.utils.events INFO:  eta: 18:52:43  iter: 11239  total_loss: 0.2372  loss_cls: 0.1226  loss_box_reg: 0.08301  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01618  time: 0.6806  data_time: 0.0645  lr: 0.01  max_mem: 11811M
[11/18 02:53:26] d2.utils.events INFO:  eta: 18:52:09  iter: 11259  total_loss: 0.2241  loss_cls: 0.1139  loss_box_reg: 0.08528  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.01639  time: 0.6805  data_time: 0.0632  lr: 0.01  max_mem: 11811M
[11/18 02:53:40] d2.utils.events INFO:  eta: 18:52:07  iter: 11279  total_loss: 0.2248  loss_cls: 0.1119  loss_box_reg: 0.08598  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.01641  time: 0.6805  data_time: 0.0705  lr: 0.01  max_mem: 11811M
[11/18 02:53:53] d2.utils.events INFO:  eta: 18:51:32  iter: 11299  total_loss: 0.2286  loss_cls: 0.1124  loss_box_reg: 0.08169  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.01704  time: 0.6804  data_time: 0.0652  lr: 0.01  max_mem: 11811M
[11/18 02:54:07] d2.utils.events INFO:  eta: 18:52:04  iter: 11319  total_loss: 0.2305  loss_cls: 0.1134  loss_box_reg: 0.08489  loss_rpn_cls: 0.009999  loss_rpn_loc: 0.01678  time: 0.6805  data_time: 0.0719  lr: 0.01  max_mem: 11811M
[11/18 02:54:21] d2.utils.events INFO:  eta: 18:52:03  iter: 11339  total_loss: 0.2271  loss_cls: 0.115  loss_box_reg: 0.08483  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01764  time: 0.6805  data_time: 0.0627  lr: 0.01  max_mem: 11811M
[11/18 02:54:34] d2.utils.events INFO:  eta: 18:51:55  iter: 11359  total_loss: 0.233  loss_cls: 0.1195  loss_box_reg: 0.08541  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.01757  time: 0.6805  data_time: 0.0697  lr: 0.01  max_mem: 11811M
[11/18 02:54:48] d2.utils.events INFO:  eta: 18:51:36  iter: 11379  total_loss: 0.223  loss_cls: 0.1191  loss_box_reg: 0.08215  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.01519  time: 0.6805  data_time: 0.0735  lr: 0.01  max_mem: 11811M
[11/18 02:55:02] d2.utils.events INFO:  eta: 18:51:45  iter: 11399  total_loss: 0.2321  loss_cls: 0.1173  loss_box_reg: 0.08547  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.01769  time: 0.6806  data_time: 0.0758  lr: 0.01  max_mem: 11811M
[11/18 02:55:16] d2.utils.events INFO:  eta: 18:51:23  iter: 11419  total_loss: 0.2098  loss_cls: 0.1071  loss_box_reg: 0.07758  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.01665  time: 0.6807  data_time: 0.0778  lr: 0.01  max_mem: 11811M
[11/18 02:55:29] d2.utils.events INFO:  eta: 18:50:43  iter: 11439  total_loss: 0.2262  loss_cls: 0.1158  loss_box_reg: 0.08255  loss_rpn_cls: 0.0105  loss_rpn_loc: 0.01686  time: 0.6807  data_time: 0.0622  lr: 0.01  max_mem: 11811M
[11/18 02:55:43] d2.utils.events INFO:  eta: 18:49:57  iter: 11459  total_loss: 0.2184  loss_cls: 0.1125  loss_box_reg: 0.0789  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01615  time: 0.6807  data_time: 0.0682  lr: 0.01  max_mem: 11811M
[11/18 02:55:56] d2.utils.events INFO:  eta: 18:49:44  iter: 11479  total_loss: 0.213  loss_cls: 0.1099  loss_box_reg: 0.07684  loss_rpn_cls: 0.00923  loss_rpn_loc: 0.01645  time: 0.6807  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/18 02:56:10] d2.utils.events INFO:  eta: 18:49:37  iter: 11499  total_loss: 0.2205  loss_cls: 0.1162  loss_box_reg: 0.08008  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.01456  time: 0.6807  data_time: 0.0724  lr: 0.01  max_mem: 11811M
[11/18 02:56:24] d2.utils.events INFO:  eta: 18:49:13  iter: 11519  total_loss: 0.2341  loss_cls: 0.1203  loss_box_reg: 0.08505  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.01673  time: 0.6807  data_time: 0.0665  lr: 0.01  max_mem: 11811M
[11/18 02:56:37] d2.utils.events INFO:  eta: 18:49:03  iter: 11539  total_loss: 0.1984  loss_cls: 0.1024  loss_box_reg: 0.07477  loss_rpn_cls: 0.009507  loss_rpn_loc: 0.01669  time: 0.6807  data_time: 0.0671  lr: 0.01  max_mem: 11811M
[11/18 02:56:51] d2.utils.events INFO:  eta: 18:48:49  iter: 11559  total_loss: 0.2155  loss_cls: 0.1075  loss_box_reg: 0.08022  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01679  time: 0.6807  data_time: 0.0652  lr: 0.01  max_mem: 11811M
[11/18 02:57:04] d2.utils.events INFO:  eta: 18:48:18  iter: 11579  total_loss: 0.2196  loss_cls: 0.1075  loss_box_reg: 0.08305  loss_rpn_cls: 0.009656  loss_rpn_loc: 0.018  time: 0.6807  data_time: 0.0703  lr: 0.01  max_mem: 11811M
[11/18 02:57:18] d2.utils.events INFO:  eta: 18:48:14  iter: 11599  total_loss: 0.2289  loss_cls: 0.115  loss_box_reg: 0.08222  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01684  time: 0.6807  data_time: 0.0664  lr: 0.01  max_mem: 11811M
[11/18 02:57:32] d2.utils.events INFO:  eta: 18:48:01  iter: 11619  total_loss: 0.2257  loss_cls: 0.1113  loss_box_reg: 0.08671  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01708  time: 0.6808  data_time: 0.0878  lr: 0.01  max_mem: 11811M
[11/18 02:57:46] d2.utils.events INFO:  eta: 18:47:51  iter: 11639  total_loss: 0.2194  loss_cls: 0.1111  loss_box_reg: 0.08178  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01669  time: 0.6809  data_time: 0.0631  lr: 0.01  max_mem: 11811M
[11/18 02:57:59] d2.utils.events INFO:  eta: 18:46:45  iter: 11659  total_loss: 0.2235  loss_cls: 0.1122  loss_box_reg: 0.0792  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.01612  time: 0.6808  data_time: 0.0672  lr: 0.01  max_mem: 11811M
[11/18 02:58:13] d2.utils.events INFO:  eta: 18:45:48  iter: 11679  total_loss: 0.2221  loss_cls: 0.1121  loss_box_reg: 0.07992  loss_rpn_cls: 0.009793  loss_rpn_loc: 0.01734  time: 0.6808  data_time: 0.0615  lr: 0.01  max_mem: 11811M
[11/18 02:58:26] d2.utils.events INFO:  eta: 18:45:41  iter: 11699  total_loss: 0.218  loss_cls: 0.1088  loss_box_reg: 0.08028  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01669  time: 0.6808  data_time: 0.0626  lr: 0.01  max_mem: 11811M
[11/18 02:58:40] d2.utils.events INFO:  eta: 18:45:50  iter: 11719  total_loss: 0.2223  loss_cls: 0.1109  loss_box_reg: 0.07945  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.01765  time: 0.6808  data_time: 0.0755  lr: 0.01  max_mem: 11811M
[11/18 02:58:54] d2.utils.events INFO:  eta: 18:45:51  iter: 11739  total_loss: 0.2348  loss_cls: 0.1179  loss_box_reg: 0.08521  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.01753  time: 0.6808  data_time: 0.0643  lr: 0.01  max_mem: 11811M
[11/18 02:59:08] d2.utils.events INFO:  eta: 18:46:18  iter: 11759  total_loss: 0.2312  loss_cls: 0.114  loss_box_reg: 0.08504  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.01719  time: 0.6809  data_time: 0.0751  lr: 0.01  max_mem: 11811M
[11/18 02:59:21] d2.utils.events INFO:  eta: 18:46:01  iter: 11779  total_loss: 0.2247  loss_cls: 0.1111  loss_box_reg: 0.08221  loss_rpn_cls: 0.012  loss_rpn_loc: 0.01691  time: 0.6809  data_time: 0.0813  lr: 0.01  max_mem: 11811M
[11/18 02:59:35] d2.utils.events INFO:  eta: 18:45:48  iter: 11799  total_loss: 0.2284  loss_cls: 0.1182  loss_box_reg: 0.0851  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.01749  time: 0.6809  data_time: 0.0726  lr: 0.01  max_mem: 11811M
[11/18 02:59:49] d2.utils.events INFO:  eta: 18:45:12  iter: 11819  total_loss: 0.229  loss_cls: 0.1194  loss_box_reg: 0.08142  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.01633  time: 0.6809  data_time: 0.0741  lr: 0.01  max_mem: 11811M
[11/18 03:00:02] d2.utils.events INFO:  eta: 18:44:19  iter: 11839  total_loss: 0.2235  loss_cls: 0.1123  loss_box_reg: 0.08591  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.01523  time: 0.6809  data_time: 0.0637  lr: 0.01  max_mem: 11811M
[11/18 03:00:16] d2.utils.events INFO:  eta: 18:45:03  iter: 11859  total_loss: 0.2231  loss_cls: 0.112  loss_box_reg: 0.08269  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.01742  time: 0.6809  data_time: 0.0692  lr: 0.01  max_mem: 11811M
[11/18 03:00:29] d2.utils.events INFO:  eta: 18:44:51  iter: 11879  total_loss: 0.2164  loss_cls: 0.1111  loss_box_reg: 0.0801  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01506  time: 0.6809  data_time: 0.0680  lr: 0.01  max_mem: 11811M
[11/18 03:00:43] d2.utils.events INFO:  eta: 18:44:36  iter: 11899  total_loss: 0.2356  loss_cls: 0.1177  loss_box_reg: 0.08377  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.0176  time: 0.6809  data_time: 0.0654  lr: 0.01  max_mem: 11811M
[11/18 03:00:57] d2.utils.events INFO:  eta: 18:44:23  iter: 11919  total_loss: 0.2141  loss_cls: 0.108  loss_box_reg: 0.08068  loss_rpn_cls: 0.0101  loss_rpn_loc: 0.01632  time: 0.6809  data_time: 0.0650  lr: 0.01  max_mem: 11811M
[11/18 03:01:10] d2.utils.events INFO:  eta: 18:43:32  iter: 11939  total_loss: 0.2155  loss_cls: 0.1078  loss_box_reg: 0.08156  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.01951  time: 0.6809  data_time: 0.0704  lr: 0.01  max_mem: 11811M
[11/18 03:01:24] d2.utils.events INFO:  eta: 18:43:37  iter: 11959  total_loss: 0.2332  loss_cls: 0.1184  loss_box_reg: 0.08281  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.01683  time: 0.6808  data_time: 0.0626  lr: 0.01  max_mem: 11811M
[11/18 03:01:38] d2.utils.events INFO:  eta: 18:43:54  iter: 11979  total_loss: 0.2258  loss_cls: 0.1138  loss_box_reg: 0.08244  loss_rpn_cls: 0.009226  loss_rpn_loc: 0.0175  time: 0.6809  data_time: 0.0631  lr: 0.01  max_mem: 11811M
[11/18 03:01:51] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0011999.pth
[11/18 03:01:52] d2.data.datasets.coco WARNING:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 03:01:52] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 03:01:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 03:01:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 03:01:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 03:01:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 03:01:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 03:01:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:02:01
[11/18 03:02:04] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:12
[11/18 03:02:09] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/18 03:02:14] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/18 03:02:19] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/18 03:02:24] d2.evaluation.evaluator INFO: Inference done 622/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/18 03:02:29] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/18 03:02:34] d2.evaluation.evaluator INFO: Inference done 862/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/18 03:02:39] d2.evaluation.evaluator INFO: Inference done 983/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/18 03:02:44] d2.evaluation.evaluator INFO: Inference done 1105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:32
[11/18 03:02:49] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:26
[11/18 03:02:54] d2.evaluation.evaluator INFO: Inference done 1350/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/18 03:02:59] d2.evaluation.evaluator INFO: Inference done 1473/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/18 03:03:04] d2.evaluation.evaluator INFO: Inference done 1595/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/18 03:03:09] d2.evaluation.evaluator INFO: Inference done 1716/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/18 03:03:14] d2.evaluation.evaluator INFO: Inference done 1839/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/18 03:03:19] d2.evaluation.evaluator INFO: Inference done 1961/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/18 03:03:24] d2.evaluation.evaluator INFO: Inference done 2085/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/18 03:03:29] d2.evaluation.evaluator INFO: Inference done 2208/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/18 03:03:34] d2.evaluation.evaluator INFO: Inference done 2333/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/18 03:03:39] d2.evaluation.evaluator INFO: Inference done 2456/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/18 03:03:44] d2.evaluation.evaluator INFO: Inference done 2578/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/18 03:03:49] d2.evaluation.evaluator INFO: Inference done 2699/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:26
[11/18 03:03:54] d2.evaluation.evaluator INFO: Inference done 2820/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/18 03:04:00] d2.evaluation.evaluator INFO: Inference done 2944/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/18 03:04:05] d2.evaluation.evaluator INFO: Inference done 3068/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:10
[11/18 03:04:10] d2.evaluation.evaluator INFO: Inference done 3184/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/18 03:04:15] d2.evaluation.evaluator INFO: Inference done 3306/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:01
[11/18 03:04:16] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.386530 (0.041270 s / iter per device, on 6 devices)
[11/18 03:04:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039317 s / iter per device, on 6 devices)
[11/18 03:04:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 03:04:18] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 03:04:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 03:04:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 03:04:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.86 seconds.
[11/18 03:04:41] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 03:04:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.86 seconds.
[11/18 03:04:43] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 10.043 | 20.893 | 8.437  | 1.481 | 4.486 | 12.132 |
[11/18 03:04:43] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 4.331  | bird          | 29.971 | hat with a wide brim | 5.651  |
| person                | 9.374  | dog           | 46.685 | lizard               | 6.769  |
| sheep                 | 5.885  | wine bottle   | 7.084  | bowl                 | 13.049 |
| airplane              | 23.080 | domestic cat  | 10.506 | car                  | 32.140 |
| porcupine             | 15.232 | bear          | 11.651 | tape player          | 9.537  |
| ray                   | 3.412  | laptop        | 7.701  | zebra                | 18.824 |
| computer keyboard     | 5.113  | pitcher       | 6.444  | artichoke            | 14.650 |
| tv or monitor         | 13.139 | table         | 7.910  | chair                | 6.779  |
| helmet                | 13.154 | traffic light | 3.450  | red panda            | 15.668 |
| sunglasses            | 0.887  | lamp          | 3.352  | bicycle              | 8.624  |
| backpack              | 8.106  | mushroom      | 5.442  | fox                  | 7.988  |
| otter                 | 3.311  | guitar        | 5.940  | microphone           | 0.267  |
| strawberry            | 7.746  | stove         | 10.271 | violin               | 1.556  |
| bookshelf             | 14.453 | sofa          | 4.091  | bell pepper          | 10.615 |
| bagel                 | 4.048  | lemon         | 9.856  | orange               | 15.238 |
| bench                 | 2.500  | piano         | 14.278 | flower pot           | 4.122  |
| butterfly             | 25.760 | purse         | 4.797  | pomegranate          | 3.431  |
| train                 | 15.513 | drum          | 1.304  | hippopotamus         | 1.114  |
| ski                   | 0.779  | ladybug       | 24.950 | banana               | 1.102  |
| monkey                | 11.291 | bus           | 27.178 | miniskirt            | 3.389  |
| camel                 | 2.891  | cream         | 13.286 | lobster              | 9.234  |
| seal                  | 2.992  | horse         | 8.127  | cart                 | 13.015 |
| elephant              | 16.673 | snake         | 8.818  | fig                  | 3.704  |
| watercraft            | 22.401 | apple         | 17.242 | antelope             | 20.484 |
| cattle                | 2.437  | whale         | 11.786 | coffee maker         | 19.702 |
| baby bed              | 15.592 | frog          | 13.014 | bathing cap          | 7.530  |
| crutch                | 0.117  | koala bear    | 14.128 | tie                  | 1.637  |
| dumbbell              | 0.064  | tiger         | 8.686  | dragonfly            | 9.633  |
| goldfish              | 6.529  | cucumber      | 0.510  | turtle               | 13.846 |
| harp                  | 7.168  | jellyfish     | 8.906  | swine                | 11.428 |
| pretzel               | 7.075  | motorcycle    | 21.079 | beaker               | 13.304 |
| rabbit                | 21.176 | nail          | 0.217  | axe                  | 3.560  |
| salt or pepper shaker | 2.309  | croquet ball  | 15.724 | skunk                | 8.355  |
| starfish              | 9.446  |               |        |                      |        |
[11/18 03:04:45] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 03:04:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 03:04:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 03:04:45] d2.evaluation.testing INFO: copypaste: 10.0431,20.8925,8.4375,1.4806,4.4863,12.1316
[11/18 03:04:45] d2.utils.events INFO:  eta: 18:43:35  iter: 11999  total_loss: 0.2209  loss_cls: 0.111  loss_box_reg: 0.08069  loss_rpn_cls: 0.011  loss_rpn_loc: 0.01702  time: 0.6809  data_time: 0.0769  lr: 0.01  max_mem: 11811M
[11/18 03:04:59] d2.utils.events INFO:  eta: 18:43:14  iter: 12019  total_loss: 0.2143  loss_cls: 0.1035  loss_box_reg: 0.0773  loss_rpn_cls: 0.009953  loss_rpn_loc: 0.01755  time: 0.6808  data_time: 0.0658  lr: 0.01  max_mem: 11811M
[11/18 03:05:12] d2.utils.events INFO:  eta: 18:42:46  iter: 12039  total_loss: 0.2138  loss_cls: 0.106  loss_box_reg: 0.08298  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.0169  time: 0.6807  data_time: 0.0675  lr: 0.01  max_mem: 11811M
[11/18 03:05:26] d2.utils.events INFO:  eta: 18:42:53  iter: 12059  total_loss: 0.2372  loss_cls: 0.1214  loss_box_reg: 0.08774  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01735  time: 0.6807  data_time: 0.0648  lr: 0.01  max_mem: 11811M
[11/18 03:05:39] d2.utils.events INFO:  eta: 18:42:34  iter: 12079  total_loss: 0.2036  loss_cls: 0.101  loss_box_reg: 0.07335  loss_rpn_cls: 0.009578  loss_rpn_loc: 0.01622  time: 0.6808  data_time: 0.0768  lr: 0.01  max_mem: 11811M
[11/18 03:05:53] d2.utils.events INFO:  eta: 18:42:13  iter: 12099  total_loss: 0.2254  loss_cls: 0.1144  loss_box_reg: 0.0838  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.01503  time: 0.6808  data_time: 0.0626  lr: 0.01  max_mem: 11811M
[11/18 03:06:06] d2.utils.events INFO:  eta: 18:41:51  iter: 12119  total_loss: 0.22  loss_cls: 0.1109  loss_box_reg: 0.08386  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01766  time: 0.6807  data_time: 0.0639  lr: 0.01  max_mem: 11811M
[11/18 03:06:20] d2.utils.events INFO:  eta: 18:41:28  iter: 12139  total_loss: 0.2083  loss_cls: 0.1062  loss_box_reg: 0.07898  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01642  time: 0.6807  data_time: 0.0783  lr: 0.01  max_mem: 11811M
[11/18 03:06:34] d2.utils.events INFO:  eta: 18:40:22  iter: 12159  total_loss: 0.2265  loss_cls: 0.1119  loss_box_reg: 0.08325  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.01608  time: 0.6807  data_time: 0.0687  lr: 0.01  max_mem: 11811M
[11/18 03:06:47] d2.utils.events INFO:  eta: 18:40:01  iter: 12179  total_loss: 0.2353  loss_cls: 0.1187  loss_box_reg: 0.08625  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.0167  time: 0.6807  data_time: 0.0623  lr: 0.01  max_mem: 11811M
[11/18 03:07:01] d2.utils.events INFO:  eta: 18:40:46  iter: 12199  total_loss: 0.2082  loss_cls: 0.1075  loss_box_reg: 0.07583  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01749  time: 0.6807  data_time: 0.0629  lr: 0.01  max_mem: 11811M
[11/18 03:07:14] d2.utils.events INFO:  eta: 18:39:41  iter: 12219  total_loss: 0.234  loss_cls: 0.1145  loss_box_reg: 0.08677  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.01673  time: 0.6807  data_time: 0.0738  lr: 0.01  max_mem: 11811M
[11/18 03:07:28] d2.utils.events INFO:  eta: 18:39:05  iter: 12239  total_loss: 0.2159  loss_cls: 0.1081  loss_box_reg: 0.0772  loss_rpn_cls: 0.00913  loss_rpn_loc: 0.01686  time: 0.6806  data_time: 0.0615  lr: 0.01  max_mem: 11811M
[11/18 03:07:41] d2.utils.events INFO:  eta: 18:39:00  iter: 12259  total_loss: 0.2256  loss_cls: 0.1099  loss_box_reg: 0.08488  loss_rpn_cls: 0.009746  loss_rpn_loc: 0.01701  time: 0.6806  data_time: 0.0661  lr: 0.01  max_mem: 11811M
[11/18 03:07:55] d2.utils.events INFO:  eta: 18:38:53  iter: 12279  total_loss: 0.2244  loss_cls: 0.1136  loss_box_reg: 0.08237  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.01776  time: 0.6806  data_time: 0.0710  lr: 0.01  max_mem: 11811M
[11/18 03:08:09] d2.utils.events INFO:  eta: 18:38:47  iter: 12299  total_loss: 0.2136  loss_cls: 0.105  loss_box_reg: 0.07845  loss_rpn_cls: 0.01011  loss_rpn_loc: 0.01722  time: 0.6807  data_time: 0.0686  lr: 0.01  max_mem: 11811M
[11/18 03:08:22] d2.utils.events INFO:  eta: 18:38:04  iter: 12319  total_loss: 0.2172  loss_cls: 0.1037  loss_box_reg: 0.08255  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.01816  time: 0.6806  data_time: 0.0712  lr: 0.01  max_mem: 11811M
[11/18 03:08:36] d2.utils.events INFO:  eta: 18:38:04  iter: 12339  total_loss: 0.2215  loss_cls: 0.1138  loss_box_reg: 0.08144  loss_rpn_cls: 0.009262  loss_rpn_loc: 0.01769  time: 0.6807  data_time: 0.0609  lr: 0.01  max_mem: 11811M
[11/18 03:08:50] d2.utils.events INFO:  eta: 18:37:52  iter: 12359  total_loss: 0.2344  loss_cls: 0.1159  loss_box_reg: 0.08447  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.01776  time: 0.6807  data_time: 0.0677  lr: 0.01  max_mem: 11811M
[11/18 03:09:03] d2.utils.events INFO:  eta: 18:37:45  iter: 12379  total_loss: 0.2219  loss_cls: 0.1147  loss_box_reg: 0.08459  loss_rpn_cls: 0.01044  loss_rpn_loc: 0.01601  time: 0.6807  data_time: 0.0616  lr: 0.01  max_mem: 11811M
[11/18 03:09:17] d2.utils.events INFO:  eta: 18:37:21  iter: 12399  total_loss: 0.2166  loss_cls: 0.1085  loss_box_reg: 0.07871  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.01547  time: 0.6807  data_time: 0.0693  lr: 0.01  max_mem: 11811M
[11/18 03:09:30] d2.utils.events INFO:  eta: 18:37:05  iter: 12419  total_loss: 0.2229  loss_cls: 0.113  loss_box_reg: 0.08669  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01766  time: 0.6806  data_time: 0.0743  lr: 0.01  max_mem: 11811M
[11/18 03:09:44] d2.utils.events INFO:  eta: 18:36:56  iter: 12439  total_loss: 0.2107  loss_cls: 0.109  loss_box_reg: 0.07834  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.01702  time: 0.6806  data_time: 0.0631  lr: 0.01  max_mem: 11811M
[11/18 03:09:57] d2.utils.events INFO:  eta: 18:36:18  iter: 12459  total_loss: 0.2265  loss_cls: 0.1153  loss_box_reg: 0.08321  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01592  time: 0.6806  data_time: 0.0649  lr: 0.01  max_mem: 11811M
[11/18 03:10:11] d2.utils.events INFO:  eta: 18:35:57  iter: 12479  total_loss: 0.22  loss_cls: 0.1123  loss_box_reg: 0.07846  loss_rpn_cls: 0.009919  loss_rpn_loc: 0.01642  time: 0.6806  data_time: 0.0729  lr: 0.01  max_mem: 11811M
[11/18 03:10:25] d2.utils.events INFO:  eta: 18:36:11  iter: 12499  total_loss: 0.2205  loss_cls: 0.1141  loss_box_reg: 0.0806  loss_rpn_cls: 0.008971  loss_rpn_loc: 0.01671  time: 0.6807  data_time: 0.0630  lr: 0.01  max_mem: 11811M
[11/18 03:10:38] d2.utils.events INFO:  eta: 18:35:57  iter: 12519  total_loss: 0.2134  loss_cls: 0.1053  loss_box_reg: 0.08577  loss_rpn_cls: 0.009067  loss_rpn_loc: 0.01533  time: 0.6806  data_time: 0.0666  lr: 0.01  max_mem: 11811M
[11/18 03:10:52] d2.utils.events INFO:  eta: 18:35:44  iter: 12539  total_loss: 0.2224  loss_cls: 0.1124  loss_box_reg: 0.08209  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.01529  time: 0.6806  data_time: 0.0596  lr: 0.01  max_mem: 11811M
[11/18 03:11:05] d2.utils.events INFO:  eta: 18:34:44  iter: 12559  total_loss: 0.2198  loss_cls: 0.1096  loss_box_reg: 0.08548  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.01623  time: 0.6806  data_time: 0.0635  lr: 0.01  max_mem: 11811M
[11/18 03:11:19] d2.utils.events INFO:  eta: 18:35:12  iter: 12579  total_loss: 0.225  loss_cls: 0.1139  loss_box_reg: 0.08057  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01651  time: 0.6805  data_time: 0.0617  lr: 0.01  max_mem: 11811M
[11/18 03:11:33] d2.utils.events INFO:  eta: 18:34:11  iter: 12599  total_loss: 0.217  loss_cls: 0.1092  loss_box_reg: 0.08018  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.01614  time: 0.6805  data_time: 0.0706  lr: 0.01  max_mem: 11811M
[11/18 03:11:46] d2.utils.events INFO:  eta: 18:33:59  iter: 12619  total_loss: 0.2119  loss_cls: 0.1075  loss_box_reg: 0.08034  loss_rpn_cls: 0.009917  loss_rpn_loc: 0.01582  time: 0.6805  data_time: 0.0707  lr: 0.01  max_mem: 11811M
[11/18 03:12:00] d2.utils.events INFO:  eta: 18:33:18  iter: 12639  total_loss: 0.2162  loss_cls: 0.11  loss_box_reg: 0.08204  loss_rpn_cls: 0.009781  loss_rpn_loc: 0.0162  time: 0.6805  data_time: 0.0617  lr: 0.01  max_mem: 11811M
[11/18 03:12:13] d2.utils.events INFO:  eta: 18:33:20  iter: 12659  total_loss: 0.2199  loss_cls: 0.1092  loss_box_reg: 0.0815  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.01879  time: 0.6805  data_time: 0.0680  lr: 0.01  max_mem: 11811M
[11/18 03:12:27] d2.utils.events INFO:  eta: 18:33:52  iter: 12679  total_loss: 0.2143  loss_cls: 0.1095  loss_box_reg: 0.08052  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.01567  time: 0.6805  data_time: 0.0669  lr: 0.01  max_mem: 11811M
[11/18 03:12:40] d2.utils.events INFO:  eta: 18:33:24  iter: 12699  total_loss: 0.2295  loss_cls: 0.1116  loss_box_reg: 0.08374  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01661  time: 0.6805  data_time: 0.0731  lr: 0.01  max_mem: 11811M
[11/18 03:12:54] d2.utils.events INFO:  eta: 18:32:39  iter: 12719  total_loss: 0.2198  loss_cls: 0.1103  loss_box_reg: 0.08029  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.01698  time: 0.6804  data_time: 0.0648  lr: 0.01  max_mem: 11811M
[11/18 03:13:07] d2.utils.events INFO:  eta: 18:31:57  iter: 12739  total_loss: 0.2219  loss_cls: 0.1119  loss_box_reg: 0.08396  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.01603  time: 0.6804  data_time: 0.0711  lr: 0.01  max_mem: 11811M
[11/18 03:13:21] d2.utils.events INFO:  eta: 18:32:12  iter: 12759  total_loss: 0.2331  loss_cls: 0.1142  loss_box_reg: 0.08943  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.01576  time: 0.6805  data_time: 0.0773  lr: 0.01  max_mem: 11811M
[11/18 03:13:35] d2.utils.events INFO:  eta: 18:32:57  iter: 12779  total_loss: 0.2276  loss_cls: 0.1155  loss_box_reg: 0.08463  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01637  time: 0.6806  data_time: 0.0745  lr: 0.01  max_mem: 11811M
[11/18 03:13:49] d2.utils.events INFO:  eta: 18:32:43  iter: 12799  total_loss: 0.2371  loss_cls: 0.1179  loss_box_reg: 0.08564  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.01731  time: 0.6807  data_time: 0.0889  lr: 0.01  max_mem: 11811M
[11/18 03:14:03] d2.utils.events INFO:  eta: 18:31:43  iter: 12819  total_loss: 0.2186  loss_cls: 0.1086  loss_box_reg: 0.08289  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.01707  time: 0.6806  data_time: 0.0695  lr: 0.01  max_mem: 11811M
[11/18 03:14:16] d2.utils.events INFO:  eta: 18:31:29  iter: 12839  total_loss: 0.2223  loss_cls: 0.1105  loss_box_reg: 0.083  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.01728  time: 0.6806  data_time: 0.0651  lr: 0.01  max_mem: 11811M
[11/18 03:14:30] d2.utils.events INFO:  eta: 18:32:02  iter: 12859  total_loss: 0.2227  loss_cls: 0.1142  loss_box_reg: 0.08341  loss_rpn_cls: 0.0108  loss_rpn_loc: 0.01604  time: 0.6806  data_time: 0.0607  lr: 0.01  max_mem: 11811M
[11/18 03:14:43] d2.utils.events INFO:  eta: 18:31:21  iter: 12879  total_loss: 0.2242  loss_cls: 0.1114  loss_box_reg: 0.08165  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01806  time: 0.6806  data_time: 0.0665  lr: 0.01  max_mem: 11811M
[11/18 03:14:57] d2.utils.events INFO:  eta: 18:31:41  iter: 12899  total_loss: 0.2203  loss_cls: 0.111  loss_box_reg: 0.08019  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.01571  time: 0.6807  data_time: 0.0686  lr: 0.01  max_mem: 11811M
[11/18 03:15:11] d2.utils.events INFO:  eta: 18:31:43  iter: 12919  total_loss: 0.218  loss_cls: 0.1119  loss_box_reg: 0.08085  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.01706  time: 0.6807  data_time: 0.0655  lr: 0.01  max_mem: 11811M
[11/18 03:15:25] d2.utils.events INFO:  eta: 18:31:29  iter: 12939  total_loss: 0.2162  loss_cls: 0.107  loss_box_reg: 0.08534  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01532  time: 0.6806  data_time: 0.0646  lr: 0.01  max_mem: 11811M
[11/18 03:15:38] d2.utils.events INFO:  eta: 18:31:06  iter: 12959  total_loss: 0.2129  loss_cls: 0.1019  loss_box_reg: 0.08009  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01713  time: 0.6806  data_time: 0.0660  lr: 0.01  max_mem: 11811M
[11/18 03:15:52] d2.utils.events INFO:  eta: 18:29:37  iter: 12979  total_loss: 0.2129  loss_cls: 0.106  loss_box_reg: 0.07822  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.01612  time: 0.6806  data_time: 0.0780  lr: 0.01  max_mem: 11811M
[11/18 03:16:05] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0012999.pth
[11/18 03:16:06] d2.data.datasets.coco WARNING:
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/18 03:16:06] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/18 03:16:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/18 03:16:06] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/18 03:16:06] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/18 03:16:06] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/18 03:16:07] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/18 03:16:13] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0427 s/iter. Eval: 0.0002 s/iter. Total: 0.0440 s/iter. ETA=0:02:26
[11/18 03:16:18] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:10
[11/18 03:16:23] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/18 03:16:28] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/18 03:16:33] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/18 03:16:39] d2.evaluation.evaluator INFO: Inference done 615/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/18 03:16:44] d2.evaluation.evaluator INFO: Inference done 737/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:47
[11/18 03:16:49] d2.evaluation.evaluator INFO: Inference done 855/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:43
[11/18 03:16:54] d2.evaluation.evaluator INFO: Inference done 972/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:38
[11/18 03:16:59] d2.evaluation.evaluator INFO: Inference done 1092/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/18 03:17:04] d2.evaluation.evaluator INFO: Inference done 1213/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/18 03:17:09] d2.evaluation.evaluator INFO: Inference done 1336/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:23
[11/18 03:17:14] d2.evaluation.evaluator INFO: Inference done 1457/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:18
[11/18 03:17:19] d2.evaluation.evaluator INFO: Inference done 1576/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/18 03:17:24] d2.evaluation.evaluator INFO: Inference done 1696/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:08
[11/18 03:17:29] d2.evaluation.evaluator INFO: Inference done 1815/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:03
[11/18 03:17:34] d2.evaluation.evaluator INFO: Inference done 1935/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:58
[11/18 03:17:39] d2.evaluation.evaluator INFO: Inference done 2059/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:53
[11/18 03:17:44] d2.evaluation.evaluator INFO: Inference done 2177/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:48
[11/18 03:17:49] d2.evaluation.evaluator INFO: Inference done 2297/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:43
[11/18 03:17:54] d2.evaluation.evaluator INFO: Inference done 2419/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:38
[11/18 03:17:59] d2.evaluation.evaluator INFO: Inference done 2537/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:33
[11/18 03:18:04] d2.evaluation.evaluator INFO: Inference done 2656/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:28
[11/18 03:18:09] d2.evaluation.evaluator INFO: Inference done 2780/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/18 03:18:14] d2.evaluation.evaluator INFO: Inference done 2901/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/18 03:18:19] d2.evaluation.evaluator INFO: Inference done 3025/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:12
[11/18 03:18:24] d2.evaluation.evaluator INFO: Inference done 3147/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/18 03:18:29] d2.evaluation.evaluator INFO: Inference done 3270/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/18 03:18:32] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.464221 (0.041593 s / iter per device, on 6 devices)
[11/18 03:18:32] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039674 s / iter per device, on 6 devices)
[11/18 03:18:34] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/18 03:18:34] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/18 03:18:36] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/18 03:18:38] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/18 03:19:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.96 seconds.
[11/18 03:19:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/18 03:19:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.97 seconds.
[11/18 03:19:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:-----:|:------:|:------:|:-----:|:-----:|:------:|
| 9.583 | 20.259 | 7.478  | 1.255 | 4.494 | 11.661 |
[11/18 03:19:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 3.645  | bird          | 30.271 | hat with a wide brim | 4.844  |
| person                | 8.045  | dog           | 44.461 | lizard               | 6.052  |
| sheep                 | 5.001  | wine bottle   | 8.233  | bowl                 | 9.918  |
| airplane              | 21.783 | domestic cat  | 9.013  | car                  | 32.381 |
| porcupine             | 13.208 | bear          | 14.703 | tape player          | 11.532 |
| ray                   | 2.706  | laptop        | 8.878  | zebra                | 21.830 |
| computer keyboard     | 5.004  | pitcher       | 6.226  | artichoke            | 17.638 |
| tv or monitor         | 10.799 | table         | 8.549  | chair                | 4.021  |
| helmet                | 12.170 | traffic light | 4.079  | red panda            | 10.103 |
| sunglasses            | 1.971  | lamp          | 2.996  | bicycle              | 9.570  |
| backpack              | 8.041  | mushroom      | 5.377  | fox                  | 8.879  |
| otter                 | 2.506  | guitar        | 8.054  | microphone           | 0.157  |
| strawberry            | 7.764  | stove         | 8.653  | violin               | 0.868  |
| bookshelf             | 12.176 | sofa          | 2.296  | bell pepper          | 4.221  |
| bagel                 | 6.555  | lemon         | 10.256 | orange               | 13.870 |
| bench                 | 1.817  | piano         | 13.213 | flower pot           | 3.044  |
| butterfly             | 30.442 | purse         | 4.104  | pomegranate          | 5.489  |
| train                 | 17.092 | drum          | 2.981  | hippopotamus         | 1.697  |
| ski                   | 0.402  | ladybug       | 28.274 | banana               | 1.051  |
| monkey                | 12.198 | bus           | 24.831 | miniskirt            | 5.773  |
| camel                 | 2.470  | cream         | 11.463 | lobster              | 8.394  |
| seal                  | 2.844  | horse         | 7.554  | cart                 | 12.358 |
| elephant              | 16.169 | snake         | 9.006  | fig                  | 1.938  |
| watercraft            | 22.412 | apple         | 13.322 | antelope             | 20.444 |
| cattle                | 2.395  | whale         | 14.026 | coffee maker         | 19.675 |
| baby bed              | 17.204 | frog          | 7.974  | bathing cap          | 7.313  |
| crutch                | 0.108  | koala bear    | 9.365  | tie                  | 2.681  |
| dumbbell              | 0.247  | tiger         | 5.624  | dragonfly            | 9.418  |
| goldfish              | 8.300  | cucumber      | 0.652  | turtle               | 11.763 |
| harp                  | 6.617  | jellyfish     | 7.717  | swine                | 9.381  |
| pretzel               | 4.618  | motorcycle    | 19.342 | beaker               | 10.057 |
| rabbit                | 20.457 | nail          | 0.397  | axe                  | 2.689  |
| salt or pepper shaker | 2.018  | croquet ball  | 12.615 | skunk                | 6.118  |
| starfish              | 9.475  |               |        |                      |        |
[11/18 03:19:05] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/18 03:19:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/18 03:19:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/18 03:19:05] d2.evaluation.testing INFO: copypaste: 9.5833,20.2586,7.4782,1.2547,4.4942,11.6614
