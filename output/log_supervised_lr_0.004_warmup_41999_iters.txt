[11/16 02:58:04] detectron2 INFO: Rank of current process: 0. World size: 6
[11/16 02:58:06] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 02:58:06] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=True, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/16 02:58:06] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: ""
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  STEPS: (14000, 17000)
  MAX_ITER: 18500
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 500
  BASE_LR: 0.004
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.00001
  WARMUP_ITERS: 3000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 500
OUTPUT_DIR: "../../output/supervised"
[11/16 02:58:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ''
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.004
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18500
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 14000
  - 17000
  WARMUP_FACTOR: 1.0e-05
  WARMUP_ITERS: 3000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 500
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 02:58:06] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/16 02:58:06] d2.utils.env INFO: Using a generated random seed 8867425
[11/16 02:58:08] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/16 02:58:08] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/16 02:58:09] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/16 02:58:09] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 281          |   person    | 4657         |     bird      | 4331         |
|   red panda   | 108          |     dog     | 8341         |     snake     | 1001         |
|      car      | 1171         |    seal     | 224          |    helmet     | 433          |
|  motorcycle   | 278          |    swine    | 259          |     stove     | 156          |
|    monkey     | 1004         | watercraft  | 1038         |     chair     | 905          |
| domestic cat  | 395          |    harp     | 152          |   antelope    | 288          |
|     camel     | 276          | koala bear  | 139          |      bus      | 322          |
| hat with a .. | 206          |     ski     | 109          |     piano     | 199          |
|     frog      | 245          |  dumbbell   | 180          |    lobster    | 253          |
|     bench     | 150          |   rabbit    | 235          |   porcupine   | 126          |
|   butterfly   | 453          |   guitar    | 295          |  microphone   | 259          |
|  tape player  | 109          |    bear     | 361          | hippopotamus  | 118          |
|     bowl      | 335          |     axe     | 127          |     skunk     | 99           |
|   airplane    | 217          |    otter    | 127          |     table     | 786          |
| coffee maker  | 143          |     tie     | 124          |    turtle     | 313          |
|     purse     | 130          |  dragonfly  | 175          |     lemon     | 170          |
|    lizard     | 640          |  backpack   | 148          | tv or monitor | 212          |
|  cup or mug   | 283          |    sheep    | 196          |      ray      | 198          |
|      fox      | 292          |    whale    | 155          | salt or pep.. | 129          |
| computer ke.. | 102          |     fig     | 133          |  bathing cap  | 163          |
|   bookshelf   | 106          |   ladybug   | 138          |    crutch     | 138          |
|    pretzel    | 124          | sunglasses  | 243          |   starfish    | 130          |
| croquet ball  | 135          |    lamp     | 319          |     apple     | 216          |
|     cream     | 194          |  artichoke  | 180          |     train     | 178          |
|   elephant    | 242          | bell pepper | 146          |   miniskirt   | 118          |
|    orange     | 207          |    tiger    | 159          |     sofa      | 160          |
|     horse     | 265          |   violin    | 118          | traffic light | 142          |
|     drum      | 251          | strawberry  | 232          |    laptop     | 172          |
|  pomegranate  | 188          |  cucumber   | 114          |    bicycle    | 187          |
|    banana     | 244          |  baby bed   | 185          |   jellyfish   | 184          |
|    pitcher    | 120          |    bagel    | 125          |    beaker     | 115          |
|   goldfish    | 228          |    nail     | 86           |   mushroom    | 124          |
|  flower pot   | 189          |   cattle    | 148          |     zebra     | 135          |
|  wine bottle  | 154          |             |              |               |              |
|     total     | 41293        |             |              |               |              |[0m
[11/16 02:58:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 02:58:09] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 02:58:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 02:58:10] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/16 02:58:10] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/16 02:58:10] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/16 02:58:10] d2.engine.train_loop INFO: Starting training from iteration 0
[11/16 02:58:32] d2.utils.events INFO:  eta: 3:30:43  iter: 19  total_loss: 156.1  loss_cls: 144.7  loss_box_reg: 1.449  loss_rpn_cls: 4.129  loss_rpn_loc: 3.169  time: 0.6774  data_time: 0.3745  lr: 2.5373e-05  max_mem: 11810M
[11/16 02:58:46] d2.utils.events INFO:  eta: 3:32:07  iter: 39  total_loss: 11.32  loss_cls: 9.551  loss_box_reg: 0.5674  loss_rpn_cls: 0.3497  loss_rpn_loc: 0.3362  time: 0.6859  data_time: 0.0725  lr: 5.2039e-05  max_mem: 11810M
[11/16 02:59:00] d2.utils.events INFO:  eta: 3:34:00  iter: 59  total_loss: 1.473  loss_cls: 1.115  loss_box_reg: 0.1275  loss_rpn_cls: 0.1956  loss_rpn_loc: 0.1091  time: 0.6921  data_time: 0.0718  lr: 7.8706e-05  max_mem: 11811M
[11/16 02:59:14] d2.utils.events INFO:  eta: 3:32:47  iter: 79  total_loss: 0.9944  loss_cls: 0.6716  loss_box_reg: 0.116  loss_rpn_cls: 0.1542  loss_rpn_loc: 0.04559  time: 0.6907  data_time: 0.0637  lr: 0.00010537  max_mem: 11811M
[11/16 02:59:28] d2.utils.events INFO:  eta: 3:32:02  iter: 99  total_loss: 0.8658  loss_cls: 0.5565  loss_box_reg: 0.116  loss_rpn_cls: 0.1576  loss_rpn_loc: 0.03313  time: 0.6916  data_time: 0.0763  lr: 0.00013204  max_mem: 11811M
[11/16 02:59:41] d2.utils.events INFO:  eta: 3:31:40  iter: 119  total_loss: 0.6622  loss_cls: 0.3476  loss_box_reg: 0.1172  loss_rpn_cls: 0.1552  loss_rpn_loc: 0.03185  time: 0.6897  data_time: 0.0711  lr: 0.00015871  max_mem: 11811M
[11/16 02:59:55] d2.utils.events INFO:  eta: 3:30:34  iter: 139  total_loss: 0.5923  loss_cls: 0.3011  loss_box_reg: 0.1096  loss_rpn_cls: 0.156  loss_rpn_loc: 0.03141  time: 0.6874  data_time: 0.0666  lr: 0.00018537  max_mem: 11811M
[11/16 03:00:08] d2.utils.events INFO:  eta: 3:29:31  iter: 159  total_loss: 0.5425  loss_cls: 0.2542  loss_box_reg: 0.1068  loss_rpn_cls: 0.1497  loss_rpn_loc: 0.02664  time: 0.6855  data_time: 0.0665  lr: 0.00021204  max_mem: 11811M
[11/16 03:00:22] d2.utils.events INFO:  eta: 3:29:11  iter: 179  total_loss: 0.5105  loss_cls: 0.2361  loss_box_reg: 0.1078  loss_rpn_cls: 0.142  loss_rpn_loc: 0.02693  time: 0.6839  data_time: 0.0653  lr: 0.0002387  max_mem: 11811M
[11/16 03:00:35] d2.utils.events INFO:  eta: 3:28:23  iter: 199  total_loss: 0.548  loss_cls: 0.2533  loss_box_reg: 0.1133  loss_rpn_cls: 0.1485  loss_rpn_loc: 0.02801  time: 0.6821  data_time: 0.0657  lr: 0.00026537  max_mem: 11811M
[11/16 03:00:48] d2.utils.events INFO:  eta: 3:28:05  iter: 219  total_loss: 0.5059  loss_cls: 0.238  loss_box_reg: 0.1069  loss_rpn_cls: 0.1405  loss_rpn_loc: 0.02684  time: 0.6815  data_time: 0.0698  lr: 0.00029204  max_mem: 11811M
[11/16 03:01:02] d2.utils.events INFO:  eta: 3:27:40  iter: 239  total_loss: 0.5037  loss_cls: 0.2448  loss_box_reg: 0.113  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.02799  time: 0.6810  data_time: 0.0704  lr: 0.0003187  max_mem: 11811M
[11/16 03:01:15] d2.utils.events INFO:  eta: 3:27:02  iter: 259  total_loss: 0.5332  loss_cls: 0.2557  loss_box_reg: 0.1159  loss_rpn_cls: 0.134  loss_rpn_loc: 0.02635  time: 0.6799  data_time: 0.0665  lr: 0.00034537  max_mem: 11811M
[11/16 03:01:29] d2.utils.events INFO:  eta: 3:26:43  iter: 279  total_loss: 0.5073  loss_cls: 0.2387  loss_box_reg: 0.1065  loss_rpn_cls: 0.1326  loss_rpn_loc: 0.02734  time: 0.6795  data_time: 0.0593  lr: 0.00037204  max_mem: 11811M
[11/16 03:01:42] d2.utils.events INFO:  eta: 3:26:08  iter: 299  total_loss: 0.5112  loss_cls: 0.2471  loss_box_reg: 0.1166  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.02809  time: 0.6789  data_time: 0.0650  lr: 0.0003987  max_mem: 11811M
[11/16 03:01:56] d2.utils.events INFO:  eta: 3:25:44  iter: 319  total_loss: 0.4991  loss_cls: 0.2431  loss_box_reg: 0.1074  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.02586  time: 0.6782  data_time: 0.0676  lr: 0.00042537  max_mem: 11811M
[11/16 03:02:09] d2.utils.events INFO:  eta: 3:25:27  iter: 339  total_loss: 0.4997  loss_cls: 0.2409  loss_box_reg: 0.1079  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.02555  time: 0.6780  data_time: 0.0627  lr: 0.00045204  max_mem: 11811M
[11/16 03:02:23] d2.utils.events INFO:  eta: 3:24:58  iter: 359  total_loss: 0.4876  loss_cls: 0.2393  loss_box_reg: 0.1088  loss_rpn_cls: 0.1165  loss_rpn_loc: 0.02448  time: 0.6779  data_time: 0.0691  lr: 0.0004787  max_mem: 11811M
[11/16 03:02:36] d2.utils.events INFO:  eta: 3:24:25  iter: 379  total_loss: 0.4856  loss_cls: 0.2338  loss_box_reg: 0.1114  loss_rpn_cls: 0.111  loss_rpn_loc: 0.02483  time: 0.6774  data_time: 0.0633  lr: 0.00050537  max_mem: 11811M
[11/16 03:02:49] d2.utils.events INFO:  eta: 3:23:58  iter: 399  total_loss: 0.4671  loss_cls: 0.2183  loss_box_reg: 0.1086  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.02746  time: 0.6771  data_time: 0.0671  lr: 0.00053203  max_mem: 11811M
[11/16 03:03:03] d2.utils.events INFO:  eta: 3:23:43  iter: 419  total_loss: 0.4751  loss_cls: 0.2286  loss_box_reg: 0.1132  loss_rpn_cls: 0.0998  loss_rpn_loc: 0.02376  time: 0.6766  data_time: 0.0669  lr: 0.0005587  max_mem: 11811M
[11/16 03:03:16] d2.utils.events INFO:  eta: 3:23:22  iter: 439  total_loss: 0.4687  loss_cls: 0.237  loss_box_reg: 0.1099  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.02528  time: 0.6764  data_time: 0.0771  lr: 0.00058537  max_mem: 11811M
[11/16 03:03:30] d2.utils.events INFO:  eta: 3:23:03  iter: 459  total_loss: 0.4731  loss_cls: 0.2286  loss_box_reg: 0.111  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.02724  time: 0.6763  data_time: 0.0696  lr: 0.00061203  max_mem: 11811M
[11/16 03:03:43] d2.utils.events INFO:  eta: 3:22:40  iter: 479  total_loss: 0.452  loss_cls: 0.2196  loss_box_reg: 0.1067  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.0263  time: 0.6759  data_time: 0.0718  lr: 0.0006387  max_mem: 11811M
[11/16 03:03:56] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0000499.pth
[11/16 03:03:57] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:03:58] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 211          |   person    | 3096         |     bird      | 2810         |
|   red panda   | 61           |     dog     | 5631         |     snake     | 664          |
|      car      | 768          |    seal     | 120          |    helmet     | 237          |
|  motorcycle   | 224          |    swine    | 159          |     stove     | 110          |
|    monkey     | 683          | watercraft  | 686          |     chair     | 578          |
| domestic cat  | 290          |    harp     | 118          |   antelope    | 173          |
|     camel     | 138          | koala bear  | 71           |      bus      | 257          |
| hat with a .. | 160          |     ski     | 104          |     piano     | 128          |
|     frog      | 164          |  dumbbell   | 104          |    lobster    | 151          |
|     bench     | 107          |   rabbit    | 159          |   porcupine   | 73           |
|   butterfly   | 302          |   guitar    | 189          |  microphone   | 174          |
|  tape player  | 81           |    bear     | 205          | hippopotamus  | 82           |
|     bowl      | 202          |     axe     | 107          |     skunk     | 88           |
|   airplane    | 128          |    otter    | 74           |     table     | 496          |
| coffee maker  | 94           |     tie     | 91           |    turtle     | 206          |
|     purse     | 124          |  dragonfly  | 119          |     lemon     | 95           |
|    lizard     | 420          |  backpack   | 110          | tv or monitor | 165          |
|  cup or mug   | 200          |    sheep    | 149          |      ray      | 192          |
|      fox      | 195          |    whale    | 113          | salt or pep.. | 68           |
| computer ke.. | 66           |     fig     | 92           |  bathing cap  | 153          |
|   bookshelf   | 68           |   ladybug   | 85           |    crutch     | 75           |
|    pretzel    | 108          | sunglasses  | 145          |   starfish    | 92           |
| croquet ball  | 85           |    lamp     | 190          |     apple     | 145          |
|     cream     | 120          |  artichoke  | 96           |     train     | 89           |
|   elephant    | 159          | bell pepper | 98           |   miniskirt   | 73           |
|    orange     | 151          |    tiger    | 76           |     sofa      | 127          |
|     horse     | 171          |   violin    | 84           | traffic light | 109          |
|     drum      | 175          | strawberry  | 162          |    laptop     | 84           |
|  pomegranate  | 114          |  cucumber   | 67           |    bicycle    | 132          |
|    banana     | 169          |  baby bed   | 134          |   jellyfish   | 103          |
|    pitcher    | 95           |    bagel    | 76           |    beaker     | 85           |
|   goldfish    | 159          |    nail     | 91           |   mushroom    | 146          |
|  flower pot   | 113          |   cattle    | 92           |     zebra     | 97           |
|  wine bottle  | 129          |             |              |               |              |
|     total     | 27584        |             |              |               |              |[0m
[11/16 03:03:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:03:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:03:58] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:03:58] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:03:58] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:04:05] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0501 s/iter. Eval: 0.0002 s/iter. Total: 0.0514 s/iter. ETA=0:02:50
[11/16 03:04:10] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:14
[11/16 03:04:15] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:07
[11/16 03:04:20] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/16 03:04:25] d2.evaluation.evaluator INFO: Inference done 505/3334. Dataloading: 0.0014 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:55
[11/16 03:04:30] d2.evaluation.evaluator INFO: Inference done 630/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:49
[11/16 03:04:35] d2.evaluation.evaluator INFO: Inference done 754/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:44
[11/16 03:04:40] d2.evaluation.evaluator INFO: Inference done 879/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:39
[11/16 03:04:45] d2.evaluation.evaluator INFO: Inference done 1002/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:34
[11/16 03:04:50] d2.evaluation.evaluator INFO: Inference done 1128/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:29
[11/16 03:04:55] d2.evaluation.evaluator INFO: Inference done 1249/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:24
[11/16 03:05:00] d2.evaluation.evaluator INFO: Inference done 1374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:19
[11/16 03:05:05] d2.evaluation.evaluator INFO: Inference done 1497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:14
[11/16 03:05:10] d2.evaluation.evaluator INFO: Inference done 1621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:09
[11/16 03:05:15] d2.evaluation.evaluator INFO: Inference done 1744/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:04
[11/16 03:05:20] d2.evaluation.evaluator INFO: Inference done 1868/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:59
[11/16 03:05:25] d2.evaluation.evaluator INFO: Inference done 1990/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:54
[11/16 03:05:30] d2.evaluation.evaluator INFO: Inference done 2114/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:49
[11/16 03:05:35] d2.evaluation.evaluator INFO: Inference done 2235/3334. Dataloading: 0.0014 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:44
[11/16 03:05:40] d2.evaluation.evaluator INFO: Inference done 2357/3334. Dataloading: 0.0014 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:39
[11/16 03:05:45] d2.evaluation.evaluator INFO: Inference done 2479/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:34
[11/16 03:05:50] d2.evaluation.evaluator INFO: Inference done 2604/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:29
[11/16 03:05:55] d2.evaluation.evaluator INFO: Inference done 2732/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:24
[11/16 03:06:00] d2.evaluation.evaluator INFO: Inference done 2856/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:19
[11/16 03:06:05] d2.evaluation.evaluator INFO: Inference done 2977/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:14
[11/16 03:06:10] d2.evaluation.evaluator INFO: Inference done 3100/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:09
[11/16 03:06:16] d2.evaluation.evaluator INFO: Inference done 3223/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:04
[11/16 03:06:21] d2.evaluation.evaluator INFO: Total inference time: 0:02:15.934732 (0.040834 s / iter per device, on 6 devices)
[11/16 03:06:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038929 s / iter per device, on 6 devices)
[11/16 03:06:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:06:24] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:06:25] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:06:27] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:06:50] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.67 seconds.
[11/16 03:06:51] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:06:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.08 seconds.
[11/16 03:06:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.010 | 0.046  | 0.001  | 0.000 | 0.006 | 0.011 |
[11/16 03:06:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.000 | bird                  | 0.006 |
| red panda            | 0.000 | dog         | 1.022 | snake                 | 0.000 |
| car                  | 0.000 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.000 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:06:55] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:06:55] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:06:55] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:06:55] d2.evaluation.testing INFO: copypaste: 0.0103,0.0457,0.0010,0.0000,0.0062,0.0106
[11/16 03:06:55] d2.utils.events INFO:  eta: 3:22:21  iter: 499  total_loss: 0.4557  loss_cls: 0.2251  loss_box_reg: 0.1115  loss_rpn_cls: 0.09212  loss_rpn_loc: 0.02415  time: 0.6758  data_time: 0.0694  lr: 0.00066537  max_mem: 11811M
[11/16 03:07:09] d2.utils.events INFO:  eta: 3:22:02  iter: 519  total_loss: 0.4481  loss_cls: 0.2193  loss_box_reg: 0.1047  loss_rpn_cls: 0.09182  loss_rpn_loc: 0.02389  time: 0.6759  data_time: 0.0795  lr: 0.00069203  max_mem: 11811M
[11/16 03:07:22] d2.utils.events INFO:  eta: 3:21:47  iter: 539  total_loss: 0.4523  loss_cls: 0.2296  loss_box_reg: 0.1091  loss_rpn_cls: 0.08782  loss_rpn_loc: 0.02497  time: 0.6757  data_time: 0.0707  lr: 0.0007187  max_mem: 11811M
[11/16 03:07:35] d2.utils.events INFO:  eta: 3:21:26  iter: 559  total_loss: 0.455  loss_cls: 0.2268  loss_box_reg: 0.1126  loss_rpn_cls: 0.08018  loss_rpn_loc: 0.02396  time: 0.6752  data_time: 0.0652  lr: 0.00074537  max_mem: 11811M
[11/16 03:07:49] d2.utils.events INFO:  eta: 3:21:11  iter: 579  total_loss: 0.4516  loss_cls: 0.2311  loss_box_reg: 0.1132  loss_rpn_cls: 0.08563  loss_rpn_loc: 0.0242  time: 0.6750  data_time: 0.0690  lr: 0.00077203  max_mem: 11811M
[11/16 03:08:02] d2.utils.events INFO:  eta: 3:20:36  iter: 599  total_loss: 0.4467  loss_cls: 0.2224  loss_box_reg: 0.1098  loss_rpn_cls: 0.08365  loss_rpn_loc: 0.02341  time: 0.6747  data_time: 0.0638  lr: 0.0007987  max_mem: 11811M
[11/16 03:08:16] d2.utils.events INFO:  eta: 3:20:21  iter: 619  total_loss: 0.4298  loss_cls: 0.2105  loss_box_reg: 0.1113  loss_rpn_cls: 0.08008  loss_rpn_loc: 0.02331  time: 0.6748  data_time: 0.0794  lr: 0.00082537  max_mem: 11811M
[11/16 03:08:29] d2.utils.events INFO:  eta: 3:20:03  iter: 639  total_loss: 0.4074  loss_cls: 0.2063  loss_box_reg: 0.1033  loss_rpn_cls: 0.07227  loss_rpn_loc: 0.02476  time: 0.6749  data_time: 0.0741  lr: 0.00085203  max_mem: 11811M
[11/16 03:08:42] d2.utils.events INFO:  eta: 3:19:43  iter: 659  total_loss: 0.4557  loss_cls: 0.234  loss_box_reg: 0.1104  loss_rpn_cls: 0.08274  loss_rpn_loc: 0.02729  time: 0.6745  data_time: 0.0655  lr: 0.0008787  max_mem: 11811M
[11/16 03:08:56] d2.utils.events INFO:  eta: 3:19:26  iter: 679  total_loss: 0.4362  loss_cls: 0.2229  loss_box_reg: 0.1136  loss_rpn_cls: 0.07715  loss_rpn_loc: 0.02561  time: 0.6743  data_time: 0.0770  lr: 0.00090536  max_mem: 11811M
[11/16 03:09:09] d2.utils.events INFO:  eta: 3:19:12  iter: 699  total_loss: 0.423  loss_cls: 0.2192  loss_box_reg: 0.1116  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.02421  time: 0.6745  data_time: 0.0713  lr: 0.00093203  max_mem: 11811M
[11/16 03:09:23] d2.utils.events INFO:  eta: 3:18:47  iter: 719  total_loss: 0.4245  loss_cls: 0.2264  loss_box_reg: 0.1107  loss_rpn_cls: 0.06983  loss_rpn_loc: 0.02382  time: 0.6743  data_time: 0.0655  lr: 0.0009587  max_mem: 11811M
[11/16 03:09:36] d2.utils.events INFO:  eta: 3:18:31  iter: 739  total_loss: 0.4406  loss_cls: 0.2352  loss_box_reg: 0.1092  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.02391  time: 0.6740  data_time: 0.0685  lr: 0.00098536  max_mem: 11811M
[11/16 03:09:50] d2.utils.events INFO:  eta: 3:18:16  iter: 759  total_loss: 0.4485  loss_cls: 0.2348  loss_box_reg: 0.1181  loss_rpn_cls: 0.0631  loss_rpn_loc: 0.02571  time: 0.6742  data_time: 0.0702  lr: 0.001012  max_mem: 11811M
[11/16 03:10:03] d2.utils.events INFO:  eta: 3:17:58  iter: 779  total_loss: 0.4274  loss_cls: 0.2223  loss_box_reg: 0.1126  loss_rpn_cls: 0.05917  loss_rpn_loc: 0.0247  time: 0.6739  data_time: 0.0653  lr: 0.0010387  max_mem: 11811M
[11/16 03:10:16] d2.utils.events INFO:  eta: 3:17:41  iter: 799  total_loss: 0.4439  loss_cls: 0.2385  loss_box_reg: 0.1166  loss_rpn_cls: 0.0574  loss_rpn_loc: 0.02556  time: 0.6736  data_time: 0.0647  lr: 0.0010654  max_mem: 11811M
[11/16 03:10:29] d2.utils.events INFO:  eta: 3:17:24  iter: 819  total_loss: 0.4176  loss_cls: 0.2203  loss_box_reg: 0.1126  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.02162  time: 0.6734  data_time: 0.0684  lr: 0.001092  max_mem: 11811M
[11/16 03:10:43] d2.utils.events INFO:  eta: 3:17:16  iter: 839  total_loss: 0.4198  loss_cls: 0.2309  loss_box_reg: 0.1162  loss_rpn_cls: 0.05054  loss_rpn_loc: 0.02464  time: 0.6735  data_time: 0.0657  lr: 0.0011187  max_mem: 11811M
[11/16 03:10:56] d2.utils.events INFO:  eta: 3:17:01  iter: 859  total_loss: 0.427  loss_cls: 0.2275  loss_box_reg: 0.1125  loss_rpn_cls: 0.05396  loss_rpn_loc: 0.02469  time: 0.6733  data_time: 0.0686  lr: 0.0011454  max_mem: 11811M
[11/16 03:11:10] d2.utils.events INFO:  eta: 3:16:48  iter: 879  total_loss: 0.421  loss_cls: 0.2337  loss_box_reg: 0.1141  loss_rpn_cls: 0.05336  loss_rpn_loc: 0.02609  time: 0.6733  data_time: 0.0679  lr: 0.001172  max_mem: 11811M
[11/16 03:11:23] d2.utils.events INFO:  eta: 3:16:31  iter: 899  total_loss: 0.4259  loss_cls: 0.2276  loss_box_reg: 0.1115  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.02248  time: 0.6731  data_time: 0.0608  lr: 0.0011987  max_mem: 11811M
[11/16 03:11:36] d2.utils.events INFO:  eta: 3:16:16  iter: 919  total_loss: 0.4118  loss_cls: 0.2165  loss_box_reg: 0.1169  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.0263  time: 0.6730  data_time: 0.0658  lr: 0.0012254  max_mem: 11811M
[11/16 03:11:50] d2.utils.events INFO:  eta: 3:16:01  iter: 939  total_loss: 0.4219  loss_cls: 0.2327  loss_box_reg: 0.1159  loss_rpn_cls: 0.05038  loss_rpn_loc: 0.02523  time: 0.6728  data_time: 0.0643  lr: 0.001252  max_mem: 11811M
[11/16 03:12:03] d2.utils.events INFO:  eta: 3:15:47  iter: 959  total_loss: 0.4364  loss_cls: 0.2425  loss_box_reg: 0.1187  loss_rpn_cls: 0.0479  loss_rpn_loc: 0.02388  time: 0.6728  data_time: 0.0665  lr: 0.0012787  max_mem: 11811M
[11/16 03:12:16] d2.utils.events INFO:  eta: 3:15:23  iter: 979  total_loss: 0.3926  loss_cls: 0.2132  loss_box_reg: 0.108  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.02247  time: 0.6724  data_time: 0.0622  lr: 0.0013054  max_mem: 11811M
[11/16 03:12:29] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0000999.pth
[11/16 03:12:30] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:12:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:12:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:12:30] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:12:30] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:12:31] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:12:38] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0443 s/iter. ETA=0:02:27
[11/16 03:12:43] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:11
[11/16 03:12:48] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:08
[11/16 03:12:53] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/16 03:12:58] d2.evaluation.evaluator INFO: Inference done 493/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:58
[11/16 03:13:03] d2.evaluation.evaluator INFO: Inference done 613/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/16 03:13:08] d2.evaluation.evaluator INFO: Inference done 734/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:48
[11/16 03:13:13] d2.evaluation.evaluator INFO: Inference done 856/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:43
[11/16 03:13:18] d2.evaluation.evaluator INFO: Inference done 979/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/16 03:13:23] d2.evaluation.evaluator INFO: Inference done 1101/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/16 03:13:28] d2.evaluation.evaluator INFO: Inference done 1223/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/16 03:13:33] d2.evaluation.evaluator INFO: Inference done 1347/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/16 03:13:38] d2.evaluation.evaluator INFO: Inference done 1470/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:17
[11/16 03:13:43] d2.evaluation.evaluator INFO: Inference done 1592/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:11
[11/16 03:13:48] d2.evaluation.evaluator INFO: Inference done 1712/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/16 03:13:53] d2.evaluation.evaluator INFO: Inference done 1835/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:01
[11/16 03:13:58] d2.evaluation.evaluator INFO: Inference done 1959/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/16 03:14:03] d2.evaluation.evaluator INFO: Inference done 2082/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:51
[11/16 03:14:08] d2.evaluation.evaluator INFO: Inference done 2202/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/16 03:14:13] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 03:14:18] d2.evaluation.evaluator INFO: Inference done 2440/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:36
[11/16 03:14:23] d2.evaluation.evaluator INFO: Inference done 2562/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:31
[11/16 03:14:28] d2.evaluation.evaluator INFO: Inference done 2685/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 03:14:33] d2.evaluation.evaluator INFO: Inference done 2811/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 03:14:38] d2.evaluation.evaluator INFO: Inference done 2932/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/16 03:14:43] d2.evaluation.evaluator INFO: Inference done 3055/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/16 03:14:48] d2.evaluation.evaluator INFO: Inference done 3179/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:06
[11/16 03:14:53] d2.evaluation.evaluator INFO: Inference done 3300/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:01
[11/16 03:14:55] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.614344 (0.041338 s / iter per device, on 6 devices)
[11/16 03:14:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039380 s / iter per device, on 6 devices)
[11/16 03:14:56] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:14:56] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:14:57] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:14:57] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:15:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.29 seconds.
[11/16 03:15:17] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:15:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.59 seconds.
[11/16 03:15:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.016 | 0.071  | 0.001  | 0.000 | 0.010 | 0.016 |
[11/16 03:15:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.000 | bird                  | 0.126 |
| red panda            | 0.000 | dog         | 1.459 | snake                 | 0.000 |
| car                  | 0.000 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.000 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:15:21] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:15:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:15:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:15:21] d2.evaluation.testing INFO: copypaste: 0.0159,0.0712,0.0012,0.0000,0.0096,0.0164
[11/16 03:15:21] d2.utils.events INFO:  eta: 3:15:04  iter: 999  total_loss: 0.4067  loss_cls: 0.2229  loss_box_reg: 0.1162  loss_rpn_cls: 0.04645  loss_rpn_loc: 0.02394  time: 0.6721  data_time: 0.0641  lr: 0.001332  max_mem: 11811M
[11/16 03:15:34] d2.utils.events INFO:  eta: 3:14:50  iter: 1019  total_loss: 0.4125  loss_cls: 0.2199  loss_box_reg: 0.1111  loss_rpn_cls: 0.05106  loss_rpn_loc: 0.02497  time: 0.6720  data_time: 0.0675  lr: 0.0013587  max_mem: 11811M
[11/16 03:15:47] d2.utils.events INFO:  eta: 3:14:25  iter: 1039  total_loss: 0.4068  loss_cls: 0.222  loss_box_reg: 0.1084  loss_rpn_cls: 0.05128  loss_rpn_loc: 0.02392  time: 0.6719  data_time: 0.0629  lr: 0.0013854  max_mem: 11811M
[11/16 03:16:01] d2.utils.events INFO:  eta: 3:14:03  iter: 1059  total_loss: 0.4167  loss_cls: 0.2165  loss_box_reg: 0.1161  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.02478  time: 0.6718  data_time: 0.0626  lr: 0.001412  max_mem: 11811M
[11/16 03:16:14] d2.utils.events INFO:  eta: 3:13:42  iter: 1079  total_loss: 0.4127  loss_cls: 0.2248  loss_box_reg: 0.1163  loss_rpn_cls: 0.0455  loss_rpn_loc: 0.0243  time: 0.6719  data_time: 0.0754  lr: 0.0014387  max_mem: 11811M
[11/16 03:16:27] d2.utils.events INFO:  eta: 3:13:19  iter: 1099  total_loss: 0.4006  loss_cls: 0.2161  loss_box_reg: 0.112  loss_rpn_cls: 0.04651  loss_rpn_loc: 0.02439  time: 0.6717  data_time: 0.0684  lr: 0.0014654  max_mem: 11811M
[11/16 03:16:41] d2.utils.events INFO:  eta: 3:13:01  iter: 1119  total_loss: 0.4178  loss_cls: 0.2269  loss_box_reg: 0.1133  loss_rpn_cls: 0.04412  loss_rpn_loc: 0.02352  time: 0.6717  data_time: 0.0791  lr: 0.001492  max_mem: 11811M
[11/16 03:16:54] d2.utils.events INFO:  eta: 3:12:46  iter: 1139  total_loss: 0.4116  loss_cls: 0.214  loss_box_reg: 0.1096  loss_rpn_cls: 0.04857  loss_rpn_loc: 0.02683  time: 0.6715  data_time: 0.0661  lr: 0.0015187  max_mem: 11811M
[11/16 03:17:07] d2.utils.events INFO:  eta: 3:12:30  iter: 1159  total_loss: 0.4082  loss_cls: 0.2247  loss_box_reg: 0.1135  loss_rpn_cls: 0.04748  loss_rpn_loc: 0.02596  time: 0.6715  data_time: 0.0678  lr: 0.0015454  max_mem: 11811M
[11/16 03:17:21] d2.utils.events INFO:  eta: 3:12:16  iter: 1179  total_loss: 0.3841  loss_cls: 0.2067  loss_box_reg: 0.1111  loss_rpn_cls: 0.0423  loss_rpn_loc: 0.02201  time: 0.6713  data_time: 0.0639  lr: 0.001572  max_mem: 11811M
[11/16 03:17:34] d2.utils.events INFO:  eta: 3:12:03  iter: 1199  total_loss: 0.3985  loss_cls: 0.2193  loss_box_reg: 0.1115  loss_rpn_cls: 0.0431  loss_rpn_loc: 0.02274  time: 0.6712  data_time: 0.0605  lr: 0.0015987  max_mem: 11811M
[11/16 03:17:47] d2.utils.events INFO:  eta: 3:11:49  iter: 1219  total_loss: 0.3795  loss_cls: 0.2044  loss_box_reg: 0.1067  loss_rpn_cls: 0.04705  loss_rpn_loc: 0.02417  time: 0.6711  data_time: 0.0613  lr: 0.0016254  max_mem: 11811M
[11/16 03:18:01] d2.utils.events INFO:  eta: 3:11:25  iter: 1239  total_loss: 0.3991  loss_cls: 0.2144  loss_box_reg: 0.1083  loss_rpn_cls: 0.04191  loss_rpn_loc: 0.02421  time: 0.6710  data_time: 0.0647  lr: 0.001652  max_mem: 11811M
[11/16 03:18:14] d2.utils.events INFO:  eta: 3:11:22  iter: 1259  total_loss: 0.3797  loss_cls: 0.2147  loss_box_reg: 0.1134  loss_rpn_cls: 0.04072  loss_rpn_loc: 0.0224  time: 0.6710  data_time: 0.0679  lr: 0.0016787  max_mem: 11811M
[11/16 03:18:27] d2.utils.events INFO:  eta: 3:11:09  iter: 1279  total_loss: 0.3951  loss_cls: 0.2152  loss_box_reg: 0.1098  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.02404  time: 0.6710  data_time: 0.0683  lr: 0.0017054  max_mem: 11811M
[11/16 03:18:41] d2.utils.events INFO:  eta: 3:10:55  iter: 1299  total_loss: 0.3986  loss_cls: 0.2136  loss_box_reg: 0.1116  loss_rpn_cls: 0.04234  loss_rpn_loc: 0.02473  time: 0.6711  data_time: 0.0644  lr: 0.001732  max_mem: 11811M
[11/16 03:18:55] d2.utils.events INFO:  eta: 3:10:44  iter: 1319  total_loss: 0.4121  loss_cls: 0.2291  loss_box_reg: 0.1123  loss_rpn_cls: 0.04327  loss_rpn_loc: 0.02618  time: 0.6712  data_time: 0.0739  lr: 0.0017587  max_mem: 11811M
[11/16 03:19:08] d2.utils.events INFO:  eta: 3:10:29  iter: 1339  total_loss: 0.407  loss_cls: 0.2259  loss_box_reg: 0.1123  loss_rpn_cls: 0.0464  loss_rpn_loc: 0.0241  time: 0.6711  data_time: 0.0569  lr: 0.0017854  max_mem: 11811M
[11/16 03:19:21] d2.utils.events INFO:  eta: 3:10:05  iter: 1359  total_loss: 0.4201  loss_cls: 0.2275  loss_box_reg: 0.1175  loss_rpn_cls: 0.04391  loss_rpn_loc: 0.02603  time: 0.6710  data_time: 0.0640  lr: 0.001812  max_mem: 11811M
[11/16 03:19:34] d2.utils.events INFO:  eta: 3:09:50  iter: 1379  total_loss: 0.4135  loss_cls: 0.2256  loss_box_reg: 0.1094  loss_rpn_cls: 0.04366  loss_rpn_loc: 0.02316  time: 0.6710  data_time: 0.0633  lr: 0.0018387  max_mem: 11811M
[11/16 03:19:48] d2.utils.events INFO:  eta: 3:09:33  iter: 1399  total_loss: 0.4127  loss_cls: 0.2299  loss_box_reg: 0.1128  loss_rpn_cls: 0.04651  loss_rpn_loc: 0.02426  time: 0.6709  data_time: 0.0652  lr: 0.0018654  max_mem: 11811M
[11/16 03:20:01] d2.utils.events INFO:  eta: 3:09:15  iter: 1419  total_loss: 0.4024  loss_cls: 0.214  loss_box_reg: 0.1107  loss_rpn_cls: 0.04211  loss_rpn_loc: 0.02332  time: 0.6708  data_time: 0.0695  lr: 0.001892  max_mem: 11811M
[11/16 03:20:15] d2.utils.events INFO:  eta: 3:09:02  iter: 1439  total_loss: 0.4085  loss_cls: 0.2264  loss_box_reg: 0.1176  loss_rpn_cls: 0.03965  loss_rpn_loc: 0.02464  time: 0.6708  data_time: 0.0688  lr: 0.0019187  max_mem: 11811M
[11/16 03:20:28] d2.utils.events INFO:  eta: 3:08:49  iter: 1459  total_loss: 0.4144  loss_cls: 0.2247  loss_box_reg: 0.1198  loss_rpn_cls: 0.03952  loss_rpn_loc: 0.023  time: 0.6709  data_time: 0.0739  lr: 0.0019454  max_mem: 11811M
[11/16 03:20:41] d2.utils.events INFO:  eta: 3:08:36  iter: 1479  total_loss: 0.3958  loss_cls: 0.2143  loss_box_reg: 0.1099  loss_rpn_cls: 0.04084  loss_rpn_loc: 0.02117  time: 0.6709  data_time: 0.0675  lr: 0.001972  max_mem: 11811M
[11/16 03:20:55] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0001499.pth
[11/16 03:20:55] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:20:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:20:56] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:20:56] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:20:56] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:20:56] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:21:03] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:19
[11/16 03:21:08] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/16 03:21:13] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/16 03:21:18] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/16 03:21:23] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/16 03:21:28] d2.evaluation.evaluator INFO: Inference done 617/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:52
[11/16 03:21:33] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 03:21:38] d2.evaluation.evaluator INFO: Inference done 863/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/16 03:21:43] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:36
[11/16 03:21:48] d2.evaluation.evaluator INFO: Inference done 1106/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/16 03:21:53] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/16 03:21:58] d2.evaluation.evaluator INFO: Inference done 1352/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/16 03:22:03] d2.evaluation.evaluator INFO: Inference done 1475/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/16 03:22:08] d2.evaluation.evaluator INFO: Inference done 1597/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/16 03:22:13] d2.evaluation.evaluator INFO: Inference done 1718/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/16 03:22:18] d2.evaluation.evaluator INFO: Inference done 1838/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/16 03:22:23] d2.evaluation.evaluator INFO: Inference done 1960/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/16 03:22:28] d2.evaluation.evaluator INFO: Inference done 2079/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/16 03:22:33] d2.evaluation.evaluator INFO: Inference done 2202/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:46
[11/16 03:22:38] d2.evaluation.evaluator INFO: Inference done 2324/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:41
[11/16 03:22:43] d2.evaluation.evaluator INFO: Inference done 2445/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/16 03:22:48] d2.evaluation.evaluator INFO: Inference done 2566/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/16 03:22:53] d2.evaluation.evaluator INFO: Inference done 2687/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 03:22:58] d2.evaluation.evaluator INFO: Inference done 2807/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 03:23:03] d2.evaluation.evaluator INFO: Inference done 2930/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:16
[11/16 03:23:08] d2.evaluation.evaluator INFO: Inference done 3050/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/16 03:23:13] d2.evaluation.evaluator INFO: Inference done 3171/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/16 03:23:18] d2.evaluation.evaluator INFO: Inference done 3292/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/16 03:23:20] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.873773 (0.041416 s / iter per device, on 6 devices)
[11/16 03:23:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039460 s / iter per device, on 6 devices)
[11/16 03:23:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:23:22] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:23:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:23:24] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:23:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.03 seconds.
[11/16 03:23:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:23:46] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.76 seconds.
[11/16 03:23:46] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.026 | 0.101  | 0.004  | 0.000 | 0.016 | 0.027 |
[11/16 03:23:46] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.003 | bird                  | 0.290 |
| red panda            | 0.000 | dog         | 2.283 | snake                 | 0.000 |
| car                  | 0.000 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.000 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:23:48] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:23:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:23:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:23:48] d2.evaluation.testing INFO: copypaste: 0.0258,0.1006,0.0042,0.0000,0.0157,0.0267
[11/16 03:23:48] d2.utils.events INFO:  eta: 3:08:22  iter: 1499  total_loss: 0.4174  loss_cls: 0.2281  loss_box_reg: 0.1222  loss_rpn_cls: 0.04111  loss_rpn_loc: 0.02442  time: 0.6708  data_time: 0.0643  lr: 0.0019987  max_mem: 11811M
[11/16 03:24:01] d2.utils.events INFO:  eta: 3:08:08  iter: 1519  total_loss: 0.3921  loss_cls: 0.2201  loss_box_reg: 0.1132  loss_rpn_cls: 0.03527  loss_rpn_loc: 0.02079  time: 0.6706  data_time: 0.0657  lr: 0.0020254  max_mem: 11811M
[11/16 03:24:14] d2.utils.events INFO:  eta: 3:07:54  iter: 1539  total_loss: 0.3962  loss_cls: 0.2111  loss_box_reg: 0.1143  loss_rpn_cls: 0.04221  loss_rpn_loc: 0.02317  time: 0.6705  data_time: 0.0691  lr: 0.002052  max_mem: 11811M
[11/16 03:24:27] d2.utils.events INFO:  eta: 3:07:40  iter: 1559  total_loss: 0.3682  loss_cls: 0.2017  loss_box_reg: 0.1055  loss_rpn_cls: 0.04128  loss_rpn_loc: 0.0224  time: 0.6704  data_time: 0.0650  lr: 0.0020787  max_mem: 11811M
[11/16 03:24:41] d2.utils.events INFO:  eta: 3:07:26  iter: 1579  total_loss: 0.3822  loss_cls: 0.213  loss_box_reg: 0.1122  loss_rpn_cls: 0.03899  loss_rpn_loc: 0.02146  time: 0.6703  data_time: 0.0687  lr: 0.0021054  max_mem: 11811M
[11/16 03:24:54] d2.utils.events INFO:  eta: 3:07:12  iter: 1599  total_loss: 0.4124  loss_cls: 0.2223  loss_box_reg: 0.1176  loss_rpn_cls: 0.04813  loss_rpn_loc: 0.0261  time: 0.6702  data_time: 0.0630  lr: 0.002132  max_mem: 11811M
[11/16 03:25:07] d2.utils.events INFO:  eta: 3:07:01  iter: 1619  total_loss: 0.4005  loss_cls: 0.2178  loss_box_reg: 0.1135  loss_rpn_cls: 0.03896  loss_rpn_loc: 0.02252  time: 0.6703  data_time: 0.0651  lr: 0.0021587  max_mem: 11811M
[11/16 03:25:21] d2.utils.events INFO:  eta: 3:06:48  iter: 1639  total_loss: 0.3967  loss_cls: 0.2172  loss_box_reg: 0.1149  loss_rpn_cls: 0.04078  loss_rpn_loc: 0.024  time: 0.6702  data_time: 0.0688  lr: 0.0021854  max_mem: 11811M
[11/16 03:25:34] d2.utils.events INFO:  eta: 3:06:34  iter: 1659  total_loss: 0.3866  loss_cls: 0.2111  loss_box_reg: 0.1092  loss_rpn_cls: 0.04153  loss_rpn_loc: 0.02372  time: 0.6701  data_time: 0.0642  lr: 0.002212  max_mem: 11811M
[11/16 03:25:47] d2.utils.events INFO:  eta: 3:06:21  iter: 1679  total_loss: 0.3789  loss_cls: 0.2066  loss_box_reg: 0.1096  loss_rpn_cls: 0.04196  loss_rpn_loc: 0.02424  time: 0.6701  data_time: 0.0628  lr: 0.0022387  max_mem: 11811M
[11/16 03:26:01] d2.utils.events INFO:  eta: 3:06:03  iter: 1699  total_loss: 0.3825  loss_cls: 0.213  loss_box_reg: 0.1137  loss_rpn_cls: 0.0371  loss_rpn_loc: 0.02251  time: 0.6701  data_time: 0.0707  lr: 0.0022654  max_mem: 11811M
[11/16 03:26:14] d2.utils.events INFO:  eta: 3:05:55  iter: 1719  total_loss: 0.402  loss_cls: 0.2197  loss_box_reg: 0.1139  loss_rpn_cls: 0.04149  loss_rpn_loc: 0.02319  time: 0.6701  data_time: 0.0656  lr: 0.002292  max_mem: 11811M
[11/16 03:26:28] d2.utils.events INFO:  eta: 3:05:41  iter: 1739  total_loss: 0.3929  loss_cls: 0.2222  loss_box_reg: 0.1166  loss_rpn_cls: 0.03688  loss_rpn_loc: 0.02402  time: 0.6701  data_time: 0.0718  lr: 0.0023187  max_mem: 11811M
[11/16 03:26:41] d2.utils.events INFO:  eta: 3:05:21  iter: 1759  total_loss: 0.417  loss_cls: 0.2297  loss_box_reg: 0.1157  loss_rpn_cls: 0.04098  loss_rpn_loc: 0.02122  time: 0.6700  data_time: 0.0659  lr: 0.0023453  max_mem: 11811M
[11/16 03:26:54] d2.utils.events INFO:  eta: 3:05:08  iter: 1779  total_loss: 0.3919  loss_cls: 0.2188  loss_box_reg: 0.1126  loss_rpn_cls: 0.03747  loss_rpn_loc: 0.02248  time: 0.6700  data_time: 0.0684  lr: 0.002372  max_mem: 11811M
[11/16 03:27:07] d2.utils.events INFO:  eta: 3:04:54  iter: 1799  total_loss: 0.3816  loss_cls: 0.2032  loss_box_reg: 0.1103  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.02271  time: 0.6699  data_time: 0.0617  lr: 0.0023987  max_mem: 11811M
[11/16 03:27:21] d2.utils.events INFO:  eta: 3:04:41  iter: 1819  total_loss: 0.3975  loss_cls: 0.2262  loss_box_reg: 0.1131  loss_rpn_cls: 0.04328  loss_rpn_loc: 0.02288  time: 0.6698  data_time: 0.0623  lr: 0.0024253  max_mem: 11811M
[11/16 03:27:34] d2.utils.events INFO:  eta: 3:04:23  iter: 1839  total_loss: 0.3832  loss_cls: 0.207  loss_box_reg: 0.1123  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.02296  time: 0.6698  data_time: 0.0641  lr: 0.002452  max_mem: 11811M
[11/16 03:27:47] d2.utils.events INFO:  eta: 3:04:14  iter: 1859  total_loss: 0.394  loss_cls: 0.2116  loss_box_reg: 0.1094  loss_rpn_cls: 0.04065  loss_rpn_loc: 0.02191  time: 0.6698  data_time: 0.0668  lr: 0.0024787  max_mem: 11811M
[11/16 03:28:01] d2.utils.events INFO:  eta: 3:04:01  iter: 1879  total_loss: 0.3792  loss_cls: 0.2049  loss_box_reg: 0.1099  loss_rpn_cls: 0.0355  loss_rpn_loc: 0.02116  time: 0.6697  data_time: 0.0675  lr: 0.0025053  max_mem: 11811M
[11/16 03:28:14] d2.utils.events INFO:  eta: 3:03:47  iter: 1899  total_loss: 0.3605  loss_cls: 0.1908  loss_box_reg: 0.1045  loss_rpn_cls: 0.0338  loss_rpn_loc: 0.02306  time: 0.6698  data_time: 0.0757  lr: 0.002532  max_mem: 11811M
[11/16 03:28:27] d2.utils.events INFO:  eta: 3:03:30  iter: 1919  total_loss: 0.3705  loss_cls: 0.2043  loss_box_reg: 0.1061  loss_rpn_cls: 0.03528  loss_rpn_loc: 0.02364  time: 0.6697  data_time: 0.0672  lr: 0.0025587  max_mem: 11811M
[11/16 03:28:41] d2.utils.events INFO:  eta: 3:03:16  iter: 1939  total_loss: 0.3923  loss_cls: 0.2086  loss_box_reg: 0.1154  loss_rpn_cls: 0.03911  loss_rpn_loc: 0.02228  time: 0.6697  data_time: 0.0669  lr: 0.0025853  max_mem: 11811M
[11/16 03:28:54] d2.utils.events INFO:  eta: 3:03:00  iter: 1959  total_loss: 0.3775  loss_cls: 0.2146  loss_box_reg: 0.1062  loss_rpn_cls: 0.03772  loss_rpn_loc: 0.02152  time: 0.6696  data_time: 0.0606  lr: 0.002612  max_mem: 11811M
[11/16 03:29:07] d2.utils.events INFO:  eta: 3:02:54  iter: 1979  total_loss: 0.3833  loss_cls: 0.2114  loss_box_reg: 0.1066  loss_rpn_cls: 0.0418  loss_rpn_loc: 0.02284  time: 0.6696  data_time: 0.0671  lr: 0.0026387  max_mem: 11811M
[11/16 03:29:21] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0001999.pth
[11/16 03:29:21] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:29:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:29:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:29:22] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:29:22] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:29:22] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:29:29] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0370 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:02:06
[11/16 03:29:34] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:09
[11/16 03:29:39] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:04
[11/16 03:29:44] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/16 03:29:49] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/16 03:29:54] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 03:29:59] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 03:30:04] d2.evaluation.evaluator INFO: Inference done 866/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/16 03:30:09] d2.evaluation.evaluator INFO: Inference done 992/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/16 03:30:14] d2.evaluation.evaluator INFO: Inference done 1118/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:30
[11/16 03:30:19] d2.evaluation.evaluator INFO: Inference done 1241/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:25
[11/16 03:30:24] d2.evaluation.evaluator INFO: Inference done 1365/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:20
[11/16 03:30:29] d2.evaluation.evaluator INFO: Inference done 1489/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:15
[11/16 03:30:34] d2.evaluation.evaluator INFO: Inference done 1614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:10
[11/16 03:30:39] d2.evaluation.evaluator INFO: Inference done 1735/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/16 03:30:44] d2.evaluation.evaluator INFO: Inference done 1855/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:00
[11/16 03:30:49] d2.evaluation.evaluator INFO: Inference done 1977/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/16 03:30:54] d2.evaluation.evaluator INFO: Inference done 2103/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/16 03:30:59] d2.evaluation.evaluator INFO: Inference done 2225/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/16 03:31:04] d2.evaluation.evaluator INFO: Inference done 2346/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/16 03:31:09] d2.evaluation.evaluator INFO: Inference done 2466/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:35
[11/16 03:31:14] d2.evaluation.evaluator INFO: Inference done 2589/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:30
[11/16 03:31:19] d2.evaluation.evaluator INFO: Inference done 2711/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/16 03:31:24] d2.evaluation.evaluator INFO: Inference done 2832/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/16 03:31:29] d2.evaluation.evaluator INFO: Inference done 2954/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:15
[11/16 03:31:34] d2.evaluation.evaluator INFO: Inference done 3078/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/16 03:31:39] d2.evaluation.evaluator INFO: Inference done 3202/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/16 03:31:44] d2.evaluation.evaluator INFO: Inference done 3325/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:00
[11/16 03:31:45] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.546658 (0.041017 s / iter per device, on 6 devices)
[11/16 03:31:45] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039056 s / iter per device, on 6 devices)
[11/16 03:31:46] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:31:46] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:31:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:31:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:32:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 17.60 seconds.
[11/16 03:32:05] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:32:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.37 seconds.
[11/16 03:32:06] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.038 | 0.144  | 0.006  | 0.000 | 0.020 | 0.040 |
[11/16 03:32:06] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.019 | bird                  | 0.380 |
| red panda            | 0.000 | dog         | 3.408 | snake                 | 0.000 |
| car                  | 0.000 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.000 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:32:08] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:32:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:32:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:32:08] d2.evaluation.testing INFO: copypaste: 0.0381,0.1435,0.0062,0.0000,0.0204,0.0395
[11/16 03:32:08] d2.utils.events INFO:  eta: 3:02:44  iter: 1999  total_loss: 0.3947  loss_cls: 0.215  loss_box_reg: 0.1123  loss_rpn_cls: 0.0406  loss_rpn_loc: 0.02337  time: 0.6695  data_time: 0.0623  lr: 0.0026653  max_mem: 11811M
[11/16 03:32:21] d2.utils.events INFO:  eta: 3:02:28  iter: 2019  total_loss: 0.3802  loss_cls: 0.2022  loss_box_reg: 0.1073  loss_rpn_cls: 0.0395  loss_rpn_loc: 0.02456  time: 0.6695  data_time: 0.0696  lr: 0.002692  max_mem: 11811M
[11/16 03:32:35] d2.utils.events INFO:  eta: 3:02:14  iter: 2039  total_loss: 0.389  loss_cls: 0.2251  loss_box_reg: 0.1112  loss_rpn_cls: 0.03569  loss_rpn_loc: 0.02365  time: 0.6695  data_time: 0.0739  lr: 0.0027187  max_mem: 11811M
[11/16 03:32:48] d2.utils.events INFO:  eta: 3:02:08  iter: 2059  total_loss: 0.3903  loss_cls: 0.2031  loss_box_reg: 0.107  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.02613  time: 0.6696  data_time: 0.0694  lr: 0.0027453  max_mem: 11811M
[11/16 03:33:02] d2.utils.events INFO:  eta: 3:01:56  iter: 2079  total_loss: 0.3884  loss_cls: 0.2158  loss_box_reg: 0.1108  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.0224  time: 0.6696  data_time: 0.0712  lr: 0.002772  max_mem: 11811M
[11/16 03:33:15] d2.utils.events INFO:  eta: 3:01:43  iter: 2099  total_loss: 0.3916  loss_cls: 0.2132  loss_box_reg: 0.1132  loss_rpn_cls: 0.03846  loss_rpn_loc: 0.02327  time: 0.6697  data_time: 0.0682  lr: 0.0027987  max_mem: 11811M
[11/16 03:33:29] d2.utils.events INFO:  eta: 3:01:30  iter: 2119  total_loss: 0.3871  loss_cls: 0.2153  loss_box_reg: 0.1092  loss_rpn_cls: 0.03554  loss_rpn_loc: 0.02139  time: 0.6696  data_time: 0.0628  lr: 0.0028253  max_mem: 11811M
[11/16 03:33:42] d2.utils.events INFO:  eta: 3:01:16  iter: 2139  total_loss: 0.3838  loss_cls: 0.2057  loss_box_reg: 0.1115  loss_rpn_cls: 0.03366  loss_rpn_loc: 0.02279  time: 0.6697  data_time: 0.0711  lr: 0.002852  max_mem: 11811M
[11/16 03:33:56] d2.utils.events INFO:  eta: 3:01:04  iter: 2159  total_loss: 0.3821  loss_cls: 0.2083  loss_box_reg: 0.1098  loss_rpn_cls: 0.03485  loss_rpn_loc: 0.02153  time: 0.6697  data_time: 0.0663  lr: 0.0028787  max_mem: 11811M
[11/16 03:34:09] d2.utils.events INFO:  eta: 3:00:51  iter: 2179  total_loss: 0.3648  loss_cls: 0.2039  loss_box_reg: 0.1105  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.02012  time: 0.6697  data_time: 0.0682  lr: 0.0029053  max_mem: 11811M
[11/16 03:34:22] d2.utils.events INFO:  eta: 3:00:37  iter: 2199  total_loss: 0.3684  loss_cls: 0.2071  loss_box_reg: 0.1067  loss_rpn_cls: 0.03349  loss_rpn_loc: 0.02155  time: 0.6696  data_time: 0.0652  lr: 0.002932  max_mem: 11811M
[11/16 03:34:35] d2.utils.events INFO:  eta: 3:00:29  iter: 2219  total_loss: 0.4039  loss_cls: 0.2226  loss_box_reg: 0.1191  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.02455  time: 0.6695  data_time: 0.0614  lr: 0.0029587  max_mem: 11811M
[11/16 03:34:49] d2.utils.events INFO:  eta: 3:00:21  iter: 2239  total_loss: 0.3945  loss_cls: 0.2199  loss_box_reg: 0.1121  loss_rpn_cls: 0.03582  loss_rpn_loc: 0.02342  time: 0.6696  data_time: 0.0787  lr: 0.0029853  max_mem: 11811M
[11/16 03:35:02] d2.utils.events INFO:  eta: 3:00:05  iter: 2259  total_loss: 0.3752  loss_cls: 0.2046  loss_box_reg: 0.1114  loss_rpn_cls: 0.035  loss_rpn_loc: 0.02338  time: 0.6696  data_time: 0.0669  lr: 0.003012  max_mem: 11811M
[11/16 03:35:16] d2.utils.events INFO:  eta: 2:59:50  iter: 2279  total_loss: 0.388  loss_cls: 0.2148  loss_box_reg: 0.1076  loss_rpn_cls: 0.03574  loss_rpn_loc: 0.02422  time: 0.6696  data_time: 0.0661  lr: 0.0030387  max_mem: 11811M
[11/16 03:35:29] d2.utils.events INFO:  eta: 2:59:36  iter: 2299  total_loss: 0.3582  loss_cls: 0.1964  loss_box_reg: 0.1042  loss_rpn_cls: 0.03588  loss_rpn_loc: 0.02219  time: 0.6696  data_time: 0.0729  lr: 0.0030653  max_mem: 11811M
[11/16 03:35:42] d2.utils.events INFO:  eta: 2:59:18  iter: 2319  total_loss: 0.3703  loss_cls: 0.2058  loss_box_reg: 0.1091  loss_rpn_cls: 0.03965  loss_rpn_loc: 0.02171  time: 0.6695  data_time: 0.0667  lr: 0.003092  max_mem: 11811M
[11/16 03:35:56] d2.utils.events INFO:  eta: 2:59:05  iter: 2339  total_loss: 0.3777  loss_cls: 0.2027  loss_box_reg: 0.1058  loss_rpn_cls: 0.04158  loss_rpn_loc: 0.02486  time: 0.6695  data_time: 0.0676  lr: 0.0031187  max_mem: 11811M
[11/16 03:36:09] d2.utils.events INFO:  eta: 2:58:58  iter: 2359  total_loss: 0.3611  loss_cls: 0.2026  loss_box_reg: 0.1108  loss_rpn_cls: 0.03413  loss_rpn_loc: 0.01952  time: 0.6696  data_time: 0.0741  lr: 0.0031453  max_mem: 11811M
[11/16 03:36:23] d2.utils.events INFO:  eta: 2:58:49  iter: 2379  total_loss: 0.389  loss_cls: 0.2102  loss_box_reg: 0.1127  loss_rpn_cls: 0.03865  loss_rpn_loc: 0.0251  time: 0.6696  data_time: 0.0650  lr: 0.003172  max_mem: 11811M
[11/16 03:36:36] d2.utils.events INFO:  eta: 2:58:39  iter: 2399  total_loss: 0.3726  loss_cls: 0.2039  loss_box_reg: 0.1101  loss_rpn_cls: 0.03404  loss_rpn_loc: 0.02129  time: 0.6696  data_time: 0.0596  lr: 0.0031987  max_mem: 11811M
[11/16 03:36:50] d2.utils.events INFO:  eta: 2:58:34  iter: 2419  total_loss: 0.3709  loss_cls: 0.2039  loss_box_reg: 0.1105  loss_rpn_cls: 0.03358  loss_rpn_loc: 0.02004  time: 0.6696  data_time: 0.0707  lr: 0.0032253  max_mem: 11811M
[11/16 03:37:03] d2.utils.events INFO:  eta: 2:58:24  iter: 2439  total_loss: 0.3803  loss_cls: 0.2074  loss_box_reg: 0.1102  loss_rpn_cls: 0.03569  loss_rpn_loc: 0.02205  time: 0.6697  data_time: 0.0652  lr: 0.003252  max_mem: 11811M
[11/16 03:37:17] d2.utils.events INFO:  eta: 2:58:12  iter: 2459  total_loss: 0.385  loss_cls: 0.2099  loss_box_reg: 0.1084  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.0251  time: 0.6697  data_time: 0.0699  lr: 0.0032787  max_mem: 11811M
[11/16 03:37:30] d2.utils.events INFO:  eta: 2:57:58  iter: 2479  total_loss: 0.3591  loss_cls: 0.1969  loss_box_reg: 0.105  loss_rpn_cls: 0.03386  loss_rpn_loc: 0.02201  time: 0.6697  data_time: 0.0648  lr: 0.0033053  max_mem: 11811M
[11/16 03:37:43] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0002499.pth
[11/16 03:37:44] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:37:44] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:37:44] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:37:44] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:37:44] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:37:44] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:37:52] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0384 s/iter. Eval: 0.0002 s/iter. Total: 0.0395 s/iter. ETA=0:02:11
[11/16 03:37:57] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:11
[11/16 03:38:02] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/16 03:38:07] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/16 03:38:12] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 03:38:17] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 03:38:22] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/16 03:38:27] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/16 03:38:32] d2.evaluation.evaluator INFO: Inference done 982/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/16 03:38:37] d2.evaluation.evaluator INFO: Inference done 1108/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/16 03:38:42] d2.evaluation.evaluator INFO: Inference done 1232/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/16 03:38:47] d2.evaluation.evaluator INFO: Inference done 1352/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/16 03:38:52] d2.evaluation.evaluator INFO: Inference done 1474/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/16 03:38:57] d2.evaluation.evaluator INFO: Inference done 1594/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/16 03:39:02] d2.evaluation.evaluator INFO: Inference done 1713/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:06
[11/16 03:39:07] d2.evaluation.evaluator INFO: Inference done 1834/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:01
[11/16 03:39:12] d2.evaluation.evaluator INFO: Inference done 1957/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/16 03:39:17] d2.evaluation.evaluator INFO: Inference done 2079/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/16 03:39:22] d2.evaluation.evaluator INFO: Inference done 2199/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/16 03:39:27] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 03:39:32] d2.evaluation.evaluator INFO: Inference done 2439/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/16 03:39:37] d2.evaluation.evaluator INFO: Inference done 2563/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/16 03:39:42] d2.evaluation.evaluator INFO: Inference done 2686/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 03:39:47] d2.evaluation.evaluator INFO: Inference done 2808/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 03:39:52] d2.evaluation.evaluator INFO: Inference done 2929/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/16 03:39:57] d2.evaluation.evaluator INFO: Inference done 3052/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/16 03:40:02] d2.evaluation.evaluator INFO: Inference done 3172/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/16 03:40:07] d2.evaluation.evaluator INFO: Inference done 3294/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/16 03:40:09] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.375001 (0.041266 s / iter per device, on 6 devices)
[11/16 03:40:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039317 s / iter per device, on 6 devices)
[11/16 03:40:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:40:11] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:40:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:40:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:40:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.55 seconds.
[11/16 03:40:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:40:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.68 seconds.
[11/16 03:40:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.035 | 0.148  | 0.003  | 0.000 | 0.028 | 0.037 |
[11/16 03:40:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.094 | bird                  | 0.601 |
| red panda            | 0.000 | dog         | 2.765 | snake                 | 0.023 |
| car                  | 0.041 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.000 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:40:36] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:40:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:40:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:40:36] d2.evaluation.testing INFO: copypaste: 0.0352,0.1479,0.0034,0.0002,0.0279,0.0368
[11/16 03:40:37] d2.utils.events INFO:  eta: 2:57:46  iter: 2499  total_loss: 0.3818  loss_cls: 0.2083  loss_box_reg: 0.1146  loss_rpn_cls: 0.03352  loss_rpn_loc: 0.02166  time: 0.6696  data_time: 0.0656  lr: 0.003332  max_mem: 11811M
[11/16 03:40:50] d2.utils.events INFO:  eta: 2:57:33  iter: 2519  total_loss: 0.3847  loss_cls: 0.2084  loss_box_reg: 0.1104  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.02424  time: 0.6696  data_time: 0.0675  lr: 0.0033587  max_mem: 11811M
[11/16 03:41:03] d2.utils.events INFO:  eta: 2:57:19  iter: 2539  total_loss: 0.3816  loss_cls: 0.2177  loss_box_reg: 0.1097  loss_rpn_cls: 0.03883  loss_rpn_loc: 0.02026  time: 0.6695  data_time: 0.0654  lr: 0.0033853  max_mem: 11811M
[11/16 03:41:17] d2.utils.events INFO:  eta: 2:57:11  iter: 2559  total_loss: 0.3708  loss_cls: 0.1919  loss_box_reg: 0.08767  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.03206  time: 0.6696  data_time: 0.0682  lr: 0.003412  max_mem: 11811M
[11/16 03:41:30] d2.utils.events INFO:  eta: 2:57:04  iter: 2579  total_loss: 0.35  loss_cls: 0.1891  loss_box_reg: 0.08853  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.02889  time: 0.6697  data_time: 0.0674  lr: 0.0034387  max_mem: 11811M
[11/16 03:41:44] d2.utils.events INFO:  eta: 2:57:03  iter: 2599  total_loss: 0.3641  loss_cls: 0.1979  loss_box_reg: 0.1032  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.02334  time: 0.6698  data_time: 0.0653  lr: 0.0034653  max_mem: 11811M
[11/16 03:41:57] d2.utils.events INFO:  eta: 2:56:51  iter: 2619  total_loss: 0.3914  loss_cls: 0.2069  loss_box_reg: 0.1099  loss_rpn_cls: 0.04211  loss_rpn_loc: 0.02194  time: 0.6699  data_time: 0.0725  lr: 0.003492  max_mem: 11811M
[11/16 03:42:11] d2.utils.events INFO:  eta: 2:56:40  iter: 2639  total_loss: 0.377  loss_cls: 0.2043  loss_box_reg: 0.1067  loss_rpn_cls: 0.03955  loss_rpn_loc: 0.02247  time: 0.6699  data_time: 0.0627  lr: 0.0035187  max_mem: 11811M
[11/16 03:42:24] d2.utils.events INFO:  eta: 2:56:30  iter: 2659  total_loss: 0.3726  loss_cls: 0.202  loss_box_reg: 0.1077  loss_rpn_cls: 0.03741  loss_rpn_loc: 0.02099  time: 0.6699  data_time: 0.0662  lr: 0.0035453  max_mem: 11811M
[11/16 03:42:38] d2.utils.events INFO:  eta: 2:56:15  iter: 2679  total_loss: 0.3848  loss_cls: 0.2056  loss_box_reg: 0.1126  loss_rpn_cls: 0.04089  loss_rpn_loc: 0.02577  time: 0.6699  data_time: 0.0678  lr: 0.003572  max_mem: 11811M
[11/16 03:42:51] d2.utils.events INFO:  eta: 2:56:03  iter: 2699  total_loss: 0.3577  loss_cls: 0.1947  loss_box_reg: 0.1071  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.02203  time: 0.6699  data_time: 0.0623  lr: 0.0035987  max_mem: 11811M
[11/16 03:43:05] d2.utils.events INFO:  eta: 2:55:48  iter: 2719  total_loss: 0.3694  loss_cls: 0.2014  loss_box_reg: 0.1045  loss_rpn_cls: 0.03745  loss_rpn_loc: 0.02222  time: 0.6699  data_time: 0.0574  lr: 0.0036253  max_mem: 11811M
[11/16 03:43:18] d2.utils.events INFO:  eta: 2:55:36  iter: 2739  total_loss: 0.387  loss_cls: 0.215  loss_box_reg: 0.1116  loss_rpn_cls: 0.03527  loss_rpn_loc: 0.02487  time: 0.6700  data_time: 0.0768  lr: 0.003652  max_mem: 11811M
[11/16 03:43:32] d2.utils.events INFO:  eta: 2:55:26  iter: 2759  total_loss: 0.3773  loss_cls: 0.2063  loss_box_reg: 0.112  loss_rpn_cls: 0.03606  loss_rpn_loc: 0.02532  time: 0.6701  data_time: 0.0660  lr: 0.0036787  max_mem: 11811M
[11/16 03:43:45] d2.utils.events INFO:  eta: 2:55:12  iter: 2779  total_loss: 0.3669  loss_cls: 0.2029  loss_box_reg: 0.1075  loss_rpn_cls: 0.03507  loss_rpn_loc: 0.02183  time: 0.6701  data_time: 0.0770  lr: 0.0037053  max_mem: 11811M
[11/16 03:43:59] d2.utils.events INFO:  eta: 2:55:02  iter: 2799  total_loss: 0.3772  loss_cls: 0.211  loss_box_reg: 0.1081  loss_rpn_cls: 0.0338  loss_rpn_loc: 0.02278  time: 0.6702  data_time: 0.0909  lr: 0.003732  max_mem: 11811M
[11/16 03:44:13] d2.utils.events INFO:  eta: 2:54:57  iter: 2819  total_loss: 0.362  loss_cls: 0.1943  loss_box_reg: 0.1033  loss_rpn_cls: 0.03399  loss_rpn_loc: 0.02185  time: 0.6703  data_time: 0.0667  lr: 0.0037587  max_mem: 11811M
[11/16 03:44:26] d2.utils.events INFO:  eta: 2:54:49  iter: 2839  total_loss: 0.3567  loss_cls: 0.1947  loss_box_reg: 0.1067  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.02262  time: 0.6703  data_time: 0.0616  lr: 0.0037853  max_mem: 11811M
[11/16 03:44:40] d2.utils.events INFO:  eta: 2:54:38  iter: 2859  total_loss: 0.3531  loss_cls: 0.1944  loss_box_reg: 0.1058  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.02174  time: 0.6703  data_time: 0.0612  lr: 0.003812  max_mem: 11811M
[11/16 03:44:53] d2.utils.events INFO:  eta: 2:54:24  iter: 2879  total_loss: 0.3686  loss_cls: 0.202  loss_box_reg: 0.1078  loss_rpn_cls: 0.03275  loss_rpn_loc: 0.02216  time: 0.6703  data_time: 0.0643  lr: 0.0038387  max_mem: 11811M
[11/16 03:45:07] d2.utils.events INFO:  eta: 2:54:15  iter: 2899  total_loss: 0.3632  loss_cls: 0.1997  loss_box_reg: 0.1053  loss_rpn_cls: 0.03218  loss_rpn_loc: 0.02227  time: 0.6704  data_time: 0.0704  lr: 0.0038653  max_mem: 11811M
[11/16 03:45:20] d2.utils.events INFO:  eta: 2:54:09  iter: 2919  total_loss: 0.3699  loss_cls: 0.2014  loss_box_reg: 0.1042  loss_rpn_cls: 0.03559  loss_rpn_loc: 0.02265  time: 0.6704  data_time: 0.0660  lr: 0.003892  max_mem: 11811M
[11/16 03:45:34] d2.utils.events INFO:  eta: 2:53:57  iter: 2939  total_loss: 0.3653  loss_cls: 0.2016  loss_box_reg: 0.1087  loss_rpn_cls: 0.03292  loss_rpn_loc: 0.02081  time: 0.6704  data_time: 0.0728  lr: 0.0039187  max_mem: 11811M
[11/16 03:45:47] d2.utils.events INFO:  eta: 2:53:49  iter: 2959  total_loss: 0.3738  loss_cls: 0.2098  loss_box_reg: 0.1092  loss_rpn_cls: 0.03475  loss_rpn_loc: 0.02194  time: 0.6705  data_time: 0.0688  lr: 0.0039453  max_mem: 11811M
[11/16 03:46:01] d2.utils.events INFO:  eta: 2:53:38  iter: 2979  total_loss: 0.3662  loss_cls: 0.202  loss_box_reg: 0.1076  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.0199  time: 0.6706  data_time: 0.0627  lr: 0.003972  max_mem: 11811M
[11/16 03:46:14] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0002999.pth
[11/16 03:46:15] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:46:15] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:46:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:46:15] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:46:16] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:46:16] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:46:23] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0360 s/iter. Eval: 0.0002 s/iter. Total: 0.0372 s/iter. ETA=0:02:03
[11/16 03:46:28] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0014 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:10
[11/16 03:46:33] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0014 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:05
[11/16 03:46:38] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0014 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/16 03:46:43] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 03:46:48] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 03:46:53] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 03:46:58] d2.evaluation.evaluator INFO: Inference done 862/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/16 03:47:03] d2.evaluation.evaluator INFO: Inference done 981/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/16 03:47:08] d2.evaluation.evaluator INFO: Inference done 1106/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:31
[11/16 03:47:13] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:26
[11/16 03:47:18] d2.evaluation.evaluator INFO: Inference done 1350/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/16 03:47:23] d2.evaluation.evaluator INFO: Inference done 1471/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/16 03:47:28] d2.evaluation.evaluator INFO: Inference done 1594/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/16 03:47:33] d2.evaluation.evaluator INFO: Inference done 1710/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/16 03:47:38] d2.evaluation.evaluator INFO: Inference done 1831/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/16 03:47:43] d2.evaluation.evaluator INFO: Inference done 1952/3334. Dataloading: 0.0014 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/16 03:47:48] d2.evaluation.evaluator INFO: Inference done 2074/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/16 03:47:53] d2.evaluation.evaluator INFO: Inference done 2198/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/16 03:47:58] d2.evaluation.evaluator INFO: Inference done 2318/3334. Dataloading: 0.0014 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 03:48:03] d2.evaluation.evaluator INFO: Inference done 2435/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/16 03:48:08] d2.evaluation.evaluator INFO: Inference done 2554/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/16 03:48:13] d2.evaluation.evaluator INFO: Inference done 2675/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/16 03:48:18] d2.evaluation.evaluator INFO: Inference done 2798/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/16 03:48:23] d2.evaluation.evaluator INFO: Inference done 2919/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/16 03:48:28] d2.evaluation.evaluator INFO: Inference done 3043/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/16 03:48:33] d2.evaluation.evaluator INFO: Inference done 3165/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:06
[11/16 03:48:38] d2.evaluation.evaluator INFO: Inference done 3289/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:01
[11/16 03:48:41] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.961784 (0.041442 s / iter per device, on 6 devices)
[11/16 03:48:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039590 s / iter per device, on 6 devices)
[11/16 03:48:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:48:42] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:48:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:48:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:49:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.67 seconds.
[11/16 03:49:04] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:49:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.52 seconds.
[11/16 03:49:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.065 | 0.210  | 0.021  | 0.000 | 0.038 | 0.069 |
[11/16 03:49:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.174 | bird                  | 0.825 |
| red panda            | 0.000 | dog         | 5.422 | snake                 | 0.000 |
| car                  | 0.029 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.042 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:49:07] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:49:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:49:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:49:07] d2.evaluation.testing INFO: copypaste: 0.0649,0.2101,0.0208,0.0000,0.0379,0.0691
[11/16 03:49:07] d2.utils.events INFO:  eta: 2:53:26  iter: 2999  total_loss: 0.3594  loss_cls: 0.2006  loss_box_reg: 0.1097  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.02024  time: 0.6706  data_time: 0.0728  lr: 0.0039987  max_mem: 11811M
[11/16 03:49:21] d2.utils.events INFO:  eta: 2:53:12  iter: 3019  total_loss: 0.3665  loss_cls: 0.1966  loss_box_reg: 0.1109  loss_rpn_cls: 0.03014  loss_rpn_loc: 0.02276  time: 0.6706  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 03:49:35] d2.utils.events INFO:  eta: 2:53:01  iter: 3039  total_loss: 0.3522  loss_cls: 0.1991  loss_box_reg: 0.106  loss_rpn_cls: 0.034  loss_rpn_loc: 0.02175  time: 0.6708  data_time: 0.0857  lr: 0.004  max_mem: 11811M
[11/16 03:49:48] d2.utils.events INFO:  eta: 2:52:48  iter: 3059  total_loss: 0.3829  loss_cls: 0.2122  loss_box_reg: 0.1122  loss_rpn_cls: 0.03507  loss_rpn_loc: 0.02188  time: 0.6708  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 03:50:02] d2.utils.events INFO:  eta: 2:52:35  iter: 3079  total_loss: 0.3697  loss_cls: 0.2095  loss_box_reg: 0.1064  loss_rpn_cls: 0.03605  loss_rpn_loc: 0.02162  time: 0.6709  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 03:50:15] d2.utils.events INFO:  eta: 2:52:24  iter: 3099  total_loss: 0.3905  loss_cls: 0.2202  loss_box_reg: 0.1082  loss_rpn_cls: 0.03432  loss_rpn_loc: 0.02128  time: 0.6709  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 03:50:29] d2.utils.events INFO:  eta: 2:52:15  iter: 3119  total_loss: 0.3922  loss_cls: 0.2115  loss_box_reg: 0.1127  loss_rpn_cls: 0.03273  loss_rpn_loc: 0.02297  time: 0.6709  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 03:50:42] d2.utils.events INFO:  eta: 2:52:10  iter: 3139  total_loss: 0.3902  loss_cls: 0.2221  loss_box_reg: 0.1061  loss_rpn_cls: 0.03949  loss_rpn_loc: 0.0233  time: 0.6710  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/16 03:50:56] d2.utils.events INFO:  eta: 2:52:04  iter: 3159  total_loss: 0.3775  loss_cls: 0.2044  loss_box_reg: 0.106  loss_rpn_cls: 0.03619  loss_rpn_loc: 0.02365  time: 0.6711  data_time: 0.0760  lr: 0.004  max_mem: 11811M
[11/16 03:51:10] d2.utils.events INFO:  eta: 2:51:57  iter: 3179  total_loss: 0.3698  loss_cls: 0.2079  loss_box_reg: 0.1079  loss_rpn_cls: 0.03283  loss_rpn_loc: 0.02104  time: 0.6711  data_time: 0.0715  lr: 0.004  max_mem: 11811M
[11/16 03:51:23] d2.utils.events INFO:  eta: 2:51:45  iter: 3199  total_loss: 0.3707  loss_cls: 0.2047  loss_box_reg: 0.1076  loss_rpn_cls: 0.03401  loss_rpn_loc: 0.02367  time: 0.6711  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 03:51:37] d2.utils.events INFO:  eta: 2:51:32  iter: 3219  total_loss: 0.3594  loss_cls: 0.1997  loss_box_reg: 0.1039  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.02049  time: 0.6712  data_time: 0.0694  lr: 0.004  max_mem: 11811M
[11/16 03:51:50] d2.utils.events INFO:  eta: 2:51:21  iter: 3239  total_loss: 0.3589  loss_cls: 0.1988  loss_box_reg: 0.1052  loss_rpn_cls: 0.03543  loss_rpn_loc: 0.02161  time: 0.6712  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 03:52:04] d2.utils.events INFO:  eta: 2:51:14  iter: 3259  total_loss: 0.3662  loss_cls: 0.202  loss_box_reg: 0.1046  loss_rpn_cls: 0.03581  loss_rpn_loc: 0.02267  time: 0.6712  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 03:52:17] d2.utils.events INFO:  eta: 2:51:00  iter: 3279  total_loss: 0.3636  loss_cls: 0.1977  loss_box_reg: 0.1076  loss_rpn_cls: 0.03205  loss_rpn_loc: 0.02181  time: 0.6712  data_time: 0.0601  lr: 0.004  max_mem: 11811M
[11/16 03:52:31] d2.utils.events INFO:  eta: 2:50:47  iter: 3299  total_loss: 0.3784  loss_cls: 0.2089  loss_box_reg: 0.1125  loss_rpn_cls: 0.02868  loss_rpn_loc: 0.02412  time: 0.6713  data_time: 0.0715  lr: 0.004  max_mem: 11811M
[11/16 03:52:45] d2.utils.events INFO:  eta: 2:50:40  iter: 3319  total_loss: 0.3667  loss_cls: 0.2007  loss_box_reg: 0.105  loss_rpn_cls: 0.03108  loss_rpn_loc: 0.02008  time: 0.6714  data_time: 0.0776  lr: 0.004  max_mem: 11811M
[11/16 03:52:58] d2.utils.events INFO:  eta: 2:50:31  iter: 3339  total_loss: 0.3555  loss_cls: 0.1945  loss_box_reg: 0.1069  loss_rpn_cls: 0.03224  loss_rpn_loc: 0.02317  time: 0.6714  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 03:53:12] d2.utils.events INFO:  eta: 2:50:18  iter: 3359  total_loss: 0.3563  loss_cls: 0.1993  loss_box_reg: 0.1035  loss_rpn_cls: 0.03172  loss_rpn_loc: 0.02315  time: 0.6714  data_time: 0.0663  lr: 0.004  max_mem: 11811M
[11/16 03:53:25] d2.utils.events INFO:  eta: 2:50:04  iter: 3379  total_loss: 0.3609  loss_cls: 0.1956  loss_box_reg: 0.1061  loss_rpn_cls: 0.0322  loss_rpn_loc: 0.02123  time: 0.6714  data_time: 0.0687  lr: 0.004  max_mem: 11811M
[11/16 03:53:39] d2.utils.events INFO:  eta: 2:49:51  iter: 3399  total_loss: 0.3666  loss_cls: 0.2029  loss_box_reg: 0.1088  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.02105  time: 0.6715  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 03:53:52] d2.utils.events INFO:  eta: 2:49:38  iter: 3419  total_loss: 0.3547  loss_cls: 0.1913  loss_box_reg: 0.1047  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.02215  time: 0.6715  data_time: 0.0653  lr: 0.004  max_mem: 11811M
[11/16 03:54:06] d2.utils.events INFO:  eta: 2:49:25  iter: 3439  total_loss: 0.3549  loss_cls: 0.1941  loss_box_reg: 0.1086  loss_rpn_cls: 0.03276  loss_rpn_loc: 0.0215  time: 0.6715  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/16 03:54:19] d2.utils.events INFO:  eta: 2:49:13  iter: 3459  total_loss: 0.3296  loss_cls: 0.1832  loss_box_reg: 0.09977  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.02157  time: 0.6716  data_time: 0.0716  lr: 0.004  max_mem: 11811M
[11/16 03:54:33] d2.utils.events INFO:  eta: 2:49:03  iter: 3479  total_loss: 0.3673  loss_cls: 0.2078  loss_box_reg: 0.1062  loss_rpn_cls: 0.03175  loss_rpn_loc: 0.02428  time: 0.6717  data_time: 0.0715  lr: 0.004  max_mem: 11811M
[11/16 03:54:47] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0003499.pth
[11/16 03:54:47] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 03:54:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 03:54:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 03:54:48] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 03:54:48] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 03:54:48] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 03:54:55] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:15
[11/16 03:55:00] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/16 03:55:05] d2.evaluation.evaluator INFO: Inference done 259/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:04
[11/16 03:55:10] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0014 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/16 03:55:15] d2.evaluation.evaluator INFO: Inference done 506/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:54
[11/16 03:55:20] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0014 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:49
[11/16 03:55:25] d2.evaluation.evaluator INFO: Inference done 749/3334. Dataloading: 0.0014 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:45
[11/16 03:55:30] d2.evaluation.evaluator INFO: Inference done 874/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/16 03:55:35] d2.evaluation.evaluator INFO: Inference done 998/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:35
[11/16 03:55:40] d2.evaluation.evaluator INFO: Inference done 1124/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:29
[11/16 03:55:45] d2.evaluation.evaluator INFO: Inference done 1250/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:24
[11/16 03:55:50] d2.evaluation.evaluator INFO: Inference done 1374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:19
[11/16 03:55:55] d2.evaluation.evaluator INFO: Inference done 1497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:14
[11/16 03:56:00] d2.evaluation.evaluator INFO: Inference done 1621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:09
[11/16 03:56:05] d2.evaluation.evaluator INFO: Inference done 1744/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:04
[11/16 03:56:10] d2.evaluation.evaluator INFO: Inference done 1866/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:59
[11/16 03:56:15] d2.evaluation.evaluator INFO: Inference done 1988/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:54
[11/16 03:56:20] d2.evaluation.evaluator INFO: Inference done 2113/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:49
[11/16 03:56:25] d2.evaluation.evaluator INFO: Inference done 2234/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:44
[11/16 03:56:30] d2.evaluation.evaluator INFO: Inference done 2358/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:39
[11/16 03:56:36] d2.evaluation.evaluator INFO: Inference done 2478/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:34
[11/16 03:56:41] d2.evaluation.evaluator INFO: Inference done 2605/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:29
[11/16 03:56:46] d2.evaluation.evaluator INFO: Inference done 2730/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:24
[11/16 03:56:51] d2.evaluation.evaluator INFO: Inference done 2853/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:19
[11/16 03:56:56] d2.evaluation.evaluator INFO: Inference done 2978/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:14
[11/16 03:57:01] d2.evaluation.evaluator INFO: Inference done 3101/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:09
[11/16 03:57:06] d2.evaluation.evaluator INFO: Inference done 3220/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:04
[11/16 03:57:11] d2.evaluation.evaluator INFO: Total inference time: 0:02:15.941707 (0.040836 s / iter per device, on 6 devices)
[11/16 03:57:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038886 s / iter per device, on 6 devices)
[11/16 03:57:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 03:57:13] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 03:57:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 03:57:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 03:57:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.55 seconds.
[11/16 03:57:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 03:57:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.31 seconds.
[11/16 03:57:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.085 | 0.299  | 0.021  | 0.000 | 0.039 | 0.094 |
[11/16 03:57:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.097 | bird                  | 1.122 |
| red panda            | 0.000 | dog         | 6.933 | snake                 | 0.000 |
| car                  | 0.179 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.160 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.000 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.006 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 03:57:36] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 03:57:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 03:57:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 03:57:36] d2.evaluation.testing INFO: copypaste: 0.0850,0.2988,0.0205,0.0000,0.0393,0.0937
[11/16 03:57:36] d2.utils.events INFO:  eta: 2:48:51  iter: 3499  total_loss: 0.358  loss_cls: 0.1989  loss_box_reg: 0.1098  loss_rpn_cls: 0.03102  loss_rpn_loc: 0.02041  time: 0.6717  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 03:57:50] d2.utils.events INFO:  eta: 2:48:36  iter: 3519  total_loss: 0.3646  loss_cls: 0.2051  loss_box_reg: 0.1051  loss_rpn_cls: 0.02929  loss_rpn_loc: 0.01952  time: 0.6717  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 03:58:04] d2.utils.events INFO:  eta: 2:48:30  iter: 3539  total_loss: 0.3601  loss_cls: 0.1999  loss_box_reg: 0.1048  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.01958  time: 0.6719  data_time: 0.0875  lr: 0.004  max_mem: 11811M
[11/16 03:58:17] d2.utils.events INFO:  eta: 2:48:11  iter: 3559  total_loss: 0.3674  loss_cls: 0.2002  loss_box_reg: 0.1093  loss_rpn_cls: 0.02841  loss_rpn_loc: 0.02148  time: 0.6719  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 03:58:31] d2.utils.events INFO:  eta: 2:48:02  iter: 3579  total_loss: 0.3586  loss_cls: 0.2  loss_box_reg: 0.1043  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.02089  time: 0.6719  data_time: 0.0706  lr: 0.004  max_mem: 11811M
[11/16 03:58:44] d2.utils.events INFO:  eta: 2:47:48  iter: 3599  total_loss: 0.3619  loss_cls: 0.199  loss_box_reg: 0.1084  loss_rpn_cls: 0.02858  loss_rpn_loc: 0.01958  time: 0.6720  data_time: 0.0647  lr: 0.004  max_mem: 11811M
[11/16 03:58:58] d2.utils.events INFO:  eta: 2:47:35  iter: 3619  total_loss: 0.3634  loss_cls: 0.201  loss_box_reg: 0.1057  loss_rpn_cls: 0.03226  loss_rpn_loc: 0.02235  time: 0.6720  data_time: 0.0717  lr: 0.004  max_mem: 11811M
[11/16 03:59:12] d2.utils.events INFO:  eta: 2:47:23  iter: 3639  total_loss: 0.3498  loss_cls: 0.197  loss_box_reg: 0.1034  loss_rpn_cls: 0.02913  loss_rpn_loc: 0.02208  time: 0.6721  data_time: 0.0669  lr: 0.004  max_mem: 11811M
[11/16 03:59:25] d2.utils.events INFO:  eta: 2:47:12  iter: 3659  total_loss: 0.3759  loss_cls: 0.2023  loss_box_reg: 0.1135  loss_rpn_cls: 0.03233  loss_rpn_loc: 0.02221  time: 0.6721  data_time: 0.0633  lr: 0.004  max_mem: 11811M
[11/16 03:59:39] d2.utils.events INFO:  eta: 2:47:00  iter: 3679  total_loss: 0.3489  loss_cls: 0.1894  loss_box_reg: 0.09924  loss_rpn_cls: 0.03243  loss_rpn_loc: 0.02305  time: 0.6721  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 03:59:53] d2.utils.events INFO:  eta: 2:46:48  iter: 3699  total_loss: 0.3534  loss_cls: 0.196  loss_box_reg: 0.1069  loss_rpn_cls: 0.02976  loss_rpn_loc: 0.02011  time: 0.6722  data_time: 0.0805  lr: 0.004  max_mem: 11811M
[11/16 04:00:06] d2.utils.events INFO:  eta: 2:46:34  iter: 3719  total_loss: 0.3595  loss_cls: 0.1973  loss_box_reg: 0.1056  loss_rpn_cls: 0.03448  loss_rpn_loc: 0.02161  time: 0.6723  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 04:00:20] d2.utils.events INFO:  eta: 2:46:20  iter: 3739  total_loss: 0.3719  loss_cls: 0.2025  loss_box_reg: 0.11  loss_rpn_cls: 0.03192  loss_rpn_loc: 0.02122  time: 0.6723  data_time: 0.0698  lr: 0.004  max_mem: 11811M
[11/16 04:00:33] d2.utils.events INFO:  eta: 2:46:07  iter: 3759  total_loss: 0.3533  loss_cls: 0.1978  loss_box_reg: 0.1055  loss_rpn_cls: 0.03249  loss_rpn_loc: 0.02026  time: 0.6723  data_time: 0.0662  lr: 0.004  max_mem: 11811M
[11/16 04:00:47] d2.utils.events INFO:  eta: 2:45:55  iter: 3779  total_loss: 0.3565  loss_cls: 0.2018  loss_box_reg: 0.1092  loss_rpn_cls: 0.0321  loss_rpn_loc: 0.02213  time: 0.6723  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/16 04:01:00] d2.utils.events INFO:  eta: 2:45:42  iter: 3799  total_loss: 0.3451  loss_cls: 0.1901  loss_box_reg: 0.1007  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.02213  time: 0.6724  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 04:01:14] d2.utils.events INFO:  eta: 2:45:26  iter: 3819  total_loss: 0.3497  loss_cls: 0.1914  loss_box_reg: 0.1016  loss_rpn_cls: 0.02655  loss_rpn_loc: 0.02166  time: 0.6724  data_time: 0.0688  lr: 0.004  max_mem: 11811M
[11/16 04:01:27] d2.utils.events INFO:  eta: 2:45:17  iter: 3839  total_loss: 0.35  loss_cls: 0.1941  loss_box_reg: 0.1038  loss_rpn_cls: 0.02992  loss_rpn_loc: 0.02164  time: 0.6724  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/16 04:01:41] d2.utils.events INFO:  eta: 2:45:01  iter: 3859  total_loss: 0.3602  loss_cls: 0.1937  loss_box_reg: 0.1046  loss_rpn_cls: 0.03662  loss_rpn_loc: 0.02436  time: 0.6725  data_time: 0.0718  lr: 0.004  max_mem: 11811M
[11/16 04:01:55] d2.utils.events INFO:  eta: 2:44:50  iter: 3879  total_loss: 0.353  loss_cls: 0.1958  loss_box_reg: 0.1044  loss_rpn_cls: 0.03247  loss_rpn_loc: 0.02094  time: 0.6725  data_time: 0.0634  lr: 0.004  max_mem: 11811M
[11/16 04:02:08] d2.utils.events INFO:  eta: 2:44:37  iter: 3899  total_loss: 0.3495  loss_cls: 0.1974  loss_box_reg: 0.1043  loss_rpn_cls: 0.02869  loss_rpn_loc: 0.02051  time: 0.6725  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 04:02:22] d2.utils.events INFO:  eta: 2:44:28  iter: 3919  total_loss: 0.3493  loss_cls: 0.1908  loss_box_reg: 0.105  loss_rpn_cls: 0.03111  loss_rpn_loc: 0.02038  time: 0.6726  data_time: 0.0683  lr: 0.004  max_mem: 11811M
[11/16 04:02:35] d2.utils.events INFO:  eta: 2:44:10  iter: 3939  total_loss: 0.3376  loss_cls: 0.1881  loss_box_reg: 0.1022  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.02412  time: 0.6726  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 04:02:49] d2.utils.events INFO:  eta: 2:43:54  iter: 3959  total_loss: 0.3471  loss_cls: 0.1905  loss_box_reg: 0.1036  loss_rpn_cls: 0.03267  loss_rpn_loc: 0.02265  time: 0.6726  data_time: 0.0683  lr: 0.004  max_mem: 11811M
[11/16 04:03:03] d2.utils.events INFO:  eta: 2:43:42  iter: 3979  total_loss: 0.3451  loss_cls: 0.1928  loss_box_reg: 0.1025  loss_rpn_cls: 0.03006  loss_rpn_loc: 0.02073  time: 0.6727  data_time: 0.0770  lr: 0.004  max_mem: 11811M
[11/16 04:03:16] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0003999.pth
[11/16 04:03:17] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:03:17] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:03:17] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:03:17] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:03:17] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:03:18] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:03:24] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0398 s/iter. ETA=0:02:12
[11/16 04:03:29] d2.evaluation.evaluator INFO: Inference done 136/3334. Dataloading: 0.0014 s/iter. Inference: 0.0384 s/iter. Eval: 0.0002 s/iter. Total: 0.0401 s/iter. ETA=0:02:08
[11/16 04:03:35] d2.evaluation.evaluator INFO: Inference done 261/3334. Dataloading: 0.0014 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:03
[11/16 04:03:40] d2.evaluation.evaluator INFO: Inference done 384/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:59
[11/16 04:03:45] d2.evaluation.evaluator INFO: Inference done 505/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:54
[11/16 04:03:50] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:49
[11/16 04:03:55] d2.evaluation.evaluator INFO: Inference done 753/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:44
[11/16 04:04:00] d2.evaluation.evaluator INFO: Inference done 878/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:39
[11/16 04:04:05] d2.evaluation.evaluator INFO: Inference done 999/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:34
[11/16 04:04:10] d2.evaluation.evaluator INFO: Inference done 1119/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:30
[11/16 04:04:15] d2.evaluation.evaluator INFO: Inference done 1243/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:25
[11/16 04:04:20] d2.evaluation.evaluator INFO: Inference done 1367/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:20
[11/16 04:04:25] d2.evaluation.evaluator INFO: Inference done 1486/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/16 04:04:30] d2.evaluation.evaluator INFO: Inference done 1608/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/16 04:04:35] d2.evaluation.evaluator INFO: Inference done 1728/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:05
[11/16 04:04:40] d2.evaluation.evaluator INFO: Inference done 1850/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/16 04:04:45] d2.evaluation.evaluator INFO: Inference done 1973/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/16 04:04:50] d2.evaluation.evaluator INFO: Inference done 2096/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:50
[11/16 04:04:55] d2.evaluation.evaluator INFO: Inference done 2218/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:45
[11/16 04:05:00] d2.evaluation.evaluator INFO: Inference done 2339/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/16 04:05:05] d2.evaluation.evaluator INFO: Inference done 2460/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/16 04:05:10] d2.evaluation.evaluator INFO: Inference done 2583/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/16 04:05:15] d2.evaluation.evaluator INFO: Inference done 2705/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/16 04:05:20] d2.evaluation.evaluator INFO: Inference done 2827/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:20
[11/16 04:05:25] d2.evaluation.evaluator INFO: Inference done 2946/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/16 04:05:30] d2.evaluation.evaluator INFO: Inference done 3066/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/16 04:05:35] d2.evaluation.evaluator INFO: Inference done 3187/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/16 04:05:40] d2.evaluation.evaluator INFO: Inference done 3310/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:00
[11/16 04:05:41] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.247808 (0.041228 s / iter per device, on 6 devices)
[11/16 04:05:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039281 s / iter per device, on 6 devices)
[11/16 04:05:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 04:05:43] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 04:05:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 04:05:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 04:06:02] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 18.36 seconds.
[11/16 04:06:02] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 04:06:04] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.55 seconds.
[11/16 04:06:04] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.040 | 0.141  | 0.011  | 0.002 | 0.021 | 0.046 |
[11/16 04:06:04] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP    | category              | AP    |
|:---------------------|:------|:------------|:------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.000 | bird                  | 0.606 |
| red panda            | 0.000 | dog         | 2.822 | snake                 | 0.021 |
| car                  | 0.132 | seal        | 0.000 | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000 | stove                 | 0.000 |
| monkey               | 0.000 | watercraft  | 0.095 | chair                 | 0.000 |
| domestic cat         | 0.000 | harp        | 0.000 | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000 | bus                   | 0.000 |
| hat with a wide brim | 0.000 | ski         | 0.000 | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000 | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000 | porcupine             | 0.000 |
| butterfly            | 0.000 | guitar      | 0.000 | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000 | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000 | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000 | table                 | 0.000 |
| coffee maker         | 0.000 | tie         | 0.000 | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000 | lemon                 | 0.000 |
| lizard               | 0.000 | backpack    | 0.000 | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000 | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000 | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000 | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000 | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000 | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000 | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000 | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000 | miniskirt             | 0.000 |
| orange               | 0.339 | tiger       | 0.000 | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000 | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.000 | laptop                | 0.000 |
| pomegranate          | 0.000 | cucumber    | 0.000 | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000 | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000 | beaker                | 0.000 |
| goldfish             | 0.000 | nail        | 0.000 | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000 | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |       |                       |       |
[11/16 04:06:06] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 04:06:06] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 04:06:06] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 04:06:06] d2.evaluation.testing INFO: copypaste: 0.0401,0.1415,0.0114,0.0015,0.0209,0.0459
[11/16 04:06:06] d2.utils.events INFO:  eta: 2:43:30  iter: 3999  total_loss: 0.3798  loss_cls: 0.2088  loss_box_reg: 0.1076  loss_rpn_cls: 0.03347  loss_rpn_loc: 0.02382  time: 0.6728  data_time: 0.0694  lr: 0.004  max_mem: 11811M
[11/16 04:06:20] d2.utils.events INFO:  eta: 2:43:33  iter: 4019  total_loss: 0.3825  loss_cls: 0.2091  loss_box_reg: 0.1145  loss_rpn_cls: 0.03478  loss_rpn_loc: 0.0222  time: 0.6728  data_time: 0.0693  lr: 0.004  max_mem: 11811M
[11/16 04:06:33] d2.utils.events INFO:  eta: 2:43:09  iter: 4039  total_loss: 0.3587  loss_cls: 0.1978  loss_box_reg: 0.1071  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.02218  time: 0.6728  data_time: 0.0586  lr: 0.004  max_mem: 11811M
[11/16 04:06:47] d2.utils.events INFO:  eta: 2:42:59  iter: 4059  total_loss: 0.3413  loss_cls: 0.1868  loss_box_reg: 0.1019  loss_rpn_cls: 0.02977  loss_rpn_loc: 0.02022  time: 0.6729  data_time: 0.0707  lr: 0.004  max_mem: 11811M
[11/16 04:07:00] d2.utils.events INFO:  eta: 2:42:41  iter: 4079  total_loss: 0.3602  loss_cls: 0.1966  loss_box_reg: 0.1098  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.02162  time: 0.6729  data_time: 0.0717  lr: 0.004  max_mem: 11811M
[11/16 04:07:14] d2.utils.events INFO:  eta: 2:42:26  iter: 4099  total_loss: 0.3401  loss_cls: 0.1828  loss_box_reg: 0.1016  loss_rpn_cls: 0.02548  loss_rpn_loc: 0.01928  time: 0.6729  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 04:07:28] d2.utils.events INFO:  eta: 2:42:12  iter: 4119  total_loss: 0.3558  loss_cls: 0.197  loss_box_reg: 0.1056  loss_rpn_cls: 0.0298  loss_rpn_loc: 0.02277  time: 0.6729  data_time: 0.0597  lr: 0.004  max_mem: 11811M
[11/16 04:07:41] d2.utils.events INFO:  eta: 2:42:03  iter: 4139  total_loss: 0.3626  loss_cls: 0.1997  loss_box_reg: 0.1002  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.0232  time: 0.6730  data_time: 0.0647  lr: 0.004  max_mem: 11811M
[11/16 04:07:55] d2.utils.events INFO:  eta: 2:41:42  iter: 4159  total_loss: 0.3563  loss_cls: 0.1962  loss_box_reg: 0.1043  loss_rpn_cls: 0.02861  loss_rpn_loc: 0.0215  time: 0.6730  data_time: 0.0659  lr: 0.004  max_mem: 11811M
[11/16 04:08:08] d2.utils.events INFO:  eta: 2:41:27  iter: 4179  total_loss: 0.3568  loss_cls: 0.1994  loss_box_reg: 0.1069  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.02202  time: 0.6730  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 04:08:22] d2.utils.events INFO:  eta: 2:41:25  iter: 4199  total_loss: 0.3444  loss_cls: 0.1894  loss_box_reg: 0.1056  loss_rpn_cls: 0.02738  loss_rpn_loc: 0.02063  time: 0.6731  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 04:08:36] d2.utils.events INFO:  eta: 2:41:12  iter: 4219  total_loss: 0.3481  loss_cls: 0.1896  loss_box_reg: 0.1041  loss_rpn_cls: 0.02869  loss_rpn_loc: 0.01984  time: 0.6731  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 04:08:49] d2.utils.events INFO:  eta: 2:40:54  iter: 4239  total_loss: 0.3344  loss_cls: 0.189  loss_box_reg: 0.1026  loss_rpn_cls: 0.02793  loss_rpn_loc: 0.01866  time: 0.6731  data_time: 0.0626  lr: 0.004  max_mem: 11811M
[11/16 04:09:03] d2.utils.events INFO:  eta: 2:40:34  iter: 4259  total_loss: 0.3454  loss_cls: 0.1915  loss_box_reg: 0.1028  loss_rpn_cls: 0.03011  loss_rpn_loc: 0.02231  time: 0.6731  data_time: 0.0713  lr: 0.004  max_mem: 11811M
[11/16 04:09:16] d2.utils.events INFO:  eta: 2:40:35  iter: 4279  total_loss: 0.3275  loss_cls: 0.1811  loss_box_reg: 0.09893  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.01905  time: 0.6732  data_time: 0.0731  lr: 0.004  max_mem: 11811M
[11/16 04:09:30] d2.utils.events INFO:  eta: 2:40:06  iter: 4299  total_loss: 0.3271  loss_cls: 0.1805  loss_box_reg: 0.1006  loss_rpn_cls: 0.02947  loss_rpn_loc: 0.02189  time: 0.6731  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 04:09:43] d2.utils.events INFO:  eta: 2:39:52  iter: 4319  total_loss: 0.3421  loss_cls: 0.1879  loss_box_reg: 0.103  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.0216  time: 0.6732  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 04:09:57] d2.utils.events INFO:  eta: 2:39:39  iter: 4339  total_loss: 0.3491  loss_cls: 0.1878  loss_box_reg: 0.1045  loss_rpn_cls: 0.03144  loss_rpn_loc: 0.02149  time: 0.6732  data_time: 0.0616  lr: 0.004  max_mem: 11811M
[11/16 04:10:10] d2.utils.events INFO:  eta: 2:39:25  iter: 4359  total_loss: 0.3492  loss_cls: 0.1893  loss_box_reg: 0.1038  loss_rpn_cls: 0.02835  loss_rpn_loc: 0.02059  time: 0.6732  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/16 04:10:24] d2.utils.events INFO:  eta: 2:39:22  iter: 4379  total_loss: 0.3507  loss_cls: 0.1881  loss_box_reg: 0.0983  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.02324  time: 0.6732  data_time: 0.0701  lr: 0.004  max_mem: 11811M
[11/16 04:10:38] d2.utils.events INFO:  eta: 2:39:14  iter: 4399  total_loss: 0.3509  loss_cls: 0.1998  loss_box_reg: 0.1058  loss_rpn_cls: 0.02929  loss_rpn_loc: 0.01972  time: 0.6733  data_time: 0.0689  lr: 0.004  max_mem: 11811M
[11/16 04:10:51] d2.utils.events INFO:  eta: 2:39:03  iter: 4419  total_loss: 0.3479  loss_cls: 0.1826  loss_box_reg: 0.1036  loss_rpn_cls: 0.02742  loss_rpn_loc: 0.02301  time: 0.6733  data_time: 0.0621  lr: 0.004  max_mem: 11811M
[11/16 04:11:05] d2.utils.events INFO:  eta: 2:38:49  iter: 4439  total_loss: 0.3546  loss_cls: 0.1913  loss_box_reg: 0.1014  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.02211  time: 0.6734  data_time: 0.0880  lr: 0.004  max_mem: 11811M
[11/16 04:11:19] d2.utils.events INFO:  eta: 2:38:36  iter: 4459  total_loss: 0.3508  loss_cls: 0.196  loss_box_reg: 0.1048  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.02177  time: 0.6735  data_time: 0.0675  lr: 0.004  max_mem: 11811M
[11/16 04:11:33] d2.utils.events INFO:  eta: 2:38:24  iter: 4479  total_loss: 0.3277  loss_cls: 0.1838  loss_box_reg: 0.1025  loss_rpn_cls: 0.02629  loss_rpn_loc: 0.02292  time: 0.6735  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 04:11:46] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0004499.pth
[11/16 04:11:46] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:11:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:11:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:11:47] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:11:47] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:11:47] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:11:54] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:16
[11/16 04:11:59] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/16 04:12:04] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:05
[11/16 04:12:09] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/16 04:12:14] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/16 04:12:19] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/16 04:12:25] d2.evaluation.evaluator INFO: Inference done 743/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 04:12:30] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/16 04:12:35] d2.evaluation.evaluator INFO: Inference done 988/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/16 04:12:40] d2.evaluation.evaluator INFO: Inference done 1115/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:30
[11/16 04:12:45] d2.evaluation.evaluator INFO: Inference done 1238/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:25
[11/16 04:12:50] d2.evaluation.evaluator INFO: Inference done 1363/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/16 04:12:55] d2.evaluation.evaluator INFO: Inference done 1487/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/16 04:13:00] d2.evaluation.evaluator INFO: Inference done 1614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:10
[11/16 04:13:05] d2.evaluation.evaluator INFO: Inference done 1739/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:04
[11/16 04:13:10] d2.evaluation.evaluator INFO: Inference done 1865/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:59
[11/16 04:13:15] d2.evaluation.evaluator INFO: Inference done 1987/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:54
[11/16 04:13:20] d2.evaluation.evaluator INFO: Inference done 2114/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:49
[11/16 04:13:25] d2.evaluation.evaluator INFO: Inference done 2239/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:00:44
[11/16 04:13:30] d2.evaluation.evaluator INFO: Inference done 2359/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:39
[11/16 04:13:35] d2.evaluation.evaluator INFO: Inference done 2478/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:34
[11/16 04:13:40] d2.evaluation.evaluator INFO: Inference done 2602/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:29
[11/16 04:13:45] d2.evaluation.evaluator INFO: Inference done 2725/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:24
[11/16 04:13:50] d2.evaluation.evaluator INFO: Inference done 2849/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:19
[11/16 04:13:55] d2.evaluation.evaluator INFO: Inference done 2969/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:14
[11/16 04:14:00] d2.evaluation.evaluator INFO: Inference done 3094/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:09
[11/16 04:14:05] d2.evaluation.evaluator INFO: Inference done 3219/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:04
[11/16 04:14:10] d2.evaluation.evaluator INFO: Total inference time: 0:02:15.991594 (0.040851 s / iter per device, on 6 devices)
[11/16 04:14:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038900 s / iter per device, on 6 devices)
[11/16 04:14:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 04:14:12] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 04:14:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 04:14:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 04:14:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.58 seconds.
[11/16 04:14:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 04:14:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.50 seconds.
[11/16 04:14:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.231 | 0.720  | 0.089  | 0.007 | 0.116 | 0.268 |
[11/16 04:14:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.475  | bird                  | 1.892 |
| red panda            | 0.000 | dog         | 12.965 | snake                 | 0.508 |
| car                  | 1.974 | seal        | 0.000  | helmet                | 0.000 |
| motorcycle           | 0.297 | swine       | 0.000  | stove                 | 0.000 |
| monkey               | 0.368 | watercraft  | 0.708  | chair                 | 0.219 |
| domestic cat         | 0.351 | harp        | 0.000  | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000  | bus                   | 0.096 |
| hat with a wide brim | 0.000 | ski         | 0.000  | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000  | lobster               | 0.045 |
| bench                | 0.000 | rabbit      | 0.000  | porcupine             | 0.000 |
| butterfly            | 0.175 | guitar      | 0.023  | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000  | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000  | table                 | 0.041 |
| coffee maker         | 0.000 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000  | lemon                 | 0.000 |
| lizard               | 0.057 | backpack    | 0.000  | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000  | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.000  | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000  | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000  | miniskirt             | 0.000 |
| orange               | 1.370 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 1.089  | laptop                | 0.000 |
| pomegranate          | 0.187 | cucumber    | 0.000  | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000  | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.215 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 04:14:37] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 04:14:37] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 04:14:37] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 04:14:37] d2.evaluation.testing INFO: copypaste: 0.2306,0.7202,0.0894,0.0068,0.1160,0.2676
[11/16 04:14:37] d2.utils.events INFO:  eta: 2:38:12  iter: 4499  total_loss: 0.3489  loss_cls: 0.1883  loss_box_reg: 0.1026  loss_rpn_cls: 0.03091  loss_rpn_loc: 0.02195  time: 0.6735  data_time: 0.0614  lr: 0.004  max_mem: 11811M
[11/16 04:14:50] d2.utils.events INFO:  eta: 2:38:03  iter: 4519  total_loss: 0.3303  loss_cls: 0.1841  loss_box_reg: 0.1005  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.02045  time: 0.6735  data_time: 0.0710  lr: 0.004  max_mem: 11811M
[11/16 04:15:04] d2.utils.events INFO:  eta: 2:37:47  iter: 4539  total_loss: 0.3479  loss_cls: 0.192  loss_box_reg: 0.1048  loss_rpn_cls: 0.03145  loss_rpn_loc: 0.02294  time: 0.6735  data_time: 0.0582  lr: 0.004  max_mem: 11811M
[11/16 04:15:17] d2.utils.events INFO:  eta: 2:37:38  iter: 4559  total_loss: 0.3305  loss_cls: 0.1755  loss_box_reg: 0.0987  loss_rpn_cls: 0.02874  loss_rpn_loc: 0.02192  time: 0.6736  data_time: 0.0702  lr: 0.004  max_mem: 11811M
[11/16 04:15:31] d2.utils.events INFO:  eta: 2:37:22  iter: 4579  total_loss: 0.3492  loss_cls: 0.1942  loss_box_reg: 0.103  loss_rpn_cls: 0.02755  loss_rpn_loc: 0.02023  time: 0.6736  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 04:15:44] d2.utils.events INFO:  eta: 2:37:07  iter: 4599  total_loss: 0.3396  loss_cls: 0.1809  loss_box_reg: 0.1007  loss_rpn_cls: 0.03178  loss_rpn_loc: 0.01988  time: 0.6736  data_time: 0.0634  lr: 0.004  max_mem: 11811M
[11/16 04:15:58] d2.utils.events INFO:  eta: 2:36:54  iter: 4619  total_loss: 0.335  loss_cls: 0.1812  loss_box_reg: 0.09906  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.02079  time: 0.6736  data_time: 0.0622  lr: 0.004  max_mem: 11811M
[11/16 04:16:11] d2.utils.events INFO:  eta: 2:36:37  iter: 4639  total_loss: 0.3346  loss_cls: 0.1858  loss_box_reg: 0.09579  loss_rpn_cls: 0.03071  loss_rpn_loc: 0.02218  time: 0.6736  data_time: 0.0725  lr: 0.004  max_mem: 11811M
[11/16 04:16:25] d2.utils.events INFO:  eta: 2:36:18  iter: 4659  total_loss: 0.3329  loss_cls: 0.182  loss_box_reg: 0.1024  loss_rpn_cls: 0.02944  loss_rpn_loc: 0.02222  time: 0.6736  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/16 04:16:39] d2.utils.events INFO:  eta: 2:36:09  iter: 4679  total_loss: 0.3301  loss_cls: 0.1792  loss_box_reg: 0.1011  loss_rpn_cls: 0.02707  loss_rpn_loc: 0.02204  time: 0.6738  data_time: 0.1017  lr: 0.004  max_mem: 11811M
[11/16 04:16:53] d2.utils.events INFO:  eta: 2:35:52  iter: 4699  total_loss: 0.327  loss_cls: 0.1824  loss_box_reg: 0.1013  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.02208  time: 0.6738  data_time: 0.0717  lr: 0.004  max_mem: 11811M
[11/16 04:17:06] d2.utils.events INFO:  eta: 2:35:38  iter: 4719  total_loss: 0.3531  loss_cls: 0.1937  loss_box_reg: 0.1041  loss_rpn_cls: 0.03214  loss_rpn_loc: 0.02126  time: 0.6738  data_time: 0.0646  lr: 0.004  max_mem: 11811M
[11/16 04:17:20] d2.utils.events INFO:  eta: 2:35:28  iter: 4739  total_loss: 0.3276  loss_cls: 0.1808  loss_box_reg: 0.1015  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.0203  time: 0.6739  data_time: 0.0691  lr: 0.004  max_mem: 11811M
[11/16 04:17:34] d2.utils.events INFO:  eta: 2:35:18  iter: 4759  total_loss: 0.3396  loss_cls: 0.1893  loss_box_reg: 0.1021  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.02109  time: 0.6739  data_time: 0.0677  lr: 0.004  max_mem: 11811M
[11/16 04:17:47] d2.utils.events INFO:  eta: 2:35:04  iter: 4779  total_loss: 0.3519  loss_cls: 0.1981  loss_box_reg: 0.1021  loss_rpn_cls: 0.02776  loss_rpn_loc: 0.02268  time: 0.6739  data_time: 0.0604  lr: 0.004  max_mem: 11811M
[11/16 04:18:01] d2.utils.events INFO:  eta: 2:34:51  iter: 4799  total_loss: 0.3433  loss_cls: 0.1878  loss_box_reg: 0.1052  loss_rpn_cls: 0.02611  loss_rpn_loc: 0.02144  time: 0.6740  data_time: 0.0806  lr: 0.004  max_mem: 11811M
[11/16 04:18:15] d2.utils.events INFO:  eta: 2:34:40  iter: 4819  total_loss: 0.3382  loss_cls: 0.1824  loss_box_reg: 0.09798  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.02225  time: 0.6741  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 04:18:28] d2.utils.events INFO:  eta: 2:34:24  iter: 4839  total_loss: 0.3346  loss_cls: 0.1884  loss_box_reg: 0.1022  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.02095  time: 0.6741  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 04:18:42] d2.utils.events INFO:  eta: 2:34:12  iter: 4859  total_loss: 0.3278  loss_cls: 0.1814  loss_box_reg: 0.1002  loss_rpn_cls: 0.02785  loss_rpn_loc: 0.02064  time: 0.6741  data_time: 0.0717  lr: 0.004  max_mem: 11811M
[11/16 04:18:56] d2.utils.events INFO:  eta: 2:33:58  iter: 4879  total_loss: 0.3425  loss_cls: 0.1858  loss_box_reg: 0.1052  loss_rpn_cls: 0.02598  loss_rpn_loc: 0.0201  time: 0.6741  data_time: 0.0626  lr: 0.004  max_mem: 11811M
[11/16 04:19:09] d2.utils.events INFO:  eta: 2:33:43  iter: 4899  total_loss: 0.3161  loss_cls: 0.1708  loss_box_reg: 0.09705  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.01916  time: 0.6742  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 04:19:23] d2.utils.events INFO:  eta: 2:33:30  iter: 4919  total_loss: 0.34  loss_cls: 0.1896  loss_box_reg: 0.1013  loss_rpn_cls: 0.03078  loss_rpn_loc: 0.0213  time: 0.6742  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 04:19:36] d2.utils.events INFO:  eta: 2:33:18  iter: 4939  total_loss: 0.3325  loss_cls: 0.1811  loss_box_reg: 0.1005  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.02086  time: 0.6742  data_time: 0.0613  lr: 0.004  max_mem: 11811M
[11/16 04:19:50] d2.utils.events INFO:  eta: 2:33:16  iter: 4959  total_loss: 0.3266  loss_cls: 0.1751  loss_box_reg: 0.09881  loss_rpn_cls: 0.02896  loss_rpn_loc: 0.02181  time: 0.6743  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 04:20:04] d2.utils.events INFO:  eta: 2:32:59  iter: 4979  total_loss: 0.3338  loss_cls: 0.1826  loss_box_reg: 0.1011  loss_rpn_cls: 0.02848  loss_rpn_loc: 0.02172  time: 0.6743  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 04:20:17] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0004999.pth
[11/16 04:20:18] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:20:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:20:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:20:18] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:20:18] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:20:19] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:20:26] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:14
[11/16 04:20:31] d2.evaluation.evaluator INFO: Inference done 136/3334. Dataloading: 0.0015 s/iter. Inference: 0.0384 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:08
[11/16 04:20:36] d2.evaluation.evaluator INFO: Inference done 261/3334. Dataloading: 0.0015 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:03
[11/16 04:20:41] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:00
[11/16 04:20:46] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/16 04:20:51] d2.evaluation.evaluator INFO: Inference done 622/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/16 04:20:56] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/16 04:21:01] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:41
[11/16 04:21:06] d2.evaluation.evaluator INFO: Inference done 986/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/16 04:21:11] d2.evaluation.evaluator INFO: Inference done 1106/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/16 04:21:16] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/16 04:21:21] d2.evaluation.evaluator INFO: Inference done 1350/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/16 04:21:26] d2.evaluation.evaluator INFO: Inference done 1470/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:16
[11/16 04:21:31] d2.evaluation.evaluator INFO: Inference done 1593/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/16 04:21:36] d2.evaluation.evaluator INFO: Inference done 1712/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:06
[11/16 04:21:41] d2.evaluation.evaluator INFO: Inference done 1832/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:02
[11/16 04:21:46] d2.evaluation.evaluator INFO: Inference done 1955/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/16 04:21:51] d2.evaluation.evaluator INFO: Inference done 2079/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/16 04:21:56] d2.evaluation.evaluator INFO: Inference done 2201/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/16 04:22:01] d2.evaluation.evaluator INFO: Inference done 2323/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 04:22:06] d2.evaluation.evaluator INFO: Inference done 2441/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/16 04:22:11] d2.evaluation.evaluator INFO: Inference done 2565/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/16 04:22:16] d2.evaluation.evaluator INFO: Inference done 2686/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 04:22:21] d2.evaluation.evaluator INFO: Inference done 2804/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 04:22:26] d2.evaluation.evaluator INFO: Inference done 2923/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/16 04:22:31] d2.evaluation.evaluator INFO: Inference done 3044/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:11
[11/16 04:22:36] d2.evaluation.evaluator INFO: Inference done 3166/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:06
[11/16 04:22:41] d2.evaluation.evaluator INFO: Inference done 3287/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:01
[11/16 04:22:43] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.202470 (0.041515 s / iter per device, on 6 devices)
[11/16 04:22:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039557 s / iter per device, on 6 devices)
[11/16 04:22:46] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 04:22:46] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 04:22:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 04:22:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 04:23:09] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.89 seconds.
[11/16 04:23:09] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 04:23:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.68 seconds.
[11/16 04:23:11] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.226 | 0.770  | 0.070  | 0.001 | 0.126 | 0.239 |
[11/16 04:23:11] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.032 | person      | 0.404  | bird                  | 1.767 |
| red panda            | 0.000 | dog         | 11.471 | snake                 | 0.677 |
| car                  | 2.122 | seal        | 0.000  | helmet                | 0.000 |
| motorcycle           | 0.022 | swine       | 0.000  | stove                 | 0.000 |
| monkey               | 0.719 | watercraft  | 0.891  | chair                 | 0.085 |
| domestic cat         | 0.199 | harp        | 0.000  | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000  | bus                   | 0.622 |
| hat with a wide brim | 0.000 | ski         | 0.000  | piano                 | 0.062 |
| frog                 | 0.000 | dumbbell    | 0.000  | lobster               | 0.182 |
| bench                | 0.000 | rabbit      | 0.000  | porcupine             | 0.000 |
| butterfly            | 0.320 | guitar      | 0.004  | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.000  | hippopotamus          | 0.000 |
| bowl                 | 0.000 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.000 | otter       | 0.000  | table                 | 0.096 |
| coffee maker         | 0.000 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000  | lemon                 | 0.392 |
| lizard               | 0.193 | backpack    | 0.000  | tv or monitor         | 0.000 |
| cup or mug           | 0.000 | sheep       | 0.000  | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 1.176  | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 0.000 |
| cream                | 0.000 | artichoke   | 0.000  | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000  | miniskirt             | 0.000 |
| orange               | 0.610 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.221  | laptop                | 0.000 |
| pomegranate          | 0.247 | cucumber    | 0.000  | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000  | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.093 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 04:23:13] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 04:23:13] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 04:23:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 04:23:13] d2.evaluation.testing INFO: copypaste: 0.2261,0.7705,0.0703,0.0007,0.1262,0.2390
[11/16 04:23:13] d2.utils.events INFO:  eta: 2:32:49  iter: 4999  total_loss: 0.3425  loss_cls: 0.187  loss_box_reg: 0.101  loss_rpn_cls: 0.029  loss_rpn_loc: 0.02158  time: 0.6743  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 04:23:27] d2.utils.events INFO:  eta: 2:32:26  iter: 5019  total_loss: 0.3284  loss_cls: 0.1782  loss_box_reg: 0.09728  loss_rpn_cls: 0.02793  loss_rpn_loc: 0.02161  time: 0.6743  data_time: 0.0635  lr: 0.004  max_mem: 11811M
[11/16 04:23:40] d2.utils.events INFO:  eta: 2:32:23  iter: 5039  total_loss: 0.3356  loss_cls: 0.1857  loss_box_reg: 0.1044  loss_rpn_cls: 0.02748  loss_rpn_loc: 0.02011  time: 0.6744  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 04:23:54] d2.utils.events INFO:  eta: 2:32:08  iter: 5059  total_loss: 0.3439  loss_cls: 0.1848  loss_box_reg: 0.1022  loss_rpn_cls: 0.02878  loss_rpn_loc: 0.02331  time: 0.6744  data_time: 0.0749  lr: 0.004  max_mem: 11811M
[11/16 04:24:08] d2.utils.events INFO:  eta: 2:31:57  iter: 5079  total_loss: 0.3281  loss_cls: 0.1773  loss_box_reg: 0.09834  loss_rpn_cls: 0.02652  loss_rpn_loc: 0.02071  time: 0.6744  data_time: 0.0707  lr: 0.004  max_mem: 11811M
[11/16 04:24:21] d2.utils.events INFO:  eta: 2:31:43  iter: 5099  total_loss: 0.3461  loss_cls: 0.1898  loss_box_reg: 0.1016  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.02232  time: 0.6745  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 04:24:35] d2.utils.events INFO:  eta: 2:31:29  iter: 5119  total_loss: 0.3264  loss_cls: 0.174  loss_box_reg: 0.1005  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.02116  time: 0.6744  data_time: 0.0652  lr: 0.004  max_mem: 11811M
[11/16 04:24:49] d2.utils.events INFO:  eta: 2:31:15  iter: 5139  total_loss: 0.3455  loss_cls: 0.1913  loss_box_reg: 0.106  loss_rpn_cls: 0.0258  loss_rpn_loc: 0.02144  time: 0.6745  data_time: 0.0728  lr: 0.004  max_mem: 11811M
[11/16 04:25:02] d2.utils.events INFO:  eta: 2:31:03  iter: 5159  total_loss: 0.3252  loss_cls: 0.1793  loss_box_reg: 0.09755  loss_rpn_cls: 0.02745  loss_rpn_loc: 0.02089  time: 0.6745  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 04:25:16] d2.utils.events INFO:  eta: 2:30:48  iter: 5179  total_loss: 0.3379  loss_cls: 0.1829  loss_box_reg: 0.1047  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.02082  time: 0.6745  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 04:25:29] d2.utils.events INFO:  eta: 2:30:31  iter: 5199  total_loss: 0.3559  loss_cls: 0.1995  loss_box_reg: 0.1067  loss_rpn_cls: 0.03049  loss_rpn_loc: 0.02335  time: 0.6745  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 04:25:43] d2.utils.events INFO:  eta: 2:30:21  iter: 5219  total_loss: 0.335  loss_cls: 0.1883  loss_box_reg: 0.1009  loss_rpn_cls: 0.02712  loss_rpn_loc: 0.02114  time: 0.6746  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 04:25:57] d2.utils.events INFO:  eta: 2:30:08  iter: 5239  total_loss: 0.3384  loss_cls: 0.1846  loss_box_reg: 0.1022  loss_rpn_cls: 0.03016  loss_rpn_loc: 0.02103  time: 0.6746  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 04:26:10] d2.utils.events INFO:  eta: 2:29:54  iter: 5259  total_loss: 0.3225  loss_cls: 0.1726  loss_box_reg: 0.09544  loss_rpn_cls: 0.0303  loss_rpn_loc: 0.0192  time: 0.6746  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 04:26:24] d2.utils.events INFO:  eta: 2:29:40  iter: 5279  total_loss: 0.3394  loss_cls: 0.1865  loss_box_reg: 0.09954  loss_rpn_cls: 0.02837  loss_rpn_loc: 0.02295  time: 0.6746  data_time: 0.0617  lr: 0.004  max_mem: 11811M
[11/16 04:26:37] d2.utils.events INFO:  eta: 2:29:31  iter: 5299  total_loss: 0.3155  loss_cls: 0.1702  loss_box_reg: 0.09632  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.01945  time: 0.6746  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 04:26:51] d2.utils.events INFO:  eta: 2:29:16  iter: 5319  total_loss: 0.3286  loss_cls: 0.1816  loss_box_reg: 0.09885  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.02084  time: 0.6746  data_time: 0.0627  lr: 0.004  max_mem: 11811M
[11/16 04:27:04] d2.utils.events INFO:  eta: 2:29:06  iter: 5339  total_loss: 0.3167  loss_cls: 0.1736  loss_box_reg: 0.09526  loss_rpn_cls: 0.02617  loss_rpn_loc: 0.02115  time: 0.6747  data_time: 0.0672  lr: 0.004  max_mem: 11811M
[11/16 04:27:18] d2.utils.events INFO:  eta: 2:28:59  iter: 5359  total_loss: 0.3377  loss_cls: 0.1839  loss_box_reg: 0.1002  loss_rpn_cls: 0.02979  loss_rpn_loc: 0.02106  time: 0.6747  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 04:27:32] d2.utils.events INFO:  eta: 2:28:42  iter: 5379  total_loss: 0.3442  loss_cls: 0.1871  loss_box_reg: 0.1032  loss_rpn_cls: 0.02915  loss_rpn_loc: 0.019  time: 0.6748  data_time: 0.0872  lr: 0.004  max_mem: 11811M
[11/16 04:27:46] d2.utils.events INFO:  eta: 2:28:29  iter: 5399  total_loss: 0.3252  loss_cls: 0.1793  loss_box_reg: 0.1011  loss_rpn_cls: 0.02835  loss_rpn_loc: 0.02058  time: 0.6748  data_time: 0.0692  lr: 0.004  max_mem: 11811M
[11/16 04:28:00] d2.utils.events INFO:  eta: 2:28:12  iter: 5419  total_loss: 0.3263  loss_cls: 0.1828  loss_box_reg: 0.1033  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.02064  time: 0.6749  data_time: 0.0634  lr: 0.004  max_mem: 11811M
[11/16 04:28:13] d2.utils.events INFO:  eta: 2:28:02  iter: 5439  total_loss: 0.3296  loss_cls: 0.176  loss_box_reg: 0.09777  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.02042  time: 0.6749  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 04:28:27] d2.utils.events INFO:  eta: 2:27:46  iter: 5459  total_loss: 0.3359  loss_cls: 0.1806  loss_box_reg: 0.09787  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.02389  time: 0.6749  data_time: 0.0694  lr: 0.004  max_mem: 11811M
[11/16 04:28:40] d2.utils.events INFO:  eta: 2:27:31  iter: 5479  total_loss: 0.3305  loss_cls: 0.1826  loss_box_reg: 0.101  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.01913  time: 0.6749  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 04:28:54] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0005499.pth
[11/16 04:28:54] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:28:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:28:55] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:28:55] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:28:55] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:28:55] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:29:02] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:15
[11/16 04:29:07] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:12
[11/16 04:29:12] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/16 04:29:17] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/16 04:29:22] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/16 04:29:27] d2.evaluation.evaluator INFO: Inference done 619/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 04:29:32] d2.evaluation.evaluator INFO: Inference done 739/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/16 04:29:37] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/16 04:29:42] d2.evaluation.evaluator INFO: Inference done 985/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:36
[11/16 04:29:47] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/16 04:29:52] d2.evaluation.evaluator INFO: Inference done 1224/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/16 04:29:57] d2.evaluation.evaluator INFO: Inference done 1343/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/16 04:30:02] d2.evaluation.evaluator INFO: Inference done 1465/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/16 04:30:07] d2.evaluation.evaluator INFO: Inference done 1585/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/16 04:30:12] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/16 04:30:17] d2.evaluation.evaluator INFO: Inference done 1829/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/16 04:30:22] d2.evaluation.evaluator INFO: Inference done 1949/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/16 04:30:27] d2.evaluation.evaluator INFO: Inference done 2073/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:52
[11/16 04:30:32] d2.evaluation.evaluator INFO: Inference done 2195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/16 04:30:37] d2.evaluation.evaluator INFO: Inference done 2315/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/16 04:30:42] d2.evaluation.evaluator INFO: Inference done 2435/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/16 04:30:47] d2.evaluation.evaluator INFO: Inference done 2557/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/16 04:30:52] d2.evaluation.evaluator INFO: Inference done 2674/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/16 04:30:57] d2.evaluation.evaluator INFO: Inference done 2793/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/16 04:31:02] d2.evaluation.evaluator INFO: Inference done 2915/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/16 04:31:07] d2.evaluation.evaluator INFO: Inference done 3037/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/16 04:31:12] d2.evaluation.evaluator INFO: Inference done 3158/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/16 04:31:17] d2.evaluation.evaluator INFO: Inference done 3279/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/16 04:31:20] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.398983 (0.041574 s / iter per device, on 6 devices)
[11/16 04:31:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039680 s / iter per device, on 6 devices)
[11/16 04:31:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 04:31:21] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 04:31:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 04:31:22] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 04:31:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 18.65 seconds.
[11/16 04:31:41] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 04:31:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.42 seconds.
[11/16 04:31:43] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.298 | 0.837  | 0.166  | 0.002 | 0.132 | 0.336 |
[11/16 04:31:43] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.000 | person      | 0.414  | bird                  | 2.512 |
| red panda            | 0.000 | dog         | 14.693 | snake                 | 1.557 |
| car                  | 1.686 | seal        | 0.000  | helmet                | 0.000 |
| motorcycle           | 0.000 | swine       | 0.000  | stove                 | 0.000 |
| monkey               | 1.256 | watercraft  | 1.508  | chair                 | 0.104 |
| domestic cat         | 0.094 | harp        | 0.000  | antelope              | 0.000 |
| camel                | 0.000 | koala bear  | 0.000  | bus                   | 0.308 |
| hat with a wide brim | 0.000 | ski         | 0.000  | piano                 | 0.000 |
| frog                 | 0.000 | dumbbell    | 0.000  | lobster               | 0.000 |
| bench                | 0.000 | rabbit      | 0.000  | porcupine             | 0.000 |
| butterfly            | 0.656 | guitar      | 0.000  | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.297  | hippopotamus          | 0.000 |
| bowl                 | 0.017 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.080 | otter       | 0.000  | table                 | 0.249 |
| coffee maker         | 0.297 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000  | lemon                 | 0.389 |
| lizard               | 0.209 | backpack    | 0.000  | tv or monitor         | 0.099 |
| cup or mug           | 0.000 | sheep       | 0.000  | ray                   | 0.000 |
| fox                  | 0.144 | whale       | 0.000  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 0.957  | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 0.096 |
| cream                | 0.000 | artichoke   | 0.000  | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000  | miniskirt             | 0.000 |
| orange               | 1.709 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.159  | laptop                | 0.000 |
| pomegranate          | 0.069 | cucumber    | 0.000  | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000  | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.233 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 04:31:45] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 04:31:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 04:31:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 04:31:45] d2.evaluation.testing INFO: copypaste: 0.2979,0.8365,0.1657,0.0020,0.1316,0.3365
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 04:44:54] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=True, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/16 04:44:54] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: ""
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (28000, 34000)
  MAX_ITER: 37000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 500
  BASE_LR: 0.01
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.0001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: "exponential"
TEST:
  EVAL_PERIOD: 500
OUTPUT_DIR: "../../output/supervised"
[11/16 04:44:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ''
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 37000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 28000
  - 34000
  WARMUP_FACTOR: 0.0001
  WARMUP_ITERS: 2000
  WARMUP_METHOD: exponential
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 500
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/16 04:44:54] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/16 04:44:54] d2.utils.env INFO: Using a generated random seed 56124812
[11/16 04:44:56] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/16 04:44:56] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/16 04:44:56] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/16 04:44:57] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 281          |   person    | 4657         |     bird      | 4331         |
|   red panda   | 108          |     dog     | 8341         |     snake     | 1001         |
|      car      | 1171         |    seal     | 224          |    helmet     | 433          |
|  motorcycle   | 278          |    swine    | 259          |     stove     | 156          |
|    monkey     | 1004         | watercraft  | 1038         |     chair     | 905          |
| domestic cat  | 395          |    harp     | 152          |   antelope    | 288          |
|     camel     | 276          | koala bear  | 139          |      bus      | 322          |
| hat with a .. | 206          |     ski     | 109          |     piano     | 199          |
|     frog      | 245          |  dumbbell   | 180          |    lobster    | 253          |
|     bench     | 150          |   rabbit    | 235          |   porcupine   | 126          |
|   butterfly   | 453          |   guitar    | 295          |  microphone   | 259          |
|  tape player  | 109          |    bear     | 361          | hippopotamus  | 118          |
|     bowl      | 335          |     axe     | 127          |     skunk     | 99           |
|   airplane    | 217          |    otter    | 127          |     table     | 786          |
| coffee maker  | 143          |     tie     | 124          |    turtle     | 313          |
|     purse     | 130          |  dragonfly  | 175          |     lemon     | 170          |
|    lizard     | 640          |  backpack   | 148          | tv or monitor | 212          |
|  cup or mug   | 283          |    sheep    | 196          |      ray      | 198          |
|      fox      | 292          |    whale    | 155          | salt or pep.. | 129          |
| computer ke.. | 102          |     fig     | 133          |  bathing cap  | 163          |
|   bookshelf   | 106          |   ladybug   | 138          |    crutch     | 138          |
|    pretzel    | 124          | sunglasses  | 243          |   starfish    | 130          |
| croquet ball  | 135          |    lamp     | 319          |     apple     | 216          |
|     cream     | 194          |  artichoke  | 180          |     train     | 178          |
|   elephant    | 242          | bell pepper | 146          |   miniskirt   | 118          |
|    orange     | 207          |    tiger    | 159          |     sofa      | 160          |
|     horse     | 265          |   violin    | 118          | traffic light | 142          |
|     drum      | 251          | strawberry  | 232          |    laptop     | 172          |
|  pomegranate  | 188          |  cucumber   | 114          |    bicycle    | 187          |
|    banana     | 244          |  baby bed   | 185          |   jellyfish   | 184          |
|    pitcher    | 120          |    bagel    | 125          |    beaker     | 115          |
|   goldfish    | 228          |    nail     | 86           |   mushroom    | 124          |
|  flower pot   | 189          |   cattle    | 148          |     zebra     | 135          |
|  wine bottle  | 154          |             |              |               |              |
|     total     | 41293        |             |              |               |              |[0m
[11/16 04:44:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/16 04:44:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/16 04:44:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:44:58] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/16 04:44:58] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/16 04:44:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_0005499.pth ...
[11/16 04:44:58] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/16 04:44:58] fvcore.common.checkpoint INFO: Loading trainer from ../../output/supervised/model_0005499.pth ...
[11/16 04:44:58] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/16 04:45:00] d2.engine.train_loop INFO: Starting training from iteration 5500
[11/16 04:45:22] d2.utils.events INFO:  eta: 5:50:57  iter: 5519  total_loss: 0.3326  loss_cls: 0.1783  loss_box_reg: 0.09897  loss_rpn_cls: 0.02489  loss_rpn_loc: 0.0207  time: 0.6683  data_time: 0.4218  lr: 0.004  max_mem: 11811M
[11/16 04:45:35] d2.utils.events INFO:  eta: 5:53:12  iter: 5539  total_loss: 0.3352  loss_cls: 0.1863  loss_box_reg: 0.09991  loss_rpn_cls: 0.03009  loss_rpn_loc: 0.02139  time: 0.6744  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 04:45:49] d2.utils.events INFO:  eta: 5:54:40  iter: 5559  total_loss: 0.3483  loss_cls: 0.1898  loss_box_reg: 0.1053  loss_rpn_cls: 0.02797  loss_rpn_loc: 0.02058  time: 0.6758  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 04:46:03] d2.utils.events INFO:  eta: 5:54:50  iter: 5579  total_loss: 0.3197  loss_cls: 0.1755  loss_box_reg: 0.09899  loss_rpn_cls: 0.02604  loss_rpn_loc: 0.02067  time: 0.6767  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/16 04:46:16] d2.utils.events INFO:  eta: 5:54:51  iter: 5599  total_loss: 0.3277  loss_cls: 0.183  loss_box_reg: 0.101  loss_rpn_cls: 0.02759  loss_rpn_loc: 0.01937  time: 0.6794  data_time: 0.0717  lr: 0.004  max_mem: 11811M
[11/16 04:46:30] d2.utils.events INFO:  eta: 5:54:34  iter: 5619  total_loss: 0.3389  loss_cls: 0.1824  loss_box_reg: 0.09964  loss_rpn_cls: 0.0278  loss_rpn_loc: 0.0196  time: 0.6825  data_time: 0.1012  lr: 0.004  max_mem: 11811M
[11/16 04:46:44] d2.utils.events INFO:  eta: 5:53:46  iter: 5639  total_loss: 0.3234  loss_cls: 0.1739  loss_box_reg: 0.102  loss_rpn_cls: 0.02829  loss_rpn_loc: 0.01978  time: 0.6805  data_time: 0.0626  lr: 0.004  max_mem: 11811M
[11/16 04:46:57] d2.utils.events INFO:  eta: 5:53:56  iter: 5659  total_loss: 0.3418  loss_cls: 0.1811  loss_box_reg: 0.1029  loss_rpn_cls: 0.02947  loss_rpn_loc: 0.02299  time: 0.6805  data_time: 0.0626  lr: 0.004  max_mem: 11811M
[11/16 04:47:11] d2.utils.events INFO:  eta: 5:54:12  iter: 5679  total_loss: 0.3378  loss_cls: 0.1839  loss_box_reg: 0.1028  loss_rpn_cls: 0.02577  loss_rpn_loc: 0.02334  time: 0.6813  data_time: 0.0698  lr: 0.004  max_mem: 11811M
[11/16 04:47:25] d2.utils.events INFO:  eta: 5:54:11  iter: 5699  total_loss: 0.3024  loss_cls: 0.1666  loss_box_reg: 0.09379  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.01922  time: 0.6819  data_time: 0.0787  lr: 0.004  max_mem: 11811M
[11/16 04:47:39] d2.utils.events INFO:  eta: 5:53:45  iter: 5719  total_loss: 0.3173  loss_cls: 0.1729  loss_box_reg: 0.1035  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.01989  time: 0.6818  data_time: 0.0701  lr: 0.004  max_mem: 11811M
[11/16 04:47:52] d2.utils.events INFO:  eta: 5:53:24  iter: 5739  total_loss: 0.3303  loss_cls: 0.1822  loss_box_reg: 0.1026  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.02037  time: 0.6822  data_time: 0.0768  lr: 0.004  max_mem: 11811M
[11/16 04:48:06] d2.utils.events INFO:  eta: 5:52:57  iter: 5759  total_loss: 0.3396  loss_cls: 0.1815  loss_box_reg: 0.1048  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.01945  time: 0.6813  data_time: 0.0646  lr: 0.004  max_mem: 11811M
[11/16 04:48:19] d2.utils.events INFO:  eta: 5:52:50  iter: 5779  total_loss: 0.338  loss_cls: 0.185  loss_box_reg: 0.103  loss_rpn_cls: 0.02891  loss_rpn_loc: 0.02186  time: 0.6812  data_time: 0.0609  lr: 0.004  max_mem: 11811M
[11/16 04:48:33] d2.utils.events INFO:  eta: 5:52:43  iter: 5799  total_loss: 0.3362  loss_cls: 0.183  loss_box_reg: 0.09676  loss_rpn_cls: 0.02902  loss_rpn_loc: 0.02174  time: 0.6822  data_time: 0.0789  lr: 0.004  max_mem: 11811M
[11/16 04:48:47] d2.utils.events INFO:  eta: 5:52:44  iter: 5819  total_loss: 0.3377  loss_cls: 0.1818  loss_box_reg: 0.1032  loss_rpn_cls: 0.02429  loss_rpn_loc: 0.02148  time: 0.6820  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 04:49:00] d2.utils.events INFO:  eta: 5:52:03  iter: 5839  total_loss: 0.3416  loss_cls: 0.1895  loss_box_reg: 0.102  loss_rpn_cls: 0.02895  loss_rpn_loc: 0.01854  time: 0.6813  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 04:49:14] d2.utils.events INFO:  eta: 5:52:03  iter: 5859  total_loss: 0.3542  loss_cls: 0.1919  loss_box_reg: 0.1056  loss_rpn_cls: 0.02938  loss_rpn_loc: 0.02154  time: 0.6813  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 04:49:27] d2.utils.events INFO:  eta: 5:51:53  iter: 5879  total_loss: 0.3171  loss_cls: 0.1738  loss_box_reg: 0.09776  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.01988  time: 0.6811  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 04:49:41] d2.utils.events INFO:  eta: 5:51:22  iter: 5899  total_loss: 0.308  loss_cls: 0.1693  loss_box_reg: 0.09355  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.01928  time: 0.6805  data_time: 0.0669  lr: 0.004  max_mem: 11811M
[11/16 04:49:55] d2.utils.events INFO:  eta: 5:51:22  iter: 5919  total_loss: 0.3473  loss_cls: 0.1903  loss_box_reg: 0.1082  loss_rpn_cls: 0.02796  loss_rpn_loc: 0.02073  time: 0.6807  data_time: 0.0635  lr: 0.004  max_mem: 11811M
[11/16 04:50:08] d2.utils.events INFO:  eta: 5:51:12  iter: 5939  total_loss: 0.3212  loss_cls: 0.1761  loss_box_reg: 0.09764  loss_rpn_cls: 0.02484  loss_rpn_loc: 0.01926  time: 0.6806  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 04:50:22] d2.utils.events INFO:  eta: 5:51:05  iter: 5959  total_loss: 0.329  loss_cls: 0.183  loss_box_reg: 0.09914  loss_rpn_cls: 0.02713  loss_rpn_loc: 0.02127  time: 0.6807  data_time: 0.0691  lr: 0.004  max_mem: 11811M
[11/16 04:50:36] d2.utils.events INFO:  eta: 5:50:56  iter: 5979  total_loss: 0.3409  loss_cls: 0.1852  loss_box_reg: 0.1001  loss_rpn_cls: 0.03017  loss_rpn_loc: 0.02333  time: 0.6814  data_time: 0.0765  lr: 0.004  max_mem: 11811M
[11/16 04:50:49] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0005999.pth
[11/16 04:50:50] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:50:51] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 211          |   person    | 3096         |     bird      | 2810         |
|   red panda   | 61           |     dog     | 5631         |     snake     | 664          |
|      car      | 768          |    seal     | 120          |    helmet     | 237          |
|  motorcycle   | 224          |    swine    | 159          |     stove     | 110          |
|    monkey     | 683          | watercraft  | 686          |     chair     | 578          |
| domestic cat  | 290          |    harp     | 118          |   antelope    | 173          |
|     camel     | 138          | koala bear  | 71           |      bus      | 257          |
| hat with a .. | 160          |     ski     | 104          |     piano     | 128          |
|     frog      | 164          |  dumbbell   | 104          |    lobster    | 151          |
|     bench     | 107          |   rabbit    | 159          |   porcupine   | 73           |
|   butterfly   | 302          |   guitar    | 189          |  microphone   | 174          |
|  tape player  | 81           |    bear     | 205          | hippopotamus  | 82           |
|     bowl      | 202          |     axe     | 107          |     skunk     | 88           |
|   airplane    | 128          |    otter    | 74           |     table     | 496          |
| coffee maker  | 94           |     tie     | 91           |    turtle     | 206          |
|     purse     | 124          |  dragonfly  | 119          |     lemon     | 95           |
|    lizard     | 420          |  backpack   | 110          | tv or monitor | 165          |
|  cup or mug   | 200          |    sheep    | 149          |      ray      | 192          |
|      fox      | 195          |    whale    | 113          | salt or pep.. | 68           |
| computer ke.. | 66           |     fig     | 92           |  bathing cap  | 153          |
|   bookshelf   | 68           |   ladybug   | 85           |    crutch     | 75           |
|    pretzel    | 108          | sunglasses  | 145          |   starfish    | 92           |
| croquet ball  | 85           |    lamp     | 190          |     apple     | 145          |
|     cream     | 120          |  artichoke  | 96           |     train     | 89           |
|   elephant    | 159          | bell pepper | 98           |   miniskirt   | 73           |
|    orange     | 151          |    tiger    | 76           |     sofa      | 127          |
|     horse     | 171          |   violin    | 84           | traffic light | 109          |
|     drum      | 175          | strawberry  | 162          |    laptop     | 84           |
|  pomegranate  | 114          |  cucumber   | 67           |    bicycle    | 132          |
|    banana     | 169          |  baby bed   | 134          |   jellyfish   | 103          |
|    pitcher    | 95           |    bagel    | 76           |    beaker     | 85           |
|   goldfish    | 159          |    nail     | 91           |   mushroom    | 146          |
|  flower pot   | 113          |   cattle    | 92           |     zebra     | 97           |
|  wine bottle  | 129          |             |              |               |              |
|     total     | 27584        |             |              |               |              |[0m
[11/16 04:50:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:50:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:50:51] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:50:51] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:50:51] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:50:58] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:18
[11/16 04:51:03] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/16 04:51:08] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/16 04:51:13] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:02
[11/16 04:51:18] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/16 04:51:23] d2.evaluation.evaluator INFO: Inference done 621/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/16 04:51:28] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:46
[11/16 04:51:33] d2.evaluation.evaluator INFO: Inference done 867/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/16 04:51:38] d2.evaluation.evaluator INFO: Inference done 989/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/16 04:51:43] d2.evaluation.evaluator INFO: Inference done 1110/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/16 04:51:48] d2.evaluation.evaluator INFO: Inference done 1236/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:26
[11/16 04:51:53] d2.evaluation.evaluator INFO: Inference done 1362/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/16 04:51:58] d2.evaluation.evaluator INFO: Inference done 1484/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/16 04:52:03] d2.evaluation.evaluator INFO: Inference done 1607/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/16 04:52:08] d2.evaluation.evaluator INFO: Inference done 1728/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:05
[11/16 04:52:13] d2.evaluation.evaluator INFO: Inference done 1850/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:00
[11/16 04:52:18] d2.evaluation.evaluator INFO: Inference done 1974/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:55
[11/16 04:52:23] d2.evaluation.evaluator INFO: Inference done 2092/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:50
[11/16 04:52:28] d2.evaluation.evaluator INFO: Inference done 2215/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:45
[11/16 04:52:33] d2.evaluation.evaluator INFO: Inference done 2338/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/16 04:52:38] d2.evaluation.evaluator INFO: Inference done 2459/3334. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:35
[11/16 04:52:43] d2.evaluation.evaluator INFO: Inference done 2580/3334. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:30
[11/16 04:52:48] d2.evaluation.evaluator INFO: Inference done 2702/3334. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:25
[11/16 04:52:53] d2.evaluation.evaluator INFO: Inference done 2821/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/16 04:52:58] d2.evaluation.evaluator INFO: Inference done 2944/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/16 04:53:04] d2.evaluation.evaluator INFO: Inference done 3066/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/16 04:53:09] d2.evaluation.evaluator INFO: Inference done 3187/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/16 04:53:14] d2.evaluation.evaluator INFO: Inference done 3311/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:00
[11/16 04:53:15] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.027929 (0.041162 s / iter per device, on 6 devices)
[11/16 04:53:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039103 s / iter per device, on 6 devices)
[11/16 04:53:17] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 04:53:17] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 04:53:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 04:53:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 04:53:38] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.01 seconds.
[11/16 04:53:38] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 04:53:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.54 seconds.
[11/16 04:53:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.467 | 1.316  | 0.229  | 0.163 | 0.287 | 0.546 |
[11/16 04:53:40] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.548 | person      | 0.700  | bird                  | 2.813 |
| red panda            | 0.000 | dog         | 16.876 | snake                 | 1.365 |
| car                  | 2.752 | seal        | 0.000  | helmet                | 0.067 |
| motorcycle           | 0.325 | swine       | 0.000  | stove                 | 0.000 |
| monkey               | 0.938 | watercraft  | 2.001  | chair                 | 0.196 |
| domestic cat         | 0.089 | harp        | 0.000  | antelope              | 0.283 |
| camel                | 0.000 | koala bear  | 0.000  | bus                   | 1.207 |
| hat with a wide brim | 0.000 | ski         | 0.000  | piano                 | 0.203 |
| frog                 | 0.012 | dumbbell    | 0.000  | lobster               | 0.500 |
| bench                | 0.000 | rabbit      | 0.000  | porcupine             | 0.000 |
| butterfly            | 0.974 | guitar      | 0.006  | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 0.287  | hippopotamus          | 0.000 |
| bowl                 | 0.344 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.563 | otter       | 0.000  | table                 | 0.323 |
| coffee maker         | 0.534 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000  | lemon                 | 0.603 |
| lizard               | 0.357 | backpack    | 0.000  | tv or monitor         | 1.200 |
| cup or mug           | 0.000 | sheep       | 0.000  | ray                   | 0.000 |
| fox                  | 0.000 | whale       | 0.000  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.000 | ladybug     | 3.821  | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 1.323 |
| cream                | 0.000 | artichoke   | 0.000  | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.000  | miniskirt             | 0.000 |
| orange               | 2.518 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.347 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 1.845  | laptop                | 0.000 |
| pomegranate          | 0.579 | cucumber    | 0.000  | bicycle               | 0.000 |
| banana               | 0.000 | baby bed    | 0.000  | jellyfish             | 0.098 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.098 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 04:53:42] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 04:53:42] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 04:53:42] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 04:53:42] d2.evaluation.testing INFO: copypaste: 0.4670,1.3156,0.2285,0.1632,0.2872,0.5460
[11/16 04:53:42] d2.utils.events INFO:  eta: 5:50:42  iter: 5999  total_loss: 0.3237  loss_cls: 0.1824  loss_box_reg: 0.09848  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.01955  time: 0.6815  data_time: 0.0660  lr: 0.004  max_mem: 11811M
[11/16 04:53:55] d2.utils.events INFO:  eta: 5:50:21  iter: 6019  total_loss: 0.3231  loss_cls: 0.1801  loss_box_reg: 0.1007  loss_rpn_cls: 0.02493  loss_rpn_loc: 0.0202  time: 0.6812  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 04:54:09] d2.utils.events INFO:  eta: 5:50:07  iter: 6039  total_loss: 0.3497  loss_cls: 0.1909  loss_box_reg: 0.1099  loss_rpn_cls: 0.02654  loss_rpn_loc: 0.02004  time: 0.6811  data_time: 0.0689  lr: 0.004  max_mem: 11811M
[11/16 04:54:23] d2.utils.events INFO:  eta: 5:49:53  iter: 6059  total_loss: 0.32  loss_cls: 0.1751  loss_box_reg: 0.09652  loss_rpn_cls: 0.03039  loss_rpn_loc: 0.02146  time: 0.6810  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 04:54:36] d2.utils.events INFO:  eta: 5:49:48  iter: 6079  total_loss: 0.3395  loss_cls: 0.1819  loss_box_reg: 0.09847  loss_rpn_cls: 0.02683  loss_rpn_loc: 0.02214  time: 0.6812  data_time: 0.0697  lr: 0.004  max_mem: 11811M
[11/16 04:54:50] d2.utils.events INFO:  eta: 5:49:46  iter: 6099  total_loss: 0.3242  loss_cls: 0.1755  loss_box_reg: 0.09853  loss_rpn_cls: 0.02596  loss_rpn_loc: 0.01906  time: 0.6812  data_time: 0.0590  lr: 0.004  max_mem: 11811M
[11/16 04:55:04] d2.utils.events INFO:  eta: 5:49:33  iter: 6119  total_loss: 0.3087  loss_cls: 0.1697  loss_box_reg: 0.09488  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.02045  time: 0.6812  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 04:55:17] d2.utils.events INFO:  eta: 5:49:27  iter: 6139  total_loss: 0.3223  loss_cls: 0.1787  loss_box_reg: 0.09525  loss_rpn_cls: 0.02459  loss_rpn_loc: 0.02203  time: 0.6815  data_time: 0.0733  lr: 0.004  max_mem: 11811M
[11/16 04:55:31] d2.utils.events INFO:  eta: 5:49:10  iter: 6159  total_loss: 0.3174  loss_cls: 0.1677  loss_box_reg: 0.09721  loss_rpn_cls: 0.02982  loss_rpn_loc: 0.02144  time: 0.6813  data_time: 0.0593  lr: 0.004  max_mem: 11811M
[11/16 04:55:45] d2.utils.events INFO:  eta: 5:48:52  iter: 6179  total_loss: 0.3392  loss_cls: 0.185  loss_box_reg: 0.1032  loss_rpn_cls: 0.02846  loss_rpn_loc: 0.0204  time: 0.6812  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 04:55:58] d2.utils.events INFO:  eta: 5:48:26  iter: 6199  total_loss: 0.3225  loss_cls: 0.1722  loss_box_reg: 0.09627  loss_rpn_cls: 0.02409  loss_rpn_loc: 0.01999  time: 0.6811  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 04:56:12] d2.utils.events INFO:  eta: 5:48:31  iter: 6219  total_loss: 0.3277  loss_cls: 0.1745  loss_box_reg: 0.1034  loss_rpn_cls: 0.02532  loss_rpn_loc: 0.02051  time: 0.6815  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 04:56:26] d2.utils.events INFO:  eta: 5:48:29  iter: 6239  total_loss: 0.3395  loss_cls: 0.1897  loss_box_reg: 0.102  loss_rpn_cls: 0.02372  loss_rpn_loc: 0.01913  time: 0.6818  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 04:56:39] d2.utils.events INFO:  eta: 5:48:22  iter: 6259  total_loss: 0.3275  loss_cls: 0.1727  loss_box_reg: 0.1014  loss_rpn_cls: 0.02374  loss_rpn_loc: 0.02087  time: 0.6817  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 04:56:53] d2.utils.events INFO:  eta: 5:48:07  iter: 6279  total_loss: 0.3328  loss_cls: 0.1859  loss_box_reg: 0.1034  loss_rpn_cls: 0.02353  loss_rpn_loc: 0.01986  time: 0.6816  data_time: 0.0690  lr: 0.004  max_mem: 11811M
[11/16 04:57:07] d2.utils.events INFO:  eta: 5:47:58  iter: 6299  total_loss: 0.3388  loss_cls: 0.1869  loss_box_reg: 0.1035  loss_rpn_cls: 0.02673  loss_rpn_loc: 0.01994  time: 0.6818  data_time: 0.0725  lr: 0.004  max_mem: 11811M
[11/16 04:57:20] d2.utils.events INFO:  eta: 5:47:41  iter: 6319  total_loss: 0.322  loss_cls: 0.1777  loss_box_reg: 0.1002  loss_rpn_cls: 0.02333  loss_rpn_loc: 0.02102  time: 0.6817  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 04:57:34] d2.utils.events INFO:  eta: 5:47:29  iter: 6339  total_loss: 0.3247  loss_cls: 0.1763  loss_box_reg: 0.09896  loss_rpn_cls: 0.02833  loss_rpn_loc: 0.01877  time: 0.6817  data_time: 0.0647  lr: 0.004  max_mem: 11811M
[11/16 04:57:47] d2.utils.events INFO:  eta: 5:47:01  iter: 6359  total_loss: 0.343  loss_cls: 0.1826  loss_box_reg: 0.1026  loss_rpn_cls: 0.02808  loss_rpn_loc: 0.02242  time: 0.6816  data_time: 0.0739  lr: 0.004  max_mem: 11811M
[11/16 04:58:01] d2.utils.events INFO:  eta: 5:46:45  iter: 6379  total_loss: 0.3375  loss_cls: 0.1898  loss_box_reg: 0.09803  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.01933  time: 0.6815  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 04:58:15] d2.utils.events INFO:  eta: 5:46:31  iter: 6399  total_loss: 0.328  loss_cls: 0.1795  loss_box_reg: 0.09788  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.01977  time: 0.6815  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 04:58:28] d2.utils.events INFO:  eta: 5:46:18  iter: 6419  total_loss: 0.3111  loss_cls: 0.169  loss_box_reg: 0.09459  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.02195  time: 0.6816  data_time: 0.0695  lr: 0.004  max_mem: 11811M
[11/16 04:58:42] d2.utils.events INFO:  eta: 5:46:04  iter: 6439  total_loss: 0.331  loss_cls: 0.1831  loss_box_reg: 0.09914  loss_rpn_cls: 0.02506  loss_rpn_loc: 0.02235  time: 0.6814  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 04:58:55] d2.utils.events INFO:  eta: 5:45:48  iter: 6459  total_loss: 0.3292  loss_cls: 0.1826  loss_box_reg: 0.09891  loss_rpn_cls: 0.02831  loss_rpn_loc: 0.01937  time: 0.6813  data_time: 0.0589  lr: 0.004  max_mem: 11811M
[11/16 04:59:09] d2.utils.events INFO:  eta: 5:45:40  iter: 6479  total_loss: 0.3329  loss_cls: 0.1847  loss_box_reg: 0.1033  loss_rpn_cls: 0.02682  loss_rpn_loc: 0.02048  time: 0.6814  data_time: 0.0727  lr: 0.004  max_mem: 11811M
[11/16 04:59:23] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0006499.pth
[11/16 04:59:23] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 04:59:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 04:59:24] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 04:59:24] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 04:59:24] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 04:59:24] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 04:59:31] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0400 s/iter. ETA=0:02:13
[11/16 04:59:36] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/16 04:59:41] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:04
[11/16 04:59:46] d2.evaluation.evaluator INFO: Inference done 383/3334. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:59
[11/16 04:59:51] d2.evaluation.evaluator INFO: Inference done 507/3334. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/16 04:59:56] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:49
[11/16 05:00:01] d2.evaluation.evaluator INFO: Inference done 748/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:45
[11/16 05:00:06] d2.evaluation.evaluator INFO: Inference done 872/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/16 05:00:11] d2.evaluation.evaluator INFO: Inference done 991/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/16 05:00:16] d2.evaluation.evaluator INFO: Inference done 1114/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:31
[11/16 05:00:21] d2.evaluation.evaluator INFO: Inference done 1235/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/16 05:00:26] d2.evaluation.evaluator INFO: Inference done 1355/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/16 05:00:31] d2.evaluation.evaluator INFO: Inference done 1474/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/16 05:00:36] d2.evaluation.evaluator INFO: Inference done 1596/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/16 05:00:41] d2.evaluation.evaluator INFO: Inference done 1720/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/16 05:00:46] d2.evaluation.evaluator INFO: Inference done 1842/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/16 05:00:51] d2.evaluation.evaluator INFO: Inference done 1963/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/16 05:00:56] d2.evaluation.evaluator INFO: Inference done 2084/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:51
[11/16 05:01:01] d2.evaluation.evaluator INFO: Inference done 2205/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:46
[11/16 05:01:06] d2.evaluation.evaluator INFO: Inference done 2325/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 05:01:11] d2.evaluation.evaluator INFO: Inference done 2442/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:36
[11/16 05:01:17] d2.evaluation.evaluator INFO: Inference done 2563/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:31
[11/16 05:01:22] d2.evaluation.evaluator INFO: Inference done 2684/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:26
[11/16 05:01:27] d2.evaluation.evaluator INFO: Inference done 2805/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:21
[11/16 05:01:32] d2.evaluation.evaluator INFO: Inference done 2927/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:16
[11/16 05:01:37] d2.evaluation.evaluator INFO: Inference done 3049/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:11
[11/16 05:01:42] d2.evaluation.evaluator INFO: Inference done 3170/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:06
[11/16 05:01:47] d2.evaluation.evaluator INFO: Inference done 3291/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:01
[11/16 05:01:49] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.018972 (0.041460 s / iter per device, on 6 devices)
[11/16 05:01:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039399 s / iter per device, on 6 devices)
[11/16 05:01:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:01:51] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:01:51] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:01:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:02:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 18.94 seconds.
[11/16 05:02:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:02:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.53 seconds.
[11/16 05:02:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.544 | 1.568  | 0.236  | 0.161 | 0.248 | 0.625 |
[11/16 05:02:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.349 | person      | 0.821  | bird                  | 3.362 |
| red panda            | 0.000 | dog         | 18.723 | snake                 | 1.544 |
| car                  | 4.321 | seal        | 0.000  | helmet                | 0.000 |
| motorcycle           | 0.416 | swine       | 0.000  | stove                 | 0.000 |
| monkey               | 1.267 | watercraft  | 2.455  | chair                 | 0.105 |
| domestic cat         | 0.005 | harp        | 0.000  | antelope              | 0.191 |
| camel                | 0.019 | koala bear  | 0.000  | bus                   | 1.423 |
| hat with a wide brim | 0.000 | ski         | 0.000  | piano                 | 0.410 |
| frog                 | 0.210 | dumbbell    | 0.000  | lobster               | 0.228 |
| bench                | 0.000 | rabbit      | 0.000  | porcupine             | 0.000 |
| butterfly            | 1.071 | guitar      | 0.097  | microphone            | 0.000 |
| tape player          | 0.000 | bear        | 1.510  | hippopotamus          | 0.000 |
| bowl                 | 0.320 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.559 | otter       | 0.000  | table                 | 0.590 |
| coffee maker         | 0.000 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.000  | lemon                 | 0.420 |
| lizard               | 0.325 | backpack    | 0.000  | tv or monitor         | 0.590 |
| cup or mug           | 0.000 | sheep       | 0.000  | ray                   | 0.000 |
| fox                  | 0.041 | whale       | 0.000  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.411 | ladybug     | 5.715  | crutch                | 0.000 |
| pretzel              | 0.198 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 1.911 |
| cream                | 0.000 | artichoke   | 0.594  | train                 | 0.000 |
| elephant             | 0.000 | bell pepper | 0.173  | miniskirt             | 0.000 |
| orange               | 2.517 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.000 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.306  | laptop                | 0.000 |
| pomegranate          | 0.124 | cucumber    | 0.000  | bicycle               | 0.033 |
| banana               | 0.084 | baby bed    | 0.466  | jellyfish             | 0.000 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.486 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.000 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:02:15] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:02:15] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:02:15] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:02:15] d2.evaluation.testing INFO: copypaste: 0.5439,1.5682,0.2358,0.1613,0.2479,0.6254
[11/16 05:02:15] d2.utils.events INFO:  eta: 5:45:26  iter: 6499  total_loss: 0.3282  loss_cls: 0.1825  loss_box_reg: 0.09949  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.01983  time: 0.6815  data_time: 0.0761  lr: 0.004  max_mem: 11811M
[11/16 05:02:28] d2.utils.events INFO:  eta: 5:45:21  iter: 6519  total_loss: 0.3195  loss_cls: 0.1755  loss_box_reg: 0.09877  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.01936  time: 0.6814  data_time: 0.0652  lr: 0.004  max_mem: 11811M
[11/16 05:02:42] d2.utils.events INFO:  eta: 5:45:11  iter: 6539  total_loss: 0.3115  loss_cls: 0.1683  loss_box_reg: 0.09302  loss_rpn_cls: 0.02898  loss_rpn_loc: 0.02109  time: 0.6814  data_time: 0.0712  lr: 0.004  max_mem: 11811M
[11/16 05:02:56] d2.utils.events INFO:  eta: 5:45:06  iter: 6559  total_loss: 0.3286  loss_cls: 0.1834  loss_box_reg: 0.09953  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.0193  time: 0.6814  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 05:03:09] d2.utils.events INFO:  eta: 5:44:58  iter: 6579  total_loss: 0.3385  loss_cls: 0.1859  loss_box_reg: 0.09967  loss_rpn_cls: 0.02691  loss_rpn_loc: 0.01955  time: 0.6814  data_time: 0.0698  lr: 0.004  max_mem: 11811M
[11/16 05:03:23] d2.utils.events INFO:  eta: 5:45:01  iter: 6599  total_loss: 0.3172  loss_cls: 0.1777  loss_box_reg: 0.09804  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.02102  time: 0.6817  data_time: 0.0677  lr: 0.004  max_mem: 11811M
[11/16 05:03:37] d2.utils.events INFO:  eta: 5:44:44  iter: 6619  total_loss: 0.3287  loss_cls: 0.1772  loss_box_reg: 0.09909  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.02273  time: 0.6815  data_time: 0.0704  lr: 0.004  max_mem: 11811M
[11/16 05:03:50] d2.utils.events INFO:  eta: 5:44:47  iter: 6639  total_loss: 0.3119  loss_cls: 0.1677  loss_box_reg: 0.09405  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.02277  time: 0.6815  data_time: 0.0663  lr: 0.004  max_mem: 11811M
[11/16 05:04:04] d2.utils.events INFO:  eta: 5:44:26  iter: 6659  total_loss: 0.3279  loss_cls: 0.1793  loss_box_reg: 0.09806  loss_rpn_cls: 0.02368  loss_rpn_loc: 0.01966  time: 0.6818  data_time: 0.0812  lr: 0.004  max_mem: 11811M
[11/16 05:04:18] d2.utils.events INFO:  eta: 5:44:03  iter: 6679  total_loss: 0.3363  loss_cls: 0.182  loss_box_reg: 0.1015  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.02113  time: 0.6819  data_time: 0.0792  lr: 0.004  max_mem: 11811M
[11/16 05:04:31] d2.utils.events INFO:  eta: 5:43:32  iter: 6699  total_loss: 0.3272  loss_cls: 0.1762  loss_box_reg: 0.09765  loss_rpn_cls: 0.0265  loss_rpn_loc: 0.02063  time: 0.6817  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 05:04:45] d2.utils.events INFO:  eta: 5:43:22  iter: 6719  total_loss: 0.3298  loss_cls: 0.1762  loss_box_reg: 0.09829  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.02197  time: 0.6817  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 05:04:59] d2.utils.events INFO:  eta: 5:43:03  iter: 6739  total_loss: 0.3258  loss_cls: 0.1827  loss_box_reg: 0.09727  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.02056  time: 0.6816  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 05:05:12] d2.utils.events INFO:  eta: 5:43:01  iter: 6759  total_loss: 0.3346  loss_cls: 0.18  loss_box_reg: 0.1003  loss_rpn_cls: 0.02719  loss_rpn_loc: 0.02353  time: 0.6817  data_time: 0.0716  lr: 0.004  max_mem: 11811M
[11/16 05:05:26] d2.utils.events INFO:  eta: 5:42:45  iter: 6779  total_loss: 0.3059  loss_cls: 0.1661  loss_box_reg: 0.09645  loss_rpn_cls: 0.02229  loss_rpn_loc: 0.01871  time: 0.6817  data_time: 0.0650  lr: 0.004  max_mem: 11811M
[11/16 05:05:39] d2.utils.events INFO:  eta: 5:42:28  iter: 6799  total_loss: 0.3308  loss_cls: 0.1796  loss_box_reg: 0.1009  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.0211  time: 0.6816  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 05:05:53] d2.utils.events INFO:  eta: 5:42:18  iter: 6819  total_loss: 0.3316  loss_cls: 0.1766  loss_box_reg: 0.1003  loss_rpn_cls: 0.02512  loss_rpn_loc: 0.0207  time: 0.6816  data_time: 0.0697  lr: 0.004  max_mem: 11811M
[11/16 05:06:07] d2.utils.events INFO:  eta: 5:42:18  iter: 6839  total_loss: 0.3182  loss_cls: 0.1716  loss_box_reg: 0.1037  loss_rpn_cls: 0.02456  loss_rpn_loc: 0.02022  time: 0.6816  data_time: 0.0615  lr: 0.004  max_mem: 11811M
[11/16 05:06:20] d2.utils.events INFO:  eta: 5:42:02  iter: 6859  total_loss: 0.3294  loss_cls: 0.1827  loss_box_reg: 0.09878  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.02018  time: 0.6815  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 05:06:34] d2.utils.events INFO:  eta: 5:41:44  iter: 6879  total_loss: 0.3103  loss_cls: 0.1674  loss_box_reg: 0.09312  loss_rpn_cls: 0.02833  loss_rpn_loc: 0.02152  time: 0.6817  data_time: 0.0950  lr: 0.004  max_mem: 11811M
[11/16 05:06:48] d2.utils.events INFO:  eta: 5:41:45  iter: 6899  total_loss: 0.3105  loss_cls: 0.1662  loss_box_reg: 0.09647  loss_rpn_cls: 0.02394  loss_rpn_loc: 0.01863  time: 0.6816  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 05:07:01] d2.utils.events INFO:  eta: 5:41:23  iter: 6919  total_loss: 0.3229  loss_cls: 0.1798  loss_box_reg: 0.102  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.02001  time: 0.6815  data_time: 0.0660  lr: 0.004  max_mem: 11811M
[11/16 05:07:15] d2.utils.events INFO:  eta: 5:41:12  iter: 6939  total_loss: 0.3126  loss_cls: 0.175  loss_box_reg: 0.09845  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.02104  time: 0.6815  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/16 05:07:29] d2.utils.events INFO:  eta: 5:40:56  iter: 6959  total_loss: 0.3196  loss_cls: 0.1755  loss_box_reg: 0.09925  loss_rpn_cls: 0.0227  loss_rpn_loc: 0.02122  time: 0.6816  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 05:07:42] d2.utils.events INFO:  eta: 5:40:29  iter: 6979  total_loss: 0.3153  loss_cls: 0.1726  loss_box_reg: 0.09536  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.01904  time: 0.6816  data_time: 0.0718  lr: 0.004  max_mem: 11811M
[11/16 05:07:56] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0006999.pth
[11/16 05:07:56] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:07:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:07:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:07:57] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:07:57] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:07:57] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:08:04] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0382 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:11
[11/16 05:08:09] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:09
[11/16 05:08:14] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/16 05:08:19] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:02
[11/16 05:08:24] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/16 05:08:29] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 05:08:34] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/16 05:08:39] d2.evaluation.evaluator INFO: Inference done 863/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:41
[11/16 05:08:44] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/16 05:08:49] d2.evaluation.evaluator INFO: Inference done 1105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:32
[11/16 05:08:54] d2.evaluation.evaluator INFO: Inference done 1224/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/16 05:08:59] d2.evaluation.evaluator INFO: Inference done 1345/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/16 05:09:04] d2.evaluation.evaluator INFO: Inference done 1465/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/16 05:09:09] d2.evaluation.evaluator INFO: Inference done 1587/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/16 05:09:14] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/16 05:09:19] d2.evaluation.evaluator INFO: Inference done 1832/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:02
[11/16 05:09:24] d2.evaluation.evaluator INFO: Inference done 1955/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/16 05:09:29] d2.evaluation.evaluator INFO: Inference done 2078/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/16 05:09:34] d2.evaluation.evaluator INFO: Inference done 2200/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/16 05:09:39] d2.evaluation.evaluator INFO: Inference done 2322/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/16 05:09:44] d2.evaluation.evaluator INFO: Inference done 2441/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/16 05:09:49] d2.evaluation.evaluator INFO: Inference done 2561/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/16 05:09:54] d2.evaluation.evaluator INFO: Inference done 2685/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 05:09:59] d2.evaluation.evaluator INFO: Inference done 2808/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 05:10:04] d2.evaluation.evaluator INFO: Inference done 2932/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:16
[11/16 05:10:09] d2.evaluation.evaluator INFO: Inference done 3053/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:11
[11/16 05:10:14] d2.evaluation.evaluator INFO: Inference done 3175/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:06
[11/16 05:10:19] d2.evaluation.evaluator INFO: Inference done 3298/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:01
[11/16 05:10:21] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.256211 (0.041230 s / iter per device, on 6 devices)
[11/16 05:10:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039244 s / iter per device, on 6 devices)
[11/16 05:10:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:10:23] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:10:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:10:25] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:10:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.41 seconds.
[11/16 05:10:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:10:46] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.72 seconds.
[11/16 05:10:46] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.779 | 2.091  | 0.427  | 0.165 | 0.386 | 0.905 |
[11/16 05:10:46] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.557 | person      | 0.974  | bird                  | 3.652 |
| red panda            | 0.000 | dog         | 19.044 | snake                 | 1.546 |
| car                  | 5.537 | seal        | 0.000  | helmet                | 0.546 |
| motorcycle           | 0.972 | swine       | 0.333  | stove                 | 0.000 |
| monkey               | 1.117 | watercraft  | 3.055  | chair                 | 0.500 |
| domestic cat         | 0.154 | harp        | 0.000  | antelope              | 0.654 |
| camel                | 0.000 | koala bear  | 0.000  | bus                   | 1.714 |
| hat with a wide brim | 0.150 | ski         | 0.000  | piano                 | 0.742 |
| frog                 | 0.235 | dumbbell    | 0.000  | lobster               | 0.365 |
| bench                | 0.000 | rabbit      | 0.248  | porcupine             | 0.000 |
| butterfly            | 1.063 | guitar      | 0.039  | microphone            | 0.000 |
| tape player          | 1.584 | bear        | 0.959  | hippopotamus          | 0.000 |
| bowl                 | 0.282 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 1.432 | otter       | 0.000  | table                 | 0.468 |
| coffee maker         | 4.740 | tie         | 0.000  | turtle                | 0.000 |
| purse                | 0.000 | dragonfly   | 0.136  | lemon                 | 0.365 |
| lizard               | 0.396 | backpack    | 0.000  | tv or monitor         | 2.713 |
| cup or mug           | 0.000 | sheep       | 0.198  | ray                   | 0.269 |
| fox                  | 0.099 | whale       | 0.408  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.018 |
| bookshelf            | 1.525 | ladybug     | 7.224  | crutch                | 0.000 |
| pretzel              | 0.033 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.038 | lamp        | 0.000  | apple                 | 3.106 |
| cream                | 0.000 | artichoke   | 0.132  | train                 | 0.066 |
| elephant             | 0.891 | bell pepper | 1.335  | miniskirt             | 0.000 |
| orange               | 1.988 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.429 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.485  | laptop                | 0.396 |
| pomegranate          | 0.801 | cucumber    | 0.000  | bicycle               | 0.924 |
| banana               | 0.000 | baby bed    | 0.361  | jellyfish             | 0.231 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.286 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.396 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:10:48] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:10:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:10:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:10:48] d2.evaluation.testing INFO: copypaste: 0.7791,2.0908,0.4274,0.1649,0.3862,0.9048
[11/16 05:10:48] d2.utils.events INFO:  eta: 5:40:18  iter: 6999  total_loss: 0.322  loss_cls: 0.1783  loss_box_reg: 0.09913  loss_rpn_cls: 0.02419  loss_rpn_loc: 0.02097  time: 0.6816  data_time: 0.0768  lr: 0.004  max_mem: 11811M
[11/16 05:11:02] d2.utils.events INFO:  eta: 5:40:10  iter: 7019  total_loss: 0.3193  loss_cls: 0.176  loss_box_reg: 0.1002  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.01886  time: 0.6816  data_time: 0.0635  lr: 0.004  max_mem: 11811M
[11/16 05:11:15] d2.utils.events INFO:  eta: 5:39:39  iter: 7039  total_loss: 0.3282  loss_cls: 0.1847  loss_box_reg: 0.1022  loss_rpn_cls: 0.02564  loss_rpn_loc: 0.01882  time: 0.6814  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 05:11:29] d2.utils.events INFO:  eta: 5:39:27  iter: 7059  total_loss: 0.3006  loss_cls: 0.1625  loss_box_reg: 0.09542  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.0182  time: 0.6814  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 05:11:42] d2.utils.events INFO:  eta: 5:38:57  iter: 7079  total_loss: 0.318  loss_cls: 0.1752  loss_box_reg: 0.1006  loss_rpn_cls: 0.02338  loss_rpn_loc: 0.02124  time: 0.6815  data_time: 0.0633  lr: 0.004  max_mem: 11811M
[11/16 05:11:56] d2.utils.events INFO:  eta: 5:38:39  iter: 7099  total_loss: 0.3153  loss_cls: 0.1672  loss_box_reg: 0.09894  loss_rpn_cls: 0.02668  loss_rpn_loc: 0.02085  time: 0.6814  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 05:12:10] d2.utils.events INFO:  eta: 5:38:30  iter: 7119  total_loss: 0.3153  loss_cls: 0.172  loss_box_reg: 0.09842  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.01986  time: 0.6814  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/16 05:12:23] d2.utils.events INFO:  eta: 5:38:12  iter: 7139  total_loss: 0.3345  loss_cls: 0.1864  loss_box_reg: 0.102  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.02164  time: 0.6815  data_time: 0.0782  lr: 0.004  max_mem: 11811M
[11/16 05:12:37] d2.utils.events INFO:  eta: 5:38:03  iter: 7159  total_loss: 0.3084  loss_cls: 0.168  loss_box_reg: 0.09745  loss_rpn_cls: 0.02357  loss_rpn_loc: 0.01923  time: 0.6815  data_time: 0.0683  lr: 0.004  max_mem: 11811M
[11/16 05:12:51] d2.utils.events INFO:  eta: 5:38:15  iter: 7179  total_loss: 0.33  loss_cls: 0.1776  loss_box_reg: 0.1019  loss_rpn_cls: 0.02339  loss_rpn_loc: 0.01999  time: 0.6816  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 05:13:04] d2.utils.events INFO:  eta: 5:38:01  iter: 7199  total_loss: 0.3196  loss_cls: 0.1753  loss_box_reg: 0.099  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.02016  time: 0.6815  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 05:13:18] d2.utils.events INFO:  eta: 5:37:18  iter: 7219  total_loss: 0.3128  loss_cls: 0.17  loss_box_reg: 0.09639  loss_rpn_cls: 0.02544  loss_rpn_loc: 0.01937  time: 0.6815  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 05:13:31] d2.utils.events INFO:  eta: 5:36:54  iter: 7239  total_loss: 0.3172  loss_cls: 0.1666  loss_box_reg: 0.09493  loss_rpn_cls: 0.02867  loss_rpn_loc: 0.01942  time: 0.6814  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 05:13:45] d2.utils.events INFO:  eta: 5:36:40  iter: 7259  total_loss: 0.2956  loss_cls: 0.1649  loss_box_reg: 0.09045  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.01896  time: 0.6814  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/16 05:13:59] d2.utils.events INFO:  eta: 5:36:30  iter: 7279  total_loss: 0.3233  loss_cls: 0.1725  loss_box_reg: 0.09745  loss_rpn_cls: 0.02927  loss_rpn_loc: 0.02115  time: 0.6814  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 05:14:12] d2.utils.events INFO:  eta: 5:36:16  iter: 7299  total_loss: 0.3256  loss_cls: 0.1737  loss_box_reg: 0.1015  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.02312  time: 0.6814  data_time: 0.0663  lr: 0.004  max_mem: 11811M
[11/16 05:14:26] d2.utils.events INFO:  eta: 5:36:03  iter: 7319  total_loss: 0.3132  loss_cls: 0.1738  loss_box_reg: 0.09769  loss_rpn_cls: 0.02324  loss_rpn_loc: 0.01914  time: 0.6814  data_time: 0.0704  lr: 0.004  max_mem: 11811M
[11/16 05:14:40] d2.utils.events INFO:  eta: 5:35:49  iter: 7339  total_loss: 0.3293  loss_cls: 0.1719  loss_box_reg: 0.09978  loss_rpn_cls: 0.02838  loss_rpn_loc: 0.02174  time: 0.6813  data_time: 0.0611  lr: 0.004  max_mem: 11811M
[11/16 05:14:53] d2.utils.events INFO:  eta: 5:35:39  iter: 7359  total_loss: 0.3087  loss_cls: 0.1672  loss_box_reg: 0.0953  loss_rpn_cls: 0.02504  loss_rpn_loc: 0.0214  time: 0.6813  data_time: 0.0710  lr: 0.004  max_mem: 11811M
[11/16 05:15:07] d2.utils.events INFO:  eta: 5:35:30  iter: 7379  total_loss: 0.3165  loss_cls: 0.1705  loss_box_reg: 0.09836  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.02006  time: 0.6814  data_time: 0.0718  lr: 0.004  max_mem: 11811M
[11/16 05:15:21] d2.utils.events INFO:  eta: 5:35:34  iter: 7399  total_loss: 0.3247  loss_cls: 0.1785  loss_box_reg: 0.09743  loss_rpn_cls: 0.02681  loss_rpn_loc: 0.02048  time: 0.6815  data_time: 0.0809  lr: 0.004  max_mem: 11811M
[11/16 05:15:34] d2.utils.events INFO:  eta: 5:34:59  iter: 7419  total_loss: 0.3273  loss_cls: 0.1783  loss_box_reg: 0.09737  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.02201  time: 0.6816  data_time: 0.0754  lr: 0.004  max_mem: 11811M
[11/16 05:15:48] d2.utils.events INFO:  eta: 5:35:07  iter: 7439  total_loss: 0.3169  loss_cls: 0.1781  loss_box_reg: 0.1001  loss_rpn_cls: 0.02414  loss_rpn_loc: 0.0205  time: 0.6816  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 05:16:02] d2.utils.events INFO:  eta: 5:34:32  iter: 7459  total_loss: 0.3056  loss_cls: 0.1658  loss_box_reg: 0.09346  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.01975  time: 0.6815  data_time: 0.0631  lr: 0.004  max_mem: 11811M
[11/16 05:16:15] d2.utils.events INFO:  eta: 5:34:15  iter: 7479  total_loss: 0.3107  loss_cls: 0.1678  loss_box_reg: 0.09639  loss_rpn_cls: 0.02283  loss_rpn_loc: 0.02074  time: 0.6815  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 05:16:29] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0007499.pth
[11/16 05:16:29] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:16:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:16:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:16:30] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:16:30] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:16:30] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:16:37] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0016 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:02:21
[11/16 05:16:42] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:12
[11/16 05:16:47] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/16 05:16:53] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/16 05:16:58] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 05:17:03] d2.evaluation.evaluator INFO: Inference done 619/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/16 05:17:08] d2.evaluation.evaluator INFO: Inference done 738/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/16 05:17:13] d2.evaluation.evaluator INFO: Inference done 861/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/16 05:17:18] d2.evaluation.evaluator INFO: Inference done 985/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:36
[11/16 05:17:23] d2.evaluation.evaluator INFO: Inference done 1109/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/16 05:17:28] d2.evaluation.evaluator INFO: Inference done 1228/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/16 05:17:33] d2.evaluation.evaluator INFO: Inference done 1350/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/16 05:17:38] d2.evaluation.evaluator INFO: Inference done 1468/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:17
[11/16 05:17:43] d2.evaluation.evaluator INFO: Inference done 1587/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/16 05:17:48] d2.evaluation.evaluator INFO: Inference done 1708/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/16 05:17:53] d2.evaluation.evaluator INFO: Inference done 1830/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/16 05:17:58] d2.evaluation.evaluator INFO: Inference done 1953/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:57
[11/16 05:18:03] d2.evaluation.evaluator INFO: Inference done 2075/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:52
[11/16 05:18:08] d2.evaluation.evaluator INFO: Inference done 2195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/16 05:18:13] d2.evaluation.evaluator INFO: Inference done 2316/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:42
[11/16 05:18:18] d2.evaluation.evaluator INFO: Inference done 2435/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/16 05:18:23] d2.evaluation.evaluator INFO: Inference done 2558/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/16 05:18:28] d2.evaluation.evaluator INFO: Inference done 2679/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:27
[11/16 05:18:33] d2.evaluation.evaluator INFO: Inference done 2800/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/16 05:18:38] d2.evaluation.evaluator INFO: Inference done 2923/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/16 05:18:43] d2.evaluation.evaluator INFO: Inference done 3046/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/16 05:18:48] d2.evaluation.evaluator INFO: Inference done 3169/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/16 05:18:53] d2.evaluation.evaluator INFO: Inference done 3290/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/16 05:18:55] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.526452 (0.041312 s / iter per device, on 6 devices)
[11/16 05:18:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039369 s / iter per device, on 6 devices)
[11/16 05:18:57] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:18:57] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:18:57] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:18:58] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:19:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.19 seconds.
[11/16 05:19:20] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:19:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.74 seconds.
[11/16 05:19:22] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.916 | 2.429  | 0.457  | 0.162 | 0.479 | 1.094 |
[11/16 05:19:22] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 1.505 | person      | 1.420  | bird                  | 4.170 |
| red panda            | 0.000 | dog         | 21.210 | snake                 | 1.879 |
| car                  | 7.581 | seal        | 0.248  | helmet                | 0.211 |
| motorcycle           | 1.356 | swine       | 0.765  | stove                 | 0.693 |
| monkey               | 1.766 | watercraft  | 3.647  | chair                 | 0.908 |
| domestic cat         | 0.781 | harp        | 0.000  | antelope              | 0.916 |
| camel                | 0.000 | koala bear  | 0.443  | bus                   | 2.660 |
| hat with a wide brim | 0.276 | ski         | 0.000  | piano                 | 0.689 |
| frog                 | 0.386 | dumbbell    | 0.000  | lobster               | 0.537 |
| bench                | 0.000 | rabbit      | 0.421  | porcupine             | 0.563 |
| butterfly            | 1.201 | guitar      | 0.101  | microphone            | 0.000 |
| tape player          | 3.703 | bear        | 1.227  | hippopotamus          | 0.000 |
| bowl                 | 0.455 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 1.750 | otter       | 0.000  | table                 | 0.498 |
| coffee maker         | 1.179 | tie         | 0.000  | turtle                | 0.824 |
| purse                | 0.000 | dragonfly   | 0.092  | lemon                 | 0.825 |
| lizard               | 0.609 | backpack    | 0.000  | tv or monitor         | 2.338 |
| cup or mug           | 0.891 | sheep       | 0.351  | ray                   | 0.147 |
| fox                  | 0.316 | whale       | 0.629  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.000 |
| bookshelf            | 0.990 | ladybug     | 7.705  | crutch                | 0.000 |
| pretzel              | 0.000 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 1.765 |
| cream                | 0.044 | artichoke   | 0.834  | train                 | 0.020 |
| elephant             | 0.274 | bell pepper | 0.330  | miniskirt             | 0.000 |
| orange               | 3.633 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.183 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 0.781  | laptop                | 0.238 |
| pomegranate          | 0.335 | cucumber    | 0.000  | bicycle               | 0.344 |
| banana               | 0.030 | baby bed    | 0.285  | jellyfish             | 0.352 |
| pitcher              | 0.000 | bagel       | 0.000  | beaker                | 0.000 |
| goldfish             | 0.746 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.000  | zebra                 | 0.585 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:19:25] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:19:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:19:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:19:25] d2.evaluation.testing INFO: copypaste: 0.9164,2.4289,0.4574,0.1615,0.4788,1.0941
[11/16 05:19:25] d2.utils.events INFO:  eta: 5:34:37  iter: 7499  total_loss: 0.3046  loss_cls: 0.1629  loss_box_reg: 0.09655  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.02174  time: 0.6816  data_time: 0.0753  lr: 0.004  max_mem: 11811M
[11/16 05:19:39] d2.utils.events INFO:  eta: 5:34:24  iter: 7519  total_loss: 0.3149  loss_cls: 0.168  loss_box_reg: 0.09749  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.01934  time: 0.6816  data_time: 0.0725  lr: 0.004  max_mem: 11811M
[11/16 05:19:52] d2.utils.events INFO:  eta: 5:33:37  iter: 7539  total_loss: 0.317  loss_cls: 0.1707  loss_box_reg: 0.09449  loss_rpn_cls: 0.03077  loss_rpn_loc: 0.01951  time: 0.6815  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 05:20:06] d2.utils.events INFO:  eta: 5:33:23  iter: 7559  total_loss: 0.3202  loss_cls: 0.1759  loss_box_reg: 0.09644  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.01968  time: 0.6815  data_time: 0.0618  lr: 0.004  max_mem: 11811M
[11/16 05:20:19] d2.utils.events INFO:  eta: 5:33:09  iter: 7579  total_loss: 0.328  loss_cls: 0.1819  loss_box_reg: 0.1011  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.01943  time: 0.6816  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 05:20:33] d2.utils.events INFO:  eta: 5:32:51  iter: 7599  total_loss: 0.312  loss_cls: 0.1762  loss_box_reg: 0.09948  loss_rpn_cls: 0.02348  loss_rpn_loc: 0.01966  time: 0.6815  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 05:20:47] d2.utils.events INFO:  eta: 5:32:43  iter: 7619  total_loss: 0.3192  loss_cls: 0.1786  loss_box_reg: 0.1007  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.02175  time: 0.6815  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 05:21:00] d2.utils.events INFO:  eta: 5:32:27  iter: 7639  total_loss: 0.3284  loss_cls: 0.179  loss_box_reg: 0.1012  loss_rpn_cls: 0.02665  loss_rpn_loc: 0.02171  time: 0.6815  data_time: 0.0619  lr: 0.004  max_mem: 11811M
[11/16 05:21:14] d2.utils.events INFO:  eta: 5:32:13  iter: 7659  total_loss: 0.3152  loss_cls: 0.1774  loss_box_reg: 0.09273  loss_rpn_cls: 0.02572  loss_rpn_loc: 0.02021  time: 0.6815  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 05:21:27] d2.utils.events INFO:  eta: 5:32:14  iter: 7679  total_loss: 0.3051  loss_cls: 0.1656  loss_box_reg: 0.09316  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.02049  time: 0.6815  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 05:21:41] d2.utils.events INFO:  eta: 5:32:02  iter: 7699  total_loss: 0.3342  loss_cls: 0.1811  loss_box_reg: 0.1051  loss_rpn_cls: 0.02615  loss_rpn_loc: 0.02108  time: 0.6815  data_time: 0.0642  lr: 0.004  max_mem: 11811M
[11/16 05:21:54] d2.utils.events INFO:  eta: 5:31:47  iter: 7719  total_loss: 0.3161  loss_cls: 0.1659  loss_box_reg: 0.099  loss_rpn_cls: 0.02667  loss_rpn_loc: 0.02034  time: 0.6814  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 05:22:08] d2.utils.events INFO:  eta: 5:31:41  iter: 7739  total_loss: 0.3194  loss_cls: 0.1747  loss_box_reg: 0.09487  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.0193  time: 0.6814  data_time: 0.0737  lr: 0.004  max_mem: 11811M
[11/16 05:22:22] d2.utils.events INFO:  eta: 5:31:41  iter: 7759  total_loss: 0.3224  loss_cls: 0.1789  loss_box_reg: 0.09825  loss_rpn_cls: 0.02605  loss_rpn_loc: 0.01948  time: 0.6815  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 05:22:36] d2.utils.events INFO:  eta: 5:31:29  iter: 7779  total_loss: 0.3158  loss_cls: 0.1739  loss_box_reg: 0.1015  loss_rpn_cls: 0.02299  loss_rpn_loc: 0.01983  time: 0.6815  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 05:22:49] d2.utils.events INFO:  eta: 5:30:54  iter: 7799  total_loss: 0.2993  loss_cls: 0.1613  loss_box_reg: 0.09427  loss_rpn_cls: 0.02432  loss_rpn_loc: 0.01947  time: 0.6814  data_time: 0.0723  lr: 0.004  max_mem: 11811M
[11/16 05:23:03] d2.utils.events INFO:  eta: 5:30:40  iter: 7819  total_loss: 0.3104  loss_cls: 0.172  loss_box_reg: 0.09463  loss_rpn_cls: 0.02261  loss_rpn_loc: 0.02046  time: 0.6815  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 05:23:16] d2.utils.events INFO:  eta: 5:30:33  iter: 7839  total_loss: 0.3182  loss_cls: 0.1721  loss_box_reg: 0.09603  loss_rpn_cls: 0.02424  loss_rpn_loc: 0.02083  time: 0.6815  data_time: 0.0725  lr: 0.004  max_mem: 11811M
[11/16 05:23:30] d2.utils.events INFO:  eta: 5:30:13  iter: 7859  total_loss: 0.3128  loss_cls: 0.1737  loss_box_reg: 0.09844  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.02165  time: 0.6814  data_time: 0.0711  lr: 0.004  max_mem: 11811M
[11/16 05:23:44] d2.utils.events INFO:  eta: 5:30:05  iter: 7879  total_loss: 0.3117  loss_cls: 0.1685  loss_box_reg: 0.09667  loss_rpn_cls: 0.02365  loss_rpn_loc: 0.02029  time: 0.6814  data_time: 0.0622  lr: 0.004  max_mem: 11811M
[11/16 05:23:57] d2.utils.events INFO:  eta: 5:29:43  iter: 7899  total_loss: 0.306  loss_cls: 0.1694  loss_box_reg: 0.09692  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.02155  time: 0.6814  data_time: 0.0663  lr: 0.004  max_mem: 11811M
[11/16 05:24:11] d2.utils.events INFO:  eta: 5:29:38  iter: 7919  total_loss: 0.3202  loss_cls: 0.181  loss_box_reg: 0.09739  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.0212  time: 0.6814  data_time: 0.0691  lr: 0.004  max_mem: 11811M
[11/16 05:24:25] d2.utils.events INFO:  eta: 5:29:36  iter: 7939  total_loss: 0.3071  loss_cls: 0.1687  loss_box_reg: 0.09508  loss_rpn_cls: 0.02395  loss_rpn_loc: 0.02071  time: 0.6814  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 05:24:38] d2.utils.events INFO:  eta: 5:29:21  iter: 7959  total_loss: 0.302  loss_cls: 0.1601  loss_box_reg: 0.09224  loss_rpn_cls: 0.02757  loss_rpn_loc: 0.02006  time: 0.6815  data_time: 0.0631  lr: 0.004  max_mem: 11811M
[11/16 05:24:52] d2.utils.events INFO:  eta: 5:29:07  iter: 7979  total_loss: 0.3077  loss_cls: 0.1685  loss_box_reg: 0.09643  loss_rpn_cls: 0.02464  loss_rpn_loc: 0.01898  time: 0.6814  data_time: 0.0606  lr: 0.004  max_mem: 11811M
[11/16 05:25:05] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0007999.pth
[11/16 05:25:06] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:25:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:25:06] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:25:06] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:25:06] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:25:07] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:25:14] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:16
[11/16 05:25:19] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0014 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:12
[11/16 05:25:24] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0014 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:06
[11/16 05:25:29] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0014 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/16 05:25:34] d2.evaluation.evaluator INFO: Inference done 502/3334. Dataloading: 0.0014 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/16 05:25:39] d2.evaluation.evaluator INFO: Inference done 624/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:50
[11/16 05:25:44] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 05:25:49] d2.evaluation.evaluator INFO: Inference done 866/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/16 05:25:54] d2.evaluation.evaluator INFO: Inference done 988/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:36
[11/16 05:25:59] d2.evaluation.evaluator INFO: Inference done 1109/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/16 05:26:04] d2.evaluation.evaluator INFO: Inference done 1230/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:26
[11/16 05:26:09] d2.evaluation.evaluator INFO: Inference done 1355/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/16 05:26:14] d2.evaluation.evaluator INFO: Inference done 1479/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:16
[11/16 05:26:19] d2.evaluation.evaluator INFO: Inference done 1601/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:11
[11/16 05:26:24] d2.evaluation.evaluator INFO: Inference done 1722/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/16 05:26:29] d2.evaluation.evaluator INFO: Inference done 1845/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/16 05:26:34] d2.evaluation.evaluator INFO: Inference done 1966/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/16 05:26:39] d2.evaluation.evaluator INFO: Inference done 2087/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/16 05:26:44] d2.evaluation.evaluator INFO: Inference done 2208/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/16 05:26:49] d2.evaluation.evaluator INFO: Inference done 2330/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/16 05:26:54] d2.evaluation.evaluator INFO: Inference done 2447/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/16 05:26:59] d2.evaluation.evaluator INFO: Inference done 2568/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/16 05:27:04] d2.evaluation.evaluator INFO: Inference done 2685/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/16 05:27:09] d2.evaluation.evaluator INFO: Inference done 2803/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/16 05:27:14] d2.evaluation.evaluator INFO: Inference done 2924/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:16
[11/16 05:27:19] d2.evaluation.evaluator INFO: Inference done 3046/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:11
[11/16 05:27:24] d2.evaluation.evaluator INFO: Inference done 3168/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/16 05:27:29] d2.evaluation.evaluator INFO: Inference done 3290/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/16 05:27:31] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.746216 (0.041378 s / iter per device, on 6 devices)
[11/16 05:27:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039441 s / iter per device, on 6 devices)
[11/16 05:27:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:27:33] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:27:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:27:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:27:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.72 seconds.
[11/16 05:27:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:27:58] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.74 seconds.
[11/16 05:27:58] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.062 | 2.786  | 0.594  | 0.189 | 0.453 | 1.246 |
[11/16 05:27:58] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.774 | person      | 1.424  | bird                  | 4.505 |
| red panda            | 0.000 | dog         | 21.068 | snake                 | 1.571 |
| car                  | 7.179 | seal        | 0.000  | helmet                | 0.519 |
| motorcycle           | 1.469 | swine       | 0.185  | stove                 | 0.528 |
| monkey               | 2.299 | watercraft  | 3.995  | chair                 | 0.862 |
| domestic cat         | 0.549 | harp        | 0.000  | antelope              | 1.020 |
| camel                | 0.046 | koala bear  | 0.396  | bus                   | 3.266 |
| hat with a wide brim | 0.031 | ski         | 0.000  | piano                 | 1.785 |
| frog                 | 0.524 | dumbbell    | 0.000  | lobster               | 0.316 |
| bench                | 0.000 | rabbit      | 0.340  | porcupine             | 0.000 |
| butterfly            | 1.694 | guitar      | 0.102  | microphone            | 0.000 |
| tape player          | 2.562 | bear        | 1.749  | hippopotamus          | 0.000 |
| bowl                 | 0.628 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 1.546 | otter       | 0.000  | table                 | 0.476 |
| coffee maker         | 5.413 | tie         | 0.000  | turtle                | 0.100 |
| purse                | 0.000 | dragonfly   | 0.186  | lemon                 | 0.896 |
| lizard               | 0.586 | backpack    | 0.297  | tv or monitor         | 2.974 |
| cup or mug           | 0.158 | sheep       | 0.072  | ray                   | 0.342 |
| fox                  | 0.707 | whale       | 1.481  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.019  | bathing cap           | 0.045 |
| bookshelf            | 3.238 | ladybug     | 8.071  | crutch                | 0.000 |
| pretzel              | 0.166 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.016 | lamp        | 0.000  | apple                 | 4.332 |
| cream                | 0.241 | artichoke   | 0.397  | train                 | 0.334 |
| elephant             | 1.193 | bell pepper | 0.464  | miniskirt             | 0.000 |
| orange               | 3.423 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.492 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 1.155  | laptop                | 0.575 |
| pomegranate          | 0.827 | cucumber    | 0.000  | bicycle               | 0.218 |
| banana               | 0.003 | baby bed    | 0.404  | jellyfish             | 0.493 |
| pitcher              | 0.000 | bagel       | 0.124  | beaker                | 1.271 |
| goldfish             | 0.910 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.306  | zebra                 | 0.855 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:28:00] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:28:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:28:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:28:00] d2.evaluation.testing INFO: copypaste: 1.0619,2.7860,0.5937,0.1893,0.4526,1.2463
[11/16 05:28:00] d2.utils.events INFO:  eta: 5:28:54  iter: 7999  total_loss: 0.3247  loss_cls: 0.1748  loss_box_reg: 0.09977  loss_rpn_cls: 0.02682  loss_rpn_loc: 0.02149  time: 0.6814  data_time: 0.0627  lr: 0.004  max_mem: 11811M
[11/16 05:28:14] d2.utils.events INFO:  eta: 5:28:24  iter: 8019  total_loss: 0.3047  loss_cls: 0.166  loss_box_reg: 0.09542  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.02054  time: 0.6814  data_time: 0.0744  lr: 0.004  max_mem: 11811M
[11/16 05:28:27] d2.utils.events INFO:  eta: 5:28:32  iter: 8039  total_loss: 0.316  loss_cls: 0.1724  loss_box_reg: 0.09607  loss_rpn_cls: 0.02689  loss_rpn_loc: 0.01998  time: 0.6814  data_time: 0.0603  lr: 0.004  max_mem: 11811M
[11/16 05:28:41] d2.utils.events INFO:  eta: 5:28:19  iter: 8059  total_loss: 0.301  loss_cls: 0.1645  loss_box_reg: 0.09735  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.01803  time: 0.6816  data_time: 0.0878  lr: 0.004  max_mem: 11811M
[11/16 05:28:55] d2.utils.events INFO:  eta: 5:28:05  iter: 8079  total_loss: 0.3221  loss_cls: 0.1731  loss_box_reg: 0.09638  loss_rpn_cls: 0.02461  loss_rpn_loc: 0.01995  time: 0.6817  data_time: 0.0777  lr: 0.004  max_mem: 11811M
[11/16 05:29:09] d2.utils.events INFO:  eta: 5:27:58  iter: 8099  total_loss: 0.3232  loss_cls: 0.1766  loss_box_reg: 0.09994  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.02015  time: 0.6817  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 05:29:23] d2.utils.events INFO:  eta: 5:27:38  iter: 8119  total_loss: 0.305  loss_cls: 0.1639  loss_box_reg: 0.09691  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.02027  time: 0.6818  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 05:29:36] d2.utils.events INFO:  eta: 5:27:19  iter: 8139  total_loss: 0.3109  loss_cls: 0.1677  loss_box_reg: 0.09669  loss_rpn_cls: 0.02586  loss_rpn_loc: 0.02121  time: 0.6818  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 05:29:50] d2.utils.events INFO:  eta: 5:27:11  iter: 8159  total_loss: 0.3182  loss_cls: 0.1729  loss_box_reg: 0.09769  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.02112  time: 0.6818  data_time: 0.0660  lr: 0.004  max_mem: 11811M
[11/16 05:30:04] d2.utils.events INFO:  eta: 5:26:51  iter: 8179  total_loss: 0.3146  loss_cls: 0.1722  loss_box_reg: 0.1002  loss_rpn_cls: 0.02201  loss_rpn_loc: 0.0202  time: 0.6817  data_time: 0.0600  lr: 0.004  max_mem: 11811M
[11/16 05:30:17] d2.utils.events INFO:  eta: 5:26:41  iter: 8199  total_loss: 0.3141  loss_cls: 0.168  loss_box_reg: 0.09906  loss_rpn_cls: 0.02507  loss_rpn_loc: 0.01893  time: 0.6817  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 05:30:31] d2.utils.events INFO:  eta: 5:26:24  iter: 8219  total_loss: 0.3179  loss_cls: 0.1687  loss_box_reg: 0.09631  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.02161  time: 0.6817  data_time: 0.0617  lr: 0.004  max_mem: 11811M
[11/16 05:30:44] d2.utils.events INFO:  eta: 5:26:16  iter: 8239  total_loss: 0.3087  loss_cls: 0.1667  loss_box_reg: 0.09455  loss_rpn_cls: 0.02493  loss_rpn_loc: 0.02107  time: 0.6817  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 05:30:58] d2.utils.events INFO:  eta: 5:25:57  iter: 8259  total_loss: 0.3058  loss_cls: 0.1738  loss_box_reg: 0.095  loss_rpn_cls: 0.02179  loss_rpn_loc: 0.02123  time: 0.6817  data_time: 0.0621  lr: 0.004  max_mem: 11811M
[11/16 05:31:11] d2.utils.events INFO:  eta: 5:25:23  iter: 8279  total_loss: 0.3152  loss_cls: 0.1685  loss_box_reg: 0.09447  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.01992  time: 0.6816  data_time: 0.0683  lr: 0.004  max_mem: 11811M
[11/16 05:31:25] d2.utils.events INFO:  eta: 5:25:02  iter: 8299  total_loss: 0.2803  loss_cls: 0.1546  loss_box_reg: 0.08966  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.01828  time: 0.6815  data_time: 0.0646  lr: 0.004  max_mem: 11811M
[11/16 05:31:38] d2.utils.events INFO:  eta: 5:24:49  iter: 8319  total_loss: 0.3161  loss_cls: 0.1735  loss_box_reg: 0.09818  loss_rpn_cls: 0.02274  loss_rpn_loc: 0.01958  time: 0.6815  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 05:31:52] d2.utils.events INFO:  eta: 5:24:35  iter: 8339  total_loss: 0.3057  loss_cls: 0.166  loss_box_reg: 0.09448  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.02039  time: 0.6816  data_time: 0.0840  lr: 0.004  max_mem: 11811M
[11/16 05:32:06] d2.utils.events INFO:  eta: 5:24:21  iter: 8359  total_loss: 0.3175  loss_cls: 0.1694  loss_box_reg: 0.09829  loss_rpn_cls: 0.02431  loss_rpn_loc: 0.01911  time: 0.6816  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/16 05:32:19] d2.utils.events INFO:  eta: 5:24:07  iter: 8379  total_loss: 0.3061  loss_cls: 0.1657  loss_box_reg: 0.09519  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.02153  time: 0.6815  data_time: 0.0671  lr: 0.004  max_mem: 11811M
[11/16 05:32:33] d2.utils.events INFO:  eta: 5:23:54  iter: 8399  total_loss: 0.3086  loss_cls: 0.1647  loss_box_reg: 0.0934  loss_rpn_cls: 0.02513  loss_rpn_loc: 0.02127  time: 0.6816  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 05:32:47] d2.utils.events INFO:  eta: 5:23:39  iter: 8419  total_loss: 0.3239  loss_cls: 0.1735  loss_box_reg: 0.1007  loss_rpn_cls: 0.02471  loss_rpn_loc: 0.02043  time: 0.6815  data_time: 0.0616  lr: 0.004  max_mem: 11811M
[11/16 05:33:00] d2.utils.events INFO:  eta: 5:23:21  iter: 8439  total_loss: 0.3125  loss_cls: 0.1716  loss_box_reg: 0.09871  loss_rpn_cls: 0.02294  loss_rpn_loc: 0.01899  time: 0.6814  data_time: 0.0642  lr: 0.004  max_mem: 11811M
[11/16 05:33:14] d2.utils.events INFO:  eta: 5:23:19  iter: 8459  total_loss: 0.3126  loss_cls: 0.1703  loss_box_reg: 0.0985  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.01891  time: 0.6814  data_time: 0.0730  lr: 0.004  max_mem: 11811M
[11/16 05:33:27] d2.utils.events INFO:  eta: 5:23:09  iter: 8479  total_loss: 0.322  loss_cls: 0.1784  loss_box_reg: 0.1016  loss_rpn_cls: 0.02615  loss_rpn_loc: 0.0192  time: 0.6815  data_time: 0.0785  lr: 0.004  max_mem: 11811M
[11/16 05:33:41] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0008499.pth
[11/16 05:33:42] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:33:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:33:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:33:42] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:33:42] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:33:42] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:33:49] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:13
[11/16 05:33:54] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:11
[11/16 05:33:59] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:05
[11/16 05:34:04] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:00
[11/16 05:34:09] d2.evaluation.evaluator INFO: Inference done 507/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/16 05:34:14] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:49
[11/16 05:34:19] d2.evaluation.evaluator INFO: Inference done 756/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:44
[11/16 05:34:24] d2.evaluation.evaluator INFO: Inference done 879/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:39
[11/16 05:34:29] d2.evaluation.evaluator INFO: Inference done 1002/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:34
[11/16 05:34:34] d2.evaluation.evaluator INFO: Inference done 1123/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:29
[11/16 05:34:39] d2.evaluation.evaluator INFO: Inference done 1244/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:25
[11/16 05:34:44] d2.evaluation.evaluator INFO: Inference done 1363/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/16 05:34:50] d2.evaluation.evaluator INFO: Inference done 1485/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/16 05:34:55] d2.evaluation.evaluator INFO: Inference done 1607/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/16 05:35:00] d2.evaluation.evaluator INFO: Inference done 1731/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:05
[11/16 05:35:05] d2.evaluation.evaluator INFO: Inference done 1854/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/16 05:35:10] d2.evaluation.evaluator INFO: Inference done 1976/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/16 05:35:15] d2.evaluation.evaluator INFO: Inference done 2102/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/16 05:35:20] d2.evaluation.evaluator INFO: Inference done 2225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/16 05:35:25] d2.evaluation.evaluator INFO: Inference done 2348/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/16 05:35:30] d2.evaluation.evaluator INFO: Inference done 2471/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/16 05:35:35] d2.evaluation.evaluator INFO: Inference done 2592/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:30
[11/16 05:35:40] d2.evaluation.evaluator INFO: Inference done 2715/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:25
[11/16 05:35:45] d2.evaluation.evaluator INFO: Inference done 2838/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/16 05:35:50] d2.evaluation.evaluator INFO: Inference done 2959/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:15
[11/16 05:35:55] d2.evaluation.evaluator INFO: Inference done 3079/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/16 05:36:00] d2.evaluation.evaluator INFO: Inference done 3202/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/16 05:36:05] d2.evaluation.evaluator INFO: Inference done 3323/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:00
[11/16 05:36:06] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.709878 (0.041066 s / iter per device, on 6 devices)
[11/16 05:36:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.039003 s / iter per device, on 6 devices)
[11/16 05:36:08] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:36:08] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:36:09] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:36:09] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:36:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.82 seconds.
[11/16 05:36:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:36:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.18 seconds.
[11/16 05:36:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.288 | 3.393  | 0.700  | 0.241 | 0.633 | 1.521 |
[11/16 05:36:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 1.230 | person      | 1.424  | bird                  | 5.124 |
| red panda            | 0.000 | dog         | 21.435 | snake                 | 2.112 |
| car                  | 9.454 | seal        | 0.322  | helmet                | 0.508 |
| motorcycle           | 1.204 | swine       | 0.640  | stove                 | 0.287 |
| monkey               | 1.681 | watercraft  | 5.299  | chair                 | 0.996 |
| domestic cat         | 0.415 | harp        | 0.000  | antelope              | 0.829 |
| camel                | 0.423 | koala bear  | 1.526  | bus                   | 3.698 |
| hat with a wide brim | 0.639 | ski         | 0.000  | piano                 | 1.834 |
| frog                 | 0.751 | dumbbell    | 0.000  | lobster               | 0.345 |
| bench                | 0.000 | rabbit      | 0.324  | porcupine             | 0.626 |
| butterfly            | 2.240 | guitar      | 0.090  | microphone            | 0.000 |
| tape player          | 4.271 | bear        | 2.460  | hippopotamus          | 0.000 |
| bowl                 | 1.632 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 2.163 | otter       | 0.000  | table                 | 0.775 |
| coffee maker         | 5.242 | tie         | 0.000  | turtle                | 0.468 |
| purse                | 0.000 | dragonfly   | 0.398  | lemon                 | 1.077 |
| lizard               | 0.833 | backpack    | 0.792  | tv or monitor         | 3.647 |
| cup or mug           | 0.151 | sheep       | 0.183  | ray                   | 0.454 |
| fox                  | 1.121 | whale       | 1.289  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.029 |
| bookshelf            | 3.019 | ladybug     | 11.068 | crutch                | 0.000 |
| pretzel              | 0.121 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.044 | lamp        | 0.000  | apple                 | 4.113 |
| cream                | 0.275 | artichoke   | 0.465  | train                 | 0.313 |
| elephant             | 1.115 | bell pepper | 0.858  | miniskirt             | 0.000 |
| orange               | 5.103 | tiger       | 0.256  | sofa                  | 0.092 |
| horse                | 0.319 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.000 | strawberry  | 1.454  | laptop                | 1.456 |
| pomegranate          | 0.887 | cucumber    | 0.000  | bicycle               | 0.380 |
| banana               | 0.076 | baby bed    | 0.507  | jellyfish             | 0.482 |
| pitcher              | 0.000 | bagel       | 0.158  | beaker                | 0.060 |
| goldfish             | 0.884 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.496  | zebra                 | 2.362 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:36:38] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:36:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:36:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:36:38] d2.evaluation.testing INFO: copypaste: 1.2881,3.3935,0.7004,0.2406,0.6327,1.5211
[11/16 05:36:38] d2.utils.events INFO:  eta: 5:22:47  iter: 8499  total_loss: 0.2873  loss_cls: 0.1593  loss_box_reg: 0.09265  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.01776  time: 0.6815  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 05:36:51] d2.utils.events INFO:  eta: 5:22:31  iter: 8519  total_loss: 0.3099  loss_cls: 0.165  loss_box_reg: 0.09714  loss_rpn_cls: 0.02272  loss_rpn_loc: 0.02055  time: 0.6815  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 05:37:05] d2.utils.events INFO:  eta: 5:22:26  iter: 8539  total_loss: 0.3122  loss_cls: 0.1705  loss_box_reg: 0.09763  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.01931  time: 0.6815  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/16 05:37:18] d2.utils.events INFO:  eta: 5:22:11  iter: 8559  total_loss: 0.3139  loss_cls: 0.1683  loss_box_reg: 0.09959  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.02138  time: 0.6815  data_time: 0.0669  lr: 0.004  max_mem: 11811M
[11/16 05:37:32] d2.utils.events INFO:  eta: 5:21:56  iter: 8579  total_loss: 0.3148  loss_cls: 0.1736  loss_box_reg: 0.09644  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.0206  time: 0.6816  data_time: 0.0723  lr: 0.004  max_mem: 11811M
[11/16 05:37:46] d2.utils.events INFO:  eta: 5:21:41  iter: 8599  total_loss: 0.3139  loss_cls: 0.1684  loss_box_reg: 0.09477  loss_rpn_cls: 0.02058  loss_rpn_loc: 0.01855  time: 0.6816  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 05:38:00] d2.utils.events INFO:  eta: 5:21:27  iter: 8619  total_loss: 0.3103  loss_cls: 0.1668  loss_box_reg: 0.09629  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.01945  time: 0.6816  data_time: 0.0715  lr: 0.004  max_mem: 11811M
[11/16 05:38:13] d2.utils.events INFO:  eta: 5:21:12  iter: 8639  total_loss: 0.2944  loss_cls: 0.1629  loss_box_reg: 0.09134  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.02048  time: 0.6815  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 05:38:27] d2.utils.events INFO:  eta: 5:21:04  iter: 8659  total_loss: 0.3073  loss_cls: 0.1662  loss_box_reg: 0.09236  loss_rpn_cls: 0.02156  loss_rpn_loc: 0.02004  time: 0.6815  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 05:38:40] d2.utils.events INFO:  eta: 5:20:47  iter: 8679  total_loss: 0.3091  loss_cls: 0.1656  loss_box_reg: 0.09557  loss_rpn_cls: 0.02147  loss_rpn_loc: 0.02157  time: 0.6816  data_time: 0.0711  lr: 0.004  max_mem: 11811M
[11/16 05:38:54] d2.utils.events INFO:  eta: 5:20:27  iter: 8699  total_loss: 0.3193  loss_cls: 0.1735  loss_box_reg: 0.09977  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.02102  time: 0.6815  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/16 05:39:08] d2.utils.events INFO:  eta: 5:20:22  iter: 8719  total_loss: 0.3108  loss_cls: 0.1691  loss_box_reg: 0.09539  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.02061  time: 0.6815  data_time: 0.0737  lr: 0.004  max_mem: 11811M
[11/16 05:39:21] d2.utils.events INFO:  eta: 5:20:02  iter: 8739  total_loss: 0.3145  loss_cls: 0.1721  loss_box_reg: 0.09942  loss_rpn_cls: 0.02457  loss_rpn_loc: 0.02141  time: 0.6815  data_time: 0.0621  lr: 0.004  max_mem: 11811M
[11/16 05:39:35] d2.utils.events INFO:  eta: 5:19:46  iter: 8759  total_loss: 0.3184  loss_cls: 0.1751  loss_box_reg: 0.1015  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.01874  time: 0.6815  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 05:39:48] d2.utils.events INFO:  eta: 5:19:33  iter: 8779  total_loss: 0.3097  loss_cls: 0.1662  loss_box_reg: 0.0941  loss_rpn_cls: 0.02521  loss_rpn_loc: 0.01887  time: 0.6815  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 05:40:02] d2.utils.events INFO:  eta: 5:19:43  iter: 8799  total_loss: 0.2983  loss_cls: 0.1628  loss_box_reg: 0.09388  loss_rpn_cls: 0.02231  loss_rpn_loc: 0.01864  time: 0.6815  data_time: 0.0739  lr: 0.004  max_mem: 11811M
[11/16 05:40:16] d2.utils.events INFO:  eta: 5:19:19  iter: 8819  total_loss: 0.317  loss_cls: 0.1675  loss_box_reg: 0.09693  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.02054  time: 0.6815  data_time: 0.0688  lr: 0.004  max_mem: 11811M
[11/16 05:40:29] d2.utils.events INFO:  eta: 5:18:57  iter: 8839  total_loss: 0.3153  loss_cls: 0.1745  loss_box_reg: 0.101  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.02056  time: 0.6815  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 05:40:43] d2.utils.events INFO:  eta: 5:18:52  iter: 8859  total_loss: 0.3113  loss_cls: 0.1652  loss_box_reg: 0.09551  loss_rpn_cls: 0.02301  loss_rpn_loc: 0.01928  time: 0.6815  data_time: 0.0765  lr: 0.004  max_mem: 11811M
[11/16 05:40:56] d2.utils.events INFO:  eta: 5:18:24  iter: 8879  total_loss: 0.2963  loss_cls: 0.1631  loss_box_reg: 0.0914  loss_rpn_cls: 0.02285  loss_rpn_loc: 0.01973  time: 0.6815  data_time: 0.0652  lr: 0.004  max_mem: 11811M
[11/16 05:41:10] d2.utils.events INFO:  eta: 5:18:11  iter: 8899  total_loss: 0.2992  loss_cls: 0.1626  loss_box_reg: 0.09586  loss_rpn_cls: 0.02419  loss_rpn_loc: 0.01933  time: 0.6814  data_time: 0.0615  lr: 0.004  max_mem: 11811M
[11/16 05:41:23] d2.utils.events INFO:  eta: 5:17:50  iter: 8919  total_loss: 0.3194  loss_cls: 0.1727  loss_box_reg: 0.09552  loss_rpn_cls: 0.02517  loss_rpn_loc: 0.01951  time: 0.6814  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 05:41:37] d2.utils.events INFO:  eta: 5:17:27  iter: 8939  total_loss: 0.3061  loss_cls: 0.1691  loss_box_reg: 0.09565  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.01954  time: 0.6813  data_time: 0.0592  lr: 0.004  max_mem: 11811M
[11/16 05:41:51] d2.utils.events INFO:  eta: 5:17:10  iter: 8959  total_loss: 0.3154  loss_cls: 0.168  loss_box_reg: 0.09821  loss_rpn_cls: 0.02121  loss_rpn_loc: 0.02096  time: 0.6814  data_time: 0.0699  lr: 0.004  max_mem: 11811M
[11/16 05:42:04] d2.utils.events INFO:  eta: 5:17:04  iter: 8979  total_loss: 0.3075  loss_cls: 0.1677  loss_box_reg: 0.09448  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.01884  time: 0.6814  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/16 05:42:18] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0008999.pth
[11/16 05:42:18] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:42:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:42:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:42:19] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:42:19] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:42:19] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:42:26] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0394 s/iter. ETA=0:02:11
[11/16 05:42:31] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:12
[11/16 05:42:36] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/16 05:42:41] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/16 05:42:46] d2.evaluation.evaluator INFO: Inference done 503/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:55
[11/16 05:42:51] d2.evaluation.evaluator INFO: Inference done 625/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:50
[11/16 05:42:56] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/16 05:43:01] d2.evaluation.evaluator INFO: Inference done 868/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:40
[11/16 05:43:06] d2.evaluation.evaluator INFO: Inference done 990/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/16 05:43:11] d2.evaluation.evaluator INFO: Inference done 1110/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/16 05:43:16] d2.evaluation.evaluator INFO: Inference done 1234/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:26
[11/16 05:43:21] d2.evaluation.evaluator INFO: Inference done 1354/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/16 05:43:26] d2.evaluation.evaluator INFO: Inference done 1476/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/16 05:43:31] d2.evaluation.evaluator INFO: Inference done 1600/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:11
[11/16 05:43:36] d2.evaluation.evaluator INFO: Inference done 1721/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/16 05:43:41] d2.evaluation.evaluator INFO: Inference done 1843/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/16 05:43:46] d2.evaluation.evaluator INFO: Inference done 1963/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/16 05:43:51] d2.evaluation.evaluator INFO: Inference done 2085/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/16 05:43:56] d2.evaluation.evaluator INFO: Inference done 2209/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/16 05:44:01] d2.evaluation.evaluator INFO: Inference done 2329/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/16 05:44:06] d2.evaluation.evaluator INFO: Inference done 2449/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/16 05:44:11] d2.evaluation.evaluator INFO: Inference done 2569/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/16 05:44:16] d2.evaluation.evaluator INFO: Inference done 2690/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:26
[11/16 05:44:22] d2.evaluation.evaluator INFO: Inference done 2812/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:21
[11/16 05:44:27] d2.evaluation.evaluator INFO: Inference done 2931/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:16
[11/16 05:44:32] d2.evaluation.evaluator INFO: Inference done 3050/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/16 05:44:37] d2.evaluation.evaluator INFO: Inference done 3172/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/16 05:44:42] d2.evaluation.evaluator INFO: Inference done 3295/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/16 05:44:43] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.486032 (0.041299 s / iter per device, on 6 devices)
[11/16 05:44:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039292 s / iter per device, on 6 devices)
[11/16 05:44:45] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:44:45] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:44:46] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:44:47] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:45:07] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.48 seconds.
[11/16 05:45:08] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:45:09] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.78 seconds.
[11/16 05:45:09] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.362 | 3.570  | 0.716  | 0.284 | 0.681 | 1.572 |
[11/16 05:45:09] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.059  | person      | 1.289  | bird                  | 5.233 |
| red panda            | 0.000  | dog         | 22.150 | snake                 | 2.126 |
| car                  | 11.631 | seal        | 0.108  | helmet                | 0.538 |
| motorcycle           | 2.277  | swine       | 0.370  | stove                 | 0.897 |
| monkey               | 1.795  | watercraft  | 5.089  | chair                 | 0.833 |
| domestic cat         | 0.594  | harp        | 0.011  | antelope              | 0.602 |
| camel                | 0.019  | koala bear  | 2.089  | bus                   | 4.434 |
| hat with a wide brim | 0.164  | ski         | 0.000  | piano                 | 2.115 |
| frog                 | 1.016  | dumbbell    | 0.000  | lobster               | 0.686 |
| bench                | 0.000  | rabbit      | 0.265  | porcupine             | 0.461 |
| butterfly            | 3.015  | guitar      | 0.173  | microphone            | 0.000 |
| tape player          | 2.473  | bear        | 1.726  | hippopotamus          | 0.000 |
| bowl                 | 1.977  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 2.903  | otter       | 0.000  | table                 | 0.641 |
| coffee maker         | 3.810  | tie         | 0.000  | turtle                | 0.436 |
| purse                | 0.792  | dragonfly   | 0.327  | lemon                 | 1.353 |
| lizard               | 0.991  | backpack    | 1.139  | tv or monitor         | 3.260 |
| cup or mug           | 0.248  | sheep       | 0.654  | ray                   | 0.610 |
| fox                  | 0.472  | whale       | 1.963  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000  | fig         | 0.000  | bathing cap           | 0.088 |
| bookshelf            | 4.281  | ladybug     | 10.807 | crutch                | 0.000 |
| pretzel              | 0.100  | sunglasses  | 0.000  | starfish              | 1.001 |
| croquet ball         | 0.082  | lamp        | 0.000  | apple                 | 4.426 |
| cream                | 0.025  | artichoke   | 0.705  | train                 | 0.742 |
| elephant             | 1.061  | bell pepper | 0.608  | miniskirt             | 0.000 |
| orange               | 3.555  | tiger       | 0.119  | sofa                  | 0.095 |
| horse                | 0.277  | violin      | 0.000  | traffic light         | 0.296 |
| drum                 | 0.042  | strawberry  | 0.862  | laptop                | 0.474 |
| pomegranate          | 1.273  | cucumber    | 0.000  | bicycle               | 0.932 |
| banana               | 0.145  | baby bed    | 0.723  | jellyfish             | 0.753 |
| pitcher              | 0.000  | bagel       | 0.586  | beaker                | 0.328 |
| goldfish             | 0.200  | nail        | 0.000  | mushroom              | 0.007 |
| flower pot           | 0.000  | cattle      | 1.188  | zebra                 | 2.619 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 05:45:11] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:45:11] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:45:11] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:45:11] d2.evaluation.testing INFO: copypaste: 1.3621,3.5701,0.7163,0.2838,0.6814,1.5716
[11/16 05:45:11] d2.utils.events INFO:  eta: 5:16:39  iter: 8999  total_loss: 0.3045  loss_cls: 0.1664  loss_box_reg: 0.0935  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.01871  time: 0.6813  data_time: 0.0685  lr: 0.004  max_mem: 11811M
[11/16 05:45:25] d2.utils.events INFO:  eta: 5:16:37  iter: 9019  total_loss: 0.3166  loss_cls: 0.1718  loss_box_reg: 0.09977  loss_rpn_cls: 0.02258  loss_rpn_loc: 0.02106  time: 0.6813  data_time: 0.0610  lr: 0.004  max_mem: 11811M
[11/16 05:45:39] d2.utils.events INFO:  eta: 5:16:24  iter: 9039  total_loss: 0.3084  loss_cls: 0.1662  loss_box_reg: 0.09612  loss_rpn_cls: 0.02484  loss_rpn_loc: 0.01925  time: 0.6814  data_time: 0.0724  lr: 0.004  max_mem: 11811M
[11/16 05:45:52] d2.utils.events INFO:  eta: 5:16:05  iter: 9059  total_loss: 0.3129  loss_cls: 0.1749  loss_box_reg: 0.09475  loss_rpn_cls: 0.02328  loss_rpn_loc: 0.01956  time: 0.6813  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/16 05:46:06] d2.utils.events INFO:  eta: 5:15:52  iter: 9079  total_loss: 0.3166  loss_cls: 0.1713  loss_box_reg: 0.09713  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.02062  time: 0.6813  data_time: 0.0607  lr: 0.004  max_mem: 11811M
[11/16 05:46:20] d2.utils.events INFO:  eta: 5:15:41  iter: 9099  total_loss: 0.3047  loss_cls: 0.163  loss_box_reg: 0.09429  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.01939  time: 0.6814  data_time: 0.0701  lr: 0.004  max_mem: 11811M
[11/16 05:46:33] d2.utils.events INFO:  eta: 5:15:25  iter: 9119  total_loss: 0.3037  loss_cls: 0.1639  loss_box_reg: 0.09853  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.02027  time: 0.6814  data_time: 0.0695  lr: 0.004  max_mem: 11811M
[11/16 05:46:47] d2.utils.events INFO:  eta: 5:15:16  iter: 9139  total_loss: 0.3208  loss_cls: 0.1778  loss_box_reg: 0.09663  loss_rpn_cls: 0.02425  loss_rpn_loc: 0.01932  time: 0.6814  data_time: 0.0710  lr: 0.004  max_mem: 11811M
[11/16 05:47:01] d2.utils.events INFO:  eta: 5:15:02  iter: 9159  total_loss: 0.3111  loss_cls: 0.1669  loss_box_reg: 0.09109  loss_rpn_cls: 0.02728  loss_rpn_loc: 0.02166  time: 0.6813  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/16 05:47:14] d2.utils.events INFO:  eta: 5:14:53  iter: 9179  total_loss: 0.3126  loss_cls: 0.1675  loss_box_reg: 0.09436  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.02013  time: 0.6814  data_time: 0.0630  lr: 0.004  max_mem: 11811M
[11/16 05:47:28] d2.utils.events INFO:  eta: 5:14:38  iter: 9199  total_loss: 0.3018  loss_cls: 0.1662  loss_box_reg: 0.09261  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.01888  time: 0.6813  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 05:47:41] d2.utils.events INFO:  eta: 5:14:22  iter: 9219  total_loss: 0.2805  loss_cls: 0.1507  loss_box_reg: 0.08969  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.01754  time: 0.6813  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 05:47:55] d2.utils.events INFO:  eta: 5:14:00  iter: 9239  total_loss: 0.3189  loss_cls: 0.1695  loss_box_reg: 0.101  loss_rpn_cls: 0.02584  loss_rpn_loc: 0.01826  time: 0.6813  data_time: 0.0828  lr: 0.004  max_mem: 11811M
[11/16 05:48:09] d2.utils.events INFO:  eta: 5:13:57  iter: 9259  total_loss: 0.314  loss_cls: 0.1679  loss_box_reg: 0.09921  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.022  time: 0.6813  data_time: 0.0684  lr: 0.004  max_mem: 11811M
[11/16 05:48:22] d2.utils.events INFO:  eta: 5:13:49  iter: 9279  total_loss: 0.3073  loss_cls: 0.1668  loss_box_reg: 0.09767  loss_rpn_cls: 0.02537  loss_rpn_loc: 0.02206  time: 0.6813  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 05:48:36] d2.utils.events INFO:  eta: 5:13:49  iter: 9299  total_loss: 0.2985  loss_cls: 0.1585  loss_box_reg: 0.09319  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.02086  time: 0.6813  data_time: 0.0728  lr: 0.004  max_mem: 11811M
[11/16 05:48:50] d2.utils.events INFO:  eta: 5:13:29  iter: 9319  total_loss: 0.2901  loss_cls: 0.1589  loss_box_reg: 0.08936  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.01912  time: 0.6813  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 05:49:03] d2.utils.events INFO:  eta: 5:13:12  iter: 9339  total_loss: 0.3051  loss_cls: 0.1665  loss_box_reg: 0.09466  loss_rpn_cls: 0.02259  loss_rpn_loc: 0.01993  time: 0.6813  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 05:49:17] d2.utils.events INFO:  eta: 5:13:09  iter: 9359  total_loss: 0.297  loss_cls: 0.16  loss_box_reg: 0.09278  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.01944  time: 0.6813  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 05:49:31] d2.utils.events INFO:  eta: 5:12:52  iter: 9379  total_loss: 0.2982  loss_cls: 0.1606  loss_box_reg: 0.09407  loss_rpn_cls: 0.02239  loss_rpn_loc: 0.01886  time: 0.6813  data_time: 0.0751  lr: 0.004  max_mem: 11811M
[11/16 05:49:44] d2.utils.events INFO:  eta: 5:12:35  iter: 9399  total_loss: 0.3045  loss_cls: 0.162  loss_box_reg: 0.09581  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.01937  time: 0.6813  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 05:49:58] d2.utils.events INFO:  eta: 5:12:21  iter: 9419  total_loss: 0.2989  loss_cls: 0.1667  loss_box_reg: 0.09433  loss_rpn_cls: 0.02088  loss_rpn_loc: 0.01827  time: 0.6813  data_time: 0.0688  lr: 0.004  max_mem: 11811M
[11/16 05:50:11] d2.utils.events INFO:  eta: 5:12:03  iter: 9439  total_loss: 0.3056  loss_cls: 0.1667  loss_box_reg: 0.09762  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.02032  time: 0.6813  data_time: 0.0607  lr: 0.004  max_mem: 11811M
[11/16 05:50:25] d2.utils.events INFO:  eta: 5:11:44  iter: 9459  total_loss: 0.309  loss_cls: 0.1703  loss_box_reg: 0.09823  loss_rpn_cls: 0.02352  loss_rpn_loc: 0.01854  time: 0.6812  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 05:50:38] d2.utils.events INFO:  eta: 5:11:23  iter: 9479  total_loss: 0.2886  loss_cls: 0.1565  loss_box_reg: 0.08635  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.02002  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 05:50:52] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0009499.pth
[11/16 05:50:52] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:50:53] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:50:53] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:50:53] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:50:53] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:50:53] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:51:00] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0351 s/iter. Eval: 0.0002 s/iter. Total: 0.0364 s/iter. ETA=0:02:01
[11/16 05:51:05] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:13
[11/16 05:51:10] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/16 05:51:15] d2.evaluation.evaluator INFO: Inference done 377/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/16 05:51:20] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/16 05:51:25] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/16 05:51:30] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/16 05:51:35] d2.evaluation.evaluator INFO: Inference done 869/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:40
[11/16 05:51:40] d2.evaluation.evaluator INFO: Inference done 991/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/16 05:51:45] d2.evaluation.evaluator INFO: Inference done 1116/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/16 05:51:50] d2.evaluation.evaluator INFO: Inference done 1238/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:25
[11/16 05:51:55] d2.evaluation.evaluator INFO: Inference done 1359/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/16 05:52:00] d2.evaluation.evaluator INFO: Inference done 1479/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:16
[11/16 05:52:05] d2.evaluation.evaluator INFO: Inference done 1603/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:10
[11/16 05:52:10] d2.evaluation.evaluator INFO: Inference done 1724/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:06
[11/16 05:52:15] d2.evaluation.evaluator INFO: Inference done 1846/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:01
[11/16 05:52:20] d2.evaluation.evaluator INFO: Inference done 1970/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:55
[11/16 05:52:25] d2.evaluation.evaluator INFO: Inference done 2093/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:50
[11/16 05:52:30] d2.evaluation.evaluator INFO: Inference done 2213/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:46
[11/16 05:52:35] d2.evaluation.evaluator INFO: Inference done 2334/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/16 05:52:40] d2.evaluation.evaluator INFO: Inference done 2449/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/16 05:52:45] d2.evaluation.evaluator INFO: Inference done 2569/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/16 05:52:50] d2.evaluation.evaluator INFO: Inference done 2693/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:26
[11/16 05:52:55] d2.evaluation.evaluator INFO: Inference done 2816/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:21
[11/16 05:53:00] d2.evaluation.evaluator INFO: Inference done 2941/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/16 05:53:05] d2.evaluation.evaluator INFO: Inference done 3065/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/16 05:53:10] d2.evaluation.evaluator INFO: Inference done 3184/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/16 05:53:15] d2.evaluation.evaluator INFO: Inference done 3307/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:01
[11/16 05:53:17] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.231360 (0.041223 s / iter per device, on 6 devices)
[11/16 05:53:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039211 s / iter per device, on 6 devices)
[11/16 05:53:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 05:53:19] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 05:53:20] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 05:53:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 05:53:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.32 seconds.
[11/16 05:53:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 05:53:42] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.07 seconds.
[11/16 05:53:42] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.231 | 3.247  | 0.632  | 0.148 | 0.584 | 1.408 |
[11/16 05:53:42] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.793 | person      | 1.430  | bird                  | 4.780 |
| red panda            | 0.000 | dog         | 23.079 | snake                 | 1.520 |
| car                  | 7.564 | seal        | 0.014  | helmet                | 0.971 |
| motorcycle           | 1.443 | swine       | 0.687  | stove                 | 1.152 |
| monkey               | 1.501 | watercraft  | 3.520  | chair                 | 0.847 |
| domestic cat         | 0.517 | harp        | 0.286  | antelope              | 1.047 |
| camel                | 0.000 | koala bear  | 1.144  | bus                   | 3.190 |
| hat with a wide brim | 0.005 | ski         | 0.000  | piano                 | 1.977 |
| frog                 | 1.017 | dumbbell    | 0.000  | lobster               | 0.169 |
| bench                | 0.017 | rabbit      | 0.266  | porcupine             | 0.347 |
| butterfly            | 3.002 | guitar      | 0.174  | microphone            | 0.000 |
| tape player          | 2.989 | bear        | 1.229  | hippopotamus          | 0.000 |
| bowl                 | 0.901 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 1.468 | otter       | 0.000  | table                 | 0.496 |
| coffee maker         | 5.133 | tie         | 0.088  | turtle                | 0.198 |
| purse                | 0.074 | dragonfly   | 0.185  | lemon                 | 1.981 |
| lizard               | 0.728 | backpack    | 1.958  | tv or monitor         | 3.968 |
| cup or mug           | 0.094 | sheep       | 0.000  | ray                   | 0.248 |
| fox                  | 0.509 | whale       | 1.217  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.009  | bathing cap           | 0.030 |
| bookshelf            | 4.366 | ladybug     | 8.234  | crutch                | 0.000 |
| pretzel              | 0.116 | sunglasses  | 0.000  | starfish              | 0.990 |
| croquet ball         | 0.136 | lamp        | 0.000  | apple                 | 5.300 |
| cream                | 0.297 | artichoke   | 2.083  | train                 | 1.254 |
| elephant             | 0.682 | bell pepper | 0.915  | miniskirt             | 0.000 |
| orange               | 1.497 | tiger       | 0.000  | sofa                  | 0.270 |
| horse                | 0.000 | violin      | 0.000  | traffic light         | 0.099 |
| drum                 | 0.000 | strawberry  | 1.980  | laptop                | 0.427 |
| pomegranate          | 0.269 | cucumber    | 0.000  | bicycle               | 0.225 |
| banana               | 0.036 | baby bed    | 1.151  | jellyfish             | 0.288 |
| pitcher              | 0.396 | bagel       | 0.292  | beaker                | 2.180 |
| goldfish             | 0.388 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.355  | zebra                 | 2.871 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 05:53:45] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 05:53:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 05:53:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 05:53:45] d2.evaluation.testing INFO: copypaste: 1.2307,3.2473,0.6315,0.1481,0.5837,1.4083
[11/16 05:53:45] d2.utils.events INFO:  eta: 5:11:03  iter: 9499  total_loss: 0.32  loss_cls: 0.1709  loss_box_reg: 0.1021  loss_rpn_cls: 0.02332  loss_rpn_loc: 0.02067  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 05:53:59] d2.utils.events INFO:  eta: 5:10:51  iter: 9519  total_loss: 0.3131  loss_cls: 0.1709  loss_box_reg: 0.09584  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.01913  time: 0.6811  data_time: 0.0602  lr: 0.004  max_mem: 11811M
[11/16 05:54:13] d2.utils.events INFO:  eta: 5:10:38  iter: 9539  total_loss: 0.3083  loss_cls: 0.1651  loss_box_reg: 0.09573  loss_rpn_cls: 0.02343  loss_rpn_loc: 0.02127  time: 0.6812  data_time: 0.0765  lr: 0.004  max_mem: 11811M
[11/16 05:54:26] d2.utils.events INFO:  eta: 5:10:22  iter: 9559  total_loss: 0.2915  loss_cls: 0.1581  loss_box_reg: 0.09328  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.01891  time: 0.6812  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 05:54:40] d2.utils.events INFO:  eta: 5:10:08  iter: 9579  total_loss: 0.296  loss_cls: 0.1634  loss_box_reg: 0.09218  loss_rpn_cls: 0.02347  loss_rpn_loc: 0.01868  time: 0.6812  data_time: 0.0628  lr: 0.004  max_mem: 11811M
[11/16 05:54:53] d2.utils.events INFO:  eta: 5:09:57  iter: 9599  total_loss: 0.3015  loss_cls: 0.1584  loss_box_reg: 0.09366  loss_rpn_cls: 0.02306  loss_rpn_loc: 0.02217  time: 0.6812  data_time: 0.0630  lr: 0.004  max_mem: 11811M
[11/16 05:55:07] d2.utils.events INFO:  eta: 5:09:44  iter: 9619  total_loss: 0.2845  loss_cls: 0.1578  loss_box_reg: 0.09061  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.01919  time: 0.6812  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 05:55:20] d2.utils.events INFO:  eta: 5:09:29  iter: 9639  total_loss: 0.2913  loss_cls: 0.1615  loss_box_reg: 0.09132  loss_rpn_cls: 0.02285  loss_rpn_loc: 0.01816  time: 0.6811  data_time: 0.0583  lr: 0.004  max_mem: 11811M
[11/16 05:55:35] d2.utils.events INFO:  eta: 5:09:17  iter: 9659  total_loss: 0.2938  loss_cls: 0.1614  loss_box_reg: 0.09031  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.01895  time: 0.6813  data_time: 0.0837  lr: 0.004  max_mem: 11811M
[11/16 05:55:48] d2.utils.events INFO:  eta: 5:09:03  iter: 9679  total_loss: 0.3135  loss_cls: 0.1635  loss_box_reg: 0.09725  loss_rpn_cls: 0.02195  loss_rpn_loc: 0.02046  time: 0.6813  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 05:56:02] d2.utils.events INFO:  eta: 5:08:48  iter: 9699  total_loss: 0.3028  loss_cls: 0.1645  loss_box_reg: 0.0957  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.0193  time: 0.6812  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 05:56:15] d2.utils.events INFO:  eta: 5:08:36  iter: 9719  total_loss: 0.3053  loss_cls: 0.1632  loss_box_reg: 0.0953  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.01981  time: 0.6813  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 05:56:29] d2.utils.events INFO:  eta: 5:08:25  iter: 9739  total_loss: 0.2994  loss_cls: 0.1646  loss_box_reg: 0.0944  loss_rpn_cls: 0.02104  loss_rpn_loc: 0.01941  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 05:56:42] d2.utils.events INFO:  eta: 5:08:02  iter: 9759  total_loss: 0.3111  loss_cls: 0.1682  loss_box_reg: 0.09495  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.01921  time: 0.6812  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 05:56:56] d2.utils.events INFO:  eta: 5:07:43  iter: 9779  total_loss: 0.3099  loss_cls: 0.1681  loss_box_reg: 0.09528  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.02046  time: 0.6812  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 05:57:10] d2.utils.events INFO:  eta: 5:07:23  iter: 9799  total_loss: 0.2958  loss_cls: 0.1581  loss_box_reg: 0.09188  loss_rpn_cls: 0.02226  loss_rpn_loc: 0.02022  time: 0.6812  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 05:57:23] d2.utils.events INFO:  eta: 5:07:15  iter: 9819  total_loss: 0.3116  loss_cls: 0.1664  loss_box_reg: 0.09626  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.02079  time: 0.6812  data_time: 0.0819  lr: 0.004  max_mem: 11811M
[11/16 05:57:37] d2.utils.events INFO:  eta: 5:07:03  iter: 9839  total_loss: 0.2936  loss_cls: 0.1607  loss_box_reg: 0.09021  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.02028  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 05:57:50] d2.utils.events INFO:  eta: 5:06:47  iter: 9859  total_loss: 0.2986  loss_cls: 0.1628  loss_box_reg: 0.09434  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.01924  time: 0.6811  data_time: 0.0694  lr: 0.004  max_mem: 11811M
[11/16 05:58:04] d2.utils.events INFO:  eta: 5:06:38  iter: 9879  total_loss: 0.3173  loss_cls: 0.1659  loss_box_reg: 0.09228  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.02144  time: 0.6811  data_time: 0.0616  lr: 0.004  max_mem: 11811M
[11/16 05:58:18] d2.utils.events INFO:  eta: 5:06:24  iter: 9899  total_loss: 0.309  loss_cls: 0.1677  loss_box_reg: 0.09663  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.02067  time: 0.6811  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 05:58:31] d2.utils.events INFO:  eta: 5:06:17  iter: 9919  total_loss: 0.3014  loss_cls: 0.165  loss_box_reg: 0.09675  loss_rpn_cls: 0.02156  loss_rpn_loc: 0.01916  time: 0.6811  data_time: 0.0621  lr: 0.004  max_mem: 11811M
[11/16 05:58:45] d2.utils.events INFO:  eta: 5:06:00  iter: 9939  total_loss: 0.3008  loss_cls: 0.1609  loss_box_reg: 0.09541  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.02181  time: 0.6811  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 05:58:58] d2.utils.events INFO:  eta: 5:05:44  iter: 9959  total_loss: 0.2959  loss_cls: 0.1588  loss_box_reg: 0.09242  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.02066  time: 0.6811  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 05:59:12] d2.utils.events INFO:  eta: 5:05:31  iter: 9979  total_loss: 0.3  loss_cls: 0.1616  loss_box_reg: 0.09221  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.01898  time: 0.6811  data_time: 0.0647  lr: 0.004  max_mem: 11811M
[11/16 05:59:26] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0009999.pth
[11/16 05:59:26] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 05:59:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 05:59:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 05:59:27] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 05:59:27] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 05:59:27] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 05:59:34] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0382 s/iter. Eval: 0.0002 s/iter. Total: 0.0396 s/iter. ETA=0:02:11
[11/16 05:59:39] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:14
[11/16 05:59:44] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/16 05:59:49] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/16 05:59:54] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 05:59:59] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/16 06:00:04] d2.evaluation.evaluator INFO: Inference done 745/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/16 06:00:09] d2.evaluation.evaluator INFO: Inference done 869/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:40
[11/16 06:00:14] d2.evaluation.evaluator INFO: Inference done 990/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/16 06:00:19] d2.evaluation.evaluator INFO: Inference done 1111/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:31
[11/16 06:00:24] d2.evaluation.evaluator INFO: Inference done 1232/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/16 06:00:29] d2.evaluation.evaluator INFO: Inference done 1358/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:21
[11/16 06:00:34] d2.evaluation.evaluator INFO: Inference done 1481/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:15
[11/16 06:00:39] d2.evaluation.evaluator INFO: Inference done 1603/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:10
[11/16 06:00:44] d2.evaluation.evaluator INFO: Inference done 1724/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:06
[11/16 06:00:49] d2.evaluation.evaluator INFO: Inference done 1843/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/16 06:00:54] d2.evaluation.evaluator INFO: Inference done 1961/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/16 06:00:59] d2.evaluation.evaluator INFO: Inference done 2081/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:51
[11/16 06:01:04] d2.evaluation.evaluator INFO: Inference done 2201/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:46
[11/16 06:01:09] d2.evaluation.evaluator INFO: Inference done 2324/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:41
[11/16 06:01:14] d2.evaluation.evaluator INFO: Inference done 2446/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/16 06:01:19] d2.evaluation.evaluator INFO: Inference done 2564/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/16 06:01:24] d2.evaluation.evaluator INFO: Inference done 2680/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:27
[11/16 06:01:30] d2.evaluation.evaluator INFO: Inference done 2800/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/16 06:01:35] d2.evaluation.evaluator INFO: Inference done 2921/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/16 06:01:40] d2.evaluation.evaluator INFO: Inference done 3043/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/16 06:01:45] d2.evaluation.evaluator INFO: Inference done 3162/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/16 06:01:50] d2.evaluation.evaluator INFO: Inference done 3282/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:02
[11/16 06:01:52] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.921356 (0.041430 s / iter per device, on 6 devices)
[11/16 06:01:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039460 s / iter per device, on 6 devices)
[11/16 06:01:54] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:01:54] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:01:55] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:01:56] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:02:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.70 seconds.
[11/16 06:02:17] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:02:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.18 seconds.
[11/16 06:02:19] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.997 | 2.734  | 0.502  | 0.007 | 0.370 | 1.180 |
[11/16 06:02:19] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 0.376 | person      | 1.412  | bird                  | 5.046 |
| red panda            | 0.000 | dog         | 19.157 | snake                 | 1.081 |
| car                  | 5.942 | seal        | 0.000  | helmet                | 0.381 |
| motorcycle           | 0.596 | swine       | 0.284  | stove                 | 0.297 |
| monkey               | 2.740 | watercraft  | 5.384  | chair                 | 0.945 |
| domestic cat         | 0.181 | harp        | 0.000  | antelope              | 0.494 |
| camel                | 0.013 | koala bear  | 1.645  | bus                   | 2.700 |
| hat with a wide brim | 0.001 | ski         | 0.000  | piano                 | 1.412 |
| frog                 | 0.917 | dumbbell    | 0.000  | lobster               | 0.431 |
| bench                | 0.000 | rabbit      | 0.507  | porcupine             | 0.000 |
| butterfly            | 3.224 | guitar      | 0.000  | microphone            | 0.000 |
| tape player          | 3.649 | bear        | 0.705  | hippopotamus          | 0.000 |
| bowl                 | 1.009 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 0.925 | otter       | 0.000  | table                 | 0.275 |
| coffee maker         | 0.644 | tie         | 0.000  | turtle                | 0.110 |
| purse                | 0.000 | dragonfly   | 0.184  | lemon                 | 2.285 |
| lizard               | 0.069 | backpack    | 0.000  | tv or monitor         | 2.526 |
| cup or mug           | 0.039 | sheep       | 0.000  | ray                   | 0.381 |
| fox                  | 0.276 | whale       | 0.585  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.000  | bathing cap           | 0.041 |
| bookshelf            | 1.967 | ladybug     | 8.515  | crutch                | 0.000 |
| pretzel              | 0.117 | sunglasses  | 0.000  | starfish              | 0.021 |
| croquet ball         | 0.000 | lamp        | 0.000  | apple                 | 0.978 |
| cream                | 0.037 | artichoke   | 1.676  | train                 | 0.290 |
| elephant             | 0.465 | bell pepper | 0.288  | miniskirt             | 0.000 |
| orange               | 4.026 | tiger       | 0.000  | sofa                  | 0.000 |
| horse                | 0.128 | violin      | 0.000  | traffic light         | 0.000 |
| drum                 | 0.011 | strawberry  | 1.975  | laptop                | 0.076 |
| pomegranate          | 2.391 | cucumber    | 0.000  | bicycle               | 0.180 |
| banana               | 0.078 | baby bed    | 0.000  | jellyfish             | 0.688 |
| pitcher              | 0.000 | bagel       | 0.145  | beaker                | 2.207 |
| goldfish             | 0.289 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.594  | zebra                 | 3.720 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 06:02:22] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:02:22] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:02:22] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:02:22] d2.evaluation.testing INFO: copypaste: 0.9973,2.7336,0.5017,0.0072,0.3700,1.1796
[11/16 06:02:22] d2.utils.events INFO:  eta: 5:05:28  iter: 9999  total_loss: 0.3354  loss_cls: 0.1802  loss_box_reg: 0.0949  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.02056  time: 0.6812  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 06:02:35] d2.utils.events INFO:  eta: 5:05:17  iter: 10019  total_loss: 0.4301  loss_cls: 0.258  loss_box_reg: 0.1117  loss_rpn_cls: 0.03911  loss_rpn_loc: 0.0233  time: 0.6812  data_time: 0.0700  lr: 0.004  max_mem: 11811M
[11/16 06:02:49] d2.utils.events INFO:  eta: 5:04:55  iter: 10039  total_loss: 0.4329  loss_cls: 0.255  loss_box_reg: 0.1098  loss_rpn_cls: 0.03424  loss_rpn_loc: 0.02234  time: 0.6811  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 06:03:02] d2.utils.events INFO:  eta: 5:04:42  iter: 10059  total_loss: 0.3461  loss_cls: 0.1895  loss_box_reg: 0.1007  loss_rpn_cls: 0.03128  loss_rpn_loc: 0.02219  time: 0.6811  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 06:03:16] d2.utils.events INFO:  eta: 5:04:21  iter: 10079  total_loss: 0.3587  loss_cls: 0.202  loss_box_reg: 0.1051  loss_rpn_cls: 0.02464  loss_rpn_loc: 0.02019  time: 0.6810  data_time: 0.0744  lr: 0.004  max_mem: 11811M
[11/16 06:03:29] d2.utils.events INFO:  eta: 5:04:05  iter: 10099  total_loss: 0.3433  loss_cls: 0.1915  loss_box_reg: 0.1025  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.02064  time: 0.6811  data_time: 0.0761  lr: 0.004  max_mem: 11811M
[11/16 06:03:43] d2.utils.events INFO:  eta: 5:03:52  iter: 10119  total_loss: 0.3047  loss_cls: 0.1693  loss_box_reg: 0.09403  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.01933  time: 0.6811  data_time: 0.0689  lr: 0.004  max_mem: 11811M
[11/16 06:03:57] d2.utils.events INFO:  eta: 5:03:37  iter: 10139  total_loss: 0.3229  loss_cls: 0.177  loss_box_reg: 0.09845  loss_rpn_cls: 0.02248  loss_rpn_loc: 0.01984  time: 0.6811  data_time: 0.0835  lr: 0.004  max_mem: 11811M
[11/16 06:04:11] d2.utils.events INFO:  eta: 5:03:27  iter: 10159  total_loss: 0.308  loss_cls: 0.1679  loss_box_reg: 0.09506  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.02036  time: 0.6811  data_time: 0.0760  lr: 0.004  max_mem: 11811M
[11/16 06:04:24] d2.utils.events INFO:  eta: 5:03:11  iter: 10179  total_loss: 0.3125  loss_cls: 0.1674  loss_box_reg: 0.09517  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.01908  time: 0.6811  data_time: 0.0625  lr: 0.004  max_mem: 11811M
[11/16 06:04:38] d2.utils.events INFO:  eta: 5:03:05  iter: 10199  total_loss: 0.316  loss_cls: 0.1721  loss_box_reg: 0.09805  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.01829  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11811M
[11/16 06:04:51] d2.utils.events INFO:  eta: 5:03:02  iter: 10219  total_loss: 0.3084  loss_cls: 0.1719  loss_box_reg: 0.09725  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.01931  time: 0.6811  data_time: 0.0780  lr: 0.004  max_mem: 11811M
[11/16 06:05:05] d2.utils.events INFO:  eta: 5:02:48  iter: 10239  total_loss: 0.309  loss_cls: 0.1666  loss_box_reg: 0.09409  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.01874  time: 0.6811  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 06:05:18] d2.utils.events INFO:  eta: 5:02:27  iter: 10259  total_loss: 0.3092  loss_cls: 0.1719  loss_box_reg: 0.09444  loss_rpn_cls: 0.02164  loss_rpn_loc: 0.01967  time: 0.6811  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 06:05:32] d2.utils.events INFO:  eta: 5:02:08  iter: 10279  total_loss: 0.3132  loss_cls: 0.1745  loss_box_reg: 0.0976  loss_rpn_cls: 0.02444  loss_rpn_loc: 0.01957  time: 0.6811  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 06:05:46] d2.utils.events INFO:  eta: 5:01:55  iter: 10299  total_loss: 0.3039  loss_cls: 0.1672  loss_box_reg: 0.0984  loss_rpn_cls: 0.0207  loss_rpn_loc: 0.01993  time: 0.6811  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 06:05:59] d2.utils.events INFO:  eta: 5:01:47  iter: 10319  total_loss: 0.3035  loss_cls: 0.1675  loss_box_reg: 0.09282  loss_rpn_cls: 0.02473  loss_rpn_loc: 0.02057  time: 0.6811  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 06:06:13] d2.utils.events INFO:  eta: 5:01:36  iter: 10339  total_loss: 0.311  loss_cls: 0.1717  loss_box_reg: 0.09337  loss_rpn_cls: 0.02176  loss_rpn_loc: 0.02063  time: 0.6811  data_time: 0.0772  lr: 0.004  max_mem: 11811M
[11/16 06:06:27] d2.utils.events INFO:  eta: 5:01:20  iter: 10359  total_loss: 0.3  loss_cls: 0.1665  loss_box_reg: 0.09241  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.0181  time: 0.6812  data_time: 0.0740  lr: 0.004  max_mem: 11811M
[11/16 06:06:41] d2.utils.events INFO:  eta: 5:01:11  iter: 10379  total_loss: 0.2969  loss_cls: 0.1686  loss_box_reg: 0.09443  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.01722  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 06:06:54] d2.utils.events INFO:  eta: 5:01:03  iter: 10399  total_loss: 0.3168  loss_cls: 0.1727  loss_box_reg: 0.09844  loss_rpn_cls: 0.02153  loss_rpn_loc: 0.02118  time: 0.6812  data_time: 0.0718  lr: 0.004  max_mem: 11811M
[11/16 06:07:08] d2.utils.events INFO:  eta: 5:00:50  iter: 10419  total_loss: 0.3039  loss_cls: 0.1659  loss_box_reg: 0.09677  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.01786  time: 0.6812  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 06:07:22] d2.utils.events INFO:  eta: 5:00:45  iter: 10439  total_loss: 0.3118  loss_cls: 0.1742  loss_box_reg: 0.09655  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.0192  time: 0.6812  data_time: 0.0659  lr: 0.004  max_mem: 11811M
[11/16 06:07:35] d2.utils.events INFO:  eta: 5:00:32  iter: 10459  total_loss: 0.2953  loss_cls: 0.1603  loss_box_reg: 0.09496  loss_rpn_cls: 0.02241  loss_rpn_loc: 0.02031  time: 0.6812  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 06:07:49] d2.utils.events INFO:  eta: 5:00:19  iter: 10479  total_loss: 0.3102  loss_cls: 0.1675  loss_box_reg: 0.09477  loss_rpn_cls: 0.02361  loss_rpn_loc: 0.01789  time: 0.6812  data_time: 0.0715  lr: 0.004  max_mem: 11811M
[11/16 06:08:03] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0010499.pth
[11/16 06:08:03] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:08:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:08:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:08:04] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:08:04] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:08:04] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:08:11] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0433 s/iter. ETA=0:02:24
[11/16 06:08:16] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:15
[11/16 06:08:21] d2.evaluation.evaluator INFO: Inference done 251/3334. Dataloading: 0.0017 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:09
[11/16 06:08:26] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/16 06:08:31] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 06:08:36] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0017 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/16 06:08:41] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/16 06:08:46] d2.evaluation.evaluator INFO: Inference done 862/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/16 06:08:51] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/16 06:08:56] d2.evaluation.evaluator INFO: Inference done 1104/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/16 06:09:01] d2.evaluation.evaluator INFO: Inference done 1225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/16 06:09:06] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/16 06:09:11] d2.evaluation.evaluator INFO: Inference done 1467/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/16 06:09:16] d2.evaluation.evaluator INFO: Inference done 1586/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/16 06:09:21] d2.evaluation.evaluator INFO: Inference done 1706/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/16 06:09:26] d2.evaluation.evaluator INFO: Inference done 1829/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/16 06:09:31] d2.evaluation.evaluator INFO: Inference done 1951/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:57
[11/16 06:09:36] d2.evaluation.evaluator INFO: Inference done 2070/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/16 06:09:41] d2.evaluation.evaluator INFO: Inference done 2192/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:47
[11/16 06:09:46] d2.evaluation.evaluator INFO: Inference done 2309/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/16 06:09:51] d2.evaluation.evaluator INFO: Inference done 2425/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/16 06:09:56] d2.evaluation.evaluator INFO: Inference done 2543/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:32
[11/16 06:10:01] d2.evaluation.evaluator INFO: Inference done 2663/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:27
[11/16 06:10:06] d2.evaluation.evaluator INFO: Inference done 2780/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/16 06:10:11] d2.evaluation.evaluator INFO: Inference done 2902/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/16 06:10:16] d2.evaluation.evaluator INFO: Inference done 3020/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:13
[11/16 06:10:21] d2.evaluation.evaluator INFO: Inference done 3140/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:08
[11/16 06:10:26] d2.evaluation.evaluator INFO: Inference done 3261/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:03
[11/16 06:10:30] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.196747 (0.041813 s / iter per device, on 6 devices)
[11/16 06:10:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039824 s / iter per device, on 6 devices)
[11/16 06:10:32] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:10:33] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:10:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:10:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:10:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.89 seconds.
[11/16 06:10:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:10:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.16 seconds.
[11/16 06:10:59] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.506 | 3.907  | 0.872  | 0.122 | 0.607 | 1.783 |
[11/16 06:10:59] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP    | category    | AP     | category              | AP    |
|:---------------------|:------|:------------|:-------|:----------------------|:------|
| cart                 | 2.483 | person      | 1.742  | bird                  | 6.227 |
| red panda            | 0.000 | dog         | 23.889 | snake                 | 3.109 |
| car                  | 9.634 | seal        | 0.824  | helmet                | 0.431 |
| motorcycle           | 1.512 | swine       | 1.206  | stove                 | 0.786 |
| monkey               | 2.675 | watercraft  | 6.021  | chair                 | 0.862 |
| domestic cat         | 0.870 | harp        | 0.767  | antelope              | 1.405 |
| camel                | 0.039 | koala bear  | 0.768  | bus                   | 3.355 |
| hat with a wide brim | 0.156 | ski         | 0.000  | piano                 | 3.776 |
| frog                 | 0.900 | dumbbell    | 0.000  | lobster               | 0.654 |
| bench                | 0.000 | rabbit      | 1.597  | porcupine             | 0.051 |
| butterfly            | 4.215 | guitar      | 0.138  | microphone            | 0.000 |
| tape player          | 1.889 | bear        | 3.584  | hippopotamus          | 0.000 |
| bowl                 | 1.717 | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 2.643 | otter       | 0.000  | table                 | 0.633 |
| coffee maker         | 6.296 | tie         | 0.000  | turtle                | 0.750 |
| purse                | 0.000 | dragonfly   | 0.425  | lemon                 | 0.893 |
| lizard               | 1.208 | backpack    | 1.019  | tv or monitor         | 4.252 |
| cup or mug           | 0.152 | sheep       | 0.466  | ray                   | 0.566 |
| fox                  | 1.087 | whale       | 1.101  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000 | fig         | 0.031  | bathing cap           | 0.155 |
| bookshelf            | 4.431 | ladybug     | 8.622  | crutch                | 0.000 |
| pretzel              | 0.368 | sunglasses  | 0.000  | starfish              | 0.000 |
| croquet ball         | 0.108 | lamp        | 0.231  | apple                 | 3.175 |
| cream                | 1.261 | artichoke   | 1.430  | train                 | 0.456 |
| elephant             | 1.611 | bell pepper | 0.122  | miniskirt             | 0.000 |
| orange               | 5.211 | tiger       | 1.188  | sofa                  | 0.619 |
| horse                | 0.560 | violin      | 0.000  | traffic light         | 0.172 |
| drum                 | 0.000 | strawberry  | 2.029  | laptop                | 0.609 |
| pomegranate          | 0.275 | cucumber    | 0.000  | bicycle               | 0.287 |
| banana               | 0.050 | baby bed    | 1.825  | jellyfish             | 1.942 |
| pitcher              | 0.000 | bagel       | 0.622  | beaker                | 1.122 |
| goldfish             | 0.675 | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000 | cattle      | 0.452  | zebra                 | 2.188 |
| wine bottle          | 0.000 |             |        |                       |       |
[11/16 06:11:02] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:11:02] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:11:02] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:11:02] d2.evaluation.testing INFO: copypaste: 1.5060,3.9073,0.8715,0.1223,0.6073,1.7833
[11/16 06:11:02] d2.utils.events INFO:  eta: 5:00:11  iter: 10499  total_loss: 0.3005  loss_cls: 0.1651  loss_box_reg: 0.09445  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.01923  time: 0.6812  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 06:11:15] d2.utils.events INFO:  eta: 4:59:57  iter: 10519  total_loss: 0.2964  loss_cls: 0.1632  loss_box_reg: 0.09372  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.02003  time: 0.6812  data_time: 0.0591  lr: 0.004  max_mem: 11811M
[11/16 06:11:29] d2.utils.events INFO:  eta: 4:59:43  iter: 10539  total_loss: 0.3036  loss_cls: 0.1627  loss_box_reg: 0.09384  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.01992  time: 0.6812  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 06:11:42] d2.utils.events INFO:  eta: 4:59:30  iter: 10559  total_loss: 0.3223  loss_cls: 0.1792  loss_box_reg: 0.1004  loss_rpn_cls: 0.02504  loss_rpn_loc: 0.02141  time: 0.6812  data_time: 0.0712  lr: 0.004  max_mem: 11811M
[11/16 06:11:56] d2.utils.events INFO:  eta: 4:59:16  iter: 10579  total_loss: 0.2986  loss_cls: 0.1651  loss_box_reg: 0.09414  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.01801  time: 0.6812  data_time: 0.0734  lr: 0.004  max_mem: 11811M
[11/16 06:12:10] d2.utils.events INFO:  eta: 4:59:03  iter: 10599  total_loss: 0.2915  loss_cls: 0.1574  loss_box_reg: 0.09542  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.01864  time: 0.6812  data_time: 0.0615  lr: 0.004  max_mem: 11811M
[11/16 06:12:23] d2.utils.events INFO:  eta: 4:58:46  iter: 10619  total_loss: 0.2962  loss_cls: 0.1556  loss_box_reg: 0.09198  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.01884  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11811M
[11/16 06:12:37] d2.utils.events INFO:  eta: 4:58:35  iter: 10639  total_loss: 0.3001  loss_cls: 0.1688  loss_box_reg: 0.09592  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.01896  time: 0.6811  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 06:12:50] d2.utils.events INFO:  eta: 4:58:19  iter: 10659  total_loss: 0.3042  loss_cls: 0.1624  loss_box_reg: 0.09737  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.01956  time: 0.6811  data_time: 0.0704  lr: 0.004  max_mem: 11811M
[11/16 06:13:04] d2.utils.events INFO:  eta: 4:58:01  iter: 10679  total_loss: 0.2976  loss_cls: 0.1621  loss_box_reg: 0.09412  loss_rpn_cls: 0.02313  loss_rpn_loc: 0.01921  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11811M
[11/16 06:13:18] d2.utils.events INFO:  eta: 4:57:52  iter: 10699  total_loss: 0.2832  loss_cls: 0.1525  loss_box_reg: 0.09134  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.01822  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 06:13:31] d2.utils.events INFO:  eta: 4:57:40  iter: 10719  total_loss: 0.3093  loss_cls: 0.1664  loss_box_reg: 0.09462  loss_rpn_cls: 0.022  loss_rpn_loc: 0.0197  time: 0.6812  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/16 06:13:45] d2.utils.events INFO:  eta: 4:57:28  iter: 10739  total_loss: 0.3144  loss_cls: 0.1658  loss_box_reg: 0.0992  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.02011  time: 0.6812  data_time: 0.0767  lr: 0.004  max_mem: 11811M
[11/16 06:13:59] d2.utils.events INFO:  eta: 4:57:15  iter: 10759  total_loss: 0.3  loss_cls: 0.1641  loss_box_reg: 0.09702  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.02074  time: 0.6812  data_time: 0.0703  lr: 0.004  max_mem: 11811M
[11/16 06:14:12] d2.utils.events INFO:  eta: 4:57:07  iter: 10779  total_loss: 0.2916  loss_cls: 0.1541  loss_box_reg: 0.09132  loss_rpn_cls: 0.02047  loss_rpn_loc: 0.01955  time: 0.6812  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/16 06:14:26] d2.utils.events INFO:  eta: 4:56:49  iter: 10799  total_loss: 0.2903  loss_cls: 0.1569  loss_box_reg: 0.08931  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.02021  time: 0.6811  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 06:14:39] d2.utils.events INFO:  eta: 4:56:35  iter: 10819  total_loss: 0.2954  loss_cls: 0.1605  loss_box_reg: 0.09504  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.02009  time: 0.6811  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 06:14:53] d2.utils.events INFO:  eta: 4:56:26  iter: 10839  total_loss: 0.3005  loss_cls: 0.1664  loss_box_reg: 0.0931  loss_rpn_cls: 0.02146  loss_rpn_loc: 0.02034  time: 0.6811  data_time: 0.0709  lr: 0.004  max_mem: 11811M
[11/16 06:15:07] d2.utils.events INFO:  eta: 4:56:13  iter: 10859  total_loss: 0.3141  loss_cls: 0.1728  loss_box_reg: 0.1003  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.01856  time: 0.6812  data_time: 0.0806  lr: 0.004  max_mem: 11811M
[11/16 06:15:21] d2.utils.events INFO:  eta: 4:56:05  iter: 10879  total_loss: 0.2944  loss_cls: 0.16  loss_box_reg: 0.09292  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.01946  time: 0.6812  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 06:15:34] d2.utils.events INFO:  eta: 4:56:00  iter: 10899  total_loss: 0.2943  loss_cls: 0.1578  loss_box_reg: 0.09187  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.02019  time: 0.6812  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 06:15:48] d2.utils.events INFO:  eta: 4:55:41  iter: 10919  total_loss: 0.2868  loss_cls: 0.157  loss_box_reg: 0.09114  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.01886  time: 0.6812  data_time: 0.0705  lr: 0.004  max_mem: 11811M
[11/16 06:16:02] d2.utils.events INFO:  eta: 4:55:33  iter: 10939  total_loss: 0.2982  loss_cls: 0.1617  loss_box_reg: 0.09664  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.01778  time: 0.6812  data_time: 0.0737  lr: 0.004  max_mem: 11811M
[11/16 06:16:15] d2.utils.events INFO:  eta: 4:55:19  iter: 10959  total_loss: 0.3016  loss_cls: 0.1684  loss_box_reg: 0.09538  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.01812  time: 0.6812  data_time: 0.0612  lr: 0.004  max_mem: 11811M
[11/16 06:16:29] d2.utils.events INFO:  eta: 4:54:52  iter: 10979  total_loss: 0.3  loss_cls: 0.1633  loss_box_reg: 0.09384  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.0193  time: 0.6812  data_time: 0.0631  lr: 0.004  max_mem: 11811M
[11/16 06:16:42] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0010999.pth
[11/16 06:16:43] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:16:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:16:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:16:43] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:16:44] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:16:44] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:16:51] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:16
[11/16 06:16:56] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:15
[11/16 06:17:01] d2.evaluation.evaluator INFO: Inference done 248/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:10
[11/16 06:17:06] d2.evaluation.evaluator INFO: Inference done 370/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:04
[11/16 06:17:11] d2.evaluation.evaluator INFO: Inference done 491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:58
[11/16 06:17:16] d2.evaluation.evaluator INFO: Inference done 611/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:53
[11/16 06:17:21] d2.evaluation.evaluator INFO: Inference done 732/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:48
[11/16 06:17:26] d2.evaluation.evaluator INFO: Inference done 850/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:43
[11/16 06:17:31] d2.evaluation.evaluator INFO: Inference done 971/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:38
[11/16 06:17:36] d2.evaluation.evaluator INFO: Inference done 1092/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/16 06:17:41] d2.evaluation.evaluator INFO: Inference done 1212/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/16 06:17:46] d2.evaluation.evaluator INFO: Inference done 1329/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:23
[11/16 06:17:51] d2.evaluation.evaluator INFO: Inference done 1445/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:19
[11/16 06:17:56] d2.evaluation.evaluator INFO: Inference done 1563/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:14
[11/16 06:18:01] d2.evaluation.evaluator INFO: Inference done 1680/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:09
[11/16 06:18:06] d2.evaluation.evaluator INFO: Inference done 1798/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:04
[11/16 06:18:11] d2.evaluation.evaluator INFO: Inference done 1918/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:59
[11/16 06:18:16] d2.evaluation.evaluator INFO: Inference done 2034/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:54
[11/16 06:18:21] d2.evaluation.evaluator INFO: Inference done 2153/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:49
[11/16 06:18:26] d2.evaluation.evaluator INFO: Inference done 2272/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:44
[11/16 06:18:31] d2.evaluation.evaluator INFO: Inference done 2390/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:39
[11/16 06:18:36] d2.evaluation.evaluator INFO: Inference done 2508/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:34
[11/16 06:18:41] d2.evaluation.evaluator INFO: Inference done 2627/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:29
[11/16 06:18:46] d2.evaluation.evaluator INFO: Inference done 2745/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:24
[11/16 06:18:51] d2.evaluation.evaluator INFO: Inference done 2863/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:19
[11/16 06:18:56] d2.evaluation.evaluator INFO: Inference done 2980/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:14
[11/16 06:19:01] d2.evaluation.evaluator INFO: Inference done 3096/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:10
[11/16 06:19:06] d2.evaluation.evaluator INFO: Inference done 3215/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:05
[11/16 06:19:11] d2.evaluation.evaluator INFO: Total inference time: 0:02:20.525847 (0.042213 s / iter per device, on 6 devices)
[11/16 06:19:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040273 s / iter per device, on 6 devices)
[11/16 06:19:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:19:13] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:19:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:19:15] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:19:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.36 seconds.
[11/16 06:19:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:19:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.89 seconds.
[11/16 06:19:39] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.732 | 4.444  | 0.956  | 0.209 | 0.904 | 2.041 |
[11/16 06:19:39] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.962  | person      | 2.393  | bird                  | 6.437 |
| red panda            | 0.132  | dog         | 25.280 | snake                 | 2.407 |
| car                  | 10.341 | seal        | 0.344  | helmet                | 0.835 |
| motorcycle           | 2.773  | swine       | 1.700  | stove                 | 1.547 |
| monkey               | 2.448  | watercraft  | 6.579  | chair                 | 1.226 |
| domestic cat         | 1.629  | harp        | 0.645  | antelope              | 1.151 |
| camel                | 0.016  | koala bear  | 1.393  | bus                   | 4.854 |
| hat with a wide brim | 0.164  | ski         | 0.000  | piano                 | 3.259 |
| frog                 | 2.034  | dumbbell    | 0.000  | lobster               | 0.571 |
| bench                | 0.000  | rabbit      | 1.880  | porcupine             | 0.866 |
| butterfly            | 5.090  | guitar      | 0.158  | microphone            | 0.000 |
| tape player          | 1.744  | bear        | 2.376  | hippopotamus          | 0.000 |
| bowl                 | 1.949  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 2.534  | otter       | 0.000  | table                 | 0.765 |
| coffee maker         | 6.841  | tie         | 0.000  | turtle                | 1.250 |
| purse                | 0.000  | dragonfly   | 0.529  | lemon                 | 1.908 |
| lizard               | 1.057  | backpack    | 0.850  | tv or monitor         | 5.006 |
| cup or mug           | 0.316  | sheep       | 0.259  | ray                   | 0.464 |
| fox                  | 1.340  | whale       | 1.925  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000  | fig         | 0.050  | bathing cap           | 0.112 |
| bookshelf            | 4.395  | ladybug     | 10.027 | crutch                | 0.000 |
| pretzel              | 0.282  | sunglasses  | 0.000  | starfish              | 0.842 |
| croquet ball         | 0.021  | lamp        | 0.000  | apple                 | 4.904 |
| cream                | 0.604  | artichoke   | 1.052  | train                 | 0.951 |
| elephant             | 2.176  | bell pepper | 1.088  | miniskirt             | 0.000 |
| orange               | 4.393  | tiger       | 1.245  | sofa                  | 0.353 |
| horse                | 0.886  | violin      | 0.000  | traffic light         | 0.323 |
| drum                 | 0.000  | strawberry  | 2.020  | laptop                | 1.367 |
| pomegranate          | 1.428  | cucumber    | 0.000  | bicycle               | 0.463 |
| banana               | 0.007  | baby bed    | 1.446  | jellyfish             | 1.641 |
| pitcher              | 0.000  | bagel       | 0.371  | beaker                | 2.395 |
| goldfish             | 1.166  | nail        | 0.000  | mushroom              | 0.000 |
| flower pot           | 0.000  | cattle      | 0.869  | zebra                 | 4.087 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 06:19:41] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:19:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:19:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:19:41] d2.evaluation.testing INFO: copypaste: 1.7319,4.4437,0.9563,0.2094,0.9037,2.0405
[11/16 06:19:41] d2.utils.events INFO:  eta: 4:54:38  iter: 10999  total_loss: 0.2928  loss_cls: 0.1574  loss_box_reg: 0.09093  loss_rpn_cls: 0.02093  loss_rpn_loc: 0.02069  time: 0.6812  data_time: 0.0661  lr: 0.004  max_mem: 11811M
[11/16 06:19:54] d2.utils.events INFO:  eta: 4:54:25  iter: 11019  total_loss: 0.2904  loss_cls: 0.161  loss_box_reg: 0.08986  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.01956  time: 0.6812  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 06:20:08] d2.utils.events INFO:  eta: 4:54:23  iter: 11039  total_loss: 0.2906  loss_cls: 0.1562  loss_box_reg: 0.09307  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.01932  time: 0.6812  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 06:20:22] d2.utils.events INFO:  eta: 4:54:16  iter: 11059  total_loss: 0.2862  loss_cls: 0.1568  loss_box_reg: 0.08901  loss_rpn_cls: 0.02137  loss_rpn_loc: 0.02013  time: 0.6812  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 06:20:35] d2.utils.events INFO:  eta: 4:54:16  iter: 11079  total_loss: 0.298  loss_cls: 0.1674  loss_box_reg: 0.09396  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.01895  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 06:20:49] d2.utils.events INFO:  eta: 4:54:04  iter: 11099  total_loss: 0.294  loss_cls: 0.1601  loss_box_reg: 0.09513  loss_rpn_cls: 0.02098  loss_rpn_loc: 0.02019  time: 0.6812  data_time: 0.0605  lr: 0.004  max_mem: 11811M
[11/16 06:21:03] d2.utils.events INFO:  eta: 4:53:55  iter: 11119  total_loss: 0.2981  loss_cls: 0.1639  loss_box_reg: 0.096  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.01916  time: 0.6813  data_time: 0.0618  lr: 0.004  max_mem: 11811M
[11/16 06:21:17] d2.utils.events INFO:  eta: 4:53:50  iter: 11139  total_loss: 0.2977  loss_cls: 0.1639  loss_box_reg: 0.09324  loss_rpn_cls: 0.02148  loss_rpn_loc: 0.02006  time: 0.6813  data_time: 0.0768  lr: 0.004  max_mem: 11811M
[11/16 06:21:30] d2.utils.events INFO:  eta: 4:53:28  iter: 11159  total_loss: 0.2965  loss_cls: 0.1608  loss_box_reg: 0.09162  loss_rpn_cls: 0.023  loss_rpn_loc: 0.01912  time: 0.6813  data_time: 0.0609  lr: 0.004  max_mem: 11811M
[11/16 06:21:44] d2.utils.events INFO:  eta: 4:53:14  iter: 11179  total_loss: 0.3032  loss_cls: 0.1638  loss_box_reg: 0.09191  loss_rpn_cls: 0.01948  loss_rpn_loc: 0.01784  time: 0.6813  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 06:21:57] d2.utils.events INFO:  eta: 4:53:01  iter: 11199  total_loss: 0.3025  loss_cls: 0.1658  loss_box_reg: 0.09708  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.01859  time: 0.6813  data_time: 0.0705  lr: 0.004  max_mem: 11811M
[11/16 06:22:11] d2.utils.events INFO:  eta: 4:52:39  iter: 11219  total_loss: 0.2928  loss_cls: 0.1586  loss_box_reg: 0.09272  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.01845  time: 0.6813  data_time: 0.0612  lr: 0.004  max_mem: 11811M
[11/16 06:22:25] d2.utils.events INFO:  eta: 4:52:28  iter: 11239  total_loss: 0.2926  loss_cls: 0.1597  loss_box_reg: 0.0952  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.01872  time: 0.6813  data_time: 0.0685  lr: 0.004  max_mem: 11811M
[11/16 06:22:39] d2.utils.events INFO:  eta: 4:52:24  iter: 11259  total_loss: 0.3067  loss_cls: 0.1673  loss_box_reg: 0.09658  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.02058  time: 0.6813  data_time: 0.0846  lr: 0.004  max_mem: 11811M
[11/16 06:22:52] d2.utils.events INFO:  eta: 4:52:14  iter: 11279  total_loss: 0.2993  loss_cls: 0.1619  loss_box_reg: 0.09501  loss_rpn_cls: 0.02266  loss_rpn_loc: 0.01916  time: 0.6813  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 06:23:06] d2.utils.events INFO:  eta: 4:52:04  iter: 11299  total_loss: 0.2951  loss_cls: 0.1588  loss_box_reg: 0.09452  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.02125  time: 0.6813  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 06:23:19] d2.utils.events INFO:  eta: 4:51:46  iter: 11319  total_loss: 0.3217  loss_cls: 0.1714  loss_box_reg: 0.09473  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.01951  time: 0.6813  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 06:23:33] d2.utils.events INFO:  eta: 4:51:33  iter: 11339  total_loss: 0.2861  loss_cls: 0.1548  loss_box_reg: 0.08896  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.01994  time: 0.6813  data_time: 0.0631  lr: 0.004  max_mem: 11811M
[11/16 06:23:47] d2.utils.events INFO:  eta: 4:51:12  iter: 11359  total_loss: 0.2961  loss_cls: 0.1615  loss_box_reg: 0.09445  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.02108  time: 0.6813  data_time: 0.0646  lr: 0.004  max_mem: 11811M
[11/16 06:24:00] d2.utils.events INFO:  eta: 4:50:58  iter: 11379  total_loss: 0.2941  loss_cls: 0.1582  loss_box_reg: 0.09298  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.01872  time: 0.6813  data_time: 0.0685  lr: 0.004  max_mem: 11811M
[11/16 06:24:14] d2.utils.events INFO:  eta: 4:50:45  iter: 11399  total_loss: 0.2898  loss_cls: 0.1606  loss_box_reg: 0.09299  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.02023  time: 0.6813  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 06:24:28] d2.utils.events INFO:  eta: 4:50:37  iter: 11419  total_loss: 0.2946  loss_cls: 0.158  loss_box_reg: 0.09407  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.01969  time: 0.6813  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 06:24:41] d2.utils.events INFO:  eta: 4:50:22  iter: 11439  total_loss: 0.31  loss_cls: 0.1707  loss_box_reg: 0.09833  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.01767  time: 0.6813  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 06:24:55] d2.utils.events INFO:  eta: 4:50:08  iter: 11459  total_loss: 0.2999  loss_cls: 0.1687  loss_box_reg: 0.09668  loss_rpn_cls: 0.02243  loss_rpn_loc: 0.01932  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11811M
[11/16 06:25:09] d2.utils.events INFO:  eta: 4:50:04  iter: 11479  total_loss: 0.2943  loss_cls: 0.1567  loss_box_reg: 0.09397  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.01956  time: 0.6813  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 06:25:22] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0011499.pth
[11/16 06:25:22] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:25:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:25:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:25:23] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:25:23] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:25:23] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:25:30] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0020 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:02:21
[11/16 06:25:35] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:14
[11/16 06:25:40] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0014 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/16 06:25:45] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:02
[11/16 06:25:50] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/16 06:25:55] d2.evaluation.evaluator INFO: Inference done 619/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:52
[11/16 06:26:00] d2.evaluation.evaluator INFO: Inference done 739/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/16 06:26:05] d2.evaluation.evaluator INFO: Inference done 858/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/16 06:26:10] d2.evaluation.evaluator INFO: Inference done 976/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/16 06:26:15] d2.evaluation.evaluator INFO: Inference done 1096/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:33
[11/16 06:26:20] d2.evaluation.evaluator INFO: Inference done 1217/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:28
[11/16 06:26:25] d2.evaluation.evaluator INFO: Inference done 1336/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:23
[11/16 06:26:30] d2.evaluation.evaluator INFO: Inference done 1458/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:18
[11/16 06:26:35] d2.evaluation.evaluator INFO: Inference done 1581/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:12
[11/16 06:26:40] d2.evaluation.evaluator INFO: Inference done 1701/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:07
[11/16 06:26:45] d2.evaluation.evaluator INFO: Inference done 1822/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/16 06:26:50] d2.evaluation.evaluator INFO: Inference done 1942/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/16 06:26:55] d2.evaluation.evaluator INFO: Inference done 2065/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/16 06:27:00] d2.evaluation.evaluator INFO: Inference done 2187/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/16 06:27:05] d2.evaluation.evaluator INFO: Inference done 2311/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/16 06:27:10] d2.evaluation.evaluator INFO: Inference done 2431/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/16 06:27:15] d2.evaluation.evaluator INFO: Inference done 2547/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/16 06:27:20] d2.evaluation.evaluator INFO: Inference done 2671/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/16 06:27:25] d2.evaluation.evaluator INFO: Inference done 2796/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/16 06:27:31] d2.evaluation.evaluator INFO: Inference done 2915/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/16 06:27:36] d2.evaluation.evaluator INFO: Inference done 3037/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/16 06:27:41] d2.evaluation.evaluator INFO: Inference done 3155/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/16 06:27:46] d2.evaluation.evaluator INFO: Inference done 3272/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/16 06:27:48] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.623332 (0.041641 s / iter per device, on 6 devices)
[11/16 06:27:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039644 s / iter per device, on 6 devices)
[11/16 06:27:50] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:27:50] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:27:51] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:27:51] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:28:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.46 seconds.
[11/16 06:28:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:28:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.12 seconds.
[11/16 06:28:15] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.836 | 4.804  | 0.946  | 0.314 | 0.878 | 2.129 |
[11/16 06:28:15] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.621  | person      | 2.225  | bird                  | 6.721 |
| red panda            | 0.190  | dog         | 25.834 | snake                 | 3.470 |
| car                  | 12.800 | seal        | 0.692  | helmet                | 1.973 |
| motorcycle           | 2.345  | swine       | 1.530  | stove                 | 2.736 |
| monkey               | 2.612  | watercraft  | 7.616  | chair                 | 1.271 |
| domestic cat         | 2.104  | harp        | 0.386  | antelope              | 2.093 |
| camel                | 0.000  | koala bear  | 1.627  | bus                   | 5.357 |
| hat with a wide brim | 0.353  | ski         | 0.000  | piano                 | 3.800 |
| frog                 | 1.350  | dumbbell    | 0.000  | lobster               | 0.243 |
| bench                | 0.066  | rabbit      | 1.502  | porcupine             | 1.000 |
| butterfly            | 4.425  | guitar      | 0.272  | microphone            | 0.000 |
| tape player          | 2.693  | bear        | 3.706  | hippopotamus          | 0.495 |
| bowl                 | 1.214  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 3.689  | otter       | 0.109  | table                 | 1.115 |
| coffee maker         | 5.342  | tie         | 0.000  | turtle                | 0.868 |
| purse                | 0.000  | dragonfly   | 0.935  | lemon                 | 1.079 |
| lizard               | 1.242  | backpack    | 0.350  | tv or monitor         | 5.355 |
| cup or mug           | 0.218  | sheep       | 0.223  | ray                   | 0.480 |
| fox                  | 2.048  | whale       | 1.630  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000  | fig         | 0.064  | bathing cap           | 0.246 |
| bookshelf            | 3.768  | ladybug     | 12.076 | crutch                | 0.000 |
| pretzel              | 0.221  | sunglasses  | 0.000  | starfish              | 0.990 |
| croquet ball         | 0.745  | lamp        | 0.050  | apple                 | 4.500 |
| cream                | 1.146  | artichoke   | 1.155  | train                 | 0.778 |
| elephant             | 1.490  | bell pepper | 0.846  | miniskirt             | 0.000 |
| orange               | 3.686  | tiger       | 0.072  | sofa                  | 0.253 |
| horse                | 0.454  | violin      | 0.000  | traffic light         | 0.468 |
| drum                 | 0.000  | strawberry  | 2.194  | laptop                | 1.233 |
| pomegranate          | 0.407  | cucumber    | 0.030  | bicycle               | 0.509 |
| banana               | 0.075  | baby bed    | 2.464  | jellyfish             | 1.881 |
| pitcher              | 0.000  | bagel       | 0.310  | beaker                | 1.016 |
| goldfish             | 1.610  | nail        | 0.000  | mushroom              | 0.239 |
| flower pot           | 0.000  | cattle      | 1.350  | zebra                 | 5.233 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 06:28:18] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:28:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:28:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:28:18] d2.evaluation.testing INFO: copypaste: 1.8356,4.8036,0.9460,0.3135,0.8777,2.1293
[11/16 06:28:18] d2.utils.events INFO:  eta: 4:49:36  iter: 11499  total_loss: 0.2931  loss_cls: 0.1603  loss_box_reg: 0.09393  loss_rpn_cls: 0.02038  loss_rpn_loc: 0.02068  time: 0.6813  data_time: 0.0678  lr: 0.004  max_mem: 11811M
[11/16 06:28:31] d2.utils.events INFO:  eta: 4:49:15  iter: 11519  total_loss: 0.2841  loss_cls: 0.1561  loss_box_reg: 0.0935  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.0185  time: 0.6812  data_time: 0.0609  lr: 0.004  max_mem: 11811M
[11/16 06:28:45] d2.utils.events INFO:  eta: 4:49:04  iter: 11539  total_loss: 0.2983  loss_cls: 0.1645  loss_box_reg: 0.09165  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.02017  time: 0.6813  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 06:28:59] d2.utils.events INFO:  eta: 4:48:51  iter: 11559  total_loss: 0.2922  loss_cls: 0.1545  loss_box_reg: 0.09187  loss_rpn_cls: 0.01851  loss_rpn_loc: 0.01698  time: 0.6813  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 06:29:12] d2.utils.events INFO:  eta: 4:48:48  iter: 11579  total_loss: 0.2891  loss_cls: 0.1608  loss_box_reg: 0.08917  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.01963  time: 0.6813  data_time: 0.0660  lr: 0.004  max_mem: 11811M
[11/16 06:29:26] d2.utils.events INFO:  eta: 4:48:23  iter: 11599  total_loss: 0.2734  loss_cls: 0.1497  loss_box_reg: 0.08542  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.02003  time: 0.6812  data_time: 0.0690  lr: 0.004  max_mem: 11811M
[11/16 06:29:40] d2.utils.events INFO:  eta: 4:48:13  iter: 11619  total_loss: 0.3006  loss_cls: 0.1577  loss_box_reg: 0.09319  loss_rpn_cls: 0.02205  loss_rpn_loc: 0.02092  time: 0.6812  data_time: 0.0647  lr: 0.004  max_mem: 11811M
[11/16 06:29:53] d2.utils.events INFO:  eta: 4:47:56  iter: 11639  total_loss: 0.2793  loss_cls: 0.1557  loss_box_reg: 0.09112  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.01895  time: 0.6812  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 06:30:07] d2.utils.events INFO:  eta: 4:47:28  iter: 11659  total_loss: 0.3026  loss_cls: 0.1679  loss_box_reg: 0.09695  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.01891  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11811M
[11/16 06:30:20] d2.utils.events INFO:  eta: 4:47:25  iter: 11679  total_loss: 0.2929  loss_cls: 0.157  loss_box_reg: 0.09252  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.01928  time: 0.6812  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 06:30:34] d2.utils.events INFO:  eta: 4:47:05  iter: 11699  total_loss: 0.2894  loss_cls: 0.1558  loss_box_reg: 0.09206  loss_rpn_cls: 0.02146  loss_rpn_loc: 0.02028  time: 0.6812  data_time: 0.0606  lr: 0.004  max_mem: 11811M
[11/16 06:30:47] d2.utils.events INFO:  eta: 4:46:38  iter: 11719  total_loss: 0.2988  loss_cls: 0.1664  loss_box_reg: 0.09347  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.01701  time: 0.6812  data_time: 0.0659  lr: 0.004  max_mem: 11811M
[11/16 06:31:01] d2.utils.events INFO:  eta: 4:46:20  iter: 11739  total_loss: 0.2964  loss_cls: 0.1608  loss_box_reg: 0.09226  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.01996  time: 0.6812  data_time: 0.0727  lr: 0.004  max_mem: 11811M
[11/16 06:31:14] d2.utils.events INFO:  eta: 4:46:10  iter: 11759  total_loss: 0.2832  loss_cls: 0.1535  loss_box_reg: 0.09205  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.01986  time: 0.6812  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 06:31:28] d2.utils.events INFO:  eta: 4:45:53  iter: 11779  total_loss: 0.2888  loss_cls: 0.1555  loss_box_reg: 0.09042  loss_rpn_cls: 0.02326  loss_rpn_loc: 0.01836  time: 0.6811  data_time: 0.0677  lr: 0.004  max_mem: 11811M
[11/16 06:31:42] d2.utils.events INFO:  eta: 4:45:50  iter: 11799  total_loss: 0.3066  loss_cls: 0.1636  loss_box_reg: 0.09499  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.01992  time: 0.6812  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 06:31:55] d2.utils.events INFO:  eta: 4:45:36  iter: 11819  total_loss: 0.3047  loss_cls: 0.1672  loss_box_reg: 0.09454  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.01962  time: 0.6812  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 06:32:09] d2.utils.events INFO:  eta: 4:45:24  iter: 11839  total_loss: 0.2737  loss_cls: 0.1472  loss_box_reg: 0.0872  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.0201  time: 0.6812  data_time: 0.0628  lr: 0.004  max_mem: 11811M
[11/16 06:32:23] d2.utils.events INFO:  eta: 4:45:05  iter: 11859  total_loss: 0.2867  loss_cls: 0.157  loss_box_reg: 0.08922  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.0213  time: 0.6812  data_time: 0.0613  lr: 0.004  max_mem: 11811M
[11/16 06:32:36] d2.utils.events INFO:  eta: 4:44:53  iter: 11879  total_loss: 0.2791  loss_cls: 0.1536  loss_box_reg: 0.08839  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.02102  time: 0.6812  data_time: 0.0620  lr: 0.004  max_mem: 11811M
[11/16 06:32:50] d2.utils.events INFO:  eta: 4:44:42  iter: 11899  total_loss: 0.2752  loss_cls: 0.1503  loss_box_reg: 0.08918  loss_rpn_cls: 0.01706  loss_rpn_loc: 0.01748  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 06:33:04] d2.utils.events INFO:  eta: 4:44:36  iter: 11919  total_loss: 0.2936  loss_cls: 0.1567  loss_box_reg: 0.0932  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.01912  time: 0.6812  data_time: 0.0723  lr: 0.004  max_mem: 11811M
[11/16 06:33:17] d2.utils.events INFO:  eta: 4:44:14  iter: 11939  total_loss: 0.2967  loss_cls: 0.1607  loss_box_reg: 0.0956  loss_rpn_cls: 0.02335  loss_rpn_loc: 0.01916  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 06:33:31] d2.utils.events INFO:  eta: 4:44:01  iter: 11959  total_loss: 0.3116  loss_cls: 0.1656  loss_box_reg: 0.09901  loss_rpn_cls: 0.02325  loss_rpn_loc: 0.01972  time: 0.6812  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/16 06:33:45] d2.utils.events INFO:  eta: 4:44:04  iter: 11979  total_loss: 0.2902  loss_cls: 0.1583  loss_box_reg: 0.09109  loss_rpn_cls: 0.01982  loss_rpn_loc: 0.01864  time: 0.6812  data_time: 0.0848  lr: 0.004  max_mem: 11811M
[11/16 06:33:59] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0011999.pth
[11/16 06:33:59] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:34:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:34:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:34:00] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:34:00] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:34:00] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:34:06] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:16
[11/16 06:34:11] d2.evaluation.evaluator INFO: Inference done 129/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:15
[11/16 06:34:16] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:09
[11/16 06:34:21] d2.evaluation.evaluator INFO: Inference done 370/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:03
[11/16 06:34:26] d2.evaluation.evaluator INFO: Inference done 492/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:58
[11/16 06:34:31] d2.evaluation.evaluator INFO: Inference done 614/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:53
[11/16 06:34:36] d2.evaluation.evaluator INFO: Inference done 735/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:48
[11/16 06:34:41] d2.evaluation.evaluator INFO: Inference done 857/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/16 06:34:46] d2.evaluation.evaluator INFO: Inference done 975/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:38
[11/16 06:34:51] d2.evaluation.evaluator INFO: Inference done 1095/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:33
[11/16 06:34:56] d2.evaluation.evaluator INFO: Inference done 1215/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:28
[11/16 06:35:01] d2.evaluation.evaluator INFO: Inference done 1334/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:23
[11/16 06:35:06] d2.evaluation.evaluator INFO: Inference done 1455/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:18
[11/16 06:35:11] d2.evaluation.evaluator INFO: Inference done 1576/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/16 06:35:17] d2.evaluation.evaluator INFO: Inference done 1697/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:08
[11/16 06:35:22] d2.evaluation.evaluator INFO: Inference done 1818/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:03
[11/16 06:35:27] d2.evaluation.evaluator INFO: Inference done 1938/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:58
[11/16 06:35:32] d2.evaluation.evaluator INFO: Inference done 2058/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:53
[11/16 06:35:37] d2.evaluation.evaluator INFO: Inference done 2179/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:48
[11/16 06:35:42] d2.evaluation.evaluator INFO: Inference done 2296/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:43
[11/16 06:35:47] d2.evaluation.evaluator INFO: Inference done 2418/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:38
[11/16 06:35:52] d2.evaluation.evaluator INFO: Inference done 2540/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:33
[11/16 06:35:57] d2.evaluation.evaluator INFO: Inference done 2658/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:28
[11/16 06:36:02] d2.evaluation.evaluator INFO: Inference done 2777/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/16 06:36:07] d2.evaluation.evaluator INFO: Inference done 2899/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/16 06:36:12] d2.evaluation.evaluator INFO: Inference done 3017/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:13
[11/16 06:36:17] d2.evaluation.evaluator INFO: Inference done 3136/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:08
[11/16 06:36:22] d2.evaluation.evaluator INFO: Inference done 3257/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:03
[11/16 06:36:25] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.241053 (0.041827 s / iter per device, on 6 devices)
[11/16 06:36:25] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039844 s / iter per device, on 6 devices)
[11/16 06:36:27] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:36:27] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:36:28] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:36:28] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:36:50] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.25 seconds.
[11/16 06:36:50] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:36:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.78 seconds.
[11/16 06:36:52] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 1.859 | 4.634  | 1.155  | 0.370 | 0.732 | 2.153 |
[11/16 06:36:52] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.240  | person      | 1.992  | bird                  | 7.318 |
| red panda            | 0.383  | dog         | 26.925 | snake                 | 3.559 |
| car                  | 12.592 | seal        | 0.264  | helmet                | 0.961 |
| motorcycle           | 2.966  | swine       | 2.332  | stove                 | 1.956 |
| monkey               | 2.895  | watercraft  | 7.258  | chair                 | 0.572 |
| domestic cat         | 1.704  | harp        | 0.518  | antelope              | 1.999 |
| camel                | 0.063  | koala bear  | 2.933  | bus                   | 6.873 |
| hat with a wide brim | 0.091  | ski         | 0.000  | piano                 | 3.012 |
| frog                 | 2.747  | dumbbell    | 0.000  | lobster               | 0.994 |
| bench                | 0.000  | rabbit      | 1.790  | porcupine             | 1.227 |
| butterfly            | 4.888  | guitar      | 0.132  | microphone            | 0.000 |
| tape player          | 3.999  | bear        | 3.322  | hippopotamus          | 0.000 |
| bowl                 | 1.626  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 3.200  | otter       | 0.000  | table                 | 1.078 |
| coffee maker         | 2.491  | tie         | 0.000  | turtle                | 0.884 |
| purse                | 0.317  | dragonfly   | 0.436  | lemon                 | 3.099 |
| lizard               | 1.817  | backpack    | 1.404  | tv or monitor         | 5.534 |
| cup or mug           | 0.293  | sheep       | 0.272  | ray                   | 0.271 |
| fox                  | 1.431  | whale       | 1.310  | salt or pepper shaker | 0.000 |
| computer keyboard    | 0.000  | fig         | 0.078  | bathing cap           | 0.213 |
| bookshelf            | 2.983  | ladybug     | 10.235 | crutch                | 0.000 |
| pretzel              | 0.638  | sunglasses  | 0.000  | starfish              | 1.152 |
| croquet ball         | 0.555  | lamp        | 0.000  | apple                 | 3.825 |
| cream                | 0.831  | artichoke   | 3.520  | train                 | 0.638 |
| elephant             | 2.669  | bell pepper | 0.345  | miniskirt             | 0.000 |
| orange               | 4.955  | tiger       | 0.234  | sofa                  | 0.465 |
| horse                | 0.528  | violin      | 0.000  | traffic light         | 0.716 |
| drum                 | 0.000  | strawberry  | 1.653  | laptop                | 0.777 |
| pomegranate          | 0.340  | cucumber    | 0.000  | bicycle               | 0.614 |
| banana               | 0.084  | baby bed    | 1.324  | jellyfish             | 1.823 |
| pitcher              | 0.000  | bagel       | 1.358  | beaker                | 1.881 |
| goldfish             | 0.915  | nail        | 0.000  | mushroom              | 0.338 |
| flower pot           | 0.000  | cattle      | 0.222  | zebra                 | 3.998 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 06:36:54] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:36:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:36:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:36:54] d2.evaluation.testing INFO: copypaste: 1.8588,4.6345,1.1550,0.3705,0.7320,2.1532
[11/16 06:36:54] d2.utils.events INFO:  eta: 4:43:52  iter: 11999  total_loss: 0.3011  loss_cls: 0.1621  loss_box_reg: 0.09341  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.02001  time: 0.6813  data_time: 0.0723  lr: 0.004  max_mem: 11811M
[11/16 06:37:08] d2.utils.events INFO:  eta: 4:43:38  iter: 12019  total_loss: 0.2952  loss_cls: 0.1562  loss_box_reg: 0.09318  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.02001  time: 0.6813  data_time: 0.0811  lr: 0.004  max_mem: 11811M
[11/16 06:37:21] d2.utils.events INFO:  eta: 4:43:24  iter: 12039  total_loss: 0.2682  loss_cls: 0.1467  loss_box_reg: 0.08827  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.01904  time: 0.6813  data_time: 0.0622  lr: 0.004  max_mem: 11811M
[11/16 06:37:35] d2.utils.events INFO:  eta: 4:43:09  iter: 12059  total_loss: 0.2798  loss_cls: 0.1533  loss_box_reg: 0.0881  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.01805  time: 0.6813  data_time: 0.0606  lr: 0.004  max_mem: 11811M
[11/16 06:37:49] d2.utils.events INFO:  eta: 4:42:39  iter: 12079  total_loss: 0.2926  loss_cls: 0.1565  loss_box_reg: 0.08933  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.01872  time: 0.6813  data_time: 0.0712  lr: 0.004  max_mem: 11811M
[11/16 06:38:02] d2.utils.events INFO:  eta: 4:42:25  iter: 12099  total_loss: 0.2883  loss_cls: 0.155  loss_box_reg: 0.09342  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.01849  time: 0.6813  data_time: 0.0709  lr: 0.004  max_mem: 11811M
[11/16 06:38:16] d2.utils.events INFO:  eta: 4:42:09  iter: 12119  total_loss: 0.3014  loss_cls: 0.1643  loss_box_reg: 0.09777  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.01994  time: 0.6813  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 06:38:30] d2.utils.events INFO:  eta: 4:41:54  iter: 12139  total_loss: 0.2979  loss_cls: 0.1673  loss_box_reg: 0.09397  loss_rpn_cls: 0.01881  loss_rpn_loc: 0.01903  time: 0.6813  data_time: 0.0623  lr: 0.004  max_mem: 11811M
[11/16 06:38:44] d2.utils.events INFO:  eta: 4:41:57  iter: 12159  total_loss: 0.2801  loss_cls: 0.1479  loss_box_reg: 0.0901  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.01859  time: 0.6813  data_time: 0.0701  lr: 0.004  max_mem: 11811M
[11/16 06:38:57] d2.utils.events INFO:  eta: 4:41:35  iter: 12179  total_loss: 0.2859  loss_cls: 0.1571  loss_box_reg: 0.09146  loss_rpn_cls: 0.02147  loss_rpn_loc: 0.01893  time: 0.6814  data_time: 0.0854  lr: 0.004  max_mem: 11811M
[11/16 06:39:11] d2.utils.events INFO:  eta: 4:41:25  iter: 12199  total_loss: 0.2775  loss_cls: 0.1525  loss_box_reg: 0.08809  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.01938  time: 0.6814  data_time: 0.0738  lr: 0.004  max_mem: 11811M
[11/16 06:39:25] d2.utils.events INFO:  eta: 4:41:08  iter: 12219  total_loss: 0.2831  loss_cls: 0.1509  loss_box_reg: 0.09018  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.01885  time: 0.6814  data_time: 0.0646  lr: 0.004  max_mem: 11811M
[11/16 06:39:38] d2.utils.events INFO:  eta: 4:41:04  iter: 12239  total_loss: 0.2845  loss_cls: 0.1567  loss_box_reg: 0.09367  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.01692  time: 0.6814  data_time: 0.0596  lr: 0.004  max_mem: 11811M
[11/16 06:39:52] d2.utils.events INFO:  eta: 4:40:52  iter: 12259  total_loss: 0.3044  loss_cls: 0.1659  loss_box_reg: 0.09694  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.01938  time: 0.6814  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 06:40:06] d2.utils.events INFO:  eta: 4:40:46  iter: 12279  total_loss: 0.283  loss_cls: 0.1488  loss_box_reg: 0.08815  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.01912  time: 0.6814  data_time: 0.0698  lr: 0.004  max_mem: 11811M
[11/16 06:40:19] d2.utils.events INFO:  eta: 4:40:28  iter: 12299  total_loss: 0.2975  loss_cls: 0.1609  loss_box_reg: 0.09667  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.01935  time: 0.6814  data_time: 0.0628  lr: 0.004  max_mem: 11811M
[11/16 06:40:33] d2.utils.events INFO:  eta: 4:40:17  iter: 12319  total_loss: 0.2722  loss_cls: 0.1458  loss_box_reg: 0.08792  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.01909  time: 0.6814  data_time: 0.0615  lr: 0.004  max_mem: 11811M
[11/16 06:40:47] d2.utils.events INFO:  eta: 4:40:01  iter: 12339  total_loss: 0.2931  loss_cls: 0.1537  loss_box_reg: 0.0944  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.01814  time: 0.6814  data_time: 0.0622  lr: 0.004  max_mem: 11811M
[11/16 06:41:00] d2.utils.events INFO:  eta: 4:39:54  iter: 12359  total_loss: 0.2973  loss_cls: 0.1647  loss_box_reg: 0.09651  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.0188  time: 0.6814  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 06:41:14] d2.utils.events INFO:  eta: 4:39:43  iter: 12379  total_loss: 0.2877  loss_cls: 0.155  loss_box_reg: 0.09218  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.01944  time: 0.6814  data_time: 0.0630  lr: 0.004  max_mem: 11811M
[11/16 06:41:28] d2.utils.events INFO:  eta: 4:39:31  iter: 12399  total_loss: 0.2916  loss_cls: 0.1602  loss_box_reg: 0.09094  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.01939  time: 0.6815  data_time: 0.0862  lr: 0.004  max_mem: 11811M
[11/16 06:41:42] d2.utils.events INFO:  eta: 4:39:17  iter: 12419  total_loss: 0.3008  loss_cls: 0.1626  loss_box_reg: 0.09644  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.0191  time: 0.6815  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 06:41:55] d2.utils.events INFO:  eta: 4:39:04  iter: 12439  total_loss: 0.2856  loss_cls: 0.1569  loss_box_reg: 0.09279  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.01855  time: 0.6815  data_time: 0.0620  lr: 0.004  max_mem: 11811M
[11/16 06:42:09] d2.utils.events INFO:  eta: 4:38:51  iter: 12459  total_loss: 0.286  loss_cls: 0.1579  loss_box_reg: 0.09123  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.01768  time: 0.6815  data_time: 0.0753  lr: 0.004  max_mem: 11811M
[11/16 06:42:23] d2.utils.events INFO:  eta: 4:38:37  iter: 12479  total_loss: 0.2954  loss_cls: 0.1567  loss_box_reg: 0.09731  loss_rpn_cls: 0.02297  loss_rpn_loc: 0.02139  time: 0.6815  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 06:42:36] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0012499.pth
[11/16 06:42:37] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:42:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:42:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:42:37] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:42:38] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:42:38] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:42:44] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0007 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:18
[11/16 06:42:49] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:15
[11/16 06:42:54] d2.evaluation.evaluator INFO: Inference done 251/3334. Dataloading: 0.0014 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:09
[11/16 06:42:59] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:02
[11/16 06:43:04] d2.evaluation.evaluator INFO: Inference done 496/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:57
[11/16 06:43:09] d2.evaluation.evaluator INFO: Inference done 618/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:52
[11/16 06:43:14] d2.evaluation.evaluator INFO: Inference done 738/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/16 06:43:19] d2.evaluation.evaluator INFO: Inference done 856/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:43
[11/16 06:43:24] d2.evaluation.evaluator INFO: Inference done 975/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/16 06:43:30] d2.evaluation.evaluator INFO: Inference done 1095/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:33
[11/16 06:43:35] d2.evaluation.evaluator INFO: Inference done 1218/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:28
[11/16 06:43:40] d2.evaluation.evaluator INFO: Inference done 1341/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:22
[11/16 06:43:45] d2.evaluation.evaluator INFO: Inference done 1463/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/16 06:43:50] d2.evaluation.evaluator INFO: Inference done 1586/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/16 06:43:55] d2.evaluation.evaluator INFO: Inference done 1707/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/16 06:44:00] d2.evaluation.evaluator INFO: Inference done 1828/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/16 06:44:05] d2.evaluation.evaluator INFO: Inference done 1944/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/16 06:44:10] d2.evaluation.evaluator INFO: Inference done 2063/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:52
[11/16 06:44:15] d2.evaluation.evaluator INFO: Inference done 2179/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:48
[11/16 06:44:20] d2.evaluation.evaluator INFO: Inference done 2296/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:43
[11/16 06:44:25] d2.evaluation.evaluator INFO: Inference done 2417/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:38
[11/16 06:44:30] d2.evaluation.evaluator INFO: Inference done 2536/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:33
[11/16 06:44:35] d2.evaluation.evaluator INFO: Inference done 2657/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:28
[11/16 06:44:40] d2.evaluation.evaluator INFO: Inference done 2777/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:23
[11/16 06:44:45] d2.evaluation.evaluator INFO: Inference done 2901/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/16 06:44:50] d2.evaluation.evaluator INFO: Inference done 3021/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:13
[11/16 06:44:55] d2.evaluation.evaluator INFO: Inference done 3139/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:08
[11/16 06:45:00] d2.evaluation.evaluator INFO: Inference done 3256/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:03
[11/16 06:45:04] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.653261 (0.041951 s / iter per device, on 6 devices)
[11/16 06:45:04] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:13 (0.039986 s / iter per device, on 6 devices)
[11/16 06:45:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:45:07] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:45:08] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:45:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:45:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.49 seconds.
[11/16 06:45:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:45:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.03 seconds.
[11/16 06:45:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.150 | 5.542  | 1.184  | 0.254 | 1.149 | 2.521 |
[11/16 06:45:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.826  | person      | 2.636  | bird                  | 7.594 |
| red panda            | 1.753  | dog         | 26.220 | snake                 | 3.632 |
| car                  | 14.482 | seal        | 0.385  | helmet                | 1.799 |
| motorcycle           | 2.944  | swine       | 1.278  | stove                 | 1.899 |
| monkey               | 2.678  | watercraft  | 8.580  | chair                 | 1.578 |
| domestic cat         | 1.152  | harp        | 0.621  | antelope              | 2.168 |
| camel                | 0.080  | koala bear  | 1.112  | bus                   | 6.488 |
| hat with a wide brim | 0.251  | ski         | 0.000  | piano                 | 5.333 |
| frog                 | 3.084  | dumbbell    | 0.000  | lobster               | 0.815 |
| bench                | 0.000  | rabbit      | 2.055  | porcupine             | 1.875 |
| butterfly            | 5.999  | guitar      | 0.231  | microphone            | 0.000 |
| tape player          | 2.875  | bear        | 2.436  | hippopotamus          | 0.047 |
| bowl                 | 2.901  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 3.854  | otter       | 0.000  | table                 | 1.354 |
| coffee maker         | 6.560  | tie         | 0.091  | turtle                | 1.767 |
| purse                | 1.890  | dragonfly   | 0.991  | lemon                 | 3.306 |
| lizard               | 1.100  | backpack    | 0.668  | tv or monitor         | 5.940 |
| cup or mug           | 0.399  | sheep       | 0.251  | ray                   | 0.934 |
| fox                  | 2.247  | whale       | 2.391  | salt or pepper shaker | 0.004 |
| computer keyboard    | 0.000  | fig         | 0.052  | bathing cap           | 0.188 |
| bookshelf            | 5.049  | ladybug     | 13.423 | crutch                | 0.000 |
| pretzel              | 0.554  | sunglasses  | 0.000  | starfish              | 2.251 |
| croquet ball         | 0.409  | lamp        | 0.330  | apple                 | 4.721 |
| cream                | 0.994  | artichoke   | 2.509  | train                 | 0.831 |
| elephant             | 1.933  | bell pepper | 0.507  | miniskirt             | 0.060 |
| orange               | 3.864  | tiger       | 0.355  | sofa                  | 0.612 |
| horse                | 0.948  | violin      | 0.636  | traffic light         | 0.669 |
| drum                 | 0.132  | strawberry  | 2.349  | laptop                | 0.986 |
| pomegranate          | 0.922  | cucumber    | 0.000  | bicycle               | 0.757 |
| banana               | 0.032  | baby bed    | 2.682  | jellyfish             | 1.825 |
| pitcher              | 0.046  | bagel       | 0.913  | beaker                | 2.653 |
| goldfish             | 1.502  | nail        | 0.000  | mushroom              | 0.265 |
| flower pot           | 0.000  | cattle      | 0.631  | zebra                 | 4.029 |
| wine bottle          | 0.788  |             |        |                       |       |
[11/16 06:45:38] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:45:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:45:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:45:38] d2.evaluation.testing INFO: copypaste: 2.1496,5.5423,1.1838,0.2538,1.1494,2.5214
[11/16 06:45:38] d2.utils.events INFO:  eta: 4:38:28  iter: 12499  total_loss: 0.276  loss_cls: 0.1561  loss_box_reg: 0.08895  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.01674  time: 0.6815  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 06:45:51] d2.utils.events INFO:  eta: 4:38:22  iter: 12519  total_loss: 0.2767  loss_cls: 0.1492  loss_box_reg: 0.09501  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.01916  time: 0.6815  data_time: 0.0654  lr: 0.004  max_mem: 11811M
[11/16 06:46:05] d2.utils.events INFO:  eta: 4:37:58  iter: 12539  total_loss: 0.2895  loss_cls: 0.1573  loss_box_reg: 0.09115  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.01846  time: 0.6815  data_time: 0.0700  lr: 0.004  max_mem: 11811M
[11/16 06:46:19] d2.utils.events INFO:  eta: 4:37:46  iter: 12559  total_loss: 0.278  loss_cls: 0.1502  loss_box_reg: 0.08874  loss_rpn_cls: 0.01737  loss_rpn_loc: 0.02061  time: 0.6815  data_time: 0.0725  lr: 0.004  max_mem: 11811M
[11/16 06:46:32] d2.utils.events INFO:  eta: 4:37:33  iter: 12579  total_loss: 0.2812  loss_cls: 0.15  loss_box_reg: 0.08944  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.02025  time: 0.6815  data_time: 0.0713  lr: 0.004  max_mem: 11811M
[11/16 06:46:46] d2.utils.events INFO:  eta: 4:37:17  iter: 12599  total_loss: 0.2834  loss_cls: 0.1523  loss_box_reg: 0.0888  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.01982  time: 0.6815  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 06:47:00] d2.utils.events INFO:  eta: 4:37:02  iter: 12619  total_loss: 0.281  loss_cls: 0.1499  loss_box_reg: 0.08689  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.01872  time: 0.6815  data_time: 0.0600  lr: 0.004  max_mem: 11811M
[11/16 06:47:13] d2.utils.events INFO:  eta: 4:36:49  iter: 12639  total_loss: 0.2975  loss_cls: 0.1583  loss_box_reg: 0.09192  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.01961  time: 0.6815  data_time: 0.0704  lr: 0.004  max_mem: 11811M
[11/16 06:47:27] d2.utils.events INFO:  eta: 4:36:47  iter: 12659  total_loss: 0.2957  loss_cls: 0.1625  loss_box_reg: 0.09476  loss_rpn_cls: 0.02012  loss_rpn_loc: 0.01813  time: 0.6815  data_time: 0.0675  lr: 0.004  max_mem: 11811M
[11/16 06:47:40] d2.utils.events INFO:  eta: 4:36:33  iter: 12679  total_loss: 0.2953  loss_cls: 0.1597  loss_box_reg: 0.09425  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.01995  time: 0.6815  data_time: 0.0716  lr: 0.004  max_mem: 11811M
[11/16 06:47:54] d2.utils.events INFO:  eta: 4:36:21  iter: 12699  total_loss: 0.2826  loss_cls: 0.1556  loss_box_reg: 0.09053  loss_rpn_cls: 0.02169  loss_rpn_loc: 0.01832  time: 0.6815  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 06:48:08] d2.utils.events INFO:  eta: 4:36:11  iter: 12719  total_loss: 0.2933  loss_cls: 0.1597  loss_box_reg: 0.09479  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.01792  time: 0.6815  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 06:48:21] d2.utils.events INFO:  eta: 4:36:05  iter: 12739  total_loss: 0.2811  loss_cls: 0.1511  loss_box_reg: 0.0884  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.01837  time: 0.6815  data_time: 0.0752  lr: 0.004  max_mem: 11811M
[11/16 06:48:35] d2.utils.events INFO:  eta: 4:35:53  iter: 12759  total_loss: 0.2907  loss_cls: 0.1582  loss_box_reg: 0.09019  loss_rpn_cls: 0.01862  loss_rpn_loc: 0.02013  time: 0.6815  data_time: 0.0619  lr: 0.004  max_mem: 11811M
[11/16 06:48:49] d2.utils.events INFO:  eta: 4:35:43  iter: 12779  total_loss: 0.278  loss_cls: 0.1507  loss_box_reg: 0.08823  loss_rpn_cls: 0.01872  loss_rpn_loc: 0.01753  time: 0.6815  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 06:49:02] d2.utils.events INFO:  eta: 4:35:25  iter: 12799  total_loss: 0.2933  loss_cls: 0.1559  loss_box_reg: 0.09517  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.01952  time: 0.6815  data_time: 0.0724  lr: 0.004  max_mem: 11811M
[11/16 06:49:16] d2.utils.events INFO:  eta: 4:35:12  iter: 12819  total_loss: 0.2901  loss_cls: 0.1564  loss_box_reg: 0.09464  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.01745  time: 0.6815  data_time: 0.0727  lr: 0.004  max_mem: 11811M
[11/16 06:49:30] d2.utils.events INFO:  eta: 4:35:00  iter: 12839  total_loss: 0.2728  loss_cls: 0.1495  loss_box_reg: 0.08844  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.01806  time: 0.6816  data_time: 0.0615  lr: 0.004  max_mem: 11811M
[11/16 06:49:44] d2.utils.events INFO:  eta: 4:34:51  iter: 12859  total_loss: 0.2906  loss_cls: 0.1595  loss_box_reg: 0.09201  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.01829  time: 0.6816  data_time: 0.0740  lr: 0.004  max_mem: 11811M
[11/16 06:49:57] d2.utils.events INFO:  eta: 4:34:31  iter: 12879  total_loss: 0.2747  loss_cls: 0.1462  loss_box_reg: 0.08947  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.01882  time: 0.6816  data_time: 0.0650  lr: 0.004  max_mem: 11811M
[11/16 06:50:11] d2.utils.events INFO:  eta: 4:34:08  iter: 12899  total_loss: 0.2978  loss_cls: 0.1623  loss_box_reg: 0.09315  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.01966  time: 0.6816  data_time: 0.0602  lr: 0.004  max_mem: 11811M
[11/16 06:50:25] d2.utils.events INFO:  eta: 4:33:52  iter: 12919  total_loss: 0.2733  loss_cls: 0.1487  loss_box_reg: 0.08711  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.01805  time: 0.6816  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 06:50:38] d2.utils.events INFO:  eta: 4:33:37  iter: 12939  total_loss: 0.2867  loss_cls: 0.1558  loss_box_reg: 0.09264  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.02048  time: 0.6815  data_time: 0.0644  lr: 0.004  max_mem: 11811M
[11/16 06:50:51] d2.utils.events INFO:  eta: 4:33:14  iter: 12959  total_loss: 0.2808  loss_cls: 0.1498  loss_box_reg: 0.09206  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.01915  time: 0.6815  data_time: 0.0727  lr: 0.004  max_mem: 11811M
[11/16 06:51:05] d2.utils.events INFO:  eta: 4:32:54  iter: 12979  total_loss: 0.2763  loss_cls: 0.1517  loss_box_reg: 0.08693  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.01799  time: 0.6815  data_time: 0.0711  lr: 0.004  max_mem: 11811M
[11/16 06:51:19] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0012999.pth
[11/16 06:51:19] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 06:51:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 06:51:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 06:51:20] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 06:51:20] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 06:51:20] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 06:51:27] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0365 s/iter. Eval: 0.0002 s/iter. Total: 0.0376 s/iter. ETA=0:02:05
[11/16 06:51:32] d2.evaluation.evaluator INFO: Inference done 129/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:15
[11/16 06:51:37] d2.evaluation.evaluator INFO: Inference done 251/3334. Dataloading: 0.0014 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:08
[11/16 06:51:42] d2.evaluation.evaluator INFO: Inference done 370/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:04
[11/16 06:51:47] d2.evaluation.evaluator INFO: Inference done 487/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:59
[11/16 06:51:52] d2.evaluation.evaluator INFO: Inference done 607/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:54
[11/16 06:51:57] d2.evaluation.evaluator INFO: Inference done 726/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:49
[11/16 06:52:03] d2.evaluation.evaluator INFO: Inference done 846/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:44
[11/16 06:52:08] d2.evaluation.evaluator INFO: Inference done 964/3334. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:39
[11/16 06:52:13] d2.evaluation.evaluator INFO: Inference done 1083/3334. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:34
[11/16 06:52:18] d2.evaluation.evaluator INFO: Inference done 1199/3334. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:30
[11/16 06:52:23] d2.evaluation.evaluator INFO: Inference done 1320/3334. Dataloading: 0.0014 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:24
[11/16 06:52:28] d2.evaluation.evaluator INFO: Inference done 1436/3334. Dataloading: 0.0014 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:20
[11/16 06:52:33] d2.evaluation.evaluator INFO: Inference done 1552/3334. Dataloading: 0.0014 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:15
[11/16 06:52:38] d2.evaluation.evaluator INFO: Inference done 1667/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:10
[11/16 06:52:43] d2.evaluation.evaluator INFO: Inference done 1787/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:05
[11/16 06:52:48] d2.evaluation.evaluator INFO: Inference done 1905/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:00
[11/16 06:52:53] d2.evaluation.evaluator INFO: Inference done 2023/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:55
[11/16 06:52:58] d2.evaluation.evaluator INFO: Inference done 2141/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:50
[11/16 06:53:03] d2.evaluation.evaluator INFO: Inference done 2260/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:45
[11/16 06:53:08] d2.evaluation.evaluator INFO: Inference done 2379/3334. Dataloading: 0.0014 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:40
[11/16 06:53:13] d2.evaluation.evaluator INFO: Inference done 2497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:35
[11/16 06:53:18] d2.evaluation.evaluator INFO: Inference done 2616/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:30
[11/16 06:53:23] d2.evaluation.evaluator INFO: Inference done 2734/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:25
[11/16 06:53:28] d2.evaluation.evaluator INFO: Inference done 2850/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:20
[11/16 06:53:33] d2.evaluation.evaluator INFO: Inference done 2968/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:15
[11/16 06:53:38] d2.evaluation.evaluator INFO: Inference done 3087/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:10
[11/16 06:53:43] d2.evaluation.evaluator INFO: Inference done 3204/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:05
[11/16 06:53:48] d2.evaluation.evaluator INFO: Total inference time: 0:02:21.001508 (0.042356 s / iter per device, on 6 devices)
[11/16 06:53:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040492 s / iter per device, on 6 devices)
[11/16 06:53:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 06:53:51] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 06:53:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 06:53:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 06:54:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.48 seconds.
[11/16 06:54:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 06:54:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.95 seconds.
[11/16 06:54:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.240 | 5.771  | 1.365  | 0.308 | 1.043 | 2.618 |
[11/16 06:54:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 3.569  | person      | 2.612  | bird                  | 8.492 |
| red panda            | 1.642  | dog         | 26.857 | snake                 | 3.069 |
| car                  | 15.012 | seal        | 0.209  | helmet                | 0.830 |
| motorcycle           | 3.571  | swine       | 2.210  | stove                 | 3.869 |
| monkey               | 2.718  | watercraft  | 8.367  | chair                 | 1.485 |
| domestic cat         | 1.140  | harp        | 1.186  | antelope              | 1.684 |
| camel                | 0.115  | koala bear  | 3.000  | bus                   | 6.622 |
| hat with a wide brim | 0.099  | ski         | 0.000  | piano                 | 5.147 |
| frog                 | 1.295  | dumbbell    | 0.000  | lobster               | 0.623 |
| bench                | 0.000  | rabbit      | 1.624  | porcupine             | 1.394 |
| butterfly            | 5.530  | guitar      | 0.223  | microphone            | 0.000 |
| tape player          | 3.541  | bear        | 3.433  | hippopotamus          | 0.132 |
| bowl                 | 2.999  | axe         | 0.000  | skunk                 | 1.683 |
| airplane             | 6.727  | otter       | 0.000  | table                 | 1.094 |
| coffee maker         | 6.128  | tie         | 0.000  | turtle                | 0.724 |
| purse                | 0.458  | dragonfly   | 0.993  | lemon                 | 3.538 |
| lizard               | 1.466  | backpack    | 1.294  | tv or monitor         | 5.066 |
| cup or mug           | 0.222  | sheep       | 0.840  | ray                   | 0.667 |
| fox                  | 0.777  | whale       | 2.296  | salt or pepper shaker | 0.015 |
| computer keyboard    | 0.000  | fig         | 0.056  | bathing cap           | 0.161 |
| bookshelf            | 4.828  | ladybug     | 13.702 | crutch                | 0.000 |
| pretzel              | 0.451  | sunglasses  | 0.000  | starfish              | 2.318 |
| croquet ball         | 1.128  | lamp        | 0.326  | apple                 | 6.723 |
| cream                | 0.740  | artichoke   | 1.534  | train                 | 0.599 |
| elephant             | 3.509  | bell pepper | 0.785  | miniskirt             | 0.020 |
| orange               | 3.550  | tiger       | 0.099  | sofa                  | 1.162 |
| horse                | 1.044  | violin      | 0.303  | traffic light         | 0.351 |
| drum                 | 0.000  | strawberry  | 1.955  | laptop                | 2.912 |
| pomegranate          | 1.511  | cucumber    | 0.023  | bicycle               | 0.649 |
| banana               | 0.006  | baby bed    | 2.906  | jellyfish             | 1.805 |
| pitcher              | 0.056  | bagel       | 0.785  | beaker                | 2.721 |
| goldfish             | 1.035  | nail        | 0.000  | mushroom              | 0.084 |
| flower pot           | 0.000  | cattle      | 0.471  | zebra                 | 5.411 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 06:54:20] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 06:54:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 06:54:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 06:54:20] d2.evaluation.testing INFO: copypaste: 2.2401,5.7708,1.3646,0.3080,1.0430,2.6177
[11/16 06:54:20] d2.utils.events INFO:  eta: 4:32:40  iter: 12999  total_loss: 0.297  loss_cls: 0.1587  loss_box_reg: 0.09633  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.01844  time: 0.6816  data_time: 0.0684  lr: 0.004  max_mem: 11811M
[11/16 06:54:34] d2.utils.events INFO:  eta: 4:32:26  iter: 13019  total_loss: 0.2892  loss_cls: 0.1552  loss_box_reg: 0.09163  loss_rpn_cls: 0.02088  loss_rpn_loc: 0.01927  time: 0.6815  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 06:54:48] d2.utils.events INFO:  eta: 4:32:12  iter: 13039  total_loss: 0.273  loss_cls: 0.1481  loss_box_reg: 0.08915  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.01918  time: 0.6815  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 06:55:01] d2.utils.events INFO:  eta: 4:32:10  iter: 13059  total_loss: 0.2735  loss_cls: 0.1486  loss_box_reg: 0.08756  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.01933  time: 0.6816  data_time: 0.0651  lr: 0.004  max_mem: 11811M
[11/16 06:55:15] d2.utils.events INFO:  eta: 4:31:57  iter: 13079  total_loss: 0.2834  loss_cls: 0.1587  loss_box_reg: 0.08913  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.01781  time: 0.6816  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 06:55:29] d2.utils.events INFO:  eta: 4:31:39  iter: 13099  total_loss: 0.2916  loss_cls: 0.1547  loss_box_reg: 0.09274  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.0189  time: 0.6816  data_time: 0.0707  lr: 0.004  max_mem: 11811M
[11/16 06:55:42] d2.utils.events INFO:  eta: 4:31:23  iter: 13119  total_loss: 0.2922  loss_cls: 0.1566  loss_box_reg: 0.09674  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.0199  time: 0.6816  data_time: 0.0692  lr: 0.004  max_mem: 11811M
[11/16 06:55:56] d2.utils.events INFO:  eta: 4:31:11  iter: 13139  total_loss: 0.2933  loss_cls: 0.1565  loss_box_reg: 0.09477  loss_rpn_cls: 0.01985  loss_rpn_loc: 0.01953  time: 0.6816  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 06:56:10] d2.utils.events INFO:  eta: 4:30:54  iter: 13159  total_loss: 0.2875  loss_cls: 0.1558  loss_box_reg: 0.094  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.0191  time: 0.6816  data_time: 0.0625  lr: 0.004  max_mem: 11811M
[11/16 06:56:24] d2.utils.events INFO:  eta: 4:30:53  iter: 13179  total_loss: 0.2891  loss_cls: 0.1548  loss_box_reg: 0.09518  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.01945  time: 0.6816  data_time: 0.0731  lr: 0.004  max_mem: 11811M
[11/16 06:56:37] d2.utils.events INFO:  eta: 4:30:26  iter: 13199  total_loss: 0.2892  loss_cls: 0.1588  loss_box_reg: 0.09519  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.01736  time: 0.6816  data_time: 0.0649  lr: 0.004  max_mem: 11811M
[11/16 06:56:51] d2.utils.events INFO:  eta: 4:30:22  iter: 13219  total_loss: 0.2735  loss_cls: 0.1508  loss_box_reg: 0.08954  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.01932  time: 0.6816  data_time: 0.0604  lr: 0.004  max_mem: 11811M
[11/16 06:57:05] d2.utils.events INFO:  eta: 4:29:57  iter: 13239  total_loss: 0.2729  loss_cls: 0.1468  loss_box_reg: 0.08757  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.01857  time: 0.6816  data_time: 0.0803  lr: 0.004  max_mem: 11811M
[11/16 06:57:19] d2.utils.events INFO:  eta: 4:29:47  iter: 13259  total_loss: 0.2856  loss_cls: 0.1515  loss_box_reg: 0.09206  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.02083  time: 0.6817  data_time: 0.0770  lr: 0.004  max_mem: 11811M
[11/16 06:57:32] d2.utils.events INFO:  eta: 4:29:28  iter: 13279  total_loss: 0.2946  loss_cls: 0.1531  loss_box_reg: 0.09168  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.02077  time: 0.6816  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 06:57:46] d2.utils.events INFO:  eta: 4:29:15  iter: 13299  total_loss: 0.2814  loss_cls: 0.1532  loss_box_reg: 0.08906  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.01959  time: 0.6816  data_time: 0.0636  lr: 0.004  max_mem: 11811M
[11/16 06:57:59] d2.utils.events INFO:  eta: 4:29:01  iter: 13319  total_loss: 0.2775  loss_cls: 0.1525  loss_box_reg: 0.08746  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.02009  time: 0.6816  data_time: 0.0684  lr: 0.004  max_mem: 11811M
[11/16 06:58:13] d2.utils.events INFO:  eta: 4:28:50  iter: 13339  total_loss: 0.2843  loss_cls: 0.156  loss_box_reg: 0.09202  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.02091  time: 0.6817  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 06:58:27] d2.utils.events INFO:  eta: 4:28:44  iter: 13359  total_loss: 0.2722  loss_cls: 0.1514  loss_box_reg: 0.09082  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.01791  time: 0.6817  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 06:58:41] d2.utils.events INFO:  eta: 4:28:26  iter: 13379  total_loss: 0.2954  loss_cls: 0.1612  loss_box_reg: 0.09539  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.0203  time: 0.6817  data_time: 0.0765  lr: 0.004  max_mem: 11811M
[11/16 06:58:54] d2.utils.events INFO:  eta: 4:28:08  iter: 13399  total_loss: 0.278  loss_cls: 0.151  loss_box_reg: 0.09235  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.0176  time: 0.6817  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 06:59:08] d2.utils.events INFO:  eta: 4:27:53  iter: 13419  total_loss: 0.2871  loss_cls: 0.1561  loss_box_reg: 0.09436  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.01836  time: 0.6817  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 06:59:22] d2.utils.events INFO:  eta: 4:27:40  iter: 13439  total_loss: 0.2788  loss_cls: 0.1507  loss_box_reg: 0.08655  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.01902  time: 0.6817  data_time: 0.0759  lr: 0.004  max_mem: 11811M
[11/16 06:59:35] d2.utils.events INFO:  eta: 4:27:25  iter: 13459  total_loss: 0.2925  loss_cls: 0.1577  loss_box_reg: 0.09522  loss_rpn_cls: 0.02266  loss_rpn_loc: 0.01864  time: 0.6817  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 06:59:49] d2.utils.events INFO:  eta: 4:27:12  iter: 13479  total_loss: 0.2763  loss_cls: 0.1529  loss_box_reg: 0.08979  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.01922  time: 0.6817  data_time: 0.0669  lr: 0.004  max_mem: 11811M
[11/16 07:00:03] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0013499.pth
[11/16 07:00:03] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 07:00:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 07:00:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 07:00:04] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 07:00:04] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 07:00:04] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 07:00:11] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0436 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:02:28
[11/16 07:00:16] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:13
[11/16 07:00:21] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/16 07:00:26] d2.evaluation.evaluator INFO: Inference done 370/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:04
[11/16 07:00:31] d2.evaluation.evaluator INFO: Inference done 488/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:02:00
[11/16 07:00:36] d2.evaluation.evaluator INFO: Inference done 604/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:55
[11/16 07:00:41] d2.evaluation.evaluator INFO: Inference done 720/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:51
[11/16 07:00:46] d2.evaluation.evaluator INFO: Inference done 841/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:45
[11/16 07:00:51] d2.evaluation.evaluator INFO: Inference done 955/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:41
[11/16 07:00:56] d2.evaluation.evaluator INFO: Inference done 1070/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:01:36
[11/16 07:01:01] d2.evaluation.evaluator INFO: Inference done 1186/3334. Dataloading: 0.0015 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:01:31
[11/16 07:01:06] d2.evaluation.evaluator INFO: Inference done 1302/3334. Dataloading: 0.0015 s/iter. Inference: 0.0411 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:01:27
[11/16 07:01:11] d2.evaluation.evaluator INFO: Inference done 1420/3334. Dataloading: 0.0015 s/iter. Inference: 0.0410 s/iter. Eval: 0.0002 s/iter. Total: 0.0428 s/iter. ETA=0:01:21
[11/16 07:01:16] d2.evaluation.evaluator INFO: Inference done 1540/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:01:16
[11/16 07:01:21] d2.evaluation.evaluator INFO: Inference done 1660/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:01:11
[11/16 07:01:26] d2.evaluation.evaluator INFO: Inference done 1777/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:01:06
[11/16 07:01:31] d2.evaluation.evaluator INFO: Inference done 1895/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:01
[11/16 07:01:36] d2.evaluation.evaluator INFO: Inference done 2016/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:56
[11/16 07:01:41] d2.evaluation.evaluator INFO: Inference done 2138/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:50
[11/16 07:01:46] d2.evaluation.evaluator INFO: Inference done 2261/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:45
[11/16 07:01:51] d2.evaluation.evaluator INFO: Inference done 2380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:40
[11/16 07:01:56] d2.evaluation.evaluator INFO: Inference done 2500/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:35
[11/16 07:02:01] d2.evaluation.evaluator INFO: Inference done 2621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:30
[11/16 07:02:06] d2.evaluation.evaluator INFO: Inference done 2737/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:25
[11/16 07:02:11] d2.evaluation.evaluator INFO: Inference done 2855/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:20
[11/16 07:02:16] d2.evaluation.evaluator INFO: Inference done 2974/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:15
[11/16 07:02:21] d2.evaluation.evaluator INFO: Inference done 3092/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:10
[11/16 07:02:26] d2.evaluation.evaluator INFO: Inference done 3214/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:05
[11/16 07:02:31] d2.evaluation.evaluator INFO: Total inference time: 0:02:20.651844 (0.042250 s / iter per device, on 6 devices)
[11/16 07:02:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040316 s / iter per device, on 6 devices)
[11/16 07:02:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 07:02:33] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 07:02:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 07:02:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 07:02:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.35 seconds.
[11/16 07:02:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 07:02:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.68 seconds.
[11/16 07:02:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.361 | 5.759  | 1.468  | 0.248 | 1.238 | 2.742 |
[11/16 07:02:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 3.057  | person      | 2.871  | bird                  | 8.503 |
| red panda            | 0.462  | dog         | 25.531 | snake                 | 3.399 |
| car                  | 14.162 | seal        | 0.134  | helmet                | 1.668 |
| motorcycle           | 3.128  | swine       | 3.125  | stove                 | 1.889 |
| monkey               | 3.646  | watercraft  | 8.111  | chair                 | 1.492 |
| domestic cat         | 1.818  | harp        | 1.286  | antelope              | 3.366 |
| camel                | 0.369  | koala bear  | 5.960  | bus                   | 8.054 |
| hat with a wide brim | 0.837  | ski         | 0.000  | piano                 | 3.090 |
| frog                 | 2.578  | dumbbell    | 0.000  | lobster               | 1.255 |
| bench                | 0.000  | rabbit      | 3.863  | porcupine             | 1.183 |
| butterfly            | 6.326  | guitar      | 0.207  | microphone            | 0.000 |
| tape player          | 4.047  | bear        | 2.951  | hippopotamus          | 0.059 |
| bowl                 | 2.946  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 3.744  | otter       | 0.036  | table                 | 1.228 |
| coffee maker         | 7.742  | tie         | 0.000  | turtle                | 0.933 |
| purse                | 0.561  | dragonfly   | 0.882  | lemon                 | 2.704 |
| lizard               | 2.230  | backpack    | 1.237  | tv or monitor         | 5.354 |
| cup or mug           | 0.263  | sheep       | 0.621  | ray                   | 0.743 |
| fox                  | 1.557  | whale       | 2.879  | salt or pepper shaker | 0.100 |
| computer keyboard    | 0.000  | fig         | 0.115  | bathing cap           | 0.307 |
| bookshelf            | 5.440  | ladybug     | 15.384 | crutch                | 0.000 |
| pretzel              | 0.410  | sunglasses  | 0.000  | starfish              | 2.157 |
| croquet ball         | 1.745  | lamp        | 0.947  | apple                 | 4.501 |
| cream                | 1.269  | artichoke   | 3.767  | train                 | 0.624 |
| elephant             | 3.589  | bell pepper | 1.152  | miniskirt             | 0.149 |
| orange               | 2.594  | tiger       | 0.664  | sofa                  | 1.176 |
| horse                | 1.088  | violin      | 0.178  | traffic light         | 0.629 |
| drum                 | 0.056  | strawberry  | 2.240  | laptop                | 0.622 |
| pomegranate          | 0.507  | cucumber    | 0.235  | bicycle               | 0.432 |
| banana               | 0.119  | baby bed    | 2.846  | jellyfish             | 1.602 |
| pitcher              | 0.215  | bagel       | 1.395  | beaker                | 3.210 |
| goldfish             | 0.939  | nail        | 0.000  | mushroom              | 0.227 |
| flower pot           | 0.180  | cattle      | 1.044  | zebra                 | 8.068 |
| wine bottle          | 0.070  |             |        |                       |       |
[11/16 07:02:58] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 07:02:58] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 07:02:58] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 07:02:58] d2.evaluation.testing INFO: copypaste: 2.3608,5.7594,1.4682,0.2480,1.2378,2.7421
[11/16 07:02:59] d2.utils.events INFO:  eta: 4:26:56  iter: 13499  total_loss: 0.3124  loss_cls: 0.1742  loss_box_reg: 0.09653  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.02017  time: 0.6817  data_time: 0.0668  lr: 0.004  max_mem: 11811M
[11/16 07:03:12] d2.utils.events INFO:  eta: 4:26:45  iter: 13519  total_loss: 0.2793  loss_cls: 0.1508  loss_box_reg: 0.08865  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.0195  time: 0.6817  data_time: 0.0683  lr: 0.004  max_mem: 11811M
[11/16 07:03:26] d2.utils.events INFO:  eta: 4:26:48  iter: 13539  total_loss: 0.2919  loss_cls: 0.1573  loss_box_reg: 0.09354  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.01892  time: 0.6817  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 07:03:40] d2.utils.events INFO:  eta: 4:26:35  iter: 13559  total_loss: 0.2965  loss_cls: 0.1551  loss_box_reg: 0.09485  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.01918  time: 0.6818  data_time: 0.0822  lr: 0.004  max_mem: 11811M
[11/16 07:03:54] d2.utils.events INFO:  eta: 4:26:26  iter: 13579  total_loss: 0.2689  loss_cls: 0.1457  loss_box_reg: 0.08951  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.02044  time: 0.6818  data_time: 0.0758  lr: 0.004  max_mem: 11811M
[11/16 07:04:08] d2.utils.events INFO:  eta: 4:26:19  iter: 13599  total_loss: 0.3001  loss_cls: 0.1587  loss_box_reg: 0.09449  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.01918  time: 0.6818  data_time: 0.0674  lr: 0.004  max_mem: 11811M
[11/16 07:04:21] d2.utils.events INFO:  eta: 4:26:10  iter: 13619  total_loss: 0.2825  loss_cls: 0.1558  loss_box_reg: 0.09146  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.02021  time: 0.6818  data_time: 0.0679  lr: 0.004  max_mem: 11811M
[11/16 07:04:35] d2.utils.events INFO:  eta: 4:26:03  iter: 13639  total_loss: 0.2842  loss_cls: 0.1554  loss_box_reg: 0.09168  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.01974  time: 0.6818  data_time: 0.0670  lr: 0.004  max_mem: 11811M
[11/16 07:04:49] d2.utils.events INFO:  eta: 4:25:43  iter: 13659  total_loss: 0.2957  loss_cls: 0.1507  loss_box_reg: 0.09225  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.0187  time: 0.6818  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 07:05:02] d2.utils.events INFO:  eta: 4:25:18  iter: 13679  total_loss: 0.2754  loss_cls: 0.1494  loss_box_reg: 0.09015  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.01895  time: 0.6818  data_time: 0.0676  lr: 0.004  max_mem: 11811M
[11/16 07:05:16] d2.utils.events INFO:  eta: 4:25:04  iter: 13699  total_loss: 0.2791  loss_cls: 0.1562  loss_box_reg: 0.09092  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.01983  time: 0.6818  data_time: 0.0617  lr: 0.004  max_mem: 11811M
[11/16 07:05:29] d2.utils.events INFO:  eta: 4:24:53  iter: 13719  total_loss: 0.2812  loss_cls: 0.1535  loss_box_reg: 0.08946  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.01959  time: 0.6818  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 07:05:43] d2.utils.events INFO:  eta: 4:24:35  iter: 13739  total_loss: 0.3006  loss_cls: 0.1634  loss_box_reg: 0.09509  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.01853  time: 0.6818  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 07:05:57] d2.utils.events INFO:  eta: 4:24:20  iter: 13759  total_loss: 0.2892  loss_cls: 0.154  loss_box_reg: 0.09406  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.01867  time: 0.6818  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 07:06:11] d2.utils.events INFO:  eta: 4:24:08  iter: 13779  total_loss: 0.2827  loss_cls: 0.1478  loss_box_reg: 0.09168  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.01837  time: 0.6818  data_time: 0.0804  lr: 0.004  max_mem: 11811M
[11/16 07:06:24] d2.utils.events INFO:  eta: 4:23:58  iter: 13799  total_loss: 0.2909  loss_cls: 0.1613  loss_box_reg: 0.09611  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.01992  time: 0.6819  data_time: 0.0657  lr: 0.004  max_mem: 11811M
[11/16 07:06:38] d2.utils.events INFO:  eta: 4:23:44  iter: 13819  total_loss: 0.2676  loss_cls: 0.1444  loss_box_reg: 0.08445  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.01845  time: 0.6819  data_time: 0.0624  lr: 0.004  max_mem: 11811M
[11/16 07:06:52] d2.utils.events INFO:  eta: 4:23:26  iter: 13839  total_loss: 0.2836  loss_cls: 0.1558  loss_box_reg: 0.09479  loss_rpn_cls: 0.01894  loss_rpn_loc: 0.01964  time: 0.6819  data_time: 0.0673  lr: 0.004  max_mem: 11811M
[11/16 07:07:05] d2.utils.events INFO:  eta: 4:23:12  iter: 13859  total_loss: 0.2905  loss_cls: 0.1592  loss_box_reg: 0.08851  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.01808  time: 0.6819  data_time: 0.0667  lr: 0.004  max_mem: 11811M
[11/16 07:07:19] d2.utils.events INFO:  eta: 4:23:00  iter: 13879  total_loss: 0.2896  loss_cls: 0.1551  loss_box_reg: 0.09448  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.01961  time: 0.6819  data_time: 0.0677  lr: 0.004  max_mem: 11811M
[11/16 07:07:32] d2.utils.events INFO:  eta: 4:22:47  iter: 13899  total_loss: 0.2818  loss_cls: 0.1545  loss_box_reg: 0.09175  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.0187  time: 0.6818  data_time: 0.0650  lr: 0.004  max_mem: 11811M
[11/16 07:07:46] d2.utils.events INFO:  eta: 4:22:32  iter: 13919  total_loss: 0.277  loss_cls: 0.1498  loss_box_reg: 0.08711  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.01808  time: 0.6818  data_time: 0.0677  lr: 0.004  max_mem: 11811M
[11/16 07:08:00] d2.utils.events INFO:  eta: 4:22:20  iter: 13939  total_loss: 0.2728  loss_cls: 0.1462  loss_box_reg: 0.09045  loss_rpn_cls: 0.01867  loss_rpn_loc: 0.01691  time: 0.6818  data_time: 0.0665  lr: 0.004  max_mem: 11811M
[11/16 07:08:13] d2.utils.events INFO:  eta: 4:22:12  iter: 13959  total_loss: 0.2963  loss_cls: 0.1587  loss_box_reg: 0.09559  loss_rpn_cls: 0.0188  loss_rpn_loc: 0.01927  time: 0.6818  data_time: 0.0695  lr: 0.004  max_mem: 11811M
[11/16 07:08:27] d2.utils.events INFO:  eta: 4:21:58  iter: 13979  total_loss: 0.2857  loss_cls: 0.1566  loss_box_reg: 0.0889  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.01822  time: 0.6818  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 07:08:40] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0013999.pth
[11/16 07:08:41] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 07:08:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 07:08:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 07:08:41] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 07:08:42] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 07:08:42] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 07:08:48] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0400 s/iter. ETA=0:02:13
[11/16 07:08:53] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0018 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/16 07:08:59] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/16 07:09:04] d2.evaluation.evaluator INFO: Inference done 377/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:01
[11/16 07:09:09] d2.evaluation.evaluator INFO: Inference done 496/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:57
[11/16 07:09:14] d2.evaluation.evaluator INFO: Inference done 614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/16 07:09:19] d2.evaluation.evaluator INFO: Inference done 731/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:49
[11/16 07:09:24] d2.evaluation.evaluator INFO: Inference done 852/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:43
[11/16 07:09:29] d2.evaluation.evaluator INFO: Inference done 973/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:38
[11/16 07:09:34] d2.evaluation.evaluator INFO: Inference done 1092/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/16 07:09:39] d2.evaluation.evaluator INFO: Inference done 1211/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:28
[11/16 07:09:44] d2.evaluation.evaluator INFO: Inference done 1329/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:24
[11/16 07:09:49] d2.evaluation.evaluator INFO: Inference done 1443/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:19
[11/16 07:09:54] d2.evaluation.evaluator INFO: Inference done 1558/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:14
[11/16 07:09:59] d2.evaluation.evaluator INFO: Inference done 1677/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:01:09
[11/16 07:10:04] d2.evaluation.evaluator INFO: Inference done 1801/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:04
[11/16 07:10:09] d2.evaluation.evaluator INFO: Inference done 1920/3334. Dataloading: 0.0016 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:59
[11/16 07:10:14] d2.evaluation.evaluator INFO: Inference done 2039/3334. Dataloading: 0.0016 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:00:54
[11/16 07:10:19] d2.evaluation.evaluator INFO: Inference done 2154/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:49
[11/16 07:10:24] d2.evaluation.evaluator INFO: Inference done 2271/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:44
[11/16 07:10:29] d2.evaluation.evaluator INFO: Inference done 2389/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:39
[11/16 07:10:34] d2.evaluation.evaluator INFO: Inference done 2507/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:34
[11/16 07:10:39] d2.evaluation.evaluator INFO: Inference done 2623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:30
[11/16 07:10:44] d2.evaluation.evaluator INFO: Inference done 2739/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:25
[11/16 07:10:49] d2.evaluation.evaluator INFO: Inference done 2859/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:20
[11/16 07:10:54] d2.evaluation.evaluator INFO: Inference done 2979/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:15
[11/16 07:10:59] d2.evaluation.evaluator INFO: Inference done 3097/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:10
[11/16 07:11:04] d2.evaluation.evaluator INFO: Inference done 3212/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:05
[11/16 07:11:09] d2.evaluation.evaluator INFO: Total inference time: 0:02:21.036549 (0.042366 s / iter per device, on 6 devices)
[11/16 07:11:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040413 s / iter per device, on 6 devices)
[11/16 07:11:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 07:11:11] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 07:11:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 07:11:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 07:11:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 19.78 seconds.
[11/16 07:11:32] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 07:11:34] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.55 seconds.
[11/16 07:11:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.544 | 6.237  | 1.603  | 0.278 | 1.069 | 3.026 |
[11/16 07:11:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.688  | person      | 3.148  | bird                  | 9.162 |
| red panda            | 1.694  | dog         | 28.038 | snake                 | 3.764 |
| car                  | 15.570 | seal        | 0.279  | helmet                | 1.174 |
| motorcycle           | 2.151  | swine       | 2.477  | stove                 | 2.563 |
| monkey               | 3.596  | watercraft  | 9.496  | chair                 | 1.250 |
| domestic cat         | 3.239  | harp        | 1.452  | antelope              | 3.147 |
| camel                | 0.228  | koala bear  | 1.937  | bus                   | 9.051 |
| hat with a wide brim | 0.178  | ski         | 0.000  | piano                 | 5.750 |
| frog                 | 3.339  | dumbbell    | 0.000  | lobster               | 1.135 |
| bench                | 0.028  | rabbit      | 3.321  | porcupine             | 1.725 |
| butterfly            | 7.439  | guitar      | 0.378  | microphone            | 0.000 |
| tape player          | 4.465  | bear        | 3.066  | hippopotamus          | 0.132 |
| bowl                 | 1.782  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 4.740  | otter       | 0.074  | table                 | 1.473 |
| coffee maker         | 6.338  | tie         | 0.000  | turtle                | 1.774 |
| purse                | 0.127  | dragonfly   | 0.703  | lemon                 | 2.611 |
| lizard               | 1.516  | backpack    | 1.306  | tv or monitor         | 7.321 |
| cup or mug           | 0.809  | sheep       | 0.170  | ray                   | 0.482 |
| fox                  | 2.587  | whale       | 2.082  | salt or pepper shaker | 0.019 |
| computer keyboard    | 0.077  | fig         | 0.569  | bathing cap           | 0.548 |
| bookshelf            | 5.962  | ladybug     | 15.857 | crutch                | 0.000 |
| pretzel              | 1.609  | sunglasses  | 0.000  | starfish              | 1.485 |
| croquet ball         | 1.397  | lamp        | 0.140  | apple                 | 5.571 |
| cream                | 1.404  | artichoke   | 4.424  | train                 | 0.721 |
| elephant             | 3.702  | bell pepper | 1.431  | miniskirt             | 0.000 |
| orange               | 6.317  | tiger       | 0.208  | sofa                  | 0.736 |
| horse                | 1.405  | violin      | 0.000  | traffic light         | 0.565 |
| drum                 | 0.000  | strawberry  | 3.334  | laptop                | 1.545 |
| pomegranate          | 0.811  | cucumber    | 0.000  | bicycle               | 0.589 |
| banana               | 0.042  | baby bed    | 2.662  | jellyfish             | 2.216 |
| pitcher              | 0.094  | bagel       | 1.589  | beaker                | 3.011 |
| goldfish             | 3.125  | nail        | 0.000  | mushroom              | 0.276 |
| flower pot           | 0.000  | cattle      | 0.493  | zebra                 | 7.524 |
| wine bottle          | 0.000  |             |        |                       |       |
[11/16 07:11:36] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 07:11:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 07:11:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 07:11:36] d2.evaluation.testing INFO: copypaste: 2.5442,6.2374,1.6025,0.2779,1.0686,3.0255
[11/16 07:11:36] d2.utils.events INFO:  eta: 4:21:43  iter: 13999  total_loss: 0.2633  loss_cls: 0.1405  loss_box_reg: 0.0894  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.01772  time: 0.6818  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 07:11:50] d2.utils.events INFO:  eta: 4:21:31  iter: 14019  total_loss: 0.2781  loss_cls: 0.1554  loss_box_reg: 0.08808  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.01714  time: 0.6818  data_time: 0.0672  lr: 0.004  max_mem: 11811M
[11/16 07:12:03] d2.utils.events INFO:  eta: 4:21:17  iter: 14039  total_loss: 0.2907  loss_cls: 0.1553  loss_box_reg: 0.09114  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.01796  time: 0.6818  data_time: 0.0652  lr: 0.004  max_mem: 11811M
[11/16 07:12:17] d2.utils.events INFO:  eta: 4:21:02  iter: 14059  total_loss: 0.287  loss_cls: 0.1577  loss_box_reg: 0.09166  loss_rpn_cls: 0.02148  loss_rpn_loc: 0.01798  time: 0.6818  data_time: 0.0750  lr: 0.004  max_mem: 11811M
[11/16 07:12:31] d2.utils.events INFO:  eta: 4:20:49  iter: 14079  total_loss: 0.2808  loss_cls: 0.1499  loss_box_reg: 0.0913  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.02067  time: 0.6818  data_time: 0.0692  lr: 0.004  max_mem: 11811M
[11/16 07:12:44] d2.utils.events INFO:  eta: 4:20:35  iter: 14099  total_loss: 0.2869  loss_cls: 0.1562  loss_box_reg: 0.09129  loss_rpn_cls: 0.01935  loss_rpn_loc: 0.01935  time: 0.6818  data_time: 0.0669  lr: 0.004  max_mem: 11811M
[11/16 07:12:58] d2.utils.events INFO:  eta: 4:20:22  iter: 14119  total_loss: 0.265  loss_cls: 0.1447  loss_box_reg: 0.08567  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.01705  time: 0.6818  data_time: 0.0641  lr: 0.004  max_mem: 11811M
[11/16 07:13:12] d2.utils.events INFO:  eta: 4:20:09  iter: 14139  total_loss: 0.2767  loss_cls: 0.1494  loss_box_reg: 0.08959  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.01682  time: 0.6818  data_time: 0.0698  lr: 0.004  max_mem: 11811M
[11/16 07:13:25] d2.utils.events INFO:  eta: 4:19:55  iter: 14159  total_loss: 0.2752  loss_cls: 0.1465  loss_box_reg: 0.09063  loss_rpn_cls: 0.01601  loss_rpn_loc: 0.02067  time: 0.6818  data_time: 0.0656  lr: 0.004  max_mem: 11811M
[11/16 07:13:39] d2.utils.events INFO:  eta: 4:19:35  iter: 14179  total_loss: 0.2805  loss_cls: 0.1498  loss_box_reg: 0.08912  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.01875  time: 0.6819  data_time: 0.0817  lr: 0.004  max_mem: 11811M
[11/16 07:13:53] d2.utils.events INFO:  eta: 4:19:25  iter: 14199  total_loss: 0.2796  loss_cls: 0.1491  loss_box_reg: 0.08919  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.01935  time: 0.6819  data_time: 0.0739  lr: 0.004  max_mem: 11811M
[11/16 07:14:06] d2.utils.events INFO:  eta: 4:19:12  iter: 14219  total_loss: 0.2843  loss_cls: 0.1564  loss_box_reg: 0.09191  loss_rpn_cls: 0.01782  loss_rpn_loc: 0.01952  time: 0.6819  data_time: 0.0666  lr: 0.004  max_mem: 11811M
[11/16 07:14:20] d2.utils.events INFO:  eta: 4:19:01  iter: 14239  total_loss: 0.2745  loss_cls: 0.1526  loss_box_reg: 0.0902  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.01883  time: 0.6819  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 07:14:34] d2.utils.events INFO:  eta: 4:18:46  iter: 14259  total_loss: 0.2838  loss_cls: 0.1511  loss_box_reg: 0.09239  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.02065  time: 0.6819  data_time: 0.0703  lr: 0.004  max_mem: 11811M
[11/16 07:14:48] d2.utils.events INFO:  eta: 4:18:33  iter: 14279  total_loss: 0.2719  loss_cls: 0.1473  loss_box_reg: 0.09049  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.01839  time: 0.6819  data_time: 0.0664  lr: 0.004  max_mem: 11811M
[11/16 07:15:01] d2.utils.events INFO:  eta: 4:18:18  iter: 14299  total_loss: 0.2906  loss_cls: 0.152  loss_box_reg: 0.09317  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.01901  time: 0.6819  data_time: 0.0729  lr: 0.004  max_mem: 11811M
[11/16 07:15:15] d2.utils.events INFO:  eta: 4:18:00  iter: 14319  total_loss: 0.2825  loss_cls: 0.1523  loss_box_reg: 0.09126  loss_rpn_cls: 0.01655  loss_rpn_loc: 0.01808  time: 0.6819  data_time: 0.0655  lr: 0.004  max_mem: 11811M
[11/16 07:15:29] d2.utils.events INFO:  eta: 4:17:47  iter: 14339  total_loss: 0.2899  loss_cls: 0.1565  loss_box_reg: 0.09065  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.02034  time: 0.6819  data_time: 0.0786  lr: 0.004  max_mem: 11811M
[11/16 07:15:42] d2.utils.events INFO:  eta: 4:17:32  iter: 14359  total_loss: 0.2793  loss_cls: 0.1508  loss_box_reg: 0.09184  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.01833  time: 0.6819  data_time: 0.0686  lr: 0.004  max_mem: 11811M
[11/16 07:15:56] d2.utils.events INFO:  eta: 4:17:18  iter: 14379  total_loss: 0.2776  loss_cls: 0.1562  loss_box_reg: 0.08837  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01737  time: 0.6819  data_time: 0.0680  lr: 0.004  max_mem: 11811M
[11/16 07:16:10] d2.utils.events INFO:  eta: 4:17:10  iter: 14399  total_loss: 0.2855  loss_cls: 0.1576  loss_box_reg: 0.09146  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.01907  time: 0.6819  data_time: 0.0746  lr: 0.004  max_mem: 11811M
[11/16 07:16:23] d2.utils.events INFO:  eta: 4:16:52  iter: 14419  total_loss: 0.2865  loss_cls: 0.1524  loss_box_reg: 0.09024  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.0194  time: 0.6819  data_time: 0.0648  lr: 0.004  max_mem: 11811M
[11/16 07:16:37] d2.utils.events INFO:  eta: 4:16:37  iter: 14439  total_loss: 0.2959  loss_cls: 0.1629  loss_box_reg: 0.09872  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.01794  time: 0.6819  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 07:16:51] d2.utils.events INFO:  eta: 4:16:23  iter: 14459  total_loss: 0.2791  loss_cls: 0.1487  loss_box_reg: 0.09027  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.01982  time: 0.6819  data_time: 0.0627  lr: 0.004  max_mem: 11811M
[11/16 07:17:04] d2.utils.events INFO:  eta: 4:16:05  iter: 14479  total_loss: 0.2835  loss_cls: 0.1498  loss_box_reg: 0.0919  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.01977  time: 0.6819  data_time: 0.0642  lr: 0.004  max_mem: 11811M
[11/16 07:17:18] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0014499.pth
[11/16 07:17:18] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 07:17:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 07:17:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 07:17:19] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 07:17:19] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 07:17:19] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 07:17:26] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0423 s/iter. Eval: 0.0002 s/iter. Total: 0.0436 s/iter. ETA=0:02:24
[11/16 07:17:31] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/16 07:17:36] d2.evaluation.evaluator INFO: Inference done 249/3334. Dataloading: 0.0016 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:09
[11/16 07:17:41] d2.evaluation.evaluator INFO: Inference done 368/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:04
[11/16 07:17:46] d2.evaluation.evaluator INFO: Inference done 485/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:00
[11/16 07:17:51] d2.evaluation.evaluator INFO: Inference done 605/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:55
[11/16 07:17:56] d2.evaluation.evaluator INFO: Inference done 726/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:49
[11/16 07:18:01] d2.evaluation.evaluator INFO: Inference done 845/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:44
[11/16 07:18:06] d2.evaluation.evaluator INFO: Inference done 965/3334. Dataloading: 0.0015 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:39
[11/16 07:18:11] d2.evaluation.evaluator INFO: Inference done 1080/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:35
[11/16 07:18:16] d2.evaluation.evaluator INFO: Inference done 1197/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:30
[11/16 07:18:21] d2.evaluation.evaluator INFO: Inference done 1313/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:25
[11/16 07:18:27] d2.evaluation.evaluator INFO: Inference done 1435/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:01:20
[11/16 07:18:32] d2.evaluation.evaluator INFO: Inference done 1551/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:15
[11/16 07:18:37] d2.evaluation.evaluator INFO: Inference done 1669/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:10
[11/16 07:18:42] d2.evaluation.evaluator INFO: Inference done 1788/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:05
[11/16 07:18:47] d2.evaluation.evaluator INFO: Inference done 1908/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:00
[11/16 07:18:52] d2.evaluation.evaluator INFO: Inference done 2030/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:55
[11/16 07:18:57] d2.evaluation.evaluator INFO: Inference done 2152/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:49
[11/16 07:19:02] d2.evaluation.evaluator INFO: Inference done 2272/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:44
[11/16 07:19:07] d2.evaluation.evaluator INFO: Inference done 2390/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0422 s/iter. ETA=0:00:39
[11/16 07:19:12] d2.evaluation.evaluator INFO: Inference done 2506/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:35
[11/16 07:19:17] d2.evaluation.evaluator INFO: Inference done 2625/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:29
[11/16 07:19:22] d2.evaluation.evaluator INFO: Inference done 2743/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:25
[11/16 07:19:27] d2.evaluation.evaluator INFO: Inference done 2861/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:20
[11/16 07:19:32] d2.evaluation.evaluator INFO: Inference done 2980/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:14
[11/16 07:19:37] d2.evaluation.evaluator INFO: Inference done 3100/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:09
[11/16 07:19:42] d2.evaluation.evaluator INFO: Inference done 3218/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:00:04
[11/16 07:19:47] d2.evaluation.evaluator INFO: Total inference time: 0:02:20.722563 (0.042272 s / iter per device, on 6 devices)
[11/16 07:19:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040367 s / iter per device, on 6 devices)
[11/16 07:19:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 07:19:49] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 07:19:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 07:19:50] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 07:20:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.33 seconds.
[11/16 07:20:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 07:20:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.75 seconds.
[11/16 07:20:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.499 | 6.081  | 1.583  | 0.493 | 1.031 | 2.934 |
[11/16 07:20:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 2.194  | person      | 2.010  | bird                  | 8.986 |
| red panda            | 0.198  | dog         | 28.556 | snake                 | 3.396 |
| car                  | 15.673 | seal        | 0.499  | helmet                | 2.195 |
| motorcycle           | 2.551  | swine       | 2.675  | stove                 | 2.545 |
| monkey               | 3.861  | watercraft  | 9.962  | chair                 | 1.255 |
| domestic cat         | 1.607  | harp        | 1.370  | antelope              | 3.389 |
| camel                | 0.022  | koala bear  | 1.329  | bus                   | 8.166 |
| hat with a wide brim | 0.583  | ski         | 0.000  | piano                 | 5.120 |
| frog                 | 3.269  | dumbbell    | 0.000  | lobster               | 1.207 |
| bench                | 0.040  | rabbit      | 2.590  | porcupine             | 1.442 |
| butterfly            | 8.194  | guitar      | 0.155  | microphone            | 0.000 |
| tape player          | 4.753  | bear        | 3.026  | hippopotamus          | 0.095 |
| bowl                 | 1.592  | axe         | 0.000  | skunk                 | 0.198 |
| airplane             | 6.061  | otter       | 0.391  | table                 | 1.569 |
| coffee maker         | 5.815  | tie         | 0.000  | turtle                | 1.357 |
| purse                | 0.475  | dragonfly   | 0.747  | lemon                 | 2.456 |
| lizard               | 1.695  | backpack    | 1.671  | tv or monitor         | 7.387 |
| cup or mug           | 0.457  | sheep       | 0.204  | ray                   | 0.694 |
| fox                  | 1.786  | whale       | 2.745  | salt or pepper shaker | 0.032 |
| computer keyboard    | 0.827  | fig         | 0.195  | bathing cap           | 0.214 |
| bookshelf            | 4.463  | ladybug     | 14.159 | crutch                | 0.000 |
| pretzel              | 1.042  | sunglasses  | 0.000  | starfish              | 1.963 |
| croquet ball         | 2.512  | lamp        | 0.537  | apple                 | 6.762 |
| cream                | 2.992  | artichoke   | 5.353  | train                 | 0.883 |
| elephant             | 2.423  | bell pepper | 0.500  | miniskirt             | 0.046 |
| orange               | 5.172  | tiger       | 0.000  | sofa                  | 0.540 |
| horse                | 1.410  | violin      | 0.000  | traffic light         | 0.843 |
| drum                 | 0.000  | strawberry  | 2.966  | laptop                | 1.858 |
| pomegranate          | 2.249  | cucumber    | 0.100  | bicycle               | 0.954 |
| banana               | 0.106  | baby bed    | 2.993  | jellyfish             | 2.010 |
| pitcher              | 0.040  | bagel       | 0.882  | beaker                | 2.418 |
| goldfish             | 2.238  | nail        | 0.000  | mushroom              | 0.240 |
| flower pot           | 0.000  | cattle      | 0.942  | zebra                 | 6.420 |
| wine bottle          | 0.436  |             |        |                       |       |
[11/16 07:20:18] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 07:20:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 07:20:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 07:20:18] d2.evaluation.testing INFO: copypaste: 2.4993,6.0808,1.5833,0.4933,1.0309,2.9341
[11/16 07:20:19] d2.utils.events INFO:  eta: 4:15:55  iter: 14499  total_loss: 0.2909  loss_cls: 0.1575  loss_box_reg: 0.09424  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.01986  time: 0.6819  data_time: 0.0687  lr: 0.004  max_mem: 11811M
[11/16 07:20:32] d2.utils.events INFO:  eta: 4:15:24  iter: 14519  total_loss: 0.2755  loss_cls: 0.1476  loss_box_reg: 0.08667  loss_rpn_cls: 0.01742  loss_rpn_loc: 0.01892  time: 0.6819  data_time: 0.0739  lr: 0.004  max_mem: 11811M
[11/16 07:20:45] d2.utils.events INFO:  eta: 4:15:03  iter: 14539  total_loss: 0.2772  loss_cls: 0.1512  loss_box_reg: 0.08722  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.01905  time: 0.6819  data_time: 0.0643  lr: 0.004  max_mem: 11811M
[11/16 07:20:59] d2.utils.events INFO:  eta: 4:14:31  iter: 14559  total_loss: 0.295  loss_cls: 0.1627  loss_box_reg: 0.09206  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.01925  time: 0.6818  data_time: 0.0629  lr: 0.004  max_mem: 11811M
[11/16 07:21:13] d2.utils.events INFO:  eta: 4:14:17  iter: 14579  total_loss: 0.2744  loss_cls: 0.1515  loss_box_reg: 0.08865  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.01881  time: 0.6818  data_time: 0.0704  lr: 0.004  max_mem: 11811M
[11/16 07:21:26] d2.utils.events INFO:  eta: 4:13:57  iter: 14599  total_loss: 0.2851  loss_cls: 0.1514  loss_box_reg: 0.09047  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.01804  time: 0.6818  data_time: 0.0640  lr: 0.004  max_mem: 11811M
[11/16 07:21:40] d2.utils.events INFO:  eta: 4:13:40  iter: 14619  total_loss: 0.2727  loss_cls: 0.143  loss_box_reg: 0.08828  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.02011  time: 0.6818  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 07:21:53] d2.utils.events INFO:  eta: 4:13:30  iter: 14639  total_loss: 0.2806  loss_cls: 0.1533  loss_box_reg: 0.09369  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.01771  time: 0.6818  data_time: 0.0689  lr: 0.004  max_mem: 11811M
[11/16 07:22:07] d2.utils.events INFO:  eta: 4:13:17  iter: 14659  total_loss: 0.2859  loss_cls: 0.1554  loss_box_reg: 0.09244  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.01996  time: 0.6818  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 07:22:21] d2.utils.events INFO:  eta: 4:13:21  iter: 14679  total_loss: 0.2814  loss_cls: 0.1545  loss_box_reg: 0.08893  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.01862  time: 0.6819  data_time: 0.0681  lr: 0.004  max_mem: 11811M
[11/16 07:22:34] d2.utils.events INFO:  eta: 4:13:07  iter: 14699  total_loss: 0.2696  loss_cls: 0.145  loss_box_reg: 0.08892  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.01829  time: 0.6818  data_time: 0.0682  lr: 0.004  max_mem: 11811M
[11/16 07:22:48] d2.utils.events INFO:  eta: 4:12:46  iter: 14719  total_loss: 0.2701  loss_cls: 0.1481  loss_box_reg: 0.08679  loss_rpn_cls: 0.01862  loss_rpn_loc: 0.01969  time: 0.6818  data_time: 0.0690  lr: 0.004  max_mem: 11811M
[11/16 07:23:02] d2.utils.events INFO:  eta: 4:12:34  iter: 14739  total_loss: 0.2738  loss_cls: 0.1519  loss_box_reg: 0.09467  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.01828  time: 0.6818  data_time: 0.0642  lr: 0.004  max_mem: 11811M
[11/16 07:23:15] d2.utils.events INFO:  eta: 4:12:26  iter: 14759  total_loss: 0.2929  loss_cls: 0.1592  loss_box_reg: 0.09745  loss_rpn_cls: 0.01947  loss_rpn_loc: 0.01879  time: 0.6819  data_time: 0.0798  lr: 0.004  max_mem: 11811M
[11/16 07:23:29] d2.utils.events INFO:  eta: 4:11:59  iter: 14779  total_loss: 0.2755  loss_cls: 0.1458  loss_box_reg: 0.0851  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.01932  time: 0.6818  data_time: 0.0632  lr: 0.004  max_mem: 11811M
[11/16 07:23:43] d2.utils.events INFO:  eta: 4:11:41  iter: 14799  total_loss: 0.2871  loss_cls: 0.1523  loss_box_reg: 0.09391  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.01819  time: 0.6818  data_time: 0.0663  lr: 0.004  max_mem: 11811M
[11/16 07:23:56] d2.utils.events INFO:  eta: 4:11:27  iter: 14819  total_loss: 0.2623  loss_cls: 0.1383  loss_box_reg: 0.08745  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.01724  time: 0.6818  data_time: 0.0724  lr: 0.004  max_mem: 11811M
[11/16 07:24:10] d2.utils.events INFO:  eta: 4:11:14  iter: 14839  total_loss: 0.273  loss_cls: 0.1485  loss_box_reg: 0.08701  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.0187  time: 0.6818  data_time: 0.0659  lr: 0.004  max_mem: 11811M
[11/16 07:24:23] d2.utils.events INFO:  eta: 4:10:57  iter: 14859  total_loss: 0.2759  loss_cls: 0.1501  loss_box_reg: 0.08858  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.01956  time: 0.6818  data_time: 0.0689  lr: 0.004  max_mem: 11811M
[11/16 07:24:37] d2.utils.events INFO:  eta: 4:10:51  iter: 14879  total_loss: 0.2775  loss_cls: 0.1491  loss_box_reg: 0.09099  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.01896  time: 0.6818  data_time: 0.0638  lr: 0.004  max_mem: 11811M
[11/16 07:24:51] d2.utils.events INFO:  eta: 4:10:49  iter: 14899  total_loss: 0.2841  loss_cls: 0.1527  loss_box_reg: 0.09224  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.01978  time: 0.6818  data_time: 0.0687  lr: 0.004  max_mem: 11811M
[11/16 07:25:04] d2.utils.events INFO:  eta: 4:10:39  iter: 14919  total_loss: 0.2743  loss_cls: 0.1519  loss_box_reg: 0.09114  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01769  time: 0.6818  data_time: 0.0696  lr: 0.004  max_mem: 11811M
[11/16 07:25:18] d2.utils.events INFO:  eta: 4:10:33  iter: 14939  total_loss: 0.2877  loss_cls: 0.1556  loss_box_reg: 0.0905  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.02152  time: 0.6818  data_time: 0.0639  lr: 0.004  max_mem: 11811M
[11/16 07:25:32] d2.utils.events INFO:  eta: 4:10:10  iter: 14959  total_loss: 0.2826  loss_cls: 0.1539  loss_box_reg: 0.09489  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.01717  time: 0.6818  data_time: 0.0659  lr: 0.004  max_mem: 11811M
[11/16 07:25:45] d2.utils.events INFO:  eta: 4:10:05  iter: 14979  total_loss: 0.2841  loss_cls: 0.1488  loss_box_reg: 0.09127  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.01866  time: 0.6818  data_time: 0.0653  lr: 0.004  max_mem: 11811M
[11/16 07:25:59] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0014999.pth
[11/16 07:25:59] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/16 07:26:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/16 07:26:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/16 07:26:00] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/16 07:26:00] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/16 07:26:00] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/16 07:26:07] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0421 s/iter. Eval: 0.0002 s/iter. Total: 0.0433 s/iter. ETA=0:02:23
[11/16 07:26:12] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/16 07:26:17] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0017 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:08
[11/16 07:26:22] d2.evaluation.evaluator INFO: Inference done 369/3334. Dataloading: 0.0017 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:04
[11/16 07:26:27] d2.evaluation.evaluator INFO: Inference done 485/3334. Dataloading: 0.0016 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:00
[11/16 07:26:32] d2.evaluation.evaluator INFO: Inference done 603/3334. Dataloading: 0.0016 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:55
[11/16 07:26:37] d2.evaluation.evaluator INFO: Inference done 721/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:50
[11/16 07:26:42] d2.evaluation.evaluator INFO: Inference done 839/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:46
[11/16 07:26:47] d2.evaluation.evaluator INFO: Inference done 959/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:01:40
[11/16 07:26:52] d2.evaluation.evaluator INFO: Inference done 1075/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:35
[11/16 07:26:57] d2.evaluation.evaluator INFO: Inference done 1193/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:31
[11/16 07:27:02] d2.evaluation.evaluator INFO: Inference done 1310/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:01:26
[11/16 07:27:07] d2.evaluation.evaluator INFO: Inference done 1426/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:21
[11/16 07:27:12] d2.evaluation.evaluator INFO: Inference done 1543/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:16
[11/16 07:27:17] d2.evaluation.evaluator INFO: Inference done 1660/3334. Dataloading: 0.0015 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0427 s/iter. ETA=0:01:11
[11/16 07:27:22] d2.evaluation.evaluator INFO: Inference done 1780/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:06
[11/16 07:27:27] d2.evaluation.evaluator INFO: Inference done 1898/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:01:01
[11/16 07:27:32] d2.evaluation.evaluator INFO: Inference done 2019/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:55
[11/16 07:27:37] d2.evaluation.evaluator INFO: Inference done 2138/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:50
[11/16 07:27:42] d2.evaluation.evaluator INFO: Inference done 2260/3334. Dataloading: 0.0015 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:00:45
[11/16 07:27:47] d2.evaluation.evaluator INFO: Inference done 2377/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:40
[11/16 07:27:52] d2.evaluation.evaluator INFO: Inference done 2491/3334. Dataloading: 0.0016 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:35
[11/16 07:27:57] d2.evaluation.evaluator INFO: Inference done 2607/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:30
[11/16 07:28:02] d2.evaluation.evaluator INFO: Inference done 2723/3334. Dataloading: 0.0015 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:26
[11/16 07:28:07] d2.evaluation.evaluator INFO: Inference done 2843/3334. Dataloading: 0.0015 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0426 s/iter. ETA=0:00:20
[11/16 07:28:12] d2.evaluation.evaluator INFO: Inference done 2965/3334. Dataloading: 0.0016 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:15
[11/16 07:28:17] d2.evaluation.evaluator INFO: Inference done 3086/3334. Dataloading: 0.0016 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:10
[11/16 07:28:22] d2.evaluation.evaluator INFO: Inference done 3205/3334. Dataloading: 0.0016 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:00:05
[11/16 07:28:28] d2.evaluation.evaluator INFO: Total inference time: 0:02:21.329397 (0.042454 s / iter per device, on 6 devices)
[11/16 07:28:28] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:14 (0.040488 s / iter per device, on 6 devices)
[11/16 07:28:30] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/16 07:28:30] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/16 07:28:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/16 07:28:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/16 07:28:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.14 seconds.
[11/16 07:28:54] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/16 07:28:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.65 seconds.
[11/16 07:28:55] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.729 | 6.793  | 1.669  | 0.532 | 1.138 | 3.277 |
[11/16 07:28:55] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP    |
|:---------------------|:-------|:------------|:-------|:----------------------|:------|
| cart                 | 3.622  | person      | 3.006  | bird                  | 9.913 |
| red panda            | 1.182  | dog         | 28.609 | snake                 | 3.821 |
| car                  | 18.320 | seal        | 0.450  | helmet                | 1.574 |
| motorcycle           | 3.827  | swine       | 2.627  | stove                 | 2.857 |
| monkey               | 4.331  | watercraft  | 10.271 | chair                 | 1.251 |
| domestic cat         | 2.633  | harp        | 1.203  | antelope              | 4.370 |
| camel                | 0.193  | koala bear  | 2.471  | bus                   | 8.763 |
| hat with a wide brim | 0.229  | ski         | 0.139  | piano                 | 4.644 |
| frog                 | 2.600  | dumbbell    | 0.000  | lobster               | 1.396 |
| bench                | 0.000  | rabbit      | 4.406  | porcupine             | 3.524 |
| butterfly            | 7.489  | guitar      | 0.300  | microphone            | 0.000 |
| tape player          | 4.086  | bear        | 4.317  | hippopotamus          | 0.258 |
| bowl                 | 2.518  | axe         | 0.000  | skunk                 | 0.000 |
| airplane             | 6.568  | otter       | 0.366  | table                 | 2.001 |
| coffee maker         | 5.942  | tie         | 0.044  | turtle                | 1.567 |
| purse                | 0.680  | dragonfly   | 1.402  | lemon                 | 3.270 |
| lizard               | 1.789  | backpack    | 0.903  | tv or monitor         | 5.707 |
| cup or mug           | 0.450  | sheep       | 0.142  | ray                   | 0.730 |
| fox                  | 3.109  | whale       | 2.501  | salt or pepper shaker | 0.095 |
| computer keyboard    | 0.000  | fig         | 0.398  | bathing cap           | 0.410 |
| bookshelf            | 4.323  | ladybug     | 17.110 | crutch                | 0.000 |
| pretzel              | 1.002  | sunglasses  | 0.011  | starfish              | 2.289 |
| croquet ball         | 1.269  | lamp        | 0.399  | apple                 | 5.333 |
| cream                | 1.611  | artichoke   | 6.068  | train                 | 0.807 |
| elephant             | 2.284  | bell pepper | 1.649  | miniskirt             | 0.061 |
| orange               | 8.273  | tiger       | 0.277  | sofa                  | 0.985 |
| horse                | 1.726  | violin      | 0.132  | traffic light         | 0.328 |
| drum                 | 0.000  | strawberry  | 3.407  | laptop                | 1.628 |
| pomegranate          | 2.130  | cucumber    | 0.127  | bicycle               | 1.159 |
| banana               | 0.061  | baby bed    | 2.670  | jellyfish             | 2.804 |
| pitcher              | 0.190  | bagel       | 0.649  | beaker                | 2.544 |
| goldfish             | 1.994  | nail        | 0.000  | mushroom              | 0.374 |
| flower pot           | 0.166  | cattle      | 0.789  | zebra                 | 6.094 |
| wine bottle          | 0.950  |             |        |                       |       |
[11/16 07:28:57] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/16 07:28:57] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/16 07:28:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/16 07:28:57] d2.evaluation.testing INFO: copypaste: 2.7295,6.7929,1.6694,0.5324,1.1385,3.2769
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 08:11:45] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=True, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/17 08:11:45] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: ""
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"ene
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (28000, 34000)
  MAX_ITER: 37000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.01
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: "../../output/supervised"
[11/17 08:11:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ''
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 37000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 28000
  - 34000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/17 08:11:45] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/17 08:11:45] d2.utils.env INFO: Using a generated random seed 47354771
[11/17 08:11:46] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/17 08:11:46] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/17 08:11:46] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/17 08:11:47] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 281          |   person    | 4657         |     bird      | 4331         |
|   red panda   | 108          |     dog     | 8341         |     snake     | 1001         |
|      car      | 1171         |    seal     | 224          |    helmet     | 433          |
|  motorcycle   | 278          |    swine    | 259          |     stove     | 156          |
|    monkey     | 1004         | watercraft  | 1038         |     chair     | 905          |
| domestic cat  | 395          |    harp     | 152          |   antelope    | 288          |
|     camel     | 276          | koala bear  | 139          |      bus      | 322          |
| hat with a .. | 206          |     ski     | 109          |     piano     | 199          |
|     frog      | 245          |  dumbbell   | 180          |    lobster    | 253          |
|     bench     | 150          |   rabbit    | 235          |   porcupine   | 126          |
|   butterfly   | 453          |   guitar    | 295          |  microphone   | 259          |
|  tape player  | 109          |    bear     | 361          | hippopotamus  | 118          |
|     bowl      | 335          |     axe     | 127          |     skunk     | 99           |
|   airplane    | 217          |    otter    | 127          |     table     | 786          |
| coffee maker  | 143          |     tie     | 124          |    turtle     | 313          |
|     purse     | 130          |  dragonfly  | 175          |     lemon     | 170          |
|    lizard     | 640          |  backpack   | 148          | tv or monitor | 212          |
|  cup or mug   | 283          |    sheep    | 196          |      ray      | 198          |
|      fox      | 292          |    whale    | 155          | salt or pep.. | 129          |
| computer ke.. | 102          |     fig     | 133          |  bathing cap  | 163          |
|   bookshelf   | 106          |   ladybug   | 138          |    crutch     | 138          |
|    pretzel    | 124          | sunglasses  | 243          |   starfish    | 130          |
| croquet ball  | 135          |    lamp     | 319          |     apple     | 216          |
|     cream     | 194          |  artichoke  | 180          |     train     | 178          |
|   elephant    | 242          | bell pepper | 146          |   miniskirt   | 118          |
|    orange     | 207          |    tiger    | 159          |     sofa      | 160          |
|     horse     | 265          |   violin    | 118          | traffic light | 142          |
|     drum      | 251          | strawberry  | 232          |    laptop     | 172          |
|  pomegranate  | 188          |  cucumber   | 114          |    bicycle    | 187          |
|    banana     | 244          |  baby bed   | 185          |   jellyfish   | 184          |
|    pitcher    | 120          |    bagel    | 125          |    beaker     | 115          |
|   goldfish    | 228          |    nail     | 86           |   mushroom    | 124          |
|  flower pot   | 189          |   cattle    | 148          |     zebra     | 135          |
|  wine bottle  | 154          |             |              |               |              |
|     total     | 41293        |             |              |               |              |[0m
[11/17 08:11:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/17 08:11:47] d2.data.build INFO: Using training sampler TrainingSampler
[11/17 08:11:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 08:11:49] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/17 08:11:49] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/17 08:11:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_0014999.pth ...
[11/17 08:11:49] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/17 08:11:49] fvcore.common.checkpoint INFO: Loading trainer from ../../output/supervised/model_0014999.pth ...
[11/17 08:11:49] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/17 08:11:51] d2.engine.train_loop INFO: Starting training from iteration 15000
[11/17 08:12:13] d2.utils.events INFO:  eta: 4:07:40  iter: 15019  total_loss: 0.2592  loss_cls: 0.1402  loss_box_reg: 0.08704  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.01758  time: 0.6781  data_time: 0.4356  lr: 0.004  max_mem: 11812M
[11/17 08:12:27] d2.utils.events INFO:  eta: 4:05:49  iter: 15039  total_loss: 0.2854  loss_cls: 0.1515  loss_box_reg: 0.09175  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.01914  time: 0.6752  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 08:12:40] d2.utils.events INFO:  eta: 4:05:38  iter: 15059  total_loss: 0.2807  loss_cls: 0.1471  loss_box_reg: 0.08619  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.02071  time: 0.6730  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 08:12:54] d2.utils.events INFO:  eta: 4:05:24  iter: 15079  total_loss: 0.2679  loss_cls: 0.143  loss_box_reg: 0.08721  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.01793  time: 0.6737  data_time: 0.0709  lr: 0.004  max_mem: 11812M
[11/17 08:13:07] d2.utils.events INFO:  eta: 4:05:12  iter: 15099  total_loss: 0.272  loss_cls: 0.1474  loss_box_reg: 0.08869  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01818  time: 0.6737  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 08:13:21] d2.utils.events INFO:  eta: 4:05:21  iter: 15119  total_loss: 0.2822  loss_cls: 0.1544  loss_box_reg: 0.09232  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.01898  time: 0.6746  data_time: 0.0718  lr: 0.004  max_mem: 11812M
[11/17 08:13:34] d2.utils.events INFO:  eta: 4:06:09  iter: 15139  total_loss: 0.2813  loss_cls: 0.1553  loss_box_reg: 0.09052  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.0201  time: 0.6758  data_time: 0.0735  lr: 0.004  max_mem: 11812M
[11/17 08:13:48] d2.utils.events INFO:  eta: 4:06:48  iter: 15159  total_loss: 0.2712  loss_cls: 0.1487  loss_box_reg: 0.08947  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.01859  time: 0.6765  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 08:14:02] d2.utils.events INFO:  eta: 4:06:36  iter: 15179  total_loss: 0.2857  loss_cls: 0.154  loss_box_reg: 0.09412  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.01843  time: 0.6771  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 08:14:15] d2.utils.events INFO:  eta: 4:06:40  iter: 15199  total_loss: 0.278  loss_cls: 0.149  loss_box_reg: 0.08793  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.0188  time: 0.6776  data_time: 0.0669  lr: 0.004  max_mem: 11812M
[11/17 08:14:29] d2.utils.events INFO:  eta: 4:06:38  iter: 15219  total_loss: 0.2989  loss_cls: 0.161  loss_box_reg: 0.09488  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.02083  time: 0.6782  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 08:14:43] d2.utils.events INFO:  eta: 4:06:50  iter: 15239  total_loss: 0.2772  loss_cls: 0.1485  loss_box_reg: 0.0915  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.01676  time: 0.6791  data_time: 0.0686  lr: 0.004  max_mem: 11812M
[11/17 08:14:56] d2.utils.events INFO:  eta: 4:06:03  iter: 15259  total_loss: 0.2852  loss_cls: 0.1525  loss_box_reg: 0.09486  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.01885  time: 0.6783  data_time: 0.0652  lr: 0.004  max_mem: 11812M
[11/17 08:15:10] d2.utils.events INFO:  eta: 4:05:57  iter: 15279  total_loss: 0.2701  loss_cls: 0.1474  loss_box_reg: 0.09006  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.01885  time: 0.6793  data_time: 0.0755  lr: 0.004  max_mem: 11812M
[11/17 08:15:24] d2.utils.events INFO:  eta: 4:05:48  iter: 15299  total_loss: 0.2638  loss_cls: 0.145  loss_box_reg: 0.08577  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.01744  time: 0.6796  data_time: 0.0702  lr: 0.004  max_mem: 11812M
[11/17 08:15:37] d2.utils.events INFO:  eta: 4:05:22  iter: 15319  total_loss: 0.2753  loss_cls: 0.1474  loss_box_reg: 0.08884  loss_rpn_cls: 0.01686  loss_rpn_loc: 0.01828  time: 0.6795  data_time: 0.0708  lr: 0.004  max_mem: 11812M
[11/17 08:15:51] d2.utils.events INFO:  eta: 4:04:58  iter: 15339  total_loss: 0.2941  loss_cls: 0.1539  loss_box_reg: 0.0957  loss_rpn_cls: 0.02008  loss_rpn_loc: 0.01814  time: 0.6787  data_time: 0.0606  lr: 0.004  max_mem: 11812M
[11/17 08:16:04] d2.utils.events INFO:  eta: 4:04:45  iter: 15359  total_loss: 0.276  loss_cls: 0.1472  loss_box_reg: 0.08888  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.01863  time: 0.6787  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 08:16:18] d2.utils.events INFO:  eta: 4:04:34  iter: 15379  total_loss: 0.2798  loss_cls: 0.151  loss_box_reg: 0.0909  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.01871  time: 0.6787  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 08:16:31] d2.utils.events INFO:  eta: 4:04:23  iter: 15399  total_loss: 0.2846  loss_cls: 0.1531  loss_box_reg: 0.09056  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.01987  time: 0.6789  data_time: 0.0663  lr: 0.004  max_mem: 11812M
[11/17 08:16:45] d2.utils.events INFO:  eta: 4:04:02  iter: 15419  total_loss: 0.2793  loss_cls: 0.1541  loss_box_reg: 0.08929  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.01897  time: 0.6784  data_time: 0.0717  lr: 0.004  max_mem: 11812M
[11/17 08:16:59] d2.utils.events INFO:  eta: 4:03:56  iter: 15439  total_loss: 0.2735  loss_cls: 0.1462  loss_box_reg: 0.08767  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.01799  time: 0.6789  data_time: 0.0711  lr: 0.004  max_mem: 11812M
[11/17 08:17:12] d2.utils.events INFO:  eta: 4:03:39  iter: 15459  total_loss: 0.2884  loss_cls: 0.1568  loss_box_reg: 0.09196  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.01968  time: 0.6789  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 08:17:26] d2.utils.events INFO:  eta: 4:03:20  iter: 15479  total_loss: 0.2805  loss_cls: 0.1494  loss_box_reg: 0.08982  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.01866  time: 0.6788  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 08:17:39] d2.utils.events INFO:  eta: 4:03:07  iter: 15499  total_loss: 0.2714  loss_cls: 0.1491  loss_box_reg: 0.08798  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.01879  time: 0.6789  data_time: 0.0591  lr: 0.004  max_mem: 11812M
[11/17 08:17:53] d2.utils.events INFO:  eta: 4:02:59  iter: 15519  total_loss: 0.2696  loss_cls: 0.149  loss_box_reg: 0.08913  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.0191  time: 0.6792  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 08:18:07] d2.utils.events INFO:  eta: 4:02:54  iter: 15539  total_loss: 0.2724  loss_cls: 0.1456  loss_box_reg: 0.08878  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.01971  time: 0.6798  data_time: 0.0844  lr: 0.004  max_mem: 11812M
[11/17 08:18:20] d2.utils.events INFO:  eta: 4:02:40  iter: 15559  total_loss: 0.2725  loss_cls: 0.1439  loss_box_reg: 0.08449  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.01748  time: 0.6797  data_time: 0.0614  lr: 0.004  max_mem: 11812M
[11/17 08:18:34] d2.utils.events INFO:  eta: 4:02:25  iter: 15579  total_loss: 0.2815  loss_cls: 0.1495  loss_box_reg: 0.0898  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.01845  time: 0.6796  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 08:18:48] d2.utils.events INFO:  eta: 4:02:12  iter: 15599  total_loss: 0.2868  loss_cls: 0.1495  loss_box_reg: 0.09078  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.02012  time: 0.6794  data_time: 0.0620  lr: 0.004  max_mem: 11812M
[11/17 08:19:01] d2.utils.events INFO:  eta: 4:01:58  iter: 15619  total_loss: 0.2817  loss_cls: 0.1505  loss_box_reg: 0.09087  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.01983  time: 0.6796  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 08:19:15] d2.utils.events INFO:  eta: 4:01:45  iter: 15639  total_loss: 0.2841  loss_cls: 0.1506  loss_box_reg: 0.08995  loss_rpn_cls: 0.01784  loss_rpn_loc: 0.02035  time: 0.6797  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 08:19:29] d2.utils.events INFO:  eta: 4:01:34  iter: 15659  total_loss: 0.2784  loss_cls: 0.1512  loss_box_reg: 0.08603  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.01707  time: 0.6799  data_time: 0.0777  lr: 0.004  max_mem: 11812M
[11/17 08:19:42] d2.utils.events INFO:  eta: 4:01:18  iter: 15679  total_loss: 0.2701  loss_cls: 0.1472  loss_box_reg: 0.08887  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.01788  time: 0.6798  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 08:19:56] d2.utils.events INFO:  eta: 4:01:04  iter: 15699  total_loss: 0.2765  loss_cls: 0.15  loss_box_reg: 0.0886  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.01922  time: 0.6798  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 08:20:09] d2.utils.events INFO:  eta: 4:00:48  iter: 15719  total_loss: 0.2631  loss_cls: 0.1419  loss_box_reg: 0.08732  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.01927  time: 0.6795  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 08:20:23] d2.utils.events INFO:  eta: 4:00:32  iter: 15739  total_loss: 0.2724  loss_cls: 0.1451  loss_box_reg: 0.08904  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.02064  time: 0.6795  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 08:20:37] d2.utils.events INFO:  eta: 4:00:18  iter: 15759  total_loss: 0.2806  loss_cls: 0.1513  loss_box_reg: 0.08973  loss_rpn_cls: 0.01752  loss_rpn_loc: 0.01869  time: 0.6798  data_time: 0.0731  lr: 0.004  max_mem: 11812M
[11/17 08:20:50] d2.utils.events INFO:  eta: 4:00:06  iter: 15779  total_loss: 0.2734  loss_cls: 0.1438  loss_box_reg: 0.08961  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.01828  time: 0.6798  data_time: 0.0684  lr: 0.004  max_mem: 11812M
[11/17 08:21:03] d2.utils.events INFO:  eta: 3:59:44  iter: 15799  total_loss: 0.2646  loss_cls: 0.1428  loss_box_reg: 0.08326  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.01915  time: 0.6794  data_time: 0.0616  lr: 0.004  max_mem: 11812M
[11/17 08:21:17] d2.utils.events INFO:  eta: 3:59:29  iter: 15819  total_loss: 0.2699  loss_cls: 0.1454  loss_box_reg: 0.08637  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.01794  time: 0.6793  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 08:21:31] d2.utils.events INFO:  eta: 3:59:17  iter: 15839  total_loss: 0.2723  loss_cls: 0.1496  loss_box_reg: 0.09155  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.01814  time: 0.6793  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 08:21:44] d2.utils.events INFO:  eta: 3:59:06  iter: 15859  total_loss: 0.281  loss_cls: 0.1502  loss_box_reg: 0.09369  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.01853  time: 0.6794  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 08:21:58] d2.utils.events INFO:  eta: 3:58:57  iter: 15879  total_loss: 0.2871  loss_cls: 0.1564  loss_box_reg: 0.09391  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.01743  time: 0.6794  data_time: 0.0643  lr: 0.004  max_mem: 11812M
[11/17 08:22:12] d2.utils.events INFO:  eta: 3:58:49  iter: 15899  total_loss: 0.2907  loss_cls: 0.1553  loss_box_reg: 0.09672  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.02047  time: 0.6796  data_time: 0.0652  lr: 0.004  max_mem: 11812M
[11/17 08:22:25] d2.utils.events INFO:  eta: 3:58:36  iter: 15919  total_loss: 0.2741  loss_cls: 0.1521  loss_box_reg: 0.08879  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.01695  time: 0.6796  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 08:22:39] d2.utils.events INFO:  eta: 3:58:25  iter: 15939  total_loss: 0.2688  loss_cls: 0.1434  loss_box_reg: 0.08905  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.01966  time: 0.6796  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 08:22:52] d2.utils.events INFO:  eta: 3:58:09  iter: 15959  total_loss: 0.2814  loss_cls: 0.1513  loss_box_reg: 0.09068  loss_rpn_cls: 0.01693  loss_rpn_loc: 0.01759  time: 0.6795  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 08:23:06] d2.utils.events INFO:  eta: 3:57:55  iter: 15979  total_loss: 0.2866  loss_cls: 0.1544  loss_box_reg: 0.09021  loss_rpn_cls: 0.01711  loss_rpn_loc: 0.01777  time: 0.6795  data_time: 0.0679  lr: 0.004  max_mem: 11812M
[11/17 08:23:20] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0015999.pth
[11/17 08:23:20] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 08:23:21] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 211          |   person    | 3096         |     bird      | 2810         |
|   red panda   | 61           |     dog     | 5631         |     snake     | 664          |
|      car      | 768          |    seal     | 120          |    helmet     | 237          |
|  motorcycle   | 224          |    swine    | 159          |     stove     | 110          |
|    monkey     | 683          | watercraft  | 686          |     chair     | 578          |
| domestic cat  | 290          |    harp     | 118          |   antelope    | 173          |
|     camel     | 138          | koala bear  | 71           |      bus      | 257          |
| hat with a .. | 160          |     ski     | 104          |     piano     | 128          |
|     frog      | 164          |  dumbbell   | 104          |    lobster    | 151          |
|     bench     | 107          |   rabbit    | 159          |   porcupine   | 73           |
|   butterfly   | 302          |   guitar    | 189          |  microphone   | 174          |
|  tape player  | 81           |    bear     | 205          | hippopotamus  | 82           |
|     bowl      | 202          |     axe     | 107          |     skunk     | 88           |
|   airplane    | 128          |    otter    | 74           |     table     | 496          |
| coffee maker  | 94           |     tie     | 91           |    turtle     | 206          |
|     purse     | 124          |  dragonfly  | 119          |     lemon     | 95           |
|    lizard     | 420          |  backpack   | 110          | tv or monitor | 165          |
|  cup or mug   | 200          |    sheep    | 149          |      ray      | 192          |
|      fox      | 195          |    whale    | 113          | salt or pep.. | 68           |
| computer ke.. | 66           |     fig     | 92           |  bathing cap  | 153          |
|   bookshelf   | 68           |   ladybug   | 85           |    crutch     | 75           |
|    pretzel    | 108          | sunglasses  | 145          |   starfish    | 92           |
| croquet ball  | 85           |    lamp     | 190          |     apple     | 145          |
|     cream     | 120          |  artichoke  | 96           |     train     | 89           |
|   elephant    | 159          | bell pepper | 98           |   miniskirt   | 73           |
|    orange     | 151          |    tiger    | 76           |     sofa      | 127          |
|     horse     | 171          |   violin    | 84           | traffic light | 109          |
|     drum      | 175          | strawberry  | 162          |    laptop     | 84           |
|  pomegranate  | 114          |  cucumber   | 67           |    bicycle    | 132          |
|    banana     | 169          |  baby bed   | 134          |   jellyfish   | 103          |
|    pitcher    | 95           |    bagel    | 76           |    beaker     | 85           |
|   goldfish    | 159          |    nail     | 91           |   mushroom    | 146          |
|  flower pot   | 113          |   cattle    | 92           |     zebra     | 97           |
|  wine bottle  | 129          |             |              |               |              |
|     total     | 27584        |             |              |               |              |[0m
[11/17 08:23:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 08:23:21] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 08:23:21] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 08:23:21] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 08:23:21] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 08:23:28] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0442 s/iter. ETA=0:02:26
[11/17 08:23:33] d2.evaluation.evaluator INFO: Inference done 136/3334. Dataloading: 0.0015 s/iter. Inference: 0.0384 s/iter. Eval: 0.0002 s/iter. Total: 0.0402 s/iter. ETA=0:02:08
[11/17 08:23:38] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:04
[11/17 08:23:43] d2.evaluation.evaluator INFO: Inference done 384/3334. Dataloading: 0.0017 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:01:58
[11/17 08:23:48] d2.evaluation.evaluator INFO: Inference done 506/3334. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/17 08:23:53] d2.evaluation.evaluator INFO: Inference done 630/3334. Dataloading: 0.0017 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:49
[11/17 08:23:58] d2.evaluation.evaluator INFO: Inference done 753/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:44
[11/17 08:24:03] d2.evaluation.evaluator INFO: Inference done 877/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:39
[11/17 08:24:08] d2.evaluation.evaluator INFO: Inference done 998/3334. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:34
[11/17 08:24:13] d2.evaluation.evaluator INFO: Inference done 1121/3334. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:29
[11/17 08:24:18] d2.evaluation.evaluator INFO: Inference done 1243/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:25
[11/17 08:24:23] d2.evaluation.evaluator INFO: Inference done 1368/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:19
[11/17 08:24:28] d2.evaluation.evaluator INFO: Inference done 1490/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:15
[11/17 08:24:33] d2.evaluation.evaluator INFO: Inference done 1612/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:10
[11/17 08:24:38] d2.evaluation.evaluator INFO: Inference done 1735/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:05
[11/17 08:24:43] d2.evaluation.evaluator INFO: Inference done 1860/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:59
[11/17 08:24:48] d2.evaluation.evaluator INFO: Inference done 1981/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:55
[11/17 08:24:53] d2.evaluation.evaluator INFO: Inference done 2108/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:49
[11/17 08:24:58] d2.evaluation.evaluator INFO: Inference done 2228/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:45
[11/17 08:25:03] d2.evaluation.evaluator INFO: Inference done 2351/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:40
[11/17 08:25:08] d2.evaluation.evaluator INFO: Inference done 2473/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/17 08:25:14] d2.evaluation.evaluator INFO: Inference done 2598/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/17 08:25:19] d2.evaluation.evaluator INFO: Inference done 2719/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:25
[11/17 08:25:24] d2.evaluation.evaluator INFO: Inference done 2843/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:20
[11/17 08:25:29] d2.evaluation.evaluator INFO: Inference done 2967/3334. Dataloading: 0.0017 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:14
[11/17 08:25:34] d2.evaluation.evaluator INFO: Inference done 3090/3334. Dataloading: 0.0017 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:09
[11/17 08:25:39] d2.evaluation.evaluator INFO: Inference done 3212/3334. Dataloading: 0.0017 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:04
[11/17 08:25:44] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.059625 (0.040871 s / iter per device, on 6 devices)
[11/17 08:25:44] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038793 s / iter per device, on 6 devices)
[11/17 08:25:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 08:25:47] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 08:25:48] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 08:25:49] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 08:26:13] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.14 seconds.
[11/17 08:26:13] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 08:26:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.86 seconds.
[11/17 08:26:15] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.963 | 7.394  | 1.762  | 0.575 | 1.415 | 3.456 |
[11/17 08:26:15] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 3.652  | person      | 3.547  | bird                  | 10.537 |
| red panda            | 1.816  | dog         | 31.167 | snake                 | 4.034  |
| car                  | 17.151 | seal        | 0.522  | helmet                | 3.185  |
| motorcycle           | 3.657  | swine       | 3.466  | stove                 | 4.264  |
| monkey               | 4.431  | watercraft  | 8.749  | chair                 | 2.193  |
| domestic cat         | 2.350  | harp        | 1.536  | antelope              | 5.669  |
| camel                | 0.240  | koala bear  | 2.944  | bus                   | 8.413  |
| hat with a wide brim | 0.543  | ski         | 0.000  | piano                 | 5.760  |
| frog                 | 3.910  | dumbbell    | 0.000  | lobster               | 1.381  |
| bench                | 0.000  | rabbit      | 3.991  | porcupine             | 3.553  |
| butterfly            | 8.992  | guitar      | 0.738  | microphone            | 0.000  |
| tape player          | 5.450  | bear        | 3.850  | hippopotamus          | 0.040  |
| bowl                 | 3.205  | axe         | 0.000  | skunk                 | 0.075  |
| airplane             | 7.545  | otter       | 0.485  | table                 | 1.770  |
| coffee maker         | 8.237  | tie         | 0.005  | turtle                | 1.308  |
| purse                | 2.321  | dragonfly   | 1.448  | lemon                 | 1.682  |
| lizard               | 1.994  | backpack    | 1.474  | tv or monitor         | 5.891  |
| cup or mug           | 0.859  | sheep       | 0.939  | ray                   | 0.551  |
| fox                  | 2.324  | whale       | 2.924  | salt or pepper shaker | 0.170  |
| computer keyboard    | 0.110  | fig         | 0.151  | bathing cap           | 0.347  |
| bookshelf            | 5.403  | ladybug     | 16.200 | crutch                | 0.018  |
| pretzel              | 1.107  | sunglasses  | 0.083  | starfish              | 3.067  |
| croquet ball         | 1.678  | lamp        | 0.319  | apple                 | 5.387  |
| cream                | 2.377  | artichoke   | 1.870  | train                 | 1.370  |
| elephant             | 3.729  | bell pepper | 1.334  | miniskirt             | 0.092  |
| orange               | 6.887  | tiger       | 0.394  | sofa                  | 0.887  |
| horse                | 1.734  | violin      | 0.188  | traffic light         | 0.613  |
| drum                 | 0.043  | strawberry  | 4.145  | laptop                | 2.307  |
| pomegranate          | 2.453  | cucumber    | 0.114  | bicycle               | 2.062  |
| banana               | 0.051  | baby bed    | 3.971  | jellyfish             | 1.826  |
| pitcher              | 0.185  | bagel       | 1.658  | beaker                | 3.248  |
| goldfish             | 2.877  | nail        | 0.000  | mushroom              | 0.504  |
| flower pot           | 0.187  | cattle      | 0.880  | zebra                 | 6.945  |
| wine bottle          | 0.566  |             |        |                       |        |
[11/17 08:26:17] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 08:26:17] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 08:26:17] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 08:26:17] d2.evaluation.testing INFO: copypaste: 2.9631,7.3943,1.7622,0.5752,1.4151,3.4560
[11/17 08:26:17] d2.utils.events INFO:  eta: 3:57:39  iter: 15999  total_loss: 0.2667  loss_cls: 0.1474  loss_box_reg: 0.08839  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.01849  time: 0.6795  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 08:26:31] d2.utils.events INFO:  eta: 3:57:25  iter: 16019  total_loss: 0.2862  loss_cls: 0.1608  loss_box_reg: 0.09235  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.01892  time: 0.6796  data_time: 0.0721  lr: 0.004  max_mem: 11812M
[11/17 08:26:45] d2.utils.events INFO:  eta: 3:57:17  iter: 16039  total_loss: 0.271  loss_cls: 0.1494  loss_box_reg: 0.08724  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.0179  time: 0.6799  data_time: 0.0675  lr: 0.004  max_mem: 11812M
[11/17 08:26:59] d2.utils.events INFO:  eta: 3:57:08  iter: 16059  total_loss: 0.2716  loss_cls: 0.1515  loss_box_reg: 0.08692  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.01923  time: 0.6800  data_time: 0.0765  lr: 0.004  max_mem: 11812M
[11/17 08:27:12] d2.utils.events INFO:  eta: 3:57:01  iter: 16079  total_loss: 0.2873  loss_cls: 0.1603  loss_box_reg: 0.08923  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.01896  time: 0.6801  data_time: 0.0711  lr: 0.004  max_mem: 11812M
[11/17 08:27:26] d2.utils.events INFO:  eta: 3:56:51  iter: 16099  total_loss: 0.2611  loss_cls: 0.141  loss_box_reg: 0.0869  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.01962  time: 0.6801  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 08:27:40] d2.utils.events INFO:  eta: 3:56:38  iter: 16119  total_loss: 0.2932  loss_cls: 0.157  loss_box_reg: 0.09276  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.01939  time: 0.6801  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 08:27:53] d2.utils.events INFO:  eta: 3:56:20  iter: 16139  total_loss: 0.2753  loss_cls: 0.1491  loss_box_reg: 0.08892  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.01717  time: 0.6800  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 08:28:07] d2.utils.events INFO:  eta: 3:56:10  iter: 16159  total_loss: 0.2793  loss_cls: 0.1507  loss_box_reg: 0.09344  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.01899  time: 0.6802  data_time: 0.0707  lr: 0.004  max_mem: 11812M
[11/17 08:28:21] d2.utils.events INFO:  eta: 3:55:56  iter: 16179  total_loss: 0.2672  loss_cls: 0.1448  loss_box_reg: 0.08584  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.0193  time: 0.6803  data_time: 0.0756  lr: 0.004  max_mem: 11812M
[11/17 08:28:34] d2.utils.events INFO:  eta: 3:55:37  iter: 16199  total_loss: 0.2789  loss_cls: 0.1531  loss_box_reg: 0.09109  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.0175  time: 0.6803  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 08:28:48] d2.utils.events INFO:  eta: 3:55:15  iter: 16219  total_loss: 0.276  loss_cls: 0.1506  loss_box_reg: 0.09131  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.01795  time: 0.6803  data_time: 0.0728  lr: 0.004  max_mem: 11812M
[11/17 08:29:01] d2.utils.events INFO:  eta: 3:55:00  iter: 16239  total_loss: 0.2644  loss_cls: 0.1419  loss_box_reg: 0.0888  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.0182  time: 0.6802  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 08:29:15] d2.utils.events INFO:  eta: 3:54:48  iter: 16259  total_loss: 0.2691  loss_cls: 0.1456  loss_box_reg: 0.08823  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.01788  time: 0.6802  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 08:29:29] d2.utils.events INFO:  eta: 3:54:34  iter: 16279  total_loss: 0.2793  loss_cls: 0.1511  loss_box_reg: 0.0903  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.01789  time: 0.6802  data_time: 0.0627  lr: 0.004  max_mem: 11812M
[11/17 08:29:42] d2.utils.events INFO:  eta: 3:54:19  iter: 16299  total_loss: 0.2774  loss_cls: 0.1493  loss_box_reg: 0.08979  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.01793  time: 0.6802  data_time: 0.0705  lr: 0.004  max_mem: 11812M
[11/17 08:29:56] d2.utils.events INFO:  eta: 3:54:07  iter: 16319  total_loss: 0.2729  loss_cls: 0.146  loss_box_reg: 0.09068  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.01825  time: 0.6803  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 08:30:10] d2.utils.events INFO:  eta: 3:53:56  iter: 16339  total_loss: 0.266  loss_cls: 0.1462  loss_box_reg: 0.09185  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.01789  time: 0.6803  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 08:30:24] d2.utils.events INFO:  eta: 3:53:54  iter: 16359  total_loss: 0.2829  loss_cls: 0.1498  loss_box_reg: 0.08984  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.01953  time: 0.6805  data_time: 0.0701  lr: 0.004  max_mem: 11812M
[11/17 08:30:37] d2.utils.events INFO:  eta: 3:53:41  iter: 16379  total_loss: 0.2537  loss_cls: 0.139  loss_box_reg: 0.08249  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.01739  time: 0.6807  data_time: 0.0733  lr: 0.004  max_mem: 11812M
[11/17 08:30:51] d2.utils.events INFO:  eta: 3:53:30  iter: 16399  total_loss: 0.2919  loss_cls: 0.1578  loss_box_reg: 0.09556  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.01872  time: 0.6809  data_time: 0.0808  lr: 0.004  max_mem: 11812M
[11/17 08:31:05] d2.utils.events INFO:  eta: 3:53:17  iter: 16419  total_loss: 0.2826  loss_cls: 0.1526  loss_box_reg: 0.09252  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.0182  time: 0.6811  data_time: 0.0809  lr: 0.004  max_mem: 11812M
[11/17 08:31:19] d2.utils.events INFO:  eta: 3:53:02  iter: 16439  total_loss: 0.2708  loss_cls: 0.1447  loss_box_reg: 0.08618  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.01956  time: 0.6811  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 08:31:32] d2.utils.events INFO:  eta: 3:52:49  iter: 16459  total_loss: 0.2783  loss_cls: 0.1485  loss_box_reg: 0.09084  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.01953  time: 0.6811  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 08:31:46] d2.utils.events INFO:  eta: 3:52:35  iter: 16479  total_loss: 0.2792  loss_cls: 0.154  loss_box_reg: 0.08862  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01876  time: 0.6810  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 08:32:00] d2.utils.events INFO:  eta: 3:52:25  iter: 16499  total_loss: 0.2703  loss_cls: 0.146  loss_box_reg: 0.08883  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.0181  time: 0.6811  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 08:32:13] d2.utils.events INFO:  eta: 3:52:08  iter: 16519  total_loss: 0.2713  loss_cls: 0.144  loss_box_reg: 0.08926  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.01746  time: 0.6810  data_time: 0.0594  lr: 0.004  max_mem: 11812M
[11/17 08:32:27] d2.utils.events INFO:  eta: 3:51:54  iter: 16539  total_loss: 0.2695  loss_cls: 0.1462  loss_box_reg: 0.08834  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.01834  time: 0.6811  data_time: 0.0762  lr: 0.004  max_mem: 11812M
[11/17 08:32:41] d2.utils.events INFO:  eta: 3:51:47  iter: 16559  total_loss: 0.285  loss_cls: 0.1488  loss_box_reg: 0.09053  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.01985  time: 0.6812  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 08:32:54] d2.utils.events INFO:  eta: 3:51:40  iter: 16579  total_loss: 0.2837  loss_cls: 0.1519  loss_box_reg: 0.09169  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.01914  time: 0.6813  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 08:33:08] d2.utils.events INFO:  eta: 3:51:28  iter: 16599  total_loss: 0.2731  loss_cls: 0.1465  loss_box_reg: 0.09025  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.01817  time: 0.6813  data_time: 0.0758  lr: 0.004  max_mem: 11812M
[11/17 08:33:22] d2.utils.events INFO:  eta: 3:51:10  iter: 16619  total_loss: 0.2896  loss_cls: 0.1525  loss_box_reg: 0.09663  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.01903  time: 0.6812  data_time: 0.0588  lr: 0.004  max_mem: 11812M
[11/17 08:33:35] d2.utils.events INFO:  eta: 3:50:57  iter: 16639  total_loss: 0.2732  loss_cls: 0.1473  loss_box_reg: 0.09053  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.01947  time: 0.6811  data_time: 0.0602  lr: 0.004  max_mem: 11812M
[11/17 08:33:49] d2.utils.events INFO:  eta: 3:50:42  iter: 16659  total_loss: 0.2886  loss_cls: 0.1608  loss_box_reg: 0.09618  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.01939  time: 0.6811  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 08:34:02] d2.utils.events INFO:  eta: 3:50:28  iter: 16679  total_loss: 0.2658  loss_cls: 0.1394  loss_box_reg: 0.08914  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.01885  time: 0.6811  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 08:34:16] d2.utils.events INFO:  eta: 3:50:15  iter: 16699  total_loss: 0.2682  loss_cls: 0.1461  loss_box_reg: 0.08843  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.01715  time: 0.6811  data_time: 0.0643  lr: 0.004  max_mem: 11812M
[11/17 08:34:29] d2.utils.events INFO:  eta: 3:50:02  iter: 16719  total_loss: 0.2837  loss_cls: 0.1533  loss_box_reg: 0.08905  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.02009  time: 0.6811  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 08:34:43] d2.utils.events INFO:  eta: 3:49:50  iter: 16739  total_loss: 0.277  loss_cls: 0.1482  loss_box_reg: 0.08971  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.01783  time: 0.6810  data_time: 0.0657  lr: 0.004  max_mem: 11812M
[11/17 08:34:57] d2.utils.events INFO:  eta: 3:49:40  iter: 16759  total_loss: 0.2821  loss_cls: 0.1503  loss_box_reg: 0.09185  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.01746  time: 0.6810  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 08:35:10] d2.utils.events INFO:  eta: 3:49:21  iter: 16779  total_loss: 0.2641  loss_cls: 0.146  loss_box_reg: 0.08633  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.01907  time: 0.6810  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 08:35:24] d2.utils.events INFO:  eta: 3:49:19  iter: 16799  total_loss: 0.2632  loss_cls: 0.1401  loss_box_reg: 0.08579  loss_rpn_cls: 0.01796  loss_rpn_loc: 0.01739  time: 0.6810  data_time: 0.0752  lr: 0.004  max_mem: 11812M
[11/17 08:35:38] d2.utils.events INFO:  eta: 3:49:06  iter: 16819  total_loss: 0.2663  loss_cls: 0.1479  loss_box_reg: 0.08705  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.01587  time: 0.6810  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 08:35:51] d2.utils.events INFO:  eta: 3:48:57  iter: 16839  total_loss: 0.2595  loss_cls: 0.1387  loss_box_reg: 0.08334  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.01881  time: 0.6810  data_time: 0.0719  lr: 0.004  max_mem: 11812M
[11/17 08:36:05] d2.utils.events INFO:  eta: 3:48:45  iter: 16859  total_loss: 0.2687  loss_cls: 0.1431  loss_box_reg: 0.08961  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.01863  time: 0.6811  data_time: 0.0681  lr: 0.004  max_mem: 11812M
[11/17 08:36:18] d2.utils.events INFO:  eta: 3:48:26  iter: 16879  total_loss: 0.271  loss_cls: 0.1459  loss_box_reg: 0.08917  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.01964  time: 0.6811  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 08:36:32] d2.utils.events INFO:  eta: 3:48:04  iter: 16899  total_loss: 0.2741  loss_cls: 0.1469  loss_box_reg: 0.08577  loss_rpn_cls: 0.0168  loss_rpn_loc: 0.01894  time: 0.6810  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 08:36:46] d2.utils.events INFO:  eta: 3:47:48  iter: 16919  total_loss: 0.2691  loss_cls: 0.1401  loss_box_reg: 0.08797  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.01834  time: 0.6809  data_time: 0.0599  lr: 0.004  max_mem: 11812M
[11/17 08:36:59] d2.utils.events INFO:  eta: 3:47:37  iter: 16939  total_loss: 0.2823  loss_cls: 0.1538  loss_box_reg: 0.08955  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.01703  time: 0.6809  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 08:37:13] d2.utils.events INFO:  eta: 3:47:31  iter: 16959  total_loss: 0.284  loss_cls: 0.1561  loss_box_reg: 0.09275  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.01976  time: 0.6810  data_time: 0.0753  lr: 0.004  max_mem: 11812M
[11/17 08:37:27] d2.utils.events INFO:  eta: 3:47:18  iter: 16979  total_loss: 0.2745  loss_cls: 0.1532  loss_box_reg: 0.08991  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.01658  time: 0.6810  data_time: 0.0691  lr: 0.004  max_mem: 11812M
[11/17 08:37:40] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0016999.pth
[11/17 08:37:40] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 08:37:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 08:37:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 08:37:41] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 08:37:41] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 08:37:41] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 08:37:48] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:19
[11/17 08:37:53] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/17 08:37:58] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0003 s/iter. Total: 0.0412 s/iter. ETA=0:02:06
[11/17 08:38:03] d2.evaluation.evaluator INFO: Inference done 378/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/17 08:38:08] d2.evaluation.evaluator INFO: Inference done 502/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/17 08:38:13] d2.evaluation.evaluator INFO: Inference done 626/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:50
[11/17 08:38:18] d2.evaluation.evaluator INFO: Inference done 751/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:45
[11/17 08:38:23] d2.evaluation.evaluator INFO: Inference done 872/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/17 08:38:28] d2.evaluation.evaluator INFO: Inference done 992/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/17 08:38:33] d2.evaluation.evaluator INFO: Inference done 1114/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:30
[11/17 08:38:38] d2.evaluation.evaluator INFO: Inference done 1237/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:25
[11/17 08:38:43] d2.evaluation.evaluator INFO: Inference done 1360/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/17 08:38:48] d2.evaluation.evaluator INFO: Inference done 1486/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/17 08:38:53] d2.evaluation.evaluator INFO: Inference done 1607/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/17 08:38:58] d2.evaluation.evaluator INFO: Inference done 1725/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:05
[11/17 08:39:03] d2.evaluation.evaluator INFO: Inference done 1846/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:01
[11/17 08:39:08] d2.evaluation.evaluator INFO: Inference done 1966/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/17 08:39:13] d2.evaluation.evaluator INFO: Inference done 2089/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/17 08:39:18] d2.evaluation.evaluator INFO: Inference done 2213/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:46
[11/17 08:39:23] d2.evaluation.evaluator INFO: Inference done 2332/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/17 08:39:28] d2.evaluation.evaluator INFO: Inference done 2453/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/17 08:39:33] d2.evaluation.evaluator INFO: Inference done 2576/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/17 08:39:38] d2.evaluation.evaluator INFO: Inference done 2698/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:26
[11/17 08:39:44] d2.evaluation.evaluator INFO: Inference done 2818/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/17 08:39:49] d2.evaluation.evaluator INFO: Inference done 2941/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/17 08:39:54] d2.evaluation.evaluator INFO: Inference done 3062/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/17 08:39:59] d2.evaluation.evaluator INFO: Inference done 3184/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/17 08:40:04] d2.evaluation.evaluator INFO: Inference done 3307/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:01
[11/17 08:40:05] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.109763 (0.041186 s / iter per device, on 6 devices)
[11/17 08:40:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039205 s / iter per device, on 6 devices)
[11/17 08:40:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 08:40:07] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 08:40:08] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 08:40:08] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 08:40:30] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.93 seconds.
[11/17 08:40:30] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 08:40:32] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.71 seconds.
[11/17 08:40:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.163 | 7.564  | 2.097  | 0.607 | 1.503 | 3.675 |
[11/17 08:40:32] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 4.120  | person      | 3.495  | bird                  | 11.421 |
| red panda            | 0.804  | dog         | 31.600 | snake                 | 4.073  |
| car                  | 18.486 | seal        | 0.717  | helmet                | 2.780  |
| motorcycle           | 4.233  | swine       | 3.783  | stove                 | 4.303  |
| monkey               | 4.329  | watercraft  | 11.429 | chair                 | 1.792  |
| domestic cat         | 2.344  | harp        | 1.030  | antelope              | 5.186  |
| camel                | 0.181  | koala bear  | 2.201  | bus                   | 10.894 |
| hat with a wide brim | 0.584  | ski         | 0.030  | piano                 | 6.035  |
| frog                 | 2.706  | dumbbell    | 0.000  | lobster               | 1.452  |
| bench                | 0.000  | rabbit      | 5.963  | porcupine             | 5.808  |
| butterfly            | 9.530  | guitar      | 0.533  | microphone            | 0.000  |
| tape player          | 4.773  | bear        | 4.092  | hippopotamus          | 0.106  |
| bowl                 | 1.632  | axe         | 0.000  | skunk                 | 0.068  |
| airplane             | 8.418  | otter       | 0.750  | table                 | 2.151  |
| coffee maker         | 8.318  | tie         | 0.000  | turtle                | 1.949  |
| purse                | 2.156  | dragonfly   | 1.174  | lemon                 | 3.766  |
| lizard               | 2.204  | backpack    | 2.034  | tv or monitor         | 7.520  |
| cup or mug           | 0.948  | sheep       | 0.994  | ray                   | 0.516  |
| fox                  | 1.643  | whale       | 2.486  | salt or pepper shaker | 0.010  |
| computer keyboard    | 0.126  | fig         | 0.274  | bathing cap           | 0.456  |
| bookshelf            | 5.695  | ladybug     | 16.062 | crutch                | 0.000  |
| pretzel              | 1.321  | sunglasses  | 0.004  | starfish              | 3.443  |
| croquet ball         | 1.692  | lamp        | 0.891  | apple                 | 8.579  |
| cream                | 3.040  | artichoke   | 4.990  | train                 | 1.590  |
| elephant             | 4.687  | bell pepper | 2.161  | miniskirt             | 0.250  |
| orange               | 5.468  | tiger       | 0.748  | sofa                  | 0.976  |
| horse                | 2.125  | violin      | 0.123  | traffic light         | 0.724  |
| drum                 | 0.041  | strawberry  | 2.276  | laptop                | 3.000  |
| pomegranate          | 0.920  | cucumber    | 0.349  | bicycle               | 1.413  |
| banana               | 0.087  | baby bed    | 3.827  | jellyfish             | 2.415  |
| pitcher              | 0.176  | bagel       | 1.306  | beaker                | 3.220  |
| goldfish             | 1.314  | nail        | 0.000  | mushroom              | 0.540  |
| flower pot           | 0.109  | cattle      | 1.203  | zebra                 | 8.027  |
| wine bottle          | 1.108  |             |        |                       |        |
[11/17 08:40:34] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 08:40:34] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 08:40:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 08:40:34] d2.evaluation.testing INFO: copypaste: 3.1630,7.5640,2.0972,0.6070,1.5032,3.6748
[11/17 08:40:34] d2.utils.events INFO:  eta: 3:47:04  iter: 16999  total_loss: 0.2802  loss_cls: 0.1511  loss_box_reg: 0.09084  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.01762  time: 0.6810  data_time: 0.0618  lr: 0.004  max_mem: 11812M
[11/17 08:40:48] d2.utils.events INFO:  eta: 3:46:51  iter: 17019  total_loss: 0.2691  loss_cls: 0.1469  loss_box_reg: 0.08749  loss_rpn_cls: 0.016  loss_rpn_loc: 0.01897  time: 0.6810  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 08:41:02] d2.utils.events INFO:  eta: 3:46:26  iter: 17039  total_loss: 0.2862  loss_cls: 0.1527  loss_box_reg: 0.09354  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.01846  time: 0.6809  data_time: 0.0612  lr: 0.004  max_mem: 11812M
[11/17 08:41:15] d2.utils.events INFO:  eta: 3:46:13  iter: 17059  total_loss: 0.2756  loss_cls: 0.1489  loss_box_reg: 0.0913  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01805  time: 0.6810  data_time: 0.0712  lr: 0.004  max_mem: 11812M
[11/17 08:41:29] d2.utils.events INFO:  eta: 3:46:02  iter: 17079  total_loss: 0.2702  loss_cls: 0.142  loss_box_reg: 0.08976  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.01813  time: 0.6810  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 08:41:43] d2.utils.events INFO:  eta: 3:45:48  iter: 17099  total_loss: 0.2817  loss_cls: 0.146  loss_box_reg: 0.08976  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.01984  time: 0.6810  data_time: 0.0734  lr: 0.004  max_mem: 11812M
[11/17 08:41:56] d2.utils.events INFO:  eta: 3:45:30  iter: 17119  total_loss: 0.275  loss_cls: 0.1472  loss_box_reg: 0.08724  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.01863  time: 0.6810  data_time: 0.0631  lr: 0.004  max_mem: 11812M
[11/17 08:42:10] d2.utils.events INFO:  eta: 3:45:28  iter: 17139  total_loss: 0.2756  loss_cls: 0.1493  loss_box_reg: 0.08686  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.01978  time: 0.6810  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 08:42:24] d2.utils.events INFO:  eta: 3:45:08  iter: 17159  total_loss: 0.2768  loss_cls: 0.1544  loss_box_reg: 0.09375  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.01796  time: 0.6810  data_time: 0.0591  lr: 0.004  max_mem: 11812M
[11/17 08:42:37] d2.utils.events INFO:  eta: 3:44:51  iter: 17179  total_loss: 0.2641  loss_cls: 0.1482  loss_box_reg: 0.08716  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.0169  time: 0.6810  data_time: 0.0675  lr: 0.004  max_mem: 11812M
[11/17 08:42:51] d2.utils.events INFO:  eta: 3:44:51  iter: 17199  total_loss: 0.2605  loss_cls: 0.1402  loss_box_reg: 0.08898  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.0184  time: 0.6811  data_time: 0.0756  lr: 0.004  max_mem: 11812M
[11/17 08:43:05] d2.utils.events INFO:  eta: 3:44:40  iter: 17219  total_loss: 0.2774  loss_cls: 0.1504  loss_box_reg: 0.09049  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.0167  time: 0.6811  data_time: 0.0707  lr: 0.004  max_mem: 11812M
[11/17 08:43:18] d2.utils.events INFO:  eta: 3:44:39  iter: 17239  total_loss: 0.2752  loss_cls: 0.1458  loss_box_reg: 0.09105  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.01913  time: 0.6812  data_time: 0.0829  lr: 0.004  max_mem: 11812M
[11/17 08:43:32] d2.utils.events INFO:  eta: 3:44:27  iter: 17259  total_loss: 0.2739  loss_cls: 0.1446  loss_box_reg: 0.08901  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.01866  time: 0.6812  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 08:43:46] d2.utils.events INFO:  eta: 3:44:12  iter: 17279  total_loss: 0.2816  loss_cls: 0.1508  loss_box_reg: 0.09074  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.01897  time: 0.6811  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 08:43:59] d2.utils.events INFO:  eta: 3:43:56  iter: 17299  total_loss: 0.2638  loss_cls: 0.144  loss_box_reg: 0.0869  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01708  time: 0.6811  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 08:44:13] d2.utils.events INFO:  eta: 3:43:34  iter: 17319  total_loss: 0.2665  loss_cls: 0.147  loss_box_reg: 0.08716  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.01885  time: 0.6811  data_time: 0.0706  lr: 0.004  max_mem: 11812M
[11/17 08:44:26] d2.utils.events INFO:  eta: 3:43:19  iter: 17339  total_loss: 0.2747  loss_cls: 0.1519  loss_box_reg: 0.08792  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.01988  time: 0.6810  data_time: 0.0644  lr: 0.004  max_mem: 11812M
[11/17 08:44:40] d2.utils.events INFO:  eta: 3:43:00  iter: 17359  total_loss: 0.2741  loss_cls: 0.1488  loss_box_reg: 0.0907  loss_rpn_cls: 0.0168  loss_rpn_loc: 0.01881  time: 0.6811  data_time: 0.0734  lr: 0.004  max_mem: 11812M
[11/17 08:44:54] d2.utils.events INFO:  eta: 3:42:46  iter: 17379  total_loss: 0.2728  loss_cls: 0.1467  loss_box_reg: 0.09316  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.01753  time: 0.6811  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 08:45:07] d2.utils.events INFO:  eta: 3:42:32  iter: 17399  total_loss: 0.2785  loss_cls: 0.1507  loss_box_reg: 0.08968  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.01787  time: 0.6811  data_time: 0.0696  lr: 0.004  max_mem: 11812M
[11/17 08:45:21] d2.utils.events INFO:  eta: 3:42:14  iter: 17419  total_loss: 0.2734  loss_cls: 0.1498  loss_box_reg: 0.09011  loss_rpn_cls: 0.01581  loss_rpn_loc: 0.01862  time: 0.6811  data_time: 0.0669  lr: 0.004  max_mem: 11812M
[11/17 08:45:34] d2.utils.events INFO:  eta: 3:41:54  iter: 17439  total_loss: 0.2645  loss_cls: 0.1391  loss_box_reg: 0.08814  loss_rpn_cls: 0.02088  loss_rpn_loc: 0.01909  time: 0.6810  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 08:45:48] d2.utils.events INFO:  eta: 3:41:47  iter: 17459  total_loss: 0.2845  loss_cls: 0.1565  loss_box_reg: 0.09301  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.01841  time: 0.6810  data_time: 0.0648  lr: 0.004  max_mem: 11812M
[11/17 08:46:02] d2.utils.events INFO:  eta: 3:41:38  iter: 17479  total_loss: 0.2643  loss_cls: 0.1444  loss_box_reg: 0.08746  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.01763  time: 0.6811  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 08:46:15] d2.utils.events INFO:  eta: 3:41:24  iter: 17499  total_loss: 0.2813  loss_cls: 0.1497  loss_box_reg: 0.08961  loss_rpn_cls: 0.01834  loss_rpn_loc: 0.0173  time: 0.6811  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 08:46:29] d2.utils.events INFO:  eta: 3:41:11  iter: 17519  total_loss: 0.2729  loss_cls: 0.1491  loss_box_reg: 0.08996  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.01923  time: 0.6811  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 08:46:43] d2.utils.events INFO:  eta: 3:40:57  iter: 17539  total_loss: 0.2829  loss_cls: 0.1528  loss_box_reg: 0.09009  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.01992  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 08:46:56] d2.utils.events INFO:  eta: 3:40:39  iter: 17559  total_loss: 0.2664  loss_cls: 0.1459  loss_box_reg: 0.08691  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.01759  time: 0.6811  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 08:47:10] d2.utils.events INFO:  eta: 3:40:20  iter: 17579  total_loss: 0.2851  loss_cls: 0.1559  loss_box_reg: 0.08904  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.01948  time: 0.6811  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 08:47:24] d2.utils.events INFO:  eta: 3:40:06  iter: 17599  total_loss: 0.2624  loss_cls: 0.1358  loss_box_reg: 0.08433  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.01885  time: 0.6811  data_time: 0.0734  lr: 0.004  max_mem: 11812M
[11/17 08:47:38] d2.utils.events INFO:  eta: 3:40:02  iter: 17619  total_loss: 0.2701  loss_cls: 0.1472  loss_box_reg: 0.08787  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.01815  time: 0.6812  data_time: 0.0738  lr: 0.004  max_mem: 11812M
[11/17 08:47:51] d2.utils.events INFO:  eta: 3:39:49  iter: 17639  total_loss: 0.2692  loss_cls: 0.1456  loss_box_reg: 0.08704  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.01715  time: 0.6812  data_time: 0.0672  lr: 0.004  max_mem: 11812M
[11/17 08:48:05] d2.utils.events INFO:  eta: 3:39:35  iter: 17659  total_loss: 0.2677  loss_cls: 0.1442  loss_box_reg: 0.08588  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.0178  time: 0.6812  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 08:48:18] d2.utils.events INFO:  eta: 3:39:22  iter: 17679  total_loss: 0.2815  loss_cls: 0.1466  loss_box_reg: 0.09283  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.01966  time: 0.6812  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 08:48:32] d2.utils.events INFO:  eta: 3:39:09  iter: 17699  total_loss: 0.2695  loss_cls: 0.1433  loss_box_reg: 0.0896  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.0196  time: 0.6812  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 08:48:46] d2.utils.events INFO:  eta: 3:38:56  iter: 17719  total_loss: 0.2772  loss_cls: 0.1546  loss_box_reg: 0.09241  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.01839  time: 0.6813  data_time: 0.0705  lr: 0.004  max_mem: 11812M
[11/17 08:48:59] d2.utils.events INFO:  eta: 3:38:42  iter: 17739  total_loss: 0.2741  loss_cls: 0.1535  loss_box_reg: 0.08751  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.01834  time: 0.6813  data_time: 0.0639  lr: 0.004  max_mem: 11812M
[11/17 08:49:13] d2.utils.events INFO:  eta: 3:38:24  iter: 17759  total_loss: 0.2761  loss_cls: 0.1513  loss_box_reg: 0.08721  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.01826  time: 0.6812  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 08:49:27] d2.utils.events INFO:  eta: 3:38:11  iter: 17779  total_loss: 0.265  loss_cls: 0.143  loss_box_reg: 0.08973  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.01666  time: 0.6812  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 08:49:40] d2.utils.events INFO:  eta: 3:37:57  iter: 17799  total_loss: 0.2725  loss_cls: 0.1428  loss_box_reg: 0.08488  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.01715  time: 0.6812  data_time: 0.0726  lr: 0.004  max_mem: 11812M
[11/17 08:49:54] d2.utils.events INFO:  eta: 3:37:39  iter: 17819  total_loss: 0.2853  loss_cls: 0.1541  loss_box_reg: 0.09584  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.01913  time: 0.6812  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 08:50:07] d2.utils.events INFO:  eta: 3:37:20  iter: 17839  total_loss: 0.2576  loss_cls: 0.1398  loss_box_reg: 0.08395  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.01869  time: 0.6812  data_time: 0.0693  lr: 0.004  max_mem: 11812M
[11/17 08:50:21] d2.utils.events INFO:  eta: 3:37:06  iter: 17859  total_loss: 0.2952  loss_cls: 0.1586  loss_box_reg: 0.09096  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.01843  time: 0.6813  data_time: 0.0719  lr: 0.004  max_mem: 11812M
[11/17 08:50:35] d2.utils.events INFO:  eta: 3:37:01  iter: 17879  total_loss: 0.258  loss_cls: 0.1419  loss_box_reg: 0.08574  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.01622  time: 0.6812  data_time: 0.0616  lr: 0.004  max_mem: 11812M
[11/17 08:50:48] d2.utils.events INFO:  eta: 3:36:51  iter: 17899  total_loss: 0.2614  loss_cls: 0.1401  loss_box_reg: 0.08952  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.01986  time: 0.6813  data_time: 0.0697  lr: 0.004  max_mem: 11812M
[11/17 08:51:02] d2.utils.events INFO:  eta: 3:36:37  iter: 17919  total_loss: 0.2746  loss_cls: 0.1464  loss_box_reg: 0.09332  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.01736  time: 0.6813  data_time: 0.0822  lr: 0.004  max_mem: 11812M
[11/17 08:51:16] d2.utils.events INFO:  eta: 3:36:23  iter: 17939  total_loss: 0.2767  loss_cls: 0.1526  loss_box_reg: 0.09269  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.01787  time: 0.6814  data_time: 0.0697  lr: 0.004  max_mem: 11812M
[11/17 08:51:29] d2.utils.events INFO:  eta: 3:36:04  iter: 17959  total_loss: 0.263  loss_cls: 0.1386  loss_box_reg: 0.08449  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.01799  time: 0.6813  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 08:51:43] d2.utils.events INFO:  eta: 3:35:44  iter: 17979  total_loss: 0.2845  loss_cls: 0.1463  loss_box_reg: 0.09073  loss_rpn_cls: 0.01979  loss_rpn_loc: 0.01921  time: 0.6813  data_time: 0.0651  lr: 0.004  max_mem: 11812M
[11/17 08:51:56] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0017999.pth
[11/17 08:51:57] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 08:51:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 08:51:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 08:51:58] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 08:51:58] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 08:51:58] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 08:52:04] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0408 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:19
[11/17 08:52:09] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:10
[11/17 08:52:14] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:05
[11/17 08:52:19] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0017 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:00
[11/17 08:52:24] d2.evaluation.evaluator INFO: Inference done 503/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/17 08:52:29] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:51
[11/17 08:52:34] d2.evaluation.evaluator INFO: Inference done 748/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:45
[11/17 08:52:39] d2.evaluation.evaluator INFO: Inference done 874/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:40
[11/17 08:52:44] d2.evaluation.evaluator INFO: Inference done 995/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:35
[11/17 08:52:49] d2.evaluation.evaluator INFO: Inference done 1117/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/17 08:52:54] d2.evaluation.evaluator INFO: Inference done 1240/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:25
[11/17 08:53:00] d2.evaluation.evaluator INFO: Inference done 1363/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/17 08:53:05] d2.evaluation.evaluator INFO: Inference done 1485/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/17 08:53:10] d2.evaluation.evaluator INFO: Inference done 1608/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/17 08:53:15] d2.evaluation.evaluator INFO: Inference done 1730/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:05
[11/17 08:53:20] d2.evaluation.evaluator INFO: Inference done 1854/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/17 08:53:25] d2.evaluation.evaluator INFO: Inference done 1977/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/17 08:53:30] d2.evaluation.evaluator INFO: Inference done 2097/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:50
[11/17 08:53:35] d2.evaluation.evaluator INFO: Inference done 2215/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:45
[11/17 08:53:40] d2.evaluation.evaluator INFO: Inference done 2340/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/17 08:53:45] d2.evaluation.evaluator INFO: Inference done 2462/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/17 08:53:50] d2.evaluation.evaluator INFO: Inference done 2587/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:30
[11/17 08:53:55] d2.evaluation.evaluator INFO: Inference done 2712/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/17 08:54:00] d2.evaluation.evaluator INFO: Inference done 2838/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 08:54:05] d2.evaluation.evaluator INFO: Inference done 2961/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:15
[11/17 08:54:10] d2.evaluation.evaluator INFO: Inference done 3082/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/17 08:54:15] d2.evaluation.evaluator INFO: Inference done 3204/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/17 08:54:20] d2.evaluation.evaluator INFO: Inference done 3330/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:00
[11/17 08:54:20] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.354008 (0.040959 s / iter per device, on 6 devices)
[11/17 08:54:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038907 s / iter per device, on 6 devices)
[11/17 08:54:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 08:54:23] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 08:54:25] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 08:54:26] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 08:54:47] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.58 seconds.
[11/17 08:54:48] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 08:54:49] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.85 seconds.
[11/17 08:54:49] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.441 | 8.375  | 2.221  | 0.514 | 1.764 | 3.963 |
[11/17 08:54:49] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 5.425  | person      | 3.898  | bird                  | 12.520 |
| red panda            | 2.478  | dog         | 31.034 | snake                 | 4.885  |
| car                  | 19.138 | seal        | 1.369  | helmet                | 3.670  |
| motorcycle           | 4.410  | swine       | 3.640  | stove                 | 5.255  |
| monkey               | 4.436  | watercraft  | 11.419 | chair                 | 2.237  |
| domestic cat         | 2.440  | harp        | 1.435  | antelope              | 4.037  |
| camel                | 0.699  | koala bear  | 5.767  | bus                   | 9.312  |
| hat with a wide brim | 1.461  | ski         | 0.000  | piano                 | 5.286  |
| frog                 | 3.534  | dumbbell    | 0.000  | lobster               | 1.170  |
| bench                | 0.113  | rabbit      | 5.033  | porcupine             | 7.171  |
| butterfly            | 9.304  | guitar      | 0.522  | microphone            | 0.000  |
| tape player          | 4.123  | bear        | 4.603  | hippopotamus          | 0.067  |
| bowl                 | 3.177  | axe         | 0.145  | skunk                 | 0.173  |
| airplane             | 7.995  | otter       | 1.125  | table                 | 2.227  |
| coffee maker         | 10.823 | tie         | 0.041  | turtle                | 1.935  |
| purse                | 2.094  | dragonfly   | 2.049  | lemon                 | 6.341  |
| lizard               | 2.454  | backpack    | 1.426  | tv or monitor         | 8.719  |
| cup or mug           | 0.587  | sheep       | 1.115  | ray                   | 0.629  |
| fox                  | 2.241  | whale       | 4.772  | salt or pepper shaker | 0.256  |
| computer keyboard    | 0.985  | fig         | 0.506  | bathing cap           | 0.529  |
| bookshelf            | 4.746  | ladybug     | 16.178 | crutch                | 0.095  |
| pretzel              | 1.812  | sunglasses  | 0.096  | starfish              | 2.978  |
| croquet ball         | 2.241  | lamp        | 0.519  | apple                 | 9.329  |
| cream                | 2.843  | artichoke   | 3.095  | train                 | 2.779  |
| elephant             | 4.718  | bell pepper | 3.079  | miniskirt             | 0.109  |
| orange               | 4.825  | tiger       | 0.845  | sofa                  | 0.415  |
| horse                | 2.134  | violin      | 0.125  | traffic light         | 2.432  |
| drum                 | 0.182  | strawberry  | 2.982  | laptop                | 2.717  |
| pomegranate          | 1.215  | cucumber    | 0.149  | bicycle               | 1.289  |
| banana               | 0.131  | baby bed    | 5.219  | jellyfish             | 3.043  |
| pitcher              | 0.264  | bagel       | 2.929  | beaker                | 3.774  |
| goldfish             | 0.992  | nail        | 0.000  | mushroom              | 0.527  |
| flower pot           | 0.289  | cattle      | 1.746  | zebra                 | 6.428  |
| wine bottle          | 0.601  |             |        |                       |        |
[11/17 08:54:52] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 08:54:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 08:54:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 08:54:52] d2.evaluation.testing INFO: copypaste: 3.4411,8.3749,2.2215,0.5141,1.7640,3.9627
[11/17 08:54:52] d2.utils.events INFO:  eta: 3:35:30  iter: 17999  total_loss: 0.2639  loss_cls: 0.1444  loss_box_reg: 0.08773  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.01743  time: 0.6812  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 08:55:05] d2.utils.events INFO:  eta: 3:35:16  iter: 18019  total_loss: 0.2617  loss_cls: 0.1413  loss_box_reg: 0.08936  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.01773  time: 0.6812  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 08:55:19] d2.utils.events INFO:  eta: 3:35:05  iter: 18039  total_loss: 0.278  loss_cls: 0.1503  loss_box_reg: 0.09155  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.01728  time: 0.6812  data_time: 0.0742  lr: 0.004  max_mem: 11812M
[11/17 08:55:33] d2.utils.events INFO:  eta: 3:34:53  iter: 18059  total_loss: 0.2662  loss_cls: 0.144  loss_box_reg: 0.09196  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0710  lr: 0.004  max_mem: 11812M
[11/17 08:55:46] d2.utils.events INFO:  eta: 3:34:37  iter: 18079  total_loss: 0.2816  loss_cls: 0.1512  loss_box_reg: 0.08809  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.01891  time: 0.6812  data_time: 0.0686  lr: 0.004  max_mem: 11812M
[11/17 08:56:00] d2.utils.events INFO:  eta: 3:34:23  iter: 18099  total_loss: 0.279  loss_cls: 0.1479  loss_box_reg: 0.09068  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.02046  time: 0.6812  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 08:56:13] d2.utils.events INFO:  eta: 3:34:12  iter: 18119  total_loss: 0.2739  loss_cls: 0.1472  loss_box_reg: 0.09095  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.01782  time: 0.6812  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 08:56:27] d2.utils.events INFO:  eta: 3:33:53  iter: 18139  total_loss: 0.2706  loss_cls: 0.1512  loss_box_reg: 0.09162  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.01726  time: 0.6812  data_time: 0.0632  lr: 0.004  max_mem: 11812M
[11/17 08:56:40] d2.utils.events INFO:  eta: 3:33:33  iter: 18159  total_loss: 0.2613  loss_cls: 0.1386  loss_box_reg: 0.08434  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.01908  time: 0.6811  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 08:56:54] d2.utils.events INFO:  eta: 3:33:19  iter: 18179  total_loss: 0.2581  loss_cls: 0.1397  loss_box_reg: 0.08492  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01903  time: 0.6811  data_time: 0.0698  lr: 0.004  max_mem: 11812M
[11/17 08:57:08] d2.utils.events INFO:  eta: 3:33:01  iter: 18199  total_loss: 0.263  loss_cls: 0.1405  loss_box_reg: 0.0896  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01905  time: 0.6811  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 08:57:21] d2.utils.events INFO:  eta: 3:32:48  iter: 18219  total_loss: 0.2812  loss_cls: 0.1517  loss_box_reg: 0.08989  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.01694  time: 0.6811  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 08:57:35] d2.utils.events INFO:  eta: 3:32:33  iter: 18239  total_loss: 0.2853  loss_cls: 0.1509  loss_box_reg: 0.09022  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.01984  time: 0.6811  data_time: 0.0646  lr: 0.004  max_mem: 11812M
[11/17 08:57:49] d2.utils.events INFO:  eta: 3:32:18  iter: 18259  total_loss: 0.2996  loss_cls: 0.1594  loss_box_reg: 0.09787  loss_rpn_cls: 0.01744  loss_rpn_loc: 0.01831  time: 0.6812  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 08:58:02] d2.utils.events INFO:  eta: 3:32:08  iter: 18279  total_loss: 0.2639  loss_cls: 0.1423  loss_box_reg: 0.08964  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.01832  time: 0.6812  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 08:58:16] d2.utils.events INFO:  eta: 3:31:56  iter: 18299  total_loss: 0.2708  loss_cls: 0.1413  loss_box_reg: 0.08823  loss_rpn_cls: 0.01744  loss_rpn_loc: 0.01933  time: 0.6811  data_time: 0.0628  lr: 0.004  max_mem: 11812M
[11/17 08:58:29] d2.utils.events INFO:  eta: 3:31:41  iter: 18319  total_loss: 0.268  loss_cls: 0.1463  loss_box_reg: 0.0887  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.01814  time: 0.6811  data_time: 0.0778  lr: 0.004  max_mem: 11812M
[11/17 08:58:43] d2.utils.events INFO:  eta: 3:31:31  iter: 18339  total_loss: 0.2711  loss_cls: 0.1482  loss_box_reg: 0.08889  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.01856  time: 0.6811  data_time: 0.0739  lr: 0.004  max_mem: 11812M
[11/17 08:58:57] d2.utils.events INFO:  eta: 3:31:16  iter: 18359  total_loss: 0.2543  loss_cls: 0.132  loss_box_reg: 0.08508  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.01697  time: 0.6811  data_time: 0.0616  lr: 0.004  max_mem: 11812M
[11/17 08:59:10] d2.utils.events INFO:  eta: 3:30:59  iter: 18379  total_loss: 0.2644  loss_cls: 0.1428  loss_box_reg: 0.0888  loss_rpn_cls: 0.0157  loss_rpn_loc: 0.01822  time: 0.6811  data_time: 0.0702  lr: 0.004  max_mem: 11812M
[11/17 08:59:24] d2.utils.events INFO:  eta: 3:30:42  iter: 18399  total_loss: 0.2879  loss_cls: 0.1474  loss_box_reg: 0.09174  loss_rpn_cls: 0.01796  loss_rpn_loc: 0.01955  time: 0.6811  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 08:59:38] d2.utils.events INFO:  eta: 3:30:36  iter: 18419  total_loss: 0.2572  loss_cls: 0.1376  loss_box_reg: 0.08514  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.01805  time: 0.6811  data_time: 0.0645  lr: 0.004  max_mem: 11812M
[11/17 08:59:51] d2.utils.events INFO:  eta: 3:30:25  iter: 18439  total_loss: 0.26  loss_cls: 0.141  loss_box_reg: 0.08465  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.01893  time: 0.6811  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 09:00:05] d2.utils.events INFO:  eta: 3:30:09  iter: 18459  total_loss: 0.3011  loss_cls: 0.1594  loss_box_reg: 0.09827  loss_rpn_cls: 0.01793  loss_rpn_loc: 0.01945  time: 0.6811  data_time: 0.0697  lr: 0.004  max_mem: 11812M
[11/17 09:00:19] d2.utils.events INFO:  eta: 3:29:55  iter: 18479  total_loss: 0.2717  loss_cls: 0.1474  loss_box_reg: 0.08801  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.01818  time: 0.6812  data_time: 0.0800  lr: 0.004  max_mem: 11812M
[11/17 09:00:32] d2.utils.events INFO:  eta: 3:29:42  iter: 18499  total_loss: 0.2755  loss_cls: 0.1429  loss_box_reg: 0.09188  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.01867  time: 0.6812  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 09:00:46] d2.utils.events INFO:  eta: 3:29:30  iter: 18519  total_loss: 0.2719  loss_cls: 0.1467  loss_box_reg: 0.08959  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.01935  time: 0.6812  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 09:01:00] d2.utils.events INFO:  eta: 3:29:15  iter: 18539  total_loss: 0.2646  loss_cls: 0.1423  loss_box_reg: 0.08778  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.0174  time: 0.6812  data_time: 0.0631  lr: 0.004  max_mem: 11812M
[11/17 09:01:13] d2.utils.events INFO:  eta: 3:29:02  iter: 18559  total_loss: 0.2691  loss_cls: 0.1418  loss_box_reg: 0.08663  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.01926  time: 0.6813  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 09:01:27] d2.utils.events INFO:  eta: 3:28:47  iter: 18579  total_loss: 0.2689  loss_cls: 0.1414  loss_box_reg: 0.08573  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.01623  time: 0.6812  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 09:01:41] d2.utils.events INFO:  eta: 3:28:34  iter: 18599  total_loss: 0.2677  loss_cls: 0.1441  loss_box_reg: 0.08802  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.01817  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11812M
[11/17 09:01:54] d2.utils.events INFO:  eta: 3:28:20  iter: 18619  total_loss: 0.2699  loss_cls: 0.1443  loss_box_reg: 0.08944  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.01916  time: 0.6812  data_time: 0.0657  lr: 0.004  max_mem: 11812M
[11/17 09:02:08] d2.utils.events INFO:  eta: 3:28:04  iter: 18639  total_loss: 0.2644  loss_cls: 0.1388  loss_box_reg: 0.08859  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.01808  time: 0.6812  data_time: 0.0646  lr: 0.004  max_mem: 11812M
[11/17 09:02:21] d2.utils.events INFO:  eta: 3:27:51  iter: 18659  total_loss: 0.2795  loss_cls: 0.143  loss_box_reg: 0.08907  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.01851  time: 0.6811  data_time: 0.0620  lr: 0.004  max_mem: 11812M
[11/17 09:02:35] d2.utils.events INFO:  eta: 3:27:38  iter: 18679  total_loss: 0.2664  loss_cls: 0.1458  loss_box_reg: 0.09244  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.01925  time: 0.6811  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 09:02:48] d2.utils.events INFO:  eta: 3:27:23  iter: 18699  total_loss: 0.2823  loss_cls: 0.1501  loss_box_reg: 0.09225  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.01758  time: 0.6811  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 09:03:02] d2.utils.events INFO:  eta: 3:27:09  iter: 18719  total_loss: 0.2708  loss_cls: 0.1449  loss_box_reg: 0.08828  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.02012  time: 0.6811  data_time: 0.0657  lr: 0.004  max_mem: 11812M
[11/17 09:03:15] d2.utils.events INFO:  eta: 3:26:56  iter: 18739  total_loss: 0.2559  loss_cls: 0.1398  loss_box_reg: 0.08649  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.01828  time: 0.6811  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 09:03:29] d2.utils.events INFO:  eta: 3:26:49  iter: 18759  total_loss: 0.2689  loss_cls: 0.1408  loss_box_reg: 0.09015  loss_rpn_cls: 0.01767  loss_rpn_loc: 0.02025  time: 0.6811  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 09:03:43] d2.utils.events INFO:  eta: 3:26:35  iter: 18779  total_loss: 0.2703  loss_cls: 0.1432  loss_box_reg: 0.08632  loss_rpn_cls: 0.01674  loss_rpn_loc: 0.01941  time: 0.6811  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 09:03:56] d2.utils.events INFO:  eta: 3:26:18  iter: 18799  total_loss: 0.2633  loss_cls: 0.1414  loss_box_reg: 0.08805  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.01837  time: 0.6810  data_time: 0.0619  lr: 0.004  max_mem: 11812M
[11/17 09:04:10] d2.utils.events INFO:  eta: 3:26:07  iter: 18819  total_loss: 0.2631  loss_cls: 0.1415  loss_box_reg: 0.08836  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.0192  time: 0.6811  data_time: 0.0854  lr: 0.004  max_mem: 11812M
[11/17 09:04:24] d2.utils.events INFO:  eta: 3:25:58  iter: 18839  total_loss: 0.2629  loss_cls: 0.1435  loss_box_reg: 0.09104  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.01721  time: 0.6811  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 09:04:37] d2.utils.events INFO:  eta: 3:25:40  iter: 18859  total_loss: 0.2713  loss_cls: 0.1435  loss_box_reg: 0.09089  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.016  time: 0.6811  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 09:04:51] d2.utils.events INFO:  eta: 3:25:24  iter: 18879  total_loss: 0.2825  loss_cls: 0.1506  loss_box_reg: 0.09067  loss_rpn_cls: 0.01711  loss_rpn_loc: 0.02001  time: 0.6811  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 09:05:04] d2.utils.events INFO:  eta: 3:25:06  iter: 18899  total_loss: 0.2596  loss_cls: 0.1387  loss_box_reg: 0.08587  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.01732  time: 0.6811  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 09:05:18] d2.utils.events INFO:  eta: 3:24:54  iter: 18919  total_loss: 0.2757  loss_cls: 0.1474  loss_box_reg: 0.09129  loss_rpn_cls: 0.01713  loss_rpn_loc: 0.01774  time: 0.6811  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 09:05:32] d2.utils.events INFO:  eta: 3:24:32  iter: 18939  total_loss: 0.2708  loss_cls: 0.1495  loss_box_reg: 0.09025  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01726  time: 0.6811  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 09:05:45] d2.utils.events INFO:  eta: 3:24:25  iter: 18959  total_loss: 0.2647  loss_cls: 0.1448  loss_box_reg: 0.08454  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.01847  time: 0.6811  data_time: 0.0685  lr: 0.004  max_mem: 11812M
[11/17 09:05:59] d2.utils.events INFO:  eta: 3:24:16  iter: 18979  total_loss: 0.264  loss_cls: 0.14  loss_box_reg: 0.08578  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01763  time: 0.6811  data_time: 0.0589  lr: 0.004  max_mem: 11812M
[11/17 09:06:13] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0018999.pth
[11/17 09:06:13] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 09:06:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 09:06:14] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 09:06:14] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 09:06:14] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 09:06:14] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 09:06:21] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0020 s/iter. Inference: 0.0496 s/iter. Eval: 0.0002 s/iter. Total: 0.0518 s/iter. ETA=0:02:52
[11/17 09:06:26] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0016 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:15
[11/17 09:06:31] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/17 09:06:36] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:03
[11/17 09:06:41] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/17 09:06:46] d2.evaluation.evaluator INFO: Inference done 617/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:52
[11/17 09:06:51] d2.evaluation.evaluator INFO: Inference done 739/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/17 09:06:56] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/17 09:07:01] d2.evaluation.evaluator INFO: Inference done 982/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/17 09:07:06] d2.evaluation.evaluator INFO: Inference done 1102/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/17 09:07:11] d2.evaluation.evaluator INFO: Inference done 1222/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/17 09:07:16] d2.evaluation.evaluator INFO: Inference done 1340/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:22
[11/17 09:07:21] d2.evaluation.evaluator INFO: Inference done 1461/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/17 09:07:26] d2.evaluation.evaluator INFO: Inference done 1583/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/17 09:07:31] d2.evaluation.evaluator INFO: Inference done 1706/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/17 09:07:36] d2.evaluation.evaluator INFO: Inference done 1828/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/17 09:07:41] d2.evaluation.evaluator INFO: Inference done 1948/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/17 09:07:46] d2.evaluation.evaluator INFO: Inference done 2069/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/17 09:07:51] d2.evaluation.evaluator INFO: Inference done 2193/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:47
[11/17 09:07:56] d2.evaluation.evaluator INFO: Inference done 2312/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/17 09:08:01] d2.evaluation.evaluator INFO: Inference done 2433/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/17 09:08:06] d2.evaluation.evaluator INFO: Inference done 2553/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:32
[11/17 09:08:11] d2.evaluation.evaluator INFO: Inference done 2674/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/17 09:08:16] d2.evaluation.evaluator INFO: Inference done 2796/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/17 09:08:21] d2.evaluation.evaluator INFO: Inference done 2915/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/17 09:08:26] d2.evaluation.evaluator INFO: Inference done 3037/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:12
[11/17 09:08:31] d2.evaluation.evaluator INFO: Inference done 3159/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/17 09:08:36] d2.evaluation.evaluator INFO: Inference done 3280/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/17 09:08:39] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.410641 (0.041577 s / iter per device, on 6 devices)
[11/17 09:08:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039622 s / iter per device, on 6 devices)
[11/17 09:08:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 09:08:42] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 09:08:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 09:08:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 09:09:06] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.60 seconds.
[11/17 09:09:06] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 09:09:08] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.75 seconds.
[11/17 09:09:08] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.660 | 8.873  | 2.306  | 0.892 | 1.606 | 4.352 |
[11/17 09:09:08] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 4.657  | person      | 4.379  | bird                  | 12.317 |
| red panda            | 2.134  | dog         | 30.448 | snake                 | 4.037  |
| car                  | 20.114 | seal        | 0.715  | helmet                | 3.523  |
| motorcycle           | 6.217  | swine       | 2.788  | stove                 | 4.631  |
| monkey               | 4.452  | watercraft  | 11.416 | chair                 | 2.325  |
| domestic cat         | 3.096  | harp        | 3.188  | antelope              | 5.097  |
| camel                | 0.811  | koala bear  | 6.171  | bus                   | 11.504 |
| hat with a wide brim | 0.824  | ski         | 0.132  | piano                 | 4.696  |
| frog                 | 3.602  | dumbbell    | 0.001  | lobster               | 1.820  |
| bench                | 0.352  | rabbit      | 4.077  | porcupine             | 5.085  |
| butterfly            | 10.947 | guitar      | 1.049  | microphone            | 0.000  |
| tape player          | 4.658  | bear        | 4.373  | hippopotamus          | 0.378  |
| bowl                 | 3.201  | axe         | 0.074  | skunk                 | 0.370  |
| airplane             | 8.639  | otter       | 2.158  | table                 | 2.971  |
| coffee maker         | 8.929  | tie         | 0.062  | turtle                | 2.341  |
| purse                | 2.397  | dragonfly   | 1.659  | lemon                 | 3.724  |
| lizard               | 2.435  | backpack    | 1.365  | tv or monitor         | 8.689  |
| cup or mug           | 1.338  | sheep       | 1.497  | ray                   | 0.790  |
| fox                  | 2.736  | whale       | 4.617  | salt or pepper shaker | 0.386  |
| computer keyboard    | 0.340  | fig         | 0.608  | bathing cap           | 0.737  |
| bookshelf            | 6.933  | ladybug     | 16.907 | crutch                | 0.000  |
| pretzel              | 1.983  | sunglasses  | 0.138  | starfish              | 3.889  |
| croquet ball         | 2.976  | lamp        | 0.793  | apple                 | 10.379 |
| cream                | 4.790  | artichoke   | 6.857  | train                 | 2.026  |
| elephant             | 3.988  | bell pepper | 2.654  | miniskirt             | 0.080  |
| orange               | 6.332  | tiger       | 0.800  | sofa                  | 1.111  |
| horse                | 2.555  | violin      | 0.057  | traffic light         | 1.047  |
| drum                 | 0.101  | strawberry  | 4.412  | laptop                | 4.507  |
| pomegranate          | 2.163  | cucumber    | 0.190  | bicycle               | 2.312  |
| banana               | 0.327  | baby bed    | 6.151  | jellyfish             | 2.991  |
| pitcher              | 0.834  | bagel       | 2.138  | beaker                | 2.112  |
| goldfish             | 1.328  | nail        | 0.000  | mushroom              | 1.207  |
| flower pot           | 0.175  | cattle      | 1.252  | zebra                 | 8.900  |
| wine bottle          | 0.504  |             |        |                       |        |
[11/17 09:09:10] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 09:09:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 09:09:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 09:09:10] d2.evaluation.testing INFO: copypaste: 3.6598,8.8734,2.3057,0.8919,1.6057,4.3516
[11/17 09:09:10] d2.utils.events INFO:  eta: 3:24:07  iter: 18999  total_loss: 0.2642  loss_cls: 0.1414  loss_box_reg: 0.08904  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.01819  time: 0.6811  data_time: 0.0707  lr: 0.004  max_mem: 11812M
[11/17 09:09:24] d2.utils.events INFO:  eta: 3:23:57  iter: 19019  total_loss: 0.2604  loss_cls: 0.1402  loss_box_reg: 0.08924  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.01727  time: 0.6811  data_time: 0.0710  lr: 0.004  max_mem: 11812M
[11/17 09:09:37] d2.utils.events INFO:  eta: 3:23:43  iter: 19039  total_loss: 0.2721  loss_cls: 0.146  loss_box_reg: 0.09079  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.01857  time: 0.6811  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 09:09:51] d2.utils.events INFO:  eta: 3:23:25  iter: 19059  total_loss: 0.2693  loss_cls: 0.1449  loss_box_reg: 0.09008  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.01692  time: 0.6811  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 09:10:04] d2.utils.events INFO:  eta: 3:23:12  iter: 19079  total_loss: 0.2681  loss_cls: 0.141  loss_box_reg: 0.08761  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.01775  time: 0.6811  data_time: 0.0694  lr: 0.004  max_mem: 11812M
[11/17 09:10:18] d2.utils.events INFO:  eta: 3:22:53  iter: 19099  total_loss: 0.2869  loss_cls: 0.1485  loss_box_reg: 0.09237  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.01868  time: 0.6811  data_time: 0.0684  lr: 0.004  max_mem: 11812M
[11/17 09:10:32] d2.utils.events INFO:  eta: 3:22:35  iter: 19119  total_loss: 0.2609  loss_cls: 0.1438  loss_box_reg: 0.08887  loss_rpn_cls: 0.01551  loss_rpn_loc: 0.01789  time: 0.6810  data_time: 0.0648  lr: 0.004  max_mem: 11812M
[11/17 09:10:45] d2.utils.events INFO:  eta: 3:22:30  iter: 19139  total_loss: 0.2766  loss_cls: 0.1458  loss_box_reg: 0.09364  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.01965  time: 0.6810  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 09:10:59] d2.utils.events INFO:  eta: 3:22:24  iter: 19159  total_loss: 0.2716  loss_cls: 0.1449  loss_box_reg: 0.08877  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.01773  time: 0.6811  data_time: 0.0729  lr: 0.004  max_mem: 11812M
[11/17 09:11:13] d2.utils.events INFO:  eta: 3:22:15  iter: 19179  total_loss: 0.2607  loss_cls: 0.1409  loss_box_reg: 0.08545  loss_rpn_cls: 0.01681  loss_rpn_loc: 0.01771  time: 0.6811  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 09:11:27] d2.utils.events INFO:  eta: 3:22:02  iter: 19199  total_loss: 0.2766  loss_cls: 0.1524  loss_box_reg: 0.09175  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01901  time: 0.6811  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 09:11:41] d2.utils.events INFO:  eta: 3:21:49  iter: 19219  total_loss: 0.2651  loss_cls: 0.1446  loss_box_reg: 0.09033  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.02035  time: 0.6812  data_time: 0.0776  lr: 0.004  max_mem: 11812M
[11/17 09:11:54] d2.utils.events INFO:  eta: 3:21:38  iter: 19239  total_loss: 0.2597  loss_cls: 0.1398  loss_box_reg: 0.08603  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.01944  time: 0.6813  data_time: 0.0626  lr: 0.004  max_mem: 11812M
[11/17 09:12:08] d2.utils.events INFO:  eta: 3:21:21  iter: 19259  total_loss: 0.2715  loss_cls: 0.1434  loss_box_reg: 0.08722  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.0212  time: 0.6812  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 09:12:22] d2.utils.events INFO:  eta: 3:21:09  iter: 19279  total_loss: 0.272  loss_cls: 0.1472  loss_box_reg: 0.08983  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.0199  time: 0.6813  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 09:12:35] d2.utils.events INFO:  eta: 3:21:00  iter: 19299  total_loss: 0.2689  loss_cls: 0.147  loss_box_reg: 0.08915  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.01797  time: 0.6813  data_time: 0.0675  lr: 0.004  max_mem: 11812M
[11/17 09:12:49] d2.utils.events INFO:  eta: 3:20:46  iter: 19319  total_loss: 0.2751  loss_cls: 0.1458  loss_box_reg: 0.08965  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.01885  time: 0.6813  data_time: 0.0734  lr: 0.004  max_mem: 11812M
[11/17 09:13:03] d2.utils.events INFO:  eta: 3:20:31  iter: 19339  total_loss: 0.281  loss_cls: 0.151  loss_box_reg: 0.09021  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.01771  time: 0.6813  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 09:13:16] d2.utils.events INFO:  eta: 3:20:19  iter: 19359  total_loss: 0.2692  loss_cls: 0.1495  loss_box_reg: 0.08965  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.01819  time: 0.6813  data_time: 0.0743  lr: 0.004  max_mem: 11812M
[11/17 09:13:30] d2.utils.events INFO:  eta: 3:20:10  iter: 19379  total_loss: 0.2696  loss_cls: 0.1444  loss_box_reg: 0.08792  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.01906  time: 0.6813  data_time: 0.0652  lr: 0.004  max_mem: 11812M
[11/17 09:13:44] d2.utils.events INFO:  eta: 3:19:56  iter: 19399  total_loss: 0.2631  loss_cls: 0.1371  loss_box_reg: 0.08846  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.01801  time: 0.6813  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 09:13:57] d2.utils.events INFO:  eta: 3:19:42  iter: 19419  total_loss: 0.2616  loss_cls: 0.1413  loss_box_reg: 0.0857  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.01979  time: 0.6813  data_time: 0.0628  lr: 0.004  max_mem: 11812M
[11/17 09:14:11] d2.utils.events INFO:  eta: 3:19:25  iter: 19439  total_loss: 0.2699  loss_cls: 0.1425  loss_box_reg: 0.08822  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.01718  time: 0.6813  data_time: 0.0698  lr: 0.004  max_mem: 11812M
[11/17 09:14:24] d2.utils.events INFO:  eta: 3:19:12  iter: 19459  total_loss: 0.2676  loss_cls: 0.1415  loss_box_reg: 0.09032  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.01783  time: 0.6813  data_time: 0.0626  lr: 0.004  max_mem: 11812M
[11/17 09:14:38] d2.utils.events INFO:  eta: 3:18:58  iter: 19479  total_loss: 0.2796  loss_cls: 0.1461  loss_box_reg: 0.0882  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.01892  time: 0.6813  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 09:14:51] d2.utils.events INFO:  eta: 3:18:43  iter: 19499  total_loss: 0.2801  loss_cls: 0.1504  loss_box_reg: 0.0944  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.01816  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 09:15:05] d2.utils.events INFO:  eta: 3:18:28  iter: 19519  total_loss: 0.2619  loss_cls: 0.1415  loss_box_reg: 0.0873  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.01737  time: 0.6812  data_time: 0.0606  lr: 0.004  max_mem: 11812M
[11/17 09:15:19] d2.utils.events INFO:  eta: 3:18:11  iter: 19539  total_loss: 0.257  loss_cls: 0.1398  loss_box_reg: 0.08693  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.01848  time: 0.6812  data_time: 0.0629  lr: 0.004  max_mem: 11812M
[11/17 09:15:32] d2.utils.events INFO:  eta: 3:17:57  iter: 19559  total_loss: 0.2847  loss_cls: 0.1524  loss_box_reg: 0.09194  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.02127  time: 0.6812  data_time: 0.0659  lr: 0.004  max_mem: 11812M
[11/17 09:15:46] d2.utils.events INFO:  eta: 3:17:42  iter: 19579  total_loss: 0.2632  loss_cls: 0.1399  loss_box_reg: 0.08692  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.01819  time: 0.6812  data_time: 0.0694  lr: 0.004  max_mem: 11812M
[11/17 09:15:59] d2.utils.events INFO:  eta: 3:17:27  iter: 19599  total_loss: 0.2761  loss_cls: 0.1435  loss_box_reg: 0.08858  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.01955  time: 0.6812  data_time: 0.0613  lr: 0.004  max_mem: 11812M
[11/17 09:16:13] d2.utils.events INFO:  eta: 3:17:14  iter: 19619  total_loss: 0.2792  loss_cls: 0.1545  loss_box_reg: 0.09462  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01717  time: 0.6812  data_time: 0.0704  lr: 0.004  max_mem: 11812M
[11/17 09:16:26] d2.utils.events INFO:  eta: 3:17:03  iter: 19639  total_loss: 0.2791  loss_cls: 0.1518  loss_box_reg: 0.09338  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.01948  time: 0.6811  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 09:16:40] d2.utils.events INFO:  eta: 3:16:48  iter: 19659  total_loss: 0.2746  loss_cls: 0.1467  loss_box_reg: 0.08836  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.01811  time: 0.6811  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 09:16:54] d2.utils.events INFO:  eta: 3:16:44  iter: 19679  total_loss: 0.2594  loss_cls: 0.1375  loss_box_reg: 0.08551  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.01817  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 09:17:07] d2.utils.events INFO:  eta: 3:16:28  iter: 19699  total_loss: 0.264  loss_cls: 0.1372  loss_box_reg: 0.08552  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.01932  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11812M
[11/17 09:17:21] d2.utils.events INFO:  eta: 3:16:14  iter: 19719  total_loss: 0.2605  loss_cls: 0.1415  loss_box_reg: 0.09235  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.0166  time: 0.6811  data_time: 0.0639  lr: 0.004  max_mem: 11812M
[11/17 09:17:35] d2.utils.events INFO:  eta: 3:16:01  iter: 19739  total_loss: 0.2736  loss_cls: 0.1472  loss_box_reg: 0.08952  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.01888  time: 0.6812  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 09:17:48] d2.utils.events INFO:  eta: 3:15:46  iter: 19759  total_loss: 0.2845  loss_cls: 0.1514  loss_box_reg: 0.0936  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.0193  time: 0.6812  data_time: 0.0697  lr: 0.004  max_mem: 11812M
[11/17 09:18:02] d2.utils.events INFO:  eta: 3:15:33  iter: 19779  total_loss: 0.271  loss_cls: 0.1462  loss_box_reg: 0.08966  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.01918  time: 0.6812  data_time: 0.0701  lr: 0.004  max_mem: 11812M
[11/17 09:18:16] d2.utils.events INFO:  eta: 3:15:24  iter: 19799  total_loss: 0.2736  loss_cls: 0.1471  loss_box_reg: 0.09144  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.01888  time: 0.6812  data_time: 0.0659  lr: 0.004  max_mem: 11812M
[11/17 09:18:29] d2.utils.events INFO:  eta: 3:15:13  iter: 19819  total_loss: 0.2792  loss_cls: 0.1454  loss_box_reg: 0.09093  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.01703  time: 0.6812  data_time: 0.0628  lr: 0.004  max_mem: 11812M
[11/17 09:18:43] d2.utils.events INFO:  eta: 3:14:59  iter: 19839  total_loss: 0.2714  loss_cls: 0.1439  loss_box_reg: 0.09199  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.01796  time: 0.6812  data_time: 0.0651  lr: 0.004  max_mem: 11812M
[11/17 09:18:56] d2.utils.events INFO:  eta: 3:14:40  iter: 19859  total_loss: 0.2801  loss_cls: 0.1519  loss_box_reg: 0.0913  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.01819  time: 0.6812  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 09:19:10] d2.utils.events INFO:  eta: 3:14:29  iter: 19879  total_loss: 0.2553  loss_cls: 0.1345  loss_box_reg: 0.08397  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.01858  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 09:19:23] d2.utils.events INFO:  eta: 3:14:18  iter: 19899  total_loss: 0.2632  loss_cls: 0.1463  loss_box_reg: 0.0845  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.01795  time: 0.6811  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 09:19:37] d2.utils.events INFO:  eta: 3:14:03  iter: 19919  total_loss: 0.2504  loss_cls: 0.1353  loss_box_reg: 0.08106  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.01756  time: 0.6812  data_time: 0.0818  lr: 0.004  max_mem: 11812M
[11/17 09:19:51] d2.utils.events INFO:  eta: 3:13:47  iter: 19939  total_loss: 0.2551  loss_cls: 0.135  loss_box_reg: 0.0834  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01801  time: 0.6811  data_time: 0.0672  lr: 0.004  max_mem: 11812M
[11/17 09:20:05] d2.utils.events INFO:  eta: 3:13:35  iter: 19959  total_loss: 0.2626  loss_cls: 0.1366  loss_box_reg: 0.08529  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.01769  time: 0.6812  data_time: 0.0732  lr: 0.004  max_mem: 11812M
[11/17 09:20:18] d2.utils.events INFO:  eta: 3:13:21  iter: 19979  total_loss: 0.2678  loss_cls: 0.1469  loss_box_reg: 0.09332  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.01911  time: 0.6812  data_time: 0.0696  lr: 0.004  max_mem: 11812M
[11/17 09:20:32] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0019999.pth
[11/17 09:20:32] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 09:20:33] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 09:20:33] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 09:20:33] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 09:20:33] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 09:20:33] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 09:20:39] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:18
[11/17 09:20:44] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:11
[11/17 09:20:49] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:06
[11/17 09:20:54] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/17 09:21:00] d2.evaluation.evaluator INFO: Inference done 500/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/17 09:21:05] d2.evaluation.evaluator INFO: Inference done 618/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:52
[11/17 09:21:10] d2.evaluation.evaluator INFO: Inference done 741/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:47
[11/17 09:21:15] d2.evaluation.evaluator INFO: Inference done 859/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/17 09:21:20] d2.evaluation.evaluator INFO: Inference done 978/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/17 09:21:25] d2.evaluation.evaluator INFO: Inference done 1101/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/17 09:21:30] d2.evaluation.evaluator INFO: Inference done 1223/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/17 09:21:35] d2.evaluation.evaluator INFO: Inference done 1341/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/17 09:21:40] d2.evaluation.evaluator INFO: Inference done 1461/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:17
[11/17 09:21:45] d2.evaluation.evaluator INFO: Inference done 1582/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:12
[11/17 09:21:50] d2.evaluation.evaluator INFO: Inference done 1704/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/17 09:21:55] d2.evaluation.evaluator INFO: Inference done 1823/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/17 09:22:00] d2.evaluation.evaluator INFO: Inference done 1942/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/17 09:22:05] d2.evaluation.evaluator INFO: Inference done 2064/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/17 09:22:10] d2.evaluation.evaluator INFO: Inference done 2185/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/17 09:22:15] d2.evaluation.evaluator INFO: Inference done 2307/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:42
[11/17 09:22:20] d2.evaluation.evaluator INFO: Inference done 2426/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/17 09:22:25] d2.evaluation.evaluator INFO: Inference done 2545/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/17 09:22:30] d2.evaluation.evaluator INFO: Inference done 2665/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/17 09:22:35] d2.evaluation.evaluator INFO: Inference done 2785/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/17 09:22:40] d2.evaluation.evaluator INFO: Inference done 2905/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/17 09:22:45] d2.evaluation.evaluator INFO: Inference done 3026/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 09:22:50] d2.evaluation.evaluator INFO: Inference done 3149/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/17 09:22:55] d2.evaluation.evaluator INFO: Inference done 3271/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/17 09:22:58] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.631458 (0.041644 s / iter per device, on 6 devices)
[11/17 09:22:58] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039673 s / iter per device, on 6 devices)
[11/17 09:23:00] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 09:23:00] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 09:23:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 09:23:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 09:23:22] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.12 seconds.
[11/17 09:23:23] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 09:23:24] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.51 seconds.
[11/17 09:23:24] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 3.929 | 9.380  | 2.654  | 0.654 | 1.702 | 4.657 |
[11/17 09:23:24] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 4.140  | person      | 4.442  | bird                  | 13.775 |
| red panda            | 3.417  | dog         | 32.175 | snake                 | 4.971  |
| car                  | 18.635 | seal        | 1.597  | helmet                | 3.869  |
| motorcycle           | 4.912  | swine       | 3.789  | stove                 | 3.768  |
| monkey               | 5.190  | watercraft  | 13.071 | chair                 | 2.494  |
| domestic cat         | 3.056  | harp        | 2.761  | antelope              | 8.526  |
| camel                | 1.001  | koala bear  | 3.997  | bus                   | 9.887  |
| hat with a wide brim | 1.591  | ski         | 0.062  | piano                 | 5.335  |
| frog                 | 3.349  | dumbbell    | 0.000  | lobster               | 2.304  |
| bench                | 0.228  | rabbit      | 6.288  | porcupine             | 4.769  |
| butterfly            | 12.922 | guitar      | 0.821  | microphone            | 0.000  |
| tape player          | 5.990  | bear        | 5.894  | hippopotamus          | 0.205  |
| bowl                 | 4.263  | axe         | 0.015  | skunk                 | 0.436  |
| airplane             | 9.222  | otter       | 0.635  | table                 | 2.385  |
| coffee maker         | 9.370  | tie         | 0.122  | turtle                | 2.239  |
| purse                | 2.522  | dragonfly   | 2.444  | lemon                 | 4.240  |
| lizard               | 3.495  | backpack    | 3.095  | tv or monitor         | 7.798  |
| cup or mug           | 1.056  | sheep       | 1.840  | ray                   | 0.805  |
| fox                  | 3.583  | whale       | 4.318  | salt or pepper shaker | 0.263  |
| computer keyboard    | 1.352  | fig         | 0.409  | bathing cap           | 0.614  |
| bookshelf            | 6.575  | ladybug     | 19.301 | crutch                | 0.034  |
| pretzel              | 2.021  | sunglasses  | 0.003  | starfish              | 3.750  |
| croquet ball         | 3.385  | lamp        | 1.020  | apple                 | 8.048  |
| cream                | 4.360  | artichoke   | 9.369  | train                 | 2.305  |
| elephant             | 5.524  | bell pepper | 1.795  | miniskirt             | 0.707  |
| orange               | 4.855  | tiger       | 0.567  | sofa                  | 1.144  |
| horse                | 2.975  | violin      | 0.115  | traffic light         | 2.066  |
| drum                 | 0.144  | strawberry  | 4.632  | laptop                | 3.154  |
| pomegranate          | 1.766  | cucumber    | 0.207  | bicycle               | 2.774  |
| banana               | 0.250  | baby bed    | 7.971  | jellyfish             | 3.564  |
| pitcher              | 0.700  | bagel       | 2.759  | beaker                | 4.222  |
| goldfish             | 3.400  | nail        | 0.000  | mushroom              | 1.456  |
| flower pot           | 0.322  | cattle      | 1.306  | zebra                 | 7.318  |
| wine bottle          | 1.313  |             |        |                       |        |
[11/17 09:23:26] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 09:23:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 09:23:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 09:23:26] d2.evaluation.testing INFO: copypaste: 3.9293,9.3804,2.6543,0.6539,1.7020,4.6573
[11/17 09:23:26] d2.utils.events INFO:  eta: 3:13:04  iter: 19999  total_loss: 0.2577  loss_cls: 0.1407  loss_box_reg: 0.0846  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.01778  time: 0.6812  data_time: 0.0681  lr: 0.004  max_mem: 11812M
[11/17 09:23:40] d2.utils.events INFO:  eta: 3:12:50  iter: 20019  total_loss: 0.2616  loss_cls: 0.1391  loss_box_reg: 0.08925  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.01927  time: 0.6812  data_time: 0.0681  lr: 0.004  max_mem: 11812M
[11/17 09:23:53] d2.utils.events INFO:  eta: 3:12:36  iter: 20039  total_loss: 0.2588  loss_cls: 0.138  loss_box_reg: 0.08525  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01846  time: 0.6812  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 09:24:07] d2.utils.events INFO:  eta: 3:12:26  iter: 20059  total_loss: 0.2699  loss_cls: 0.1459  loss_box_reg: 0.08778  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.01647  time: 0.6812  data_time: 0.0858  lr: 0.004  max_mem: 11812M
[11/17 09:24:21] d2.utils.events INFO:  eta: 3:12:09  iter: 20079  total_loss: 0.2583  loss_cls: 0.1389  loss_box_reg: 0.08832  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01635  time: 0.6812  data_time: 0.0642  lr: 0.004  max_mem: 11812M
[11/17 09:24:34] d2.utils.events INFO:  eta: 3:11:55  iter: 20099  total_loss: 0.2716  loss_cls: 0.1412  loss_box_reg: 0.09011  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.01877  time: 0.6812  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 09:24:48] d2.utils.events INFO:  eta: 3:11:45  iter: 20119  total_loss: 0.2542  loss_cls: 0.1429  loss_box_reg: 0.08311  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.01643  time: 0.6812  data_time: 0.0696  lr: 0.004  max_mem: 11812M
[11/17 09:25:01] d2.utils.events INFO:  eta: 3:11:27  iter: 20139  total_loss: 0.2655  loss_cls: 0.1426  loss_box_reg: 0.08951  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01757  time: 0.6812  data_time: 0.0632  lr: 0.004  max_mem: 11812M
[11/17 09:25:15] d2.utils.events INFO:  eta: 3:11:13  iter: 20159  total_loss: 0.2638  loss_cls: 0.145  loss_box_reg: 0.08729  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01892  time: 0.6812  data_time: 0.0698  lr: 0.004  max_mem: 11812M
[11/17 09:25:29] d2.utils.events INFO:  eta: 3:10:54  iter: 20179  total_loss: 0.2523  loss_cls: 0.1358  loss_box_reg: 0.08438  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01768  time: 0.6812  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 09:25:43] d2.utils.events INFO:  eta: 3:10:36  iter: 20199  total_loss: 0.2697  loss_cls: 0.1446  loss_box_reg: 0.09161  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.01767  time: 0.6812  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 09:25:56] d2.utils.events INFO:  eta: 3:10:14  iter: 20219  total_loss: 0.2586  loss_cls: 0.1409  loss_box_reg: 0.08591  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.01852  time: 0.6812  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 09:26:10] d2.utils.events INFO:  eta: 3:09:58  iter: 20239  total_loss: 0.2768  loss_cls: 0.1465  loss_box_reg: 0.08995  loss_rpn_cls: 0.01803  loss_rpn_loc: 0.01932  time: 0.6812  data_time: 0.0645  lr: 0.004  max_mem: 11812M
[11/17 09:26:23] d2.utils.events INFO:  eta: 3:09:44  iter: 20259  total_loss: 0.2599  loss_cls: 0.1392  loss_box_reg: 0.08907  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.01772  time: 0.6812  data_time: 0.0644  lr: 0.004  max_mem: 11812M
[11/17 09:26:37] d2.utils.events INFO:  eta: 3:09:21  iter: 20279  total_loss: 0.2708  loss_cls: 0.1476  loss_box_reg: 0.09133  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.01775  time: 0.6811  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 09:26:51] d2.utils.events INFO:  eta: 3:09:09  iter: 20299  total_loss: 0.2807  loss_cls: 0.15  loss_box_reg: 0.09271  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.02044  time: 0.6812  data_time: 0.0884  lr: 0.004  max_mem: 11812M
[11/17 09:27:04] d2.utils.events INFO:  eta: 3:08:59  iter: 20319  total_loss: 0.262  loss_cls: 0.1395  loss_box_reg: 0.09098  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01789  time: 0.6812  data_time: 0.0731  lr: 0.004  max_mem: 11812M
[11/17 09:27:18] d2.utils.events INFO:  eta: 3:08:50  iter: 20339  total_loss: 0.2639  loss_cls: 0.1448  loss_box_reg: 0.08685  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01904  time: 0.6812  data_time: 0.0663  lr: 0.004  max_mem: 11812M
[11/17 09:27:32] d2.utils.events INFO:  eta: 3:08:38  iter: 20359  total_loss: 0.2789  loss_cls: 0.1473  loss_box_reg: 0.0918  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.01861  time: 0.6813  data_time: 0.0745  lr: 0.004  max_mem: 11812M
[11/17 09:27:46] d2.utils.events INFO:  eta: 3:08:24  iter: 20379  total_loss: 0.2577  loss_cls: 0.1413  loss_box_reg: 0.08507  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.0192  time: 0.6813  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 09:28:00] d2.utils.events INFO:  eta: 3:08:11  iter: 20399  total_loss: 0.2691  loss_cls: 0.1442  loss_box_reg: 0.08896  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.01736  time: 0.6814  data_time: 0.0949  lr: 0.004  max_mem: 11812M
[11/17 09:28:14] d2.utils.events INFO:  eta: 3:07:57  iter: 20419  total_loss: 0.284  loss_cls: 0.1568  loss_box_reg: 0.09584  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.01955  time: 0.6814  data_time: 0.0691  lr: 0.004  max_mem: 11812M
[11/17 09:28:27] d2.utils.events INFO:  eta: 3:07:49  iter: 20439  total_loss: 0.2635  loss_cls: 0.1441  loss_box_reg: 0.0879  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.0183  time: 0.6814  data_time: 0.0746  lr: 0.004  max_mem: 11812M
[11/17 09:28:41] d2.utils.events INFO:  eta: 3:07:35  iter: 20459  total_loss: 0.274  loss_cls: 0.1481  loss_box_reg: 0.09222  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.0185  time: 0.6814  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 09:28:55] d2.utils.events INFO:  eta: 3:07:20  iter: 20479  total_loss: 0.267  loss_cls: 0.1416  loss_box_reg: 0.08661  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01991  time: 0.6814  data_time: 0.0593  lr: 0.004  max_mem: 11812M
[11/17 09:29:08] d2.utils.events INFO:  eta: 3:07:03  iter: 20499  total_loss: 0.2701  loss_cls: 0.1439  loss_box_reg: 0.08793  loss_rpn_cls: 0.01548  loss_rpn_loc: 0.01821  time: 0.6814  data_time: 0.0601  lr: 0.004  max_mem: 11812M
[11/17 09:29:22] d2.utils.events INFO:  eta: 3:06:54  iter: 20519  total_loss: 0.2541  loss_cls: 0.1378  loss_box_reg: 0.08666  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.01699  time: 0.6814  data_time: 0.0707  lr: 0.004  max_mem: 11812M
[11/17 09:29:35] d2.utils.events INFO:  eta: 3:06:39  iter: 20539  total_loss: 0.2523  loss_cls: 0.1308  loss_box_reg: 0.08383  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.01822  time: 0.6814  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 09:29:49] d2.utils.events INFO:  eta: 3:06:22  iter: 20559  total_loss: 0.2653  loss_cls: 0.1379  loss_box_reg: 0.08434  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.01848  time: 0.6813  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 09:30:02] d2.utils.events INFO:  eta: 3:06:14  iter: 20579  total_loss: 0.2602  loss_cls: 0.1402  loss_box_reg: 0.08792  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01877  time: 0.6813  data_time: 0.0733  lr: 0.004  max_mem: 11812M
[11/17 09:30:16] d2.utils.events INFO:  eta: 3:06:08  iter: 20599  total_loss: 0.2543  loss_cls: 0.1394  loss_box_reg: 0.08471  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01843  time: 0.6814  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 09:30:30] d2.utils.events INFO:  eta: 3:05:55  iter: 20619  total_loss: 0.2667  loss_cls: 0.1454  loss_box_reg: 0.08893  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.01898  time: 0.6814  data_time: 0.0709  lr: 0.004  max_mem: 11812M
[11/17 09:30:43] d2.utils.events INFO:  eta: 3:05:33  iter: 20639  total_loss: 0.2644  loss_cls: 0.1425  loss_box_reg: 0.08297  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.01742  time: 0.6814  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 09:30:57] d2.utils.events INFO:  eta: 3:05:19  iter: 20659  total_loss: 0.2764  loss_cls: 0.1479  loss_box_reg: 0.08969  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.01916  time: 0.6813  data_time: 0.0689  lr: 0.004  max_mem: 11812M
[11/17 09:31:11] d2.utils.events INFO:  eta: 3:05:05  iter: 20679  total_loss: 0.2751  loss_cls: 0.1458  loss_box_reg: 0.09309  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01793  time: 0.6814  data_time: 0.0670  lr: 0.004  max_mem: 11812M
[11/17 09:31:25] d2.utils.events INFO:  eta: 3:05:04  iter: 20699  total_loss: 0.2433  loss_cls: 0.1288  loss_box_reg: 0.08187  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.01771  time: 0.6814  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 09:31:38] d2.utils.events INFO:  eta: 3:04:52  iter: 20719  total_loss: 0.273  loss_cls: 0.1457  loss_box_reg: 0.09062  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.01903  time: 0.6815  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 09:31:52] d2.utils.events INFO:  eta: 3:04:37  iter: 20739  total_loss: 0.2705  loss_cls: 0.1504  loss_box_reg: 0.09272  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.01627  time: 0.6814  data_time: 0.0646  lr: 0.004  max_mem: 11812M
[11/17 09:32:06] d2.utils.events INFO:  eta: 3:04:24  iter: 20759  total_loss: 0.2682  loss_cls: 0.1468  loss_box_reg: 0.08847  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.01899  time: 0.6814  data_time: 0.0697  lr: 0.004  max_mem: 11812M
[11/17 09:32:19] d2.utils.events INFO:  eta: 3:04:09  iter: 20779  total_loss: 0.2679  loss_cls: 0.1432  loss_box_reg: 0.08813  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.0187  time: 0.6814  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 09:32:33] d2.utils.events INFO:  eta: 3:03:52  iter: 20799  total_loss: 0.274  loss_cls: 0.1468  loss_box_reg: 0.09047  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.0192  time: 0.6814  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 09:32:46] d2.utils.events INFO:  eta: 3:03:27  iter: 20819  total_loss: 0.266  loss_cls: 0.1442  loss_box_reg: 0.08952  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01854  time: 0.6814  data_time: 0.0718  lr: 0.004  max_mem: 11812M
[11/17 09:33:00] d2.utils.events INFO:  eta: 3:03:17  iter: 20839  total_loss: 0.2744  loss_cls: 0.1489  loss_box_reg: 0.09182  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.01809  time: 0.6814  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 09:33:14] d2.utils.events INFO:  eta: 3:03:16  iter: 20859  total_loss: 0.2877  loss_cls: 0.1553  loss_box_reg: 0.09087  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.01922  time: 0.6814  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 09:33:27] d2.utils.events INFO:  eta: 3:03:02  iter: 20879  total_loss: 0.2536  loss_cls: 0.1332  loss_box_reg: 0.084  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01696  time: 0.6814  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 09:33:41] d2.utils.events INFO:  eta: 3:02:49  iter: 20899  total_loss: 0.2638  loss_cls: 0.1392  loss_box_reg: 0.08685  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.01773  time: 0.6814  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 09:33:54] d2.utils.events INFO:  eta: 3:02:36  iter: 20919  total_loss: 0.2721  loss_cls: 0.1469  loss_box_reg: 0.08881  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.01659  time: 0.6814  data_time: 0.0644  lr: 0.004  max_mem: 11812M
[11/17 09:34:08] d2.utils.events INFO:  eta: 3:02:23  iter: 20939  total_loss: 0.2821  loss_cls: 0.1477  loss_box_reg: 0.09455  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.01734  time: 0.6814  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 09:34:21] d2.utils.events INFO:  eta: 3:02:08  iter: 20959  total_loss: 0.2822  loss_cls: 0.1472  loss_box_reg: 0.09228  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.01787  time: 0.6814  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 09:34:35] d2.utils.events INFO:  eta: 3:01:54  iter: 20979  total_loss: 0.2748  loss_cls: 0.1499  loss_box_reg: 0.09011  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.01907  time: 0.6814  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 09:34:49] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0020999.pth
[11/17 09:34:49] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 09:34:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 09:34:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 09:34:50] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 09:34:50] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 09:34:50] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 09:34:57] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0414 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:02:21
[11/17 09:35:02] d2.evaluation.evaluator INFO: Inference done 130/3334. Dataloading: 0.0015 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:15
[11/17 09:35:07] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:08
[11/17 09:35:12] d2.evaluation.evaluator INFO: Inference done 374/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/17 09:35:17] d2.evaluation.evaluator INFO: Inference done 495/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:57
[11/17 09:35:22] d2.evaluation.evaluator INFO: Inference done 618/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:52
[11/17 09:35:27] d2.evaluation.evaluator INFO: Inference done 739/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/17 09:35:32] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/17 09:35:37] d2.evaluation.evaluator INFO: Inference done 981/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/17 09:35:42] d2.evaluation.evaluator INFO: Inference done 1099/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:32
[11/17 09:35:47] d2.evaluation.evaluator INFO: Inference done 1220/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/17 09:35:52] d2.evaluation.evaluator INFO: Inference done 1339/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:23
[11/17 09:35:57] d2.evaluation.evaluator INFO: Inference done 1462/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/17 09:36:02] d2.evaluation.evaluator INFO: Inference done 1585/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/17 09:36:07] d2.evaluation.evaluator INFO: Inference done 1705/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/17 09:36:12] d2.evaluation.evaluator INFO: Inference done 1825/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/17 09:36:17] d2.evaluation.evaluator INFO: Inference done 1946/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/17 09:36:22] d2.evaluation.evaluator INFO: Inference done 2064/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:52
[11/17 09:36:27] d2.evaluation.evaluator INFO: Inference done 2185/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/17 09:36:32] d2.evaluation.evaluator INFO: Inference done 2309/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/17 09:36:37] d2.evaluation.evaluator INFO: Inference done 2428/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/17 09:36:42] d2.evaluation.evaluator INFO: Inference done 2549/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/17 09:36:47] d2.evaluation.evaluator INFO: Inference done 2669/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/17 09:36:52] d2.evaluation.evaluator INFO: Inference done 2789/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/17 09:36:57] d2.evaluation.evaluator INFO: Inference done 2910/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/17 09:37:02] d2.evaluation.evaluator INFO: Inference done 3030/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 09:37:07] d2.evaluation.evaluator INFO: Inference done 3148/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/17 09:37:12] d2.evaluation.evaluator INFO: Inference done 3267/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/17 09:37:15] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.549457 (0.041619 s / iter per device, on 6 devices)
[11/17 09:37:15] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039583 s / iter per device, on 6 devices)
[11/17 09:37:17] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 09:37:17] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 09:37:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 09:37:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 09:37:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.92 seconds.
[11/17 09:37:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 09:37:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.97 seconds.
[11/17 09:37:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.272 | 10.004 | 2.910  | 0.968 | 1.995 | 5.078 |
[11/17 09:37:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 4.865  | person      | 4.397  | bird                  | 14.601 |
| red panda            | 4.711  | dog         | 32.566 | snake                 | 5.091  |
| car                  | 21.958 | seal        | 0.741  | helmet                | 3.332  |
| motorcycle           | 6.676  | swine       | 4.085  | stove                 | 4.031  |
| monkey               | 4.915  | watercraft  | 11.493 | chair                 | 3.032  |
| domestic cat         | 3.827  | harp        | 2.269  | antelope              | 7.292  |
| camel                | 1.425  | koala bear  | 3.626  | bus                   | 12.333 |
| hat with a wide brim | 2.065  | ski         | 0.865  | piano                 | 6.806  |
| frog                 | 4.674  | dumbbell    | 0.000  | lobster               | 1.745  |
| bench                | 0.104  | rabbit      | 7.398  | porcupine             | 6.757  |
| butterfly            | 13.167 | guitar      | 1.783  | microphone            | 0.000  |
| tape player          | 4.280  | bear        | 5.598  | hippopotamus          | 0.155  |
| bowl                 | 3.525  | axe         | 0.169  | skunk                 | 0.404  |
| airplane             | 8.771  | otter       | 1.309  | table                 | 3.197  |
| coffee maker         | 10.947 | tie         | 0.664  | turtle                | 2.183  |
| purse                | 2.679  | dragonfly   | 2.958  | lemon                 | 7.604  |
| lizard               | 2.762  | backpack    | 1.986  | tv or monitor         | 10.496 |
| cup or mug           | 1.224  | sheep       | 0.996  | ray                   | 0.945  |
| fox                  | 3.621  | whale       | 3.849  | salt or pepper shaker | 0.500  |
| computer keyboard    | 0.288  | fig         | 0.987  | bathing cap           | 1.224  |
| bookshelf            | 8.439  | ladybug     | 21.347 | crutch                | 0.000  |
| pretzel              | 2.289  | sunglasses  | 0.104  | starfish              | 4.690  |
| croquet ball         | 4.054  | lamp        | 0.413  | apple                 | 10.029 |
| cream                | 3.687  | artichoke   | 9.800  | train                 | 2.821  |
| elephant             | 5.177  | bell pepper | 4.921  | miniskirt             | 0.132  |
| orange               | 7.730  | tiger       | 0.664  | sofa                  | 0.942  |
| horse                | 2.837  | violin      | 0.543  | traffic light         | 1.558  |
| drum                 | 0.371  | strawberry  | 4.214  | laptop                | 3.536  |
| pomegranate          | 3.076  | cucumber    | 0.433  | bicycle               | 2.175  |
| banana               | 0.413  | baby bed    | 8.593  | jellyfish             | 2.458  |
| pitcher              | 0.370  | bagel       | 2.268  | beaker                | 2.503  |
| goldfish             | 3.965  | nail        | 0.000  | mushroom              | 1.623  |
| flower pot           | 0.143  | cattle      | 1.006  | zebra                 | 11.008 |
| wine bottle          | 0.965  |             |        |                       |        |
[11/17 09:37:48] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 09:37:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 09:37:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 09:37:48] d2.evaluation.testing INFO: copypaste: 4.2725,10.0041,2.9103,0.9681,1.9947,5.0781
[11/17 09:37:48] d2.utils.events INFO:  eta: 3:01:41  iter: 20999  total_loss: 0.2751  loss_cls: 0.1459  loss_box_reg: 0.09086  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.01815  time: 0.6814  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 09:38:01] d2.utils.events INFO:  eta: 3:01:22  iter: 21019  total_loss: 0.29  loss_cls: 0.1574  loss_box_reg: 0.09987  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.01955  time: 0.6813  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 09:38:15] d2.utils.events INFO:  eta: 3:01:11  iter: 21039  total_loss: 0.2652  loss_cls: 0.1377  loss_box_reg: 0.08841  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.01679  time: 0.6813  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 09:38:29] d2.utils.events INFO:  eta: 3:00:59  iter: 21059  total_loss: 0.2651  loss_cls: 0.1404  loss_box_reg: 0.08919  loss_rpn_cls: 0.01548  loss_rpn_loc: 0.01755  time: 0.6813  data_time: 0.0632  lr: 0.004  max_mem: 11812M
[11/17 09:38:42] d2.utils.events INFO:  eta: 3:00:46  iter: 21079  total_loss: 0.2763  loss_cls: 0.1426  loss_box_reg: 0.08893  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.01992  time: 0.6813  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 09:38:56] d2.utils.events INFO:  eta: 3:00:35  iter: 21099  total_loss: 0.2744  loss_cls: 0.1428  loss_box_reg: 0.09172  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.01967  time: 0.6814  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 09:39:09] d2.utils.events INFO:  eta: 3:00:19  iter: 21119  total_loss: 0.2536  loss_cls: 0.134  loss_box_reg: 0.08756  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.01871  time: 0.6813  data_time: 0.0645  lr: 0.004  max_mem: 11812M
[11/17 09:39:23] d2.utils.events INFO:  eta: 3:00:07  iter: 21139  total_loss: 0.2671  loss_cls: 0.144  loss_box_reg: 0.09019  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.01912  time: 0.6813  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 09:39:37] d2.utils.events INFO:  eta: 2:59:51  iter: 21159  total_loss: 0.2578  loss_cls: 0.1343  loss_box_reg: 0.08627  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.0183  time: 0.6813  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 09:39:50] d2.utils.events INFO:  eta: 2:59:37  iter: 21179  total_loss: 0.2586  loss_cls: 0.1404  loss_box_reg: 0.08443  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01643  time: 0.6813  data_time: 0.0663  lr: 0.004  max_mem: 11812M
[11/17 09:40:04] d2.utils.events INFO:  eta: 2:59:24  iter: 21199  total_loss: 0.2665  loss_cls: 0.1431  loss_box_reg: 0.08851  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.01736  time: 0.6813  data_time: 0.0690  lr: 0.004  max_mem: 11812M
[11/17 09:40:17] d2.utils.events INFO:  eta: 2:59:10  iter: 21219  total_loss: 0.2651  loss_cls: 0.1479  loss_box_reg: 0.08635  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.01667  time: 0.6813  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 09:40:31] d2.utils.events INFO:  eta: 2:58:57  iter: 21239  total_loss: 0.2668  loss_cls: 0.1447  loss_box_reg: 0.08726  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.0187  time: 0.6813  data_time: 0.0611  lr: 0.004  max_mem: 11812M
[11/17 09:40:44] d2.utils.events INFO:  eta: 2:58:43  iter: 21259  total_loss: 0.2625  loss_cls: 0.1404  loss_box_reg: 0.08818  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01644  time: 0.6813  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 09:40:58] d2.utils.events INFO:  eta: 2:58:32  iter: 21279  total_loss: 0.2711  loss_cls: 0.1487  loss_box_reg: 0.09079  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.01939  time: 0.6813  data_time: 0.0732  lr: 0.004  max_mem: 11812M
[11/17 09:41:12] d2.utils.events INFO:  eta: 2:58:20  iter: 21299  total_loss: 0.275  loss_cls: 0.1422  loss_box_reg: 0.08964  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.01866  time: 0.6813  data_time: 0.0693  lr: 0.004  max_mem: 11812M
[11/17 09:41:26] d2.utils.events INFO:  eta: 2:58:09  iter: 21319  total_loss: 0.262  loss_cls: 0.1409  loss_box_reg: 0.08867  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.01765  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 09:41:39] d2.utils.events INFO:  eta: 2:57:52  iter: 21339  total_loss: 0.2526  loss_cls: 0.1391  loss_box_reg: 0.08424  loss_rpn_cls: 0.01655  loss_rpn_loc: 0.01747  time: 0.6813  data_time: 0.0696  lr: 0.004  max_mem: 11812M
[11/17 09:41:53] d2.utils.events INFO:  eta: 2:57:35  iter: 21359  total_loss: 0.2584  loss_cls: 0.1409  loss_box_reg: 0.08681  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.01852  time: 0.6813  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 09:42:06] d2.utils.events INFO:  eta: 2:57:12  iter: 21379  total_loss: 0.2626  loss_cls: 0.1424  loss_box_reg: 0.08745  loss_rpn_cls: 0.015  loss_rpn_loc: 0.01733  time: 0.6813  data_time: 0.0654  lr: 0.004  max_mem: 11812M
[11/17 09:42:20] d2.utils.events INFO:  eta: 2:56:51  iter: 21399  total_loss: 0.2744  loss_cls: 0.143  loss_box_reg: 0.09269  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.01883  time: 0.6813  data_time: 0.0623  lr: 0.004  max_mem: 11812M
[11/17 09:42:34] d2.utils.events INFO:  eta: 2:56:35  iter: 21419  total_loss: 0.2523  loss_cls: 0.1309  loss_box_reg: 0.08455  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.01717  time: 0.6813  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 09:42:47] d2.utils.events INFO:  eta: 2:56:19  iter: 21439  total_loss: 0.2554  loss_cls: 0.1345  loss_box_reg: 0.08658  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.01812  time: 0.6813  data_time: 0.0711  lr: 0.004  max_mem: 11812M
[11/17 09:43:01] d2.utils.events INFO:  eta: 2:56:06  iter: 21459  total_loss: 0.2757  loss_cls: 0.1507  loss_box_reg: 0.09015  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.01902  time: 0.6813  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 09:43:15] d2.utils.events INFO:  eta: 2:55:52  iter: 21479  total_loss: 0.2724  loss_cls: 0.1478  loss_box_reg: 0.09022  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.01949  time: 0.6813  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 09:43:28] d2.utils.events INFO:  eta: 2:55:44  iter: 21499  total_loss: 0.2561  loss_cls: 0.1367  loss_box_reg: 0.08543  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01828  time: 0.6813  data_time: 0.0713  lr: 0.004  max_mem: 11812M
[11/17 09:43:42] d2.utils.events INFO:  eta: 2:55:27  iter: 21519  total_loss: 0.26  loss_cls: 0.1414  loss_box_reg: 0.08663  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01754  time: 0.6813  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 09:43:56] d2.utils.events INFO:  eta: 2:55:17  iter: 21539  total_loss: 0.2677  loss_cls: 0.1412  loss_box_reg: 0.08954  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.01896  time: 0.6813  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 09:44:09] d2.utils.events INFO:  eta: 2:55:13  iter: 21559  total_loss: 0.2586  loss_cls: 0.1408  loss_box_reg: 0.08908  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.01799  time: 0.6813  data_time: 0.0619  lr: 0.004  max_mem: 11812M
[11/17 09:44:23] d2.utils.events INFO:  eta: 2:54:44  iter: 21579  total_loss: 0.2574  loss_cls: 0.1396  loss_box_reg: 0.08362  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0663  lr: 0.004  max_mem: 11812M
[11/17 09:44:36] d2.utils.events INFO:  eta: 2:54:31  iter: 21599  total_loss: 0.2675  loss_cls: 0.141  loss_box_reg: 0.08753  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.01759  time: 0.6813  data_time: 0.0734  lr: 0.004  max_mem: 11812M
[11/17 09:44:50] d2.utils.events INFO:  eta: 2:54:14  iter: 21619  total_loss: 0.261  loss_cls: 0.1448  loss_box_reg: 0.0869  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.01815  time: 0.6813  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 09:45:04] d2.utils.events INFO:  eta: 2:54:03  iter: 21639  total_loss: 0.2579  loss_cls: 0.1389  loss_box_reg: 0.08988  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.01898  time: 0.6813  data_time: 0.0691  lr: 0.004  max_mem: 11812M
[11/17 09:45:17] d2.utils.events INFO:  eta: 2:53:50  iter: 21659  total_loss: 0.2514  loss_cls: 0.1329  loss_box_reg: 0.08415  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.0172  time: 0.6813  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 09:45:31] d2.utils.events INFO:  eta: 2:53:32  iter: 21679  total_loss: 0.2642  loss_cls: 0.1415  loss_box_reg: 0.08592  loss_rpn_cls: 0.015  loss_rpn_loc: 0.01783  time: 0.6813  data_time: 0.0685  lr: 0.004  max_mem: 11812M
[11/17 09:45:44] d2.utils.events INFO:  eta: 2:53:16  iter: 21699  total_loss: 0.2576  loss_cls: 0.1392  loss_box_reg: 0.09027  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.01651  time: 0.6813  data_time: 0.0612  lr: 0.004  max_mem: 11812M
[11/17 09:45:58] d2.utils.events INFO:  eta: 2:53:00  iter: 21719  total_loss: 0.2748  loss_cls: 0.144  loss_box_reg: 0.08993  loss_rpn_cls: 0.01845  loss_rpn_loc: 0.02056  time: 0.6813  data_time: 0.0588  lr: 0.004  max_mem: 11812M
[11/17 09:46:12] d2.utils.events INFO:  eta: 2:52:49  iter: 21739  total_loss: 0.2618  loss_cls: 0.1366  loss_box_reg: 0.08766  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.01819  time: 0.6813  data_time: 0.0691  lr: 0.004  max_mem: 11812M
[11/17 09:46:26] d2.utils.events INFO:  eta: 2:52:35  iter: 21759  total_loss: 0.2735  loss_cls: 0.148  loss_box_reg: 0.09089  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.01709  time: 0.6814  data_time: 0.0984  lr: 0.004  max_mem: 11812M
[11/17 09:46:39] d2.utils.events INFO:  eta: 2:52:22  iter: 21779  total_loss: 0.2655  loss_cls: 0.1398  loss_box_reg: 0.08864  loss_rpn_cls: 0.01653  loss_rpn_loc: 0.0194  time: 0.6814  data_time: 0.0690  lr: 0.004  max_mem: 11812M
[11/17 09:46:53] d2.utils.events INFO:  eta: 2:52:08  iter: 21799  total_loss: 0.2681  loss_cls: 0.1422  loss_box_reg: 0.09239  loss_rpn_cls: 0.016  loss_rpn_loc: 0.01794  time: 0.6813  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 09:47:07] d2.utils.events INFO:  eta: 2:51:55  iter: 21819  total_loss: 0.2538  loss_cls: 0.1345  loss_box_reg: 0.08294  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.01934  time: 0.6813  data_time: 0.0708  lr: 0.004  max_mem: 11812M
[11/17 09:47:20] d2.utils.events INFO:  eta: 2:51:38  iter: 21839  total_loss: 0.2518  loss_cls: 0.1351  loss_box_reg: 0.08657  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.01766  time: 0.6814  data_time: 0.0712  lr: 0.004  max_mem: 11812M
[11/17 09:47:34] d2.utils.events INFO:  eta: 2:51:24  iter: 21859  total_loss: 0.2536  loss_cls: 0.1347  loss_box_reg: 0.08843  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01692  time: 0.6813  data_time: 0.0644  lr: 0.004  max_mem: 11812M
[11/17 09:47:47] d2.utils.events INFO:  eta: 2:51:10  iter: 21879  total_loss: 0.2756  loss_cls: 0.1462  loss_box_reg: 0.08806  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.01813  time: 0.6813  data_time: 0.0687  lr: 0.004  max_mem: 11812M
[11/17 09:48:01] d2.utils.events INFO:  eta: 2:50:54  iter: 21899  total_loss: 0.2598  loss_cls: 0.1391  loss_box_reg: 0.08729  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.01767  time: 0.6813  data_time: 0.0684  lr: 0.004  max_mem: 11812M
[11/17 09:48:14] d2.utils.events INFO:  eta: 2:50:37  iter: 21919  total_loss: 0.2732  loss_cls: 0.1477  loss_box_reg: 0.09116  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.0191  time: 0.6813  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 09:48:28] d2.utils.events INFO:  eta: 2:50:27  iter: 21939  total_loss: 0.2802  loss_cls: 0.1478  loss_box_reg: 0.09126  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.01867  time: 0.6813  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 09:48:42] d2.utils.events INFO:  eta: 2:50:14  iter: 21959  total_loss: 0.2574  loss_cls: 0.1404  loss_box_reg: 0.08538  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.01667  time: 0.6813  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 09:48:55] d2.utils.events INFO:  eta: 2:50:00  iter: 21979  total_loss: 0.2652  loss_cls: 0.1418  loss_box_reg: 0.08788  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.01825  time: 0.6813  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 09:49:09] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0021999.pth
[11/17 09:49:09] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 09:49:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 09:49:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 09:49:10] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 09:49:10] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 09:49:10] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 09:49:17] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0426 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:02:26
[11/17 09:49:22] d2.evaluation.evaluator INFO: Inference done 129/3334. Dataloading: 0.0017 s/iter. Inference: 0.0405 s/iter. Eval: 0.0002 s/iter. Total: 0.0425 s/iter. ETA=0:02:16
[11/17 09:49:27] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/17 09:49:32] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/17 09:49:37] d2.evaluation.evaluator INFO: Inference done 492/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:58
[11/17 09:49:42] d2.evaluation.evaluator INFO: Inference done 613/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/17 09:49:47] d2.evaluation.evaluator INFO: Inference done 731/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:48
[11/17 09:49:52] d2.evaluation.evaluator INFO: Inference done 852/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:43
[11/17 09:49:57] d2.evaluation.evaluator INFO: Inference done 972/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:38
[11/17 09:50:02] d2.evaluation.evaluator INFO: Inference done 1091/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:33
[11/17 09:50:07] d2.evaluation.evaluator INFO: Inference done 1211/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/17 09:50:12] d2.evaluation.evaluator INFO: Inference done 1331/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:23
[11/17 09:50:17] d2.evaluation.evaluator INFO: Inference done 1453/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:18
[11/17 09:50:22] d2.evaluation.evaluator INFO: Inference done 1573/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:13
[11/17 09:50:27] d2.evaluation.evaluator INFO: Inference done 1694/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:08
[11/17 09:50:32] d2.evaluation.evaluator INFO: Inference done 1813/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:03
[11/17 09:50:37] d2.evaluation.evaluator INFO: Inference done 1933/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:58
[11/17 09:50:42] d2.evaluation.evaluator INFO: Inference done 2053/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:53
[11/17 09:50:47] d2.evaluation.evaluator INFO: Inference done 2172/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:48
[11/17 09:50:52] d2.evaluation.evaluator INFO: Inference done 2290/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:43
[11/17 09:50:57] d2.evaluation.evaluator INFO: Inference done 2406/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:38
[11/17 09:51:02] d2.evaluation.evaluator INFO: Inference done 2523/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:34
[11/17 09:51:07] d2.evaluation.evaluator INFO: Inference done 2645/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:28
[11/17 09:51:12] d2.evaluation.evaluator INFO: Inference done 2767/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:23
[11/17 09:51:17] d2.evaluation.evaluator INFO: Inference done 2890/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:18
[11/17 09:51:22] d2.evaluation.evaluator INFO: Inference done 3010/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:13
[11/17 09:51:27] d2.evaluation.evaluator INFO: Inference done 3130/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:08
[11/17 09:51:32] d2.evaluation.evaluator INFO: Inference done 3250/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:03
[11/17 09:51:36] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.192493 (0.041812 s / iter per device, on 6 devices)
[11/17 09:51:36] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039849 s / iter per device, on 6 devices)
[11/17 09:51:38] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 09:51:38] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 09:51:39] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 09:51:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 09:52:03] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.78 seconds.
[11/17 09:52:03] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 09:52:05] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.85 seconds.
[11/17 09:52:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.268 | 10.156 | 2.775  | 0.721 | 2.037 | 5.075 |
[11/17 09:52:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 5.095  | person      | 4.633  | bird                  | 14.175 |
| red panda            | 2.967  | dog         | 33.458 | snake                 | 4.705  |
| car                  | 21.665 | seal        | 1.089  | helmet                | 5.286  |
| motorcycle           | 7.549  | swine       | 3.824  | stove                 | 4.501  |
| monkey               | 4.983  | watercraft  | 12.807 | chair                 | 2.384  |
| domestic cat         | 3.990  | harp        | 3.622  | antelope              | 7.269  |
| camel                | 1.373  | koala bear  | 3.204  | bus                   | 12.801 |
| hat with a wide brim | 1.299  | ski         | 0.091  | piano                 | 6.461  |
| frog                 | 4.692  | dumbbell    | 0.042  | lobster               | 1.992  |
| bench                | 0.260  | rabbit      | 6.545  | porcupine             | 5.222  |
| butterfly            | 14.383 | guitar      | 2.017  | microphone            | 0.000  |
| tape player          | 5.017  | bear        | 5.726  | hippopotamus          | 0.109  |
| bowl                 | 3.635  | axe         | 0.848  | skunk                 | 0.622  |
| airplane             | 8.849  | otter       | 1.886  | table                 | 3.756  |
| coffee maker         | 12.380 | tie         | 0.153  | turtle                | 2.529  |
| purse                | 2.509  | dragonfly   | 2.311  | lemon                 | 3.493  |
| lizard               | 3.176  | backpack    | 1.960  | tv or monitor         | 8.157  |
| cup or mug           | 1.310  | sheep       | 0.912  | ray                   | 1.041  |
| fox                  | 3.064  | whale       | 4.482  | salt or pepper shaker | 0.267  |
| computer keyboard    | 1.468  | fig         | 0.587  | bathing cap           | 1.026  |
| bookshelf            | 6.740  | ladybug     | 20.935 | crutch                | 0.040  |
| pretzel              | 3.877  | sunglasses  | 0.048  | starfish              | 4.021  |
| croquet ball         | 4.344  | lamp        | 0.826  | apple                 | 10.029 |
| cream                | 4.927  | artichoke   | 5.512  | train                 | 4.807  |
| elephant             | 6.240  | bell pepper | 2.944  | miniskirt             | 0.263  |
| orange               | 7.396  | tiger       | 0.822  | sofa                  | 1.782  |
| horse                | 3.516  | violin      | 0.208  | traffic light         | 1.405  |
| drum                 | 0.755  | strawberry  | 5.894  | laptop                | 4.672  |
| pomegranate          | 1.262  | cucumber    | 0.391  | bicycle               | 2.824  |
| banana               | 0.299  | baby bed    | 6.966  | jellyfish             | 3.251  |
| pitcher              | 0.624  | bagel       | 1.633  | beaker                | 3.265  |
| goldfish             | 3.397  | nail        | 0.000  | mushroom              | 1.090  |
| flower pot           | 0.434  | cattle      | 1.407  | zebra                 | 10.750 |
| wine bottle          | 1.519  |             |        |                       |        |
[11/17 09:52:08] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 09:52:08] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 09:52:08] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 09:52:08] d2.evaluation.testing INFO: copypaste: 4.2678,10.1564,2.7751,0.7212,2.0373,5.0751
[11/17 09:52:08] d2.utils.events INFO:  eta: 2:49:45  iter: 21999  total_loss: 0.2759  loss_cls: 0.1409  loss_box_reg: 0.09245  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.01957  time: 0.6813  data_time: 0.0600  lr: 0.004  max_mem: 11812M
[11/17 09:52:21] d2.utils.events INFO:  eta: 2:49:36  iter: 22019  total_loss: 0.2588  loss_cls: 0.1332  loss_box_reg: 0.08618  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.01646  time: 0.6813  data_time: 0.0707  lr: 0.004  max_mem: 11812M
[11/17 09:52:35] d2.utils.events INFO:  eta: 2:49:23  iter: 22039  total_loss: 0.2696  loss_cls: 0.1478  loss_box_reg: 0.09181  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.01747  time: 0.6813  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 09:52:49] d2.utils.events INFO:  eta: 2:49:08  iter: 22059  total_loss: 0.2555  loss_cls: 0.1367  loss_box_reg: 0.09085  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01721  time: 0.6813  data_time: 0.0877  lr: 0.004  max_mem: 11812M
[11/17 09:53:02] d2.utils.events INFO:  eta: 2:48:54  iter: 22079  total_loss: 0.2564  loss_cls: 0.1347  loss_box_reg: 0.08775  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.01787  time: 0.6813  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 09:53:16] d2.utils.events INFO:  eta: 2:48:37  iter: 22099  total_loss: 0.2592  loss_cls: 0.1453  loss_box_reg: 0.08932  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01875  time: 0.6813  data_time: 0.0624  lr: 0.004  max_mem: 11812M
[11/17 09:53:29] d2.utils.events INFO:  eta: 2:48:24  iter: 22119  total_loss: 0.2536  loss_cls: 0.1332  loss_box_reg: 0.08649  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.01909  time: 0.6813  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 09:53:43] d2.utils.events INFO:  eta: 2:48:11  iter: 22139  total_loss: 0.2638  loss_cls: 0.1363  loss_box_reg: 0.0899  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.01906  time: 0.6813  data_time: 0.0733  lr: 0.004  max_mem: 11812M
[11/17 09:53:57] d2.utils.events INFO:  eta: 2:47:57  iter: 22159  total_loss: 0.2568  loss_cls: 0.1397  loss_box_reg: 0.08666  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01733  time: 0.6813  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 09:54:10] d2.utils.events INFO:  eta: 2:47:44  iter: 22179  total_loss: 0.2593  loss_cls: 0.1394  loss_box_reg: 0.08422  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.01955  time: 0.6813  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 09:54:24] d2.utils.events INFO:  eta: 2:47:34  iter: 22199  total_loss: 0.2642  loss_cls: 0.1395  loss_box_reg: 0.08772  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.01754  time: 0.6813  data_time: 0.0744  lr: 0.004  max_mem: 11812M
[11/17 09:54:38] d2.utils.events INFO:  eta: 2:47:23  iter: 22219  total_loss: 0.2771  loss_cls: 0.1467  loss_box_reg: 0.0892  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.01977  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 09:54:52] d2.utils.events INFO:  eta: 2:47:09  iter: 22239  total_loss: 0.2572  loss_cls: 0.1383  loss_box_reg: 0.08304  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.01757  time: 0.6813  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 09:55:05] d2.utils.events INFO:  eta: 2:46:59  iter: 22259  total_loss: 0.2629  loss_cls: 0.1452  loss_box_reg: 0.08731  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.01679  time: 0.6814  data_time: 0.0684  lr: 0.004  max_mem: 11812M
[11/17 09:55:19] d2.utils.events INFO:  eta: 2:46:45  iter: 22279  total_loss: 0.2628  loss_cls: 0.1409  loss_box_reg: 0.09083  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.0185  time: 0.6814  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 09:55:33] d2.utils.events INFO:  eta: 2:46:29  iter: 22299  total_loss: 0.2597  loss_cls: 0.1373  loss_box_reg: 0.08477  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.01791  time: 0.6814  data_time: 0.0704  lr: 0.004  max_mem: 11812M
[11/17 09:55:46] d2.utils.events INFO:  eta: 2:46:12  iter: 22319  total_loss: 0.2706  loss_cls: 0.1394  loss_box_reg: 0.08734  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.01797  time: 0.6814  data_time: 0.0639  lr: 0.004  max_mem: 11812M
[11/17 09:56:00] d2.utils.events INFO:  eta: 2:45:57  iter: 22339  total_loss: 0.2602  loss_cls: 0.1403  loss_box_reg: 0.08712  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.01696  time: 0.6814  data_time: 0.0760  lr: 0.004  max_mem: 11812M
[11/17 09:56:13] d2.utils.events INFO:  eta: 2:45:42  iter: 22359  total_loss: 0.2677  loss_cls: 0.1429  loss_box_reg: 0.08743  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.0175  time: 0.6813  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 09:56:27] d2.utils.events INFO:  eta: 2:45:31  iter: 22379  total_loss: 0.282  loss_cls: 0.1484  loss_box_reg: 0.09314  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.01987  time: 0.6814  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 09:56:41] d2.utils.events INFO:  eta: 2:45:22  iter: 22399  total_loss: 0.2662  loss_cls: 0.1431  loss_box_reg: 0.09052  loss_rpn_cls: 0.0157  loss_rpn_loc: 0.01867  time: 0.6814  data_time: 0.0729  lr: 0.004  max_mem: 11812M
[11/17 09:56:55] d2.utils.events INFO:  eta: 2:45:09  iter: 22419  total_loss: 0.2685  loss_cls: 0.1439  loss_box_reg: 0.09162  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01725  time: 0.6814  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 09:57:08] d2.utils.events INFO:  eta: 2:44:54  iter: 22439  total_loss: 0.2648  loss_cls: 0.1409  loss_box_reg: 0.09127  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.01577  time: 0.6814  data_time: 0.0620  lr: 0.004  max_mem: 11812M
[11/17 09:57:22] d2.utils.events INFO:  eta: 2:44:35  iter: 22459  total_loss: 0.2469  loss_cls: 0.1286  loss_box_reg: 0.08387  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.01883  time: 0.6813  data_time: 0.0595  lr: 0.004  max_mem: 11812M
[11/17 09:57:35] d2.utils.events INFO:  eta: 2:44:22  iter: 22479  total_loss: 0.2634  loss_cls: 0.1421  loss_box_reg: 0.09084  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01695  time: 0.6813  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 09:57:49] d2.utils.events INFO:  eta: 2:44:11  iter: 22499  total_loss: 0.2611  loss_cls: 0.1384  loss_box_reg: 0.0859  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.01962  time: 0.6813  data_time: 0.0696  lr: 0.004  max_mem: 11812M
[11/17 09:58:02] d2.utils.events INFO:  eta: 2:43:58  iter: 22519  total_loss: 0.2646  loss_cls: 0.1421  loss_box_reg: 0.09046  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.01825  time: 0.6813  data_time: 0.0646  lr: 0.004  max_mem: 11812M
[11/17 09:58:16] d2.utils.events INFO:  eta: 2:43:46  iter: 22539  total_loss: 0.2719  loss_cls: 0.1457  loss_box_reg: 0.09144  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.01832  time: 0.6813  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 09:58:29] d2.utils.events INFO:  eta: 2:43:33  iter: 22559  total_loss: 0.2744  loss_cls: 0.1481  loss_box_reg: 0.09141  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.01857  time: 0.6813  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 09:58:43] d2.utils.events INFO:  eta: 2:43:21  iter: 22579  total_loss: 0.2623  loss_cls: 0.1367  loss_box_reg: 0.08922  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.01797  time: 0.6813  data_time: 0.0693  lr: 0.004  max_mem: 11812M
[11/17 09:58:57] d2.utils.events INFO:  eta: 2:43:07  iter: 22599  total_loss: 0.2615  loss_cls: 0.1424  loss_box_reg: 0.08898  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01819  time: 0.6813  data_time: 0.0691  lr: 0.004  max_mem: 11812M
[11/17 09:59:11] d2.utils.events INFO:  eta: 2:42:54  iter: 22619  total_loss: 0.2637  loss_cls: 0.1466  loss_box_reg: 0.08646  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.01705  time: 0.6813  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 09:59:24] d2.utils.events INFO:  eta: 2:42:40  iter: 22639  total_loss: 0.2507  loss_cls: 0.1388  loss_box_reg: 0.08259  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.01686  time: 0.6813  data_time: 0.0753  lr: 0.004  max_mem: 11812M
[11/17 09:59:38] d2.utils.events INFO:  eta: 2:42:26  iter: 22659  total_loss: 0.2648  loss_cls: 0.1439  loss_box_reg: 0.08785  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.01839  time: 0.6813  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 09:59:51] d2.utils.events INFO:  eta: 2:42:11  iter: 22679  total_loss: 0.2573  loss_cls: 0.1349  loss_box_reg: 0.09093  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01668  time: 0.6813  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 10:00:05] d2.utils.events INFO:  eta: 2:41:57  iter: 22699  total_loss: 0.2448  loss_cls: 0.1289  loss_box_reg: 0.08478  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.01863  time: 0.6813  data_time: 0.0768  lr: 0.004  max_mem: 11812M
[11/17 10:00:19] d2.utils.events INFO:  eta: 2:41:44  iter: 22719  total_loss: 0.2582  loss_cls: 0.1395  loss_box_reg: 0.08882  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01767  time: 0.6813  data_time: 0.0810  lr: 0.004  max_mem: 11812M
[11/17 10:00:32] d2.utils.events INFO:  eta: 2:41:28  iter: 22739  total_loss: 0.2577  loss_cls: 0.1362  loss_box_reg: 0.08532  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01739  time: 0.6813  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 10:00:46] d2.utils.events INFO:  eta: 2:41:15  iter: 22759  total_loss: 0.2595  loss_cls: 0.1364  loss_box_reg: 0.08785  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01641  time: 0.6813  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 10:00:59] d2.utils.events INFO:  eta: 2:41:03  iter: 22779  total_loss: 0.2603  loss_cls: 0.1355  loss_box_reg: 0.08695  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.0197  time: 0.6813  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 10:01:13] d2.utils.events INFO:  eta: 2:40:51  iter: 22799  total_loss: 0.2602  loss_cls: 0.1395  loss_box_reg: 0.08827  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01981  time: 0.6813  data_time: 0.0577  lr: 0.004  max_mem: 11812M
[11/17 10:01:27] d2.utils.events INFO:  eta: 2:40:37  iter: 22819  total_loss: 0.2821  loss_cls: 0.1521  loss_box_reg: 0.09046  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.01984  time: 0.6813  data_time: 0.0654  lr: 0.004  max_mem: 11812M
[11/17 10:01:40] d2.utils.events INFO:  eta: 2:40:26  iter: 22839  total_loss: 0.2703  loss_cls: 0.1431  loss_box_reg: 0.09178  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.01931  time: 0.6813  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 10:01:54] d2.utils.events INFO:  eta: 2:40:10  iter: 22859  total_loss: 0.2456  loss_cls: 0.1282  loss_box_reg: 0.08364  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.01763  time: 0.6813  data_time: 0.0713  lr: 0.004  max_mem: 11812M
[11/17 10:02:08] d2.utils.events INFO:  eta: 2:40:00  iter: 22879  total_loss: 0.2605  loss_cls: 0.1369  loss_box_reg: 0.09091  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.01732  time: 0.6813  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 10:02:21] d2.utils.events INFO:  eta: 2:39:46  iter: 22899  total_loss: 0.2678  loss_cls: 0.1428  loss_box_reg: 0.08948  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.01889  time: 0.6813  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 10:02:35] d2.utils.events INFO:  eta: 2:39:33  iter: 22919  total_loss: 0.2587  loss_cls: 0.1378  loss_box_reg: 0.08559  loss_rpn_cls: 0.01548  loss_rpn_loc: 0.01812  time: 0.6813  data_time: 0.0775  lr: 0.004  max_mem: 11812M
[11/17 10:02:49] d2.utils.events INFO:  eta: 2:39:16  iter: 22939  total_loss: 0.2515  loss_cls: 0.1353  loss_box_reg: 0.08351  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01671  time: 0.6814  data_time: 0.0787  lr: 0.004  max_mem: 11812M
[11/17 10:03:02] d2.utils.events INFO:  eta: 2:39:04  iter: 22959  total_loss: 0.267  loss_cls: 0.1445  loss_box_reg: 0.09052  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.0181  time: 0.6814  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 10:03:16] d2.utils.events INFO:  eta: 2:38:49  iter: 22979  total_loss: 0.2649  loss_cls: 0.1395  loss_box_reg: 0.089  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.01872  time: 0.6813  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 10:03:29] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0022999.pth
[11/17 10:03:30] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 10:03:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 10:03:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 10:03:30] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 10:03:31] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 10:03:31] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 10:03:38] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0013 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:17
[11/17 10:03:43] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:12
[11/17 10:03:48] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/17 10:03:53] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:02
[11/17 10:03:58] d2.evaluation.evaluator INFO: Inference done 494/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:57
[11/17 10:04:03] d2.evaluation.evaluator INFO: Inference done 614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:53
[11/17 10:04:08] d2.evaluation.evaluator INFO: Inference done 732/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:48
[11/17 10:04:13] d2.evaluation.evaluator INFO: Inference done 853/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:43
[11/17 10:04:18] d2.evaluation.evaluator INFO: Inference done 971/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:38
[11/17 10:04:23] d2.evaluation.evaluator INFO: Inference done 1090/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/17 10:04:28] d2.evaluation.evaluator INFO: Inference done 1209/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/17 10:04:33] d2.evaluation.evaluator INFO: Inference done 1328/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:23
[11/17 10:04:38] d2.evaluation.evaluator INFO: Inference done 1449/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:18
[11/17 10:04:43] d2.evaluation.evaluator INFO: Inference done 1573/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/17 10:04:48] d2.evaluation.evaluator INFO: Inference done 1698/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:08
[11/17 10:04:53] d2.evaluation.evaluator INFO: Inference done 1820/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/17 10:04:58] d2.evaluation.evaluator INFO: Inference done 1944/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/17 10:05:03] d2.evaluation.evaluator INFO: Inference done 2065/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/17 10:05:08] d2.evaluation.evaluator INFO: Inference done 2186/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:47
[11/17 10:05:13] d2.evaluation.evaluator INFO: Inference done 2304/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/17 10:05:18] d2.evaluation.evaluator INFO: Inference done 2426/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/17 10:05:23] d2.evaluation.evaluator INFO: Inference done 2544/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/17 10:05:28] d2.evaluation.evaluator INFO: Inference done 2665/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/17 10:05:33] d2.evaluation.evaluator INFO: Inference done 2788/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/17 10:05:38] d2.evaluation.evaluator INFO: Inference done 2908/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/17 10:05:43] d2.evaluation.evaluator INFO: Inference done 3029/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 10:05:48] d2.evaluation.evaluator INFO: Inference done 3151/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/17 10:05:53] d2.evaluation.evaluator INFO: Inference done 3275/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/17 10:05:55] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.983822 (0.041449 s / iter per device, on 6 devices)
[11/17 10:05:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039542 s / iter per device, on 6 devices)
[11/17 10:05:58] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 10:05:58] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 10:05:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 10:06:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 10:06:25] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.90 seconds.
[11/17 10:06:25] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 10:06:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.96 seconds.
[11/17 10:06:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 4.456 | 10.384 | 3.056  | 0.893 | 2.063 | 5.262 |
[11/17 10:06:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 4.400  | person      | 5.002  | bird                  | 15.562 |
| red panda            | 3.981  | dog         | 34.665 | snake                 | 4.113  |
| car                  | 22.188 | seal        | 0.718  | helmet                | 3.878  |
| motorcycle           | 6.414  | swine       | 3.922  | stove                 | 6.523  |
| monkey               | 5.579  | watercraft  | 13.999 | chair                 | 2.851  |
| domestic cat         | 4.197  | harp        | 3.467  | antelope              | 8.189  |
| camel                | 1.699  | koala bear  | 4.364  | bus                   | 14.261 |
| hat with a wide brim | 1.453  | ski         | 0.595  | piano                 | 6.993  |
| frog                 | 4.818  | dumbbell    | 0.001  | lobster               | 1.826  |
| bench                | 0.952  | rabbit      | 6.302  | porcupine             | 5.507  |
| butterfly            | 14.535 | guitar      | 1.703  | microphone            | 0.010  |
| tape player          | 5.218  | bear        | 5.461  | hippopotamus          | 0.323  |
| bowl                 | 3.209  | axe         | 0.865  | skunk                 | 0.633  |
| airplane             | 10.879 | otter       | 1.640  | table                 | 3.418  |
| coffee maker         | 11.601 | tie         | 0.180  | turtle                | 2.366  |
| purse                | 2.603  | dragonfly   | 2.014  | lemon                 | 5.629  |
| lizard               | 2.256  | backpack    | 3.334  | tv or monitor         | 9.086  |
| cup or mug           | 1.708  | sheep       | 2.731  | ray                   | 0.837  |
| fox                  | 2.255  | whale       | 4.766  | salt or pepper shaker | 0.223  |
| computer keyboard    | 0.617  | fig         | 1.712  | bathing cap           | 1.162  |
| bookshelf            | 5.765  | ladybug     | 20.714 | crutch                | 0.027  |
| pretzel              | 2.962  | sunglasses  | 0.084  | starfish              | 4.197  |
| croquet ball         | 4.925  | lamp        | 1.175  | apple                 | 10.383 |
| cream                | 5.536  | artichoke   | 8.369  | train                 | 4.753  |
| elephant             | 6.224  | bell pepper | 4.433  | miniskirt             | 0.513  |
| orange               | 6.572  | tiger       | 1.036  | sofa                  | 1.546  |
| horse                | 4.118  | violin      | 0.223  | traffic light         | 1.127  |
| drum                 | 0.458  | strawberry  | 4.527  | laptop                | 4.270  |
| pomegranate          | 2.900  | cucumber    | 0.219  | bicycle               | 2.463  |
| banana               | 0.380  | baby bed    | 7.400  | jellyfish             | 3.601  |
| pitcher              | 0.598  | bagel       | 2.023  | beaker                | 3.030  |
| goldfish             | 3.207  | nail        | 0.000  | mushroom              | 1.760  |
| flower pot           | 0.300  | cattle      | 1.141  | zebra                 | 10.091 |
| wine bottle          | 1.130  |             |        |                       |        |
[11/17 10:06:29] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 10:06:29] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 10:06:29] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 10:06:29] d2.evaluation.testing INFO: copypaste: 4.4558,10.3840,3.0559,0.8927,2.0629,5.2622
[11/17 10:06:29] d2.utils.events INFO:  eta: 2:38:36  iter: 22999  total_loss: 0.2769  loss_cls: 0.1499  loss_box_reg: 0.0896  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.01898  time: 0.6813  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 10:06:43] d2.utils.events INFO:  eta: 2:38:23  iter: 23019  total_loss: 0.2649  loss_cls: 0.1433  loss_box_reg: 0.09012  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0722  lr: 0.004  max_mem: 11812M
[11/17 10:06:57] d2.utils.events INFO:  eta: 2:38:09  iter: 23039  total_loss: 0.2686  loss_cls: 0.1462  loss_box_reg: 0.09199  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01854  time: 0.6813  data_time: 0.0623  lr: 0.004  max_mem: 11812M
[11/17 10:07:10] d2.utils.events INFO:  eta: 2:37:55  iter: 23059  total_loss: 0.2689  loss_cls: 0.145  loss_box_reg: 0.09055  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.01709  time: 0.6813  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 10:07:24] d2.utils.events INFO:  eta: 2:37:42  iter: 23079  total_loss: 0.2521  loss_cls: 0.1357  loss_box_reg: 0.08654  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.01737  time: 0.6813  data_time: 0.0683  lr: 0.004  max_mem: 11812M
[11/17 10:07:38] d2.utils.events INFO:  eta: 2:37:31  iter: 23099  total_loss: 0.2535  loss_cls: 0.1327  loss_box_reg: 0.08633  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.01706  time: 0.6814  data_time: 0.0926  lr: 0.004  max_mem: 11812M
[11/17 10:07:52] d2.utils.events INFO:  eta: 2:37:20  iter: 23119  total_loss: 0.2548  loss_cls: 0.1378  loss_box_reg: 0.08469  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.0171  time: 0.6814  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 10:08:05] d2.utils.events INFO:  eta: 2:37:06  iter: 23139  total_loss: 0.2455  loss_cls: 0.1311  loss_box_reg: 0.08495  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.01808  time: 0.6814  data_time: 0.0634  lr: 0.004  max_mem: 11812M
[11/17 10:08:19] d2.utils.events INFO:  eta: 2:36:51  iter: 23159  total_loss: 0.261  loss_cls: 0.1353  loss_box_reg: 0.08735  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.01831  time: 0.6813  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 10:08:32] d2.utils.events INFO:  eta: 2:36:36  iter: 23179  total_loss: 0.2535  loss_cls: 0.134  loss_box_reg: 0.08519  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01758  time: 0.6813  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 10:08:46] d2.utils.events INFO:  eta: 2:36:20  iter: 23199  total_loss: 0.2582  loss_cls: 0.1396  loss_box_reg: 0.08615  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.01818  time: 0.6814  data_time: 0.0902  lr: 0.004  max_mem: 11812M
[11/17 10:09:00] d2.utils.events INFO:  eta: 2:36:06  iter: 23219  total_loss: 0.2686  loss_cls: 0.1421  loss_box_reg: 0.09365  loss_rpn_cls: 0.01691  loss_rpn_loc: 0.01803  time: 0.6814  data_time: 0.0688  lr: 0.004  max_mem: 11812M
[11/17 10:09:14] d2.utils.events INFO:  eta: 2:35:52  iter: 23239  total_loss: 0.2582  loss_cls: 0.1367  loss_box_reg: 0.08279  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.01935  time: 0.6814  data_time: 0.0750  lr: 0.004  max_mem: 11812M
[11/17 10:09:27] d2.utils.events INFO:  eta: 2:35:38  iter: 23259  total_loss: 0.2511  loss_cls: 0.13  loss_box_reg: 0.08662  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.01814  time: 0.6814  data_time: 0.0704  lr: 0.004  max_mem: 11812M
[11/17 10:09:41] d2.utils.events INFO:  eta: 2:35:24  iter: 23279  total_loss: 0.2638  loss_cls: 0.141  loss_box_reg: 0.08793  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.01751  time: 0.6814  data_time: 0.0727  lr: 0.004  max_mem: 11812M
[11/17 10:09:55] d2.utils.events INFO:  eta: 2:35:10  iter: 23299  total_loss: 0.2685  loss_cls: 0.1434  loss_box_reg: 0.08837  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.01928  time: 0.6814  data_time: 0.0729  lr: 0.004  max_mem: 11812M
[11/17 10:10:08] d2.utils.events INFO:  eta: 2:34:56  iter: 23319  total_loss: 0.2631  loss_cls: 0.1367  loss_box_reg: 0.08727  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.01775  time: 0.6814  data_time: 0.0607  lr: 0.004  max_mem: 11812M
[11/17 10:10:21] d2.utils.events INFO:  eta: 2:34:44  iter: 23339  total_loss: 0.2502  loss_cls: 0.1333  loss_box_reg: 0.0862  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.01865  time: 0.6813  data_time: 0.0654  lr: 0.004  max_mem: 11812M
[11/17 10:10:35] d2.utils.events INFO:  eta: 2:34:30  iter: 23359  total_loss: 0.2597  loss_cls: 0.1423  loss_box_reg: 0.08297  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.01878  time: 0.6813  data_time: 0.0642  lr: 0.004  max_mem: 11812M
[11/17 10:10:49] d2.utils.events INFO:  eta: 2:34:15  iter: 23379  total_loss: 0.2671  loss_cls: 0.1417  loss_box_reg: 0.09015  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.01708  time: 0.6813  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 10:11:02] d2.utils.events INFO:  eta: 2:33:59  iter: 23399  total_loss: 0.265  loss_cls: 0.1438  loss_box_reg: 0.08919  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.01739  time: 0.6813  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 10:11:16] d2.utils.events INFO:  eta: 2:33:42  iter: 23419  total_loss: 0.2771  loss_cls: 0.1479  loss_box_reg: 0.09352  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0599  lr: 0.004  max_mem: 11812M
[11/17 10:11:29] d2.utils.events INFO:  eta: 2:33:29  iter: 23439  total_loss: 0.2517  loss_cls: 0.1398  loss_box_reg: 0.08533  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 10:11:43] d2.utils.events INFO:  eta: 2:33:18  iter: 23459  total_loss: 0.2578  loss_cls: 0.1408  loss_box_reg: 0.08575  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.01688  time: 0.6813  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 10:11:57] d2.utils.events INFO:  eta: 2:33:04  iter: 23479  total_loss: 0.2808  loss_cls: 0.1489  loss_box_reg: 0.09482  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.01815  time: 0.6813  data_time: 0.0788  lr: 0.004  max_mem: 11812M
[11/17 10:12:10] d2.utils.events INFO:  eta: 2:32:49  iter: 23499  total_loss: 0.2589  loss_cls: 0.1363  loss_box_reg: 0.08491  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.01838  time: 0.6813  data_time: 0.0715  lr: 0.004  max_mem: 11812M
[11/17 10:12:24] d2.utils.events INFO:  eta: 2:32:36  iter: 23519  total_loss: 0.2762  loss_cls: 0.1489  loss_box_reg: 0.09431  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01669  time: 0.6813  data_time: 0.0729  lr: 0.004  max_mem: 11812M
[11/17 10:12:38] d2.utils.events INFO:  eta: 2:32:21  iter: 23539  total_loss: 0.2612  loss_cls: 0.1374  loss_box_reg: 0.08671  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.01708  time: 0.6813  data_time: 0.0749  lr: 0.004  max_mem: 11812M
[11/17 10:12:51] d2.utils.events INFO:  eta: 2:32:07  iter: 23559  total_loss: 0.2595  loss_cls: 0.1367  loss_box_reg: 0.08483  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.01761  time: 0.6813  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 10:13:05] d2.utils.events INFO:  eta: 2:31:58  iter: 23579  total_loss: 0.2579  loss_cls: 0.1394  loss_box_reg: 0.0877  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.01718  time: 0.6813  data_time: 0.0807  lr: 0.004  max_mem: 11812M
[11/17 10:13:19] d2.utils.events INFO:  eta: 2:31:44  iter: 23599  total_loss: 0.2744  loss_cls: 0.1447  loss_box_reg: 0.09455  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.0178  time: 0.6813  data_time: 0.0693  lr: 0.004  max_mem: 11812M
[11/17 10:13:32] d2.utils.events INFO:  eta: 2:31:28  iter: 23619  total_loss: 0.2568  loss_cls: 0.1354  loss_box_reg: 0.08611  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01723  time: 0.6813  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 10:13:46] d2.utils.events INFO:  eta: 2:31:14  iter: 23639  total_loss: 0.2671  loss_cls: 0.1438  loss_box_reg: 0.08782  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.01787  time: 0.6813  data_time: 0.0718  lr: 0.004  max_mem: 11812M
[11/17 10:13:59] d2.utils.events INFO:  eta: 2:31:03  iter: 23659  total_loss: 0.263  loss_cls: 0.1408  loss_box_reg: 0.09012  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.01807  time: 0.6813  data_time: 0.0747  lr: 0.004  max_mem: 11812M
[11/17 10:14:13] d2.utils.events INFO:  eta: 2:30:53  iter: 23679  total_loss: 0.2491  loss_cls: 0.1336  loss_box_reg: 0.08562  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.01614  time: 0.6813  data_time: 0.0672  lr: 0.004  max_mem: 11812M
[11/17 10:14:27] d2.utils.events INFO:  eta: 2:30:41  iter: 23699  total_loss: 0.272  loss_cls: 0.1447  loss_box_reg: 0.08996  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.0219  time: 0.6813  data_time: 0.0698  lr: 0.004  max_mem: 11812M
[11/17 10:14:40] d2.utils.events INFO:  eta: 2:30:23  iter: 23719  total_loss: 0.2663  loss_cls: 0.1406  loss_box_reg: 0.08989  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.02025  time: 0.6813  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 10:14:54] d2.utils.events INFO:  eta: 2:30:08  iter: 23739  total_loss: 0.2654  loss_cls: 0.1413  loss_box_reg: 0.09164  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.01714  time: 0.6813  data_time: 0.0731  lr: 0.004  max_mem: 11812M
[11/17 10:15:08] d2.utils.events INFO:  eta: 2:29:56  iter: 23759  total_loss: 0.2518  loss_cls: 0.1326  loss_box_reg: 0.08694  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.01721  time: 0.6813  data_time: 0.0639  lr: 0.004  max_mem: 11812M
[11/17 10:15:21] d2.utils.events INFO:  eta: 2:29:43  iter: 23779  total_loss: 0.2407  loss_cls: 0.1284  loss_box_reg: 0.08421  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.01794  time: 0.6813  data_time: 0.0621  lr: 0.004  max_mem: 11812M
[11/17 10:15:35] d2.utils.events INFO:  eta: 2:29:24  iter: 23799  total_loss: 0.247  loss_cls: 0.1308  loss_box_reg: 0.08739  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01712  time: 0.6813  data_time: 0.0706  lr: 0.004  max_mem: 11812M
[11/17 10:15:48] d2.utils.events INFO:  eta: 2:29:07  iter: 23819  total_loss: 0.2488  loss_cls: 0.1353  loss_box_reg: 0.08371  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.01748  time: 0.6813  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 10:16:02] d2.utils.events INFO:  eta: 2:28:51  iter: 23839  total_loss: 0.264  loss_cls: 0.1379  loss_box_reg: 0.08709  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.01679  time: 0.6813  data_time: 0.0602  lr: 0.004  max_mem: 11812M
[11/17 10:16:15] d2.utils.events INFO:  eta: 2:28:39  iter: 23859  total_loss: 0.2538  loss_cls: 0.1379  loss_box_reg: 0.08647  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01736  time: 0.6813  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 10:16:29] d2.utils.events INFO:  eta: 2:28:25  iter: 23879  total_loss: 0.2479  loss_cls: 0.1324  loss_box_reg: 0.08569  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.01791  time: 0.6813  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 10:16:42] d2.utils.events INFO:  eta: 2:28:12  iter: 23899  total_loss: 0.2483  loss_cls: 0.1291  loss_box_reg: 0.08374  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.01759  time: 0.6812  data_time: 0.0598  lr: 0.004  max_mem: 11812M
[11/17 10:16:56] d2.utils.events INFO:  eta: 2:28:03  iter: 23919  total_loss: 0.2436  loss_cls: 0.1302  loss_box_reg: 0.08226  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01742  time: 0.6813  data_time: 0.0759  lr: 0.004  max_mem: 11812M
[11/17 10:17:10] d2.utils.events INFO:  eta: 2:27:51  iter: 23939  total_loss: 0.2608  loss_cls: 0.1405  loss_box_reg: 0.08584  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01851  time: 0.6813  data_time: 0.0737  lr: 0.004  max_mem: 11812M
[11/17 10:17:23] d2.utils.events INFO:  eta: 2:27:36  iter: 23959  total_loss: 0.2614  loss_cls: 0.1395  loss_box_reg: 0.08849  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.01823  time: 0.6813  data_time: 0.0625  lr: 0.004  max_mem: 11812M
[11/17 10:17:37] d2.utils.events INFO:  eta: 2:27:27  iter: 23979  total_loss: 0.2497  loss_cls: 0.1301  loss_box_reg: 0.08412  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.01899  time: 0.6813  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 10:17:51] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0023999.pth
[11/17 10:17:51] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 10:17:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 10:17:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 10:17:52] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 10:17:52] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 10:17:52] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 10:17:59] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0032 s/iter. Inference: 0.0406 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:02:26
[11/17 10:18:04] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0018 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/17 10:18:09] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0017 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/17 10:18:14] d2.evaluation.evaluator INFO: Inference done 373/3334. Dataloading: 0.0017 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/17 10:18:19] d2.evaluation.evaluator INFO: Inference done 498/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/17 10:18:24] d2.evaluation.evaluator INFO: Inference done 620/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:51
[11/17 10:18:29] d2.evaluation.evaluator INFO: Inference done 740/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/17 10:18:34] d2.evaluation.evaluator INFO: Inference done 863/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:42
[11/17 10:18:39] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:37
[11/17 10:18:44] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:31
[11/17 10:18:49] d2.evaluation.evaluator INFO: Inference done 1227/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:27
[11/17 10:18:54] d2.evaluation.evaluator INFO: Inference done 1349/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:21
[11/17 10:18:59] d2.evaluation.evaluator INFO: Inference done 1468/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/17 10:19:04] d2.evaluation.evaluator INFO: Inference done 1591/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:12
[11/17 10:19:09] d2.evaluation.evaluator INFO: Inference done 1712/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/17 10:19:14] d2.evaluation.evaluator INFO: Inference done 1833/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:02
[11/17 10:19:19] d2.evaluation.evaluator INFO: Inference done 1958/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/17 10:19:24] d2.evaluation.evaluator INFO: Inference done 2080/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/17 10:19:29] d2.evaluation.evaluator INFO: Inference done 2202/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/17 10:19:34] d2.evaluation.evaluator INFO: Inference done 2325/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:41
[11/17 10:19:39] d2.evaluation.evaluator INFO: Inference done 2448/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/17 10:19:44] d2.evaluation.evaluator INFO: Inference done 2570/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:31
[11/17 10:19:49] d2.evaluation.evaluator INFO: Inference done 2690/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:26
[11/17 10:19:54] d2.evaluation.evaluator INFO: Inference done 2812/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:21
[11/17 10:19:59] d2.evaluation.evaluator INFO: Inference done 2933/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:16
[11/17 10:20:04] d2.evaluation.evaluator INFO: Inference done 3053/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:11
[11/17 10:20:09] d2.evaluation.evaluator INFO: Inference done 3173/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/17 10:20:14] d2.evaluation.evaluator INFO: Inference done 3291/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/17 10:20:16] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.774051 (0.041386 s / iter per device, on 6 devices)
[11/17 10:20:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039398 s / iter per device, on 6 devices)
[11/17 10:20:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 10:20:18] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 10:20:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 10:20:20] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 10:20:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.24 seconds.
[11/17 10:20:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 10:20:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.76 seconds.
[11/17 10:20:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.290 | 11.842 | 3.770  | 0.754 | 2.385 | 6.354 |
[11/17 10:20:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 6.702  | person      | 5.644  | bird                  | 16.650 |
| red panda            | 5.958  | dog         | 35.906 | snake                 | 5.412  |
| car                  | 24.598 | seal        | 0.811  | helmet                | 7.048  |
| motorcycle           | 8.072  | swine       | 4.205  | stove                 | 6.793  |
| monkey               | 5.724  | watercraft  | 14.654 | chair                 | 3.386  |
| domestic cat         | 4.859  | harp        | 4.284  | antelope              | 11.757 |
| camel                | 1.742  | koala bear  | 4.902  | bus                   | 17.229 |
| hat with a wide brim | 2.216  | ski         | 0.297  | piano                 | 6.865  |
| frog                 | 4.500  | dumbbell    | 0.000  | lobster               | 3.450  |
| bench                | 0.489  | rabbit      | 7.851  | porcupine             | 8.513  |
| butterfly            | 17.057 | guitar      | 3.515  | microphone            | 0.132  |
| tape player          | 5.360  | bear        | 6.384  | hippopotamus          | 0.275  |
| bowl                 | 4.998  | axe         | 0.583  | skunk                 | 1.952  |
| airplane             | 10.355 | otter       | 2.789  | table                 | 4.228  |
| coffee maker         | 12.093 | tie         | 0.297  | turtle                | 2.942  |
| purse                | 3.455  | dragonfly   | 2.900  | lemon                 | 8.947  |
| lizard               | 4.111  | backpack    | 2.670  | tv or monitor         | 9.400  |
| cup or mug           | 2.126  | sheep       | 2.490  | ray                   | 1.415  |
| fox                  | 3.555  | whale       | 4.918  | salt or pepper shaker | 0.286  |
| computer keyboard    | 1.191  | fig         | 1.700  | bathing cap           | 1.333  |
| bookshelf            | 9.118  | ladybug     | 19.983 | crutch                | 0.026  |
| pretzel              | 4.416  | sunglasses  | 0.133  | starfish              | 5.249  |
| croquet ball         | 6.509  | lamp        | 0.713  | apple                 | 10.318 |
| cream                | 5.025  | artichoke   | 10.862 | train                 | 5.774  |
| elephant             | 6.776  | bell pepper | 4.964  | miniskirt             | 0.349  |
| orange               | 8.782  | tiger       | 3.125  | sofa                  | 1.524  |
| horse                | 4.324  | violin      | 0.366  | traffic light         | 1.035  |
| drum                 | 0.609  | strawberry  | 6.562  | laptop                | 5.128  |
| pomegranate          | 2.956  | cucumber    | 0.301  | bicycle               | 3.582  |
| banana               | 0.323  | baby bed    | 9.200  | jellyfish             | 3.922  |
| pitcher              | 1.493  | bagel       | 3.020  | beaker                | 5.436  |
| goldfish             | 4.106  | nail        | 0.000  | mushroom              | 1.861  |
| flower pot           | 0.920  | cattle      | 1.351  | zebra                 | 13.245 |
| wine bottle          | 1.640  |             |        |                       |        |
[11/17 10:20:48] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 10:20:48] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 10:20:48] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 10:20:48] d2.evaluation.testing INFO: copypaste: 5.2900,11.8420,3.7696,0.7543,2.3851,6.3543
[11/17 10:20:48] d2.utils.events INFO:  eta: 2:27:12  iter: 23999  total_loss: 0.2558  loss_cls: 0.1343  loss_box_reg: 0.08836  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.0176  time: 0.6813  data_time: 0.0664  lr: 0.004  max_mem: 11812M
[11/17 10:21:01] d2.utils.events INFO:  eta: 2:26:55  iter: 24019  total_loss: 0.2682  loss_cls: 0.1406  loss_box_reg: 0.09027  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01783  time: 0.6813  data_time: 0.0670  lr: 0.004  max_mem: 11812M
[11/17 10:21:15] d2.utils.events INFO:  eta: 2:26:42  iter: 24039  total_loss: 0.2724  loss_cls: 0.1461  loss_box_reg: 0.09244  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.01681  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 10:21:29] d2.utils.events INFO:  eta: 2:26:28  iter: 24059  total_loss: 0.2674  loss_cls: 0.1484  loss_box_reg: 0.08996  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.01978  time: 0.6813  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 10:21:42] d2.utils.events INFO:  eta: 2:26:14  iter: 24079  total_loss: 0.2696  loss_cls: 0.1401  loss_box_reg: 0.09059  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.01963  time: 0.6813  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 10:21:56] d2.utils.events INFO:  eta: 2:26:01  iter: 24099  total_loss: 0.2533  loss_cls: 0.133  loss_box_reg: 0.08295  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.01693  time: 0.6813  data_time: 0.0843  lr: 0.004  max_mem: 11812M
[11/17 10:22:10] d2.utils.events INFO:  eta: 2:25:46  iter: 24119  total_loss: 0.2414  loss_cls: 0.1311  loss_box_reg: 0.07824  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01778  time: 0.6813  data_time: 0.0763  lr: 0.004  max_mem: 11812M
[11/17 10:22:23] d2.utils.events INFO:  eta: 2:25:31  iter: 24139  total_loss: 0.2593  loss_cls: 0.1373  loss_box_reg: 0.09021  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.01632  time: 0.6813  data_time: 0.0671  lr: 0.004  max_mem: 11812M
[11/17 10:22:37] d2.utils.events INFO:  eta: 2:25:20  iter: 24159  total_loss: 0.2516  loss_cls: 0.133  loss_box_reg: 0.08617  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.01851  time: 0.6813  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 10:22:51] d2.utils.events INFO:  eta: 2:25:07  iter: 24179  total_loss: 0.2738  loss_cls: 0.1484  loss_box_reg: 0.09123  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.01603  time: 0.6813  data_time: 0.0719  lr: 0.004  max_mem: 11812M
[11/17 10:23:04] d2.utils.events INFO:  eta: 2:24:53  iter: 24199  total_loss: 0.2805  loss_cls: 0.1502  loss_box_reg: 0.09506  loss_rpn_cls: 0.0155  loss_rpn_loc: 0.01827  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 10:23:18] d2.utils.events INFO:  eta: 2:24:38  iter: 24219  total_loss: 0.2588  loss_cls: 0.139  loss_box_reg: 0.08816  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.01777  time: 0.6813  data_time: 0.0679  lr: 0.004  max_mem: 11812M
[11/17 10:23:31] d2.utils.events INFO:  eta: 2:24:24  iter: 24239  total_loss: 0.2614  loss_cls: 0.1392  loss_box_reg: 0.08864  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01787  time: 0.6813  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 10:23:45] d2.utils.events INFO:  eta: 2:24:09  iter: 24259  total_loss: 0.2618  loss_cls: 0.1444  loss_box_reg: 0.08543  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.01917  time: 0.6813  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 10:23:58] d2.utils.events INFO:  eta: 2:23:52  iter: 24279  total_loss: 0.2568  loss_cls: 0.1375  loss_box_reg: 0.0891  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01754  time: 0.6812  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 10:24:12] d2.utils.events INFO:  eta: 2:23:37  iter: 24299  total_loss: 0.2588  loss_cls: 0.1387  loss_box_reg: 0.08774  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.0184  time: 0.6812  data_time: 0.0708  lr: 0.004  max_mem: 11812M
[11/17 10:24:26] d2.utils.events INFO:  eta: 2:23:25  iter: 24319  total_loss: 0.2555  loss_cls: 0.1347  loss_box_reg: 0.08709  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.01755  time: 0.6812  data_time: 0.0651  lr: 0.004  max_mem: 11812M
[11/17 10:24:39] d2.utils.events INFO:  eta: 2:23:13  iter: 24339  total_loss: 0.2555  loss_cls: 0.1351  loss_box_reg: 0.08597  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.01912  time: 0.6812  data_time: 0.0750  lr: 0.004  max_mem: 11812M
[11/17 10:24:53] d2.utils.events INFO:  eta: 2:23:01  iter: 24359  total_loss: 0.2579  loss_cls: 0.1375  loss_box_reg: 0.08574  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01727  time: 0.6812  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 10:25:06] d2.utils.events INFO:  eta: 2:22:49  iter: 24379  total_loss: 0.2522  loss_cls: 0.136  loss_box_reg: 0.08534  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01678  time: 0.6812  data_time: 0.0644  lr: 0.004  max_mem: 11812M
[11/17 10:25:20] d2.utils.events INFO:  eta: 2:22:34  iter: 24399  total_loss: 0.2503  loss_cls: 0.1331  loss_box_reg: 0.08564  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01801  time: 0.6812  data_time: 0.0602  lr: 0.004  max_mem: 11812M
[11/17 10:25:34] d2.utils.events INFO:  eta: 2:22:22  iter: 24419  total_loss: 0.2685  loss_cls: 0.1448  loss_box_reg: 0.08928  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.01823  time: 0.6812  data_time: 0.0617  lr: 0.004  max_mem: 11812M
[11/17 10:25:47] d2.utils.events INFO:  eta: 2:22:09  iter: 24439  total_loss: 0.2461  loss_cls: 0.1309  loss_box_reg: 0.08272  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01734  time: 0.6812  data_time: 0.0590  lr: 0.004  max_mem: 11812M
[11/17 10:26:01] d2.utils.events INFO:  eta: 2:21:58  iter: 24459  total_loss: 0.2702  loss_cls: 0.1441  loss_box_reg: 0.08852  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.01958  time: 0.6812  data_time: 0.0757  lr: 0.004  max_mem: 11812M
[11/17 10:26:15] d2.utils.events INFO:  eta: 2:21:47  iter: 24479  total_loss: 0.2619  loss_cls: 0.1413  loss_box_reg: 0.08976  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.01828  time: 0.6812  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 10:26:28] d2.utils.events INFO:  eta: 2:21:33  iter: 24499  total_loss: 0.2592  loss_cls: 0.1387  loss_box_reg: 0.08811  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01819  time: 0.6812  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 10:26:42] d2.utils.events INFO:  eta: 2:21:24  iter: 24519  total_loss: 0.2645  loss_cls: 0.1384  loss_box_reg: 0.08949  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.0187  time: 0.6812  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 10:26:56] d2.utils.events INFO:  eta: 2:21:11  iter: 24539  total_loss: 0.2708  loss_cls: 0.1438  loss_box_reg: 0.09473  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.01793  time: 0.6813  data_time: 0.0835  lr: 0.004  max_mem: 11812M
[11/17 10:27:09] d2.utils.events INFO:  eta: 2:20:54  iter: 24559  total_loss: 0.2504  loss_cls: 0.1346  loss_box_reg: 0.08875  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.01865  time: 0.6813  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 10:27:23] d2.utils.events INFO:  eta: 2:20:41  iter: 24579  total_loss: 0.2646  loss_cls: 0.1417  loss_box_reg: 0.08853  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.01814  time: 0.6813  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 10:27:37] d2.utils.events INFO:  eta: 2:20:22  iter: 24599  total_loss: 0.2653  loss_cls: 0.1407  loss_box_reg: 0.08929  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.01663  time: 0.6813  data_time: 0.0735  lr: 0.004  max_mem: 11812M
[11/17 10:27:50] d2.utils.events INFO:  eta: 2:20:08  iter: 24619  total_loss: 0.2584  loss_cls: 0.1376  loss_box_reg: 0.09006  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01612  time: 0.6813  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 10:28:04] d2.utils.events INFO:  eta: 2:19:55  iter: 24639  total_loss: 0.2656  loss_cls: 0.1444  loss_box_reg: 0.08817  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.01927  time: 0.6812  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 10:28:17] d2.utils.events INFO:  eta: 2:19:41  iter: 24659  total_loss: 0.2567  loss_cls: 0.1367  loss_box_reg: 0.08485  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.01711  time: 0.6812  data_time: 0.0680  lr: 0.004  max_mem: 11812M
[11/17 10:28:31] d2.utils.events INFO:  eta: 2:19:25  iter: 24679  total_loss: 0.2558  loss_cls: 0.1334  loss_box_reg: 0.0861  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01798  time: 0.6812  data_time: 0.0613  lr: 0.004  max_mem: 11812M
[11/17 10:28:44] d2.utils.events INFO:  eta: 2:19:10  iter: 24699  total_loss: 0.2508  loss_cls: 0.127  loss_box_reg: 0.08468  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01849  time: 0.6812  data_time: 0.0679  lr: 0.004  max_mem: 11812M
[11/17 10:28:58] d2.utils.events INFO:  eta: 2:18:57  iter: 24719  total_loss: 0.2547  loss_cls: 0.1353  loss_box_reg: 0.08569  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01698  time: 0.6812  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 10:29:11] d2.utils.events INFO:  eta: 2:18:41  iter: 24739  total_loss: 0.2513  loss_cls: 0.1316  loss_box_reg: 0.08617  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.01753  time: 0.6812  data_time: 0.0637  lr: 0.004  max_mem: 11812M
[11/17 10:29:25] d2.utils.events INFO:  eta: 2:18:28  iter: 24759  total_loss: 0.2605  loss_cls: 0.1387  loss_box_reg: 0.09038  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01845  time: 0.6812  data_time: 0.0721  lr: 0.004  max_mem: 11812M
[11/17 10:29:38] d2.utils.events INFO:  eta: 2:18:11  iter: 24779  total_loss: 0.2499  loss_cls: 0.1301  loss_box_reg: 0.08761  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.01734  time: 0.6812  data_time: 0.0635  lr: 0.004  max_mem: 11812M
[11/17 10:29:52] d2.utils.events INFO:  eta: 2:18:02  iter: 24799  total_loss: 0.2583  loss_cls: 0.139  loss_box_reg: 0.08754  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.01946  time: 0.6812  data_time: 0.0702  lr: 0.004  max_mem: 11812M
[11/17 10:30:06] d2.utils.events INFO:  eta: 2:17:48  iter: 24819  total_loss: 0.2462  loss_cls: 0.1336  loss_box_reg: 0.08282  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.01728  time: 0.6812  data_time: 0.0643  lr: 0.004  max_mem: 11812M
[11/17 10:30:19] d2.utils.events INFO:  eta: 2:17:35  iter: 24839  total_loss: 0.2612  loss_cls: 0.1368  loss_box_reg: 0.08372  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.01865  time: 0.6811  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 10:30:33] d2.utils.events INFO:  eta: 2:17:23  iter: 24859  total_loss: 0.2513  loss_cls: 0.1373  loss_box_reg: 0.08821  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01611  time: 0.6811  data_time: 0.0706  lr: 0.004  max_mem: 11812M
[11/17 10:30:46] d2.utils.events INFO:  eta: 2:17:05  iter: 24879  total_loss: 0.264  loss_cls: 0.138  loss_box_reg: 0.08776  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01808  time: 0.6811  data_time: 0.0694  lr: 0.004  max_mem: 11812M
[11/17 10:31:00] d2.utils.events INFO:  eta: 2:16:48  iter: 24899  total_loss: 0.2631  loss_cls: 0.1388  loss_box_reg: 0.08886  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.01827  time: 0.6811  data_time: 0.0678  lr: 0.004  max_mem: 11812M
[11/17 10:31:13] d2.utils.events INFO:  eta: 2:16:30  iter: 24919  total_loss: 0.2625  loss_cls: 0.1404  loss_box_reg: 0.08764  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.01784  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11812M
[11/17 10:31:26] d2.utils.events INFO:  eta: 2:16:14  iter: 24939  total_loss: 0.2498  loss_cls: 0.1345  loss_box_reg: 0.08628  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.01857  time: 0.6811  data_time: 0.0609  lr: 0.004  max_mem: 11812M
[11/17 10:31:40] d2.utils.events INFO:  eta: 2:16:00  iter: 24959  total_loss: 0.2678  loss_cls: 0.139  loss_box_reg: 0.09147  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.01762  time: 0.6811  data_time: 0.0663  lr: 0.004  max_mem: 11812M
[11/17 10:31:54] d2.utils.events INFO:  eta: 2:15:46  iter: 24979  total_loss: 0.2496  loss_cls: 0.1347  loss_box_reg: 0.08513  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.0189  time: 0.6811  data_time: 0.0735  lr: 0.004  max_mem: 11812M
[11/17 10:32:07] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0024999.pth
[11/17 10:32:08] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 10:32:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 10:32:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 10:32:08] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 10:32:08] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 10:32:09] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 10:32:15] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0384 s/iter. Eval: 0.0002 s/iter. Total: 0.0397 s/iter. ETA=0:02:11
[11/17 10:32:20] d2.evaluation.evaluator INFO: Inference done 129/3334. Dataloading: 0.0016 s/iter. Inference: 0.0404 s/iter. Eval: 0.0002 s/iter. Total: 0.0423 s/iter. ETA=0:02:15
[11/17 10:32:25] d2.evaluation.evaluator INFO: Inference done 252/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:08
[11/17 10:32:30] d2.evaluation.evaluator INFO: Inference done 373/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:03
[11/17 10:32:35] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:57
[11/17 10:32:40] d2.evaluation.evaluator INFO: Inference done 616/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:52
[11/17 10:32:46] d2.evaluation.evaluator INFO: Inference done 737/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/17 10:32:51] d2.evaluation.evaluator INFO: Inference done 858/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:42
[11/17 10:32:56] d2.evaluation.evaluator INFO: Inference done 979/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/17 10:33:01] d2.evaluation.evaluator INFO: Inference done 1098/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:32
[11/17 10:33:06] d2.evaluation.evaluator INFO: Inference done 1221/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/17 10:33:11] d2.evaluation.evaluator INFO: Inference done 1341/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:22
[11/17 10:33:16] d2.evaluation.evaluator INFO: Inference done 1462/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/17 10:33:21] d2.evaluation.evaluator INFO: Inference done 1587/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:12
[11/17 10:33:26] d2.evaluation.evaluator INFO: Inference done 1709/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:07
[11/17 10:33:31] d2.evaluation.evaluator INFO: Inference done 1833/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:02
[11/17 10:33:36] d2.evaluation.evaluator INFO: Inference done 1958/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:56
[11/17 10:33:41] d2.evaluation.evaluator INFO: Inference done 2080/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/17 10:33:46] d2.evaluation.evaluator INFO: Inference done 2199/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/17 10:33:51] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/17 10:33:56] d2.evaluation.evaluator INFO: Inference done 2440/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/17 10:34:01] d2.evaluation.evaluator INFO: Inference done 2560/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/17 10:34:06] d2.evaluation.evaluator INFO: Inference done 2678/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:27
[11/17 10:34:11] d2.evaluation.evaluator INFO: Inference done 2800/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/17 10:34:16] d2.evaluation.evaluator INFO: Inference done 2920/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/17 10:34:21] d2.evaluation.evaluator INFO: Inference done 3039/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/17 10:34:26] d2.evaluation.evaluator INFO: Inference done 3158/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:07
[11/17 10:34:31] d2.evaluation.evaluator INFO: Inference done 3279/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/17 10:34:33] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.909119 (0.041427 s / iter per device, on 6 devices)
[11/17 10:34:33] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039524 s / iter per device, on 6 devices)
[11/17 10:34:34] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 10:34:35] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 10:34:35] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 10:34:36] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 10:34:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.74 seconds.
[11/17 10:34:57] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 10:34:59] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.63 seconds.
[11/17 10:34:59] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.506 | 12.449 | 4.034  | 1.178 | 2.625 | 6.523 |
[11/17 10:34:59] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 6.672  | person      | 5.635  | bird                  | 16.826 |
| red panda            | 5.560  | dog         | 36.930 | snake                 | 5.708  |
| car                  | 24.746 | seal        | 1.306  | helmet                | 7.047  |
| motorcycle           | 7.343  | swine       | 3.991  | stove                 | 6.869  |
| monkey               | 5.681  | watercraft  | 16.606 | chair                 | 3.018  |
| domestic cat         | 4.566  | harp        | 4.580  | antelope              | 10.749 |
| camel                | 1.216  | koala bear  | 4.604  | bus                   | 15.805 |
| hat with a wide brim | 2.427  | ski         | 0.776  | piano                 | 7.765  |
| frog                 | 4.647  | dumbbell    | 0.012  | lobster               | 3.410  |
| bench                | 0.759  | rabbit      | 7.377  | porcupine             | 6.785  |
| butterfly            | 18.325 | guitar      | 3.156  | microphone            | 0.000  |
| tape player          | 4.734  | bear        | 6.535  | hippopotamus          | 0.264  |
| bowl                 | 5.228  | axe         | 2.425  | skunk                 | 1.775  |
| airplane             | 9.908  | otter       | 2.108  | table                 | 3.932  |
| coffee maker         | 15.200 | tie         | 0.197  | turtle                | 3.639  |
| purse                | 2.805  | dragonfly   | 3.665  | lemon                 | 8.978  |
| lizard               | 3.719  | backpack    | 3.262  | tv or monitor         | 11.023 |
| cup or mug           | 1.530  | sheep       | 2.521  | ray                   | 1.518  |
| fox                  | 4.579  | whale       | 6.026  | salt or pepper shaker | 0.250  |
| computer keyboard    | 1.433  | fig         | 3.001  | bathing cap           | 1.417  |
| bookshelf            | 6.458  | ladybug     | 24.559 | crutch                | 0.074  |
| pretzel              | 3.533  | sunglasses  | 0.181  | starfish              | 5.941  |
| croquet ball         | 6.484  | lamp        | 1.650  | apple                 | 10.689 |
| cream                | 4.879  | artichoke   | 11.051 | train                 | 6.795  |
| elephant             | 8.668  | bell pepper | 5.806  | miniskirt             | 1.108  |
| orange               | 10.073 | tiger       | 1.733  | sofa                  | 2.605  |
| horse                | 4.103  | violin      | 0.424  | traffic light         | 2.015  |
| drum                 | 1.085  | strawberry  | 5.640  | laptop                | 7.307  |
| pomegranate          | 2.687  | cucumber    | 0.764  | bicycle               | 3.956  |
| banana               | 0.421  | baby bed    | 9.285  | jellyfish             | 6.140  |
| pitcher              | 1.092  | bagel       | 2.164  | beaker                | 5.117  |
| goldfish             | 4.045  | nail        | 0.046  | mushroom              | 1.376  |
| flower pot           | 1.301  | cattle      | 2.438  | zebra                 | 12.142 |
| wine bottle          | 2.238  |             |        |                       |        |
[11/17 10:35:01] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 10:35:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 10:35:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 10:35:01] d2.evaluation.testing INFO: copypaste: 5.5064,12.4493,4.0338,1.1777,2.6254,6.5232
[11/17 10:35:01] d2.utils.events INFO:  eta: 2:15:33  iter: 24999  total_loss: 0.2467  loss_cls: 0.1288  loss_box_reg: 0.08278  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.0184  time: 0.6811  data_time: 0.0639  lr: 0.004  max_mem: 11812M
[11/17 10:35:15] d2.utils.events INFO:  eta: 2:15:21  iter: 25019  total_loss: 0.2448  loss_cls: 0.1281  loss_box_reg: 0.08285  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.01782  time: 0.6811  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 10:35:29] d2.utils.events INFO:  eta: 2:15:06  iter: 25039  total_loss: 0.2536  loss_cls: 0.132  loss_box_reg: 0.08678  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.0199  time: 0.6811  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 10:35:42] d2.utils.events INFO:  eta: 2:14:55  iter: 25059  total_loss: 0.2568  loss_cls: 0.1352  loss_box_reg: 0.08665  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01641  time: 0.6811  data_time: 0.0670  lr: 0.004  max_mem: 11812M
[11/17 10:35:56] d2.utils.events INFO:  eta: 2:14:42  iter: 25079  total_loss: 0.2512  loss_cls: 0.1352  loss_box_reg: 0.08844  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.01666  time: 0.6811  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 10:36:10] d2.utils.events INFO:  eta: 2:14:29  iter: 25099  total_loss: 0.2537  loss_cls: 0.1348  loss_box_reg: 0.08788  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.01927  time: 0.6811  data_time: 0.0830  lr: 0.004  max_mem: 11812M
[11/17 10:36:23] d2.utils.events INFO:  eta: 2:14:16  iter: 25119  total_loss: 0.2649  loss_cls: 0.1376  loss_box_reg: 0.08936  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.01835  time: 0.6811  data_time: 0.0631  lr: 0.004  max_mem: 11812M
[11/17 10:36:37] d2.utils.events INFO:  eta: 2:14:01  iter: 25139  total_loss: 0.2672  loss_cls: 0.1358  loss_box_reg: 0.08774  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.01716  time: 0.6811  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 10:36:50] d2.utils.events INFO:  eta: 2:13:46  iter: 25159  total_loss: 0.2581  loss_cls: 0.1364  loss_box_reg: 0.0867  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.01781  time: 0.6811  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 10:37:04] d2.utils.events INFO:  eta: 2:13:34  iter: 25179  total_loss: 0.2554  loss_cls: 0.1367  loss_box_reg: 0.08733  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.02007  time: 0.6811  data_time: 0.0690  lr: 0.004  max_mem: 11812M
[11/17 10:37:18] d2.utils.events INFO:  eta: 2:13:20  iter: 25199  total_loss: 0.2661  loss_cls: 0.1455  loss_box_reg: 0.09159  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.01702  time: 0.6811  data_time: 0.0716  lr: 0.004  max_mem: 11812M
[11/17 10:37:31] d2.utils.events INFO:  eta: 2:13:07  iter: 25219  total_loss: 0.2733  loss_cls: 0.1432  loss_box_reg: 0.0915  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.01772  time: 0.6811  data_time: 0.0662  lr: 0.004  max_mem: 11812M
[11/17 10:37:45] d2.utils.events INFO:  eta: 2:12:55  iter: 25239  total_loss: 0.2627  loss_cls: 0.1394  loss_box_reg: 0.08638  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01861  time: 0.6811  data_time: 0.0701  lr: 0.004  max_mem: 11812M
[11/17 10:37:59] d2.utils.events INFO:  eta: 2:12:43  iter: 25259  total_loss: 0.2623  loss_cls: 0.1371  loss_box_reg: 0.09018  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01831  time: 0.6811  data_time: 0.0742  lr: 0.004  max_mem: 11812M
[11/17 10:38:12] d2.utils.events INFO:  eta: 2:12:36  iter: 25279  total_loss: 0.2662  loss_cls: 0.1407  loss_box_reg: 0.09064  loss_rpn_cls: 0.016  loss_rpn_loc: 0.01843  time: 0.6811  data_time: 0.0646  lr: 0.004  max_mem: 11812M
[11/17 10:38:26] d2.utils.events INFO:  eta: 2:12:19  iter: 25299  total_loss: 0.2624  loss_cls: 0.1424  loss_box_reg: 0.08786  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.01794  time: 0.6811  data_time: 0.0596  lr: 0.004  max_mem: 11812M
[11/17 10:38:39] d2.utils.events INFO:  eta: 2:12:01  iter: 25319  total_loss: 0.278  loss_cls: 0.1468  loss_box_reg: 0.09054  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.01901  time: 0.6811  data_time: 0.0681  lr: 0.004  max_mem: 11812M
[11/17 10:38:53] d2.utils.events INFO:  eta: 2:11:42  iter: 25339  total_loss: 0.2573  loss_cls: 0.1368  loss_box_reg: 0.08438  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.01935  time: 0.6810  data_time: 0.0627  lr: 0.004  max_mem: 11812M
[11/17 10:39:06] d2.utils.events INFO:  eta: 2:11:32  iter: 25359  total_loss: 0.2479  loss_cls: 0.1365  loss_box_reg: 0.08393  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01744  time: 0.6811  data_time: 0.0819  lr: 0.004  max_mem: 11812M
[11/17 10:39:20] d2.utils.events INFO:  eta: 2:11:20  iter: 25379  total_loss: 0.2564  loss_cls: 0.1362  loss_box_reg: 0.08974  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.01768  time: 0.6811  data_time: 0.0723  lr: 0.004  max_mem: 11812M
[11/17 10:39:34] d2.utils.events INFO:  eta: 2:11:08  iter: 25399  total_loss: 0.2369  loss_cls: 0.1259  loss_box_reg: 0.08028  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.01719  time: 0.6811  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 10:39:47] d2.utils.events INFO:  eta: 2:10:52  iter: 25419  total_loss: 0.255  loss_cls: 0.137  loss_box_reg: 0.08778  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.01677  time: 0.6811  data_time: 0.0660  lr: 0.004  max_mem: 11812M
[11/17 10:40:01] d2.utils.events INFO:  eta: 2:10:38  iter: 25439  total_loss: 0.2718  loss_cls: 0.1382  loss_box_reg: 0.09447  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.01835  time: 0.6811  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 10:40:14] d2.utils.events INFO:  eta: 2:10:25  iter: 25459  total_loss: 0.2575  loss_cls: 0.1356  loss_box_reg: 0.08864  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01665  time: 0.6811  data_time: 0.0684  lr: 0.004  max_mem: 11812M
[11/17 10:40:28] d2.utils.events INFO:  eta: 2:10:12  iter: 25479  total_loss: 0.2732  loss_cls: 0.1432  loss_box_reg: 0.09361  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.01744  time: 0.6811  data_time: 0.0850  lr: 0.004  max_mem: 11812M
[11/17 10:40:42] d2.utils.events INFO:  eta: 2:09:57  iter: 25499  total_loss: 0.253  loss_cls: 0.1334  loss_box_reg: 0.08735  loss_rpn_cls: 0.01517  loss_rpn_loc: 0.01835  time: 0.6811  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 10:40:56] d2.utils.events INFO:  eta: 2:09:43  iter: 25519  total_loss: 0.2776  loss_cls: 0.1525  loss_box_reg: 0.09442  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.01852  time: 0.6811  data_time: 0.0670  lr: 0.004  max_mem: 11812M
[11/17 10:41:09] d2.utils.events INFO:  eta: 2:09:31  iter: 25539  total_loss: 0.258  loss_cls: 0.1399  loss_box_reg: 0.08719  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.01802  time: 0.6811  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 10:41:23] d2.utils.events INFO:  eta: 2:09:16  iter: 25559  total_loss: 0.2802  loss_cls: 0.1485  loss_box_reg: 0.09527  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.01747  time: 0.6811  data_time: 0.0692  lr: 0.004  max_mem: 11812M
[11/17 10:41:37] d2.utils.events INFO:  eta: 2:09:02  iter: 25579  total_loss: 0.2533  loss_cls: 0.135  loss_box_reg: 0.08301  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.01728  time: 0.6811  data_time: 0.0724  lr: 0.004  max_mem: 11812M
[11/17 10:41:50] d2.utils.events INFO:  eta: 2:08:52  iter: 25599  total_loss: 0.2554  loss_cls: 0.1308  loss_box_reg: 0.08819  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.01851  time: 0.6811  data_time: 0.0619  lr: 0.004  max_mem: 11812M
[11/17 10:42:04] d2.utils.events INFO:  eta: 2:08:41  iter: 25619  total_loss: 0.2598  loss_cls: 0.1353  loss_box_reg: 0.08771  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.01713  time: 0.6811  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 10:42:17] d2.utils.events INFO:  eta: 2:08:29  iter: 25639  total_loss: 0.2644  loss_cls: 0.1387  loss_box_reg: 0.08669  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.01794  time: 0.6811  data_time: 0.0642  lr: 0.004  max_mem: 11812M
[11/17 10:42:31] d2.utils.events INFO:  eta: 2:08:11  iter: 25659  total_loss: 0.2621  loss_cls: 0.138  loss_box_reg: 0.09063  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01781  time: 0.6811  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 10:42:45] d2.utils.events INFO:  eta: 2:07:58  iter: 25679  total_loss: 0.2482  loss_cls: 0.1337  loss_box_reg: 0.08648  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.01741  time: 0.6811  data_time: 0.0611  lr: 0.004  max_mem: 11812M
[11/17 10:42:59] d2.utils.events INFO:  eta: 2:07:51  iter: 25699  total_loss: 0.2476  loss_cls: 0.1319  loss_box_reg: 0.0841  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.01686  time: 0.6811  data_time: 0.0769  lr: 0.004  max_mem: 11812M
[11/17 10:43:12] d2.utils.events INFO:  eta: 2:07:39  iter: 25719  total_loss: 0.2478  loss_cls: 0.1302  loss_box_reg: 0.08674  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.01787  time: 0.6811  data_time: 0.0591  lr: 0.004  max_mem: 11812M
[11/17 10:43:26] d2.utils.events INFO:  eta: 2:07:28  iter: 25739  total_loss: 0.2506  loss_cls: 0.1335  loss_box_reg: 0.08744  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01673  time: 0.6811  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 10:43:39] d2.utils.events INFO:  eta: 2:07:14  iter: 25759  total_loss: 0.2517  loss_cls: 0.1344  loss_box_reg: 0.08656  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.0186  time: 0.6811  data_time: 0.0694  lr: 0.004  max_mem: 11812M
[11/17 10:43:53] d2.utils.events INFO:  eta: 2:07:00  iter: 25779  total_loss: 0.2482  loss_cls: 0.1299  loss_box_reg: 0.0905  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01698  time: 0.6811  data_time: 0.0761  lr: 0.004  max_mem: 11812M
[11/17 10:44:07] d2.utils.events INFO:  eta: 2:06:45  iter: 25799  total_loss: 0.2671  loss_cls: 0.1406  loss_box_reg: 0.09113  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.01917  time: 0.6811  data_time: 0.0615  lr: 0.004  max_mem: 11812M
[11/17 10:44:20] d2.utils.events INFO:  eta: 2:06:34  iter: 25819  total_loss: 0.2519  loss_cls: 0.1339  loss_box_reg: 0.08661  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.01614  time: 0.6811  data_time: 0.0621  lr: 0.004  max_mem: 11812M
[11/17 10:44:34] d2.utils.events INFO:  eta: 2:06:21  iter: 25839  total_loss: 0.2552  loss_cls: 0.1366  loss_box_reg: 0.0887  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.0175  time: 0.6811  data_time: 0.0760  lr: 0.004  max_mem: 11812M
[11/17 10:44:47] d2.utils.events INFO:  eta: 2:06:05  iter: 25859  total_loss: 0.2551  loss_cls: 0.1385  loss_box_reg: 0.0851  loss_rpn_cls: 0.015  loss_rpn_loc: 0.01806  time: 0.6811  data_time: 0.0672  lr: 0.004  max_mem: 11812M
[11/17 10:45:01] d2.utils.events INFO:  eta: 2:05:52  iter: 25879  total_loss: 0.2637  loss_cls: 0.1391  loss_box_reg: 0.09073  loss_rpn_cls: 0.01515  loss_rpn_loc: 0.01853  time: 0.6811  data_time: 0.0891  lr: 0.004  max_mem: 11812M
[11/17 10:45:15] d2.utils.events INFO:  eta: 2:05:40  iter: 25899  total_loss: 0.2546  loss_cls: 0.1322  loss_box_reg: 0.08531  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.01892  time: 0.6811  data_time: 0.0737  lr: 0.004  max_mem: 11812M
[11/17 10:45:28] d2.utils.events INFO:  eta: 2:05:27  iter: 25919  total_loss: 0.2511  loss_cls: 0.1332  loss_box_reg: 0.08703  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01794  time: 0.6811  data_time: 0.0649  lr: 0.004  max_mem: 11812M
[11/17 10:45:42] d2.utils.events INFO:  eta: 2:05:13  iter: 25939  total_loss: 0.2827  loss_cls: 0.1499  loss_box_reg: 0.09357  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.01822  time: 0.6811  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 10:45:55] d2.utils.events INFO:  eta: 2:05:03  iter: 25959  total_loss: 0.2587  loss_cls: 0.1354  loss_box_reg: 0.08748  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.0167  time: 0.6811  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 10:46:09] d2.utils.events INFO:  eta: 2:04:45  iter: 25979  total_loss: 0.2371  loss_cls: 0.1278  loss_box_reg: 0.08362  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01686  time: 0.6811  data_time: 0.0702  lr: 0.004  max_mem: 11812M
[11/17 10:46:22] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0025999.pth
[11/17 10:46:23] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 10:46:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 10:46:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 10:46:23] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 10:46:23] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 10:46:24] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 10:46:30] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:27
[11/17 10:46:35] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0018 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:11
[11/17 10:46:40] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:06
[11/17 10:46:45] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:01
[11/17 10:46:50] d2.evaluation.evaluator INFO: Inference done 502/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:56
[11/17 10:46:55] d2.evaluation.evaluator INFO: Inference done 623/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/17 10:47:00] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/17 10:47:05] d2.evaluation.evaluator INFO: Inference done 865/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/17 10:47:10] d2.evaluation.evaluator INFO: Inference done 983/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/17 10:47:16] d2.evaluation.evaluator INFO: Inference done 1105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/17 10:47:21] d2.evaluation.evaluator INFO: Inference done 1225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/17 10:47:26] d2.evaluation.evaluator INFO: Inference done 1346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/17 10:47:31] d2.evaluation.evaluator INFO: Inference done 1465/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/17 10:47:36] d2.evaluation.evaluator INFO: Inference done 1587/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/17 10:47:41] d2.evaluation.evaluator INFO: Inference done 1707/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:07
[11/17 10:47:46] d2.evaluation.evaluator INFO: Inference done 1829/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:02
[11/17 10:47:51] d2.evaluation.evaluator INFO: Inference done 1948/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/17 10:47:56] d2.evaluation.evaluator INFO: Inference done 2071/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/17 10:48:01] d2.evaluation.evaluator INFO: Inference done 2192/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:47
[11/17 10:48:06] d2.evaluation.evaluator INFO: Inference done 2313/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:42
[11/17 10:48:11] d2.evaluation.evaluator INFO: Inference done 2433/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:37
[11/17 10:48:16] d2.evaluation.evaluator INFO: Inference done 2552/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:32
[11/17 10:48:21] d2.evaluation.evaluator INFO: Inference done 2674/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/17 10:48:26] d2.evaluation.evaluator INFO: Inference done 2794/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:22
[11/17 10:48:31] d2.evaluation.evaluator INFO: Inference done 2914/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:17
[11/17 10:48:36] d2.evaluation.evaluator INFO: Inference done 3034/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 10:48:41] d2.evaluation.evaluator INFO: Inference done 3152/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/17 10:48:46] d2.evaluation.evaluator INFO: Inference done 3270/3334. Dataloading: 0.0016 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/17 10:48:49] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.548839 (0.041619 s / iter per device, on 6 devices)
[11/17 10:48:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039642 s / iter per device, on 6 devices)
[11/17 10:48:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 10:48:51] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 10:48:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 10:48:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 10:49:15] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.80 seconds.
[11/17 10:49:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 10:49:17] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.83 seconds.
[11/17 10:49:17] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.387 | 12.304 | 3.849  | 0.854 | 2.386 | 6.503 |
[11/17 10:49:17] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 7.298  | person      | 5.134  | bird                  | 16.724 |
| red panda            | 5.253  | dog         | 36.277 | snake                 | 5.933  |
| car                  | 25.149 | seal        | 1.213  | helmet                | 6.869  |
| motorcycle           | 7.670  | swine       | 5.738  | stove                 | 6.360  |
| monkey               | 5.154  | watercraft  | 15.282 | chair                 | 3.577  |
| domestic cat         | 5.437  | harp        | 4.312  | antelope              | 12.412 |
| camel                | 1.837  | koala bear  | 6.303  | bus                   | 15.070 |
| hat with a wide brim | 3.129  | ski         | 0.935  | piano                 | 6.084  |
| frog                 | 4.088  | dumbbell    | 0.032  | lobster               | 2.899  |
| bench                | 1.200  | rabbit      | 8.103  | porcupine             | 5.878  |
| butterfly            | 17.621 | guitar      | 2.275  | microphone            | 0.016  |
| tape player          | 5.359  | bear        | 5.220  | hippopotamus          | 0.259  |
| bowl                 | 4.875  | axe         | 1.853  | skunk                 | 1.126  |
| airplane             | 13.150 | otter       | 1.926  | table                 | 3.884  |
| coffee maker         | 13.538 | tie         | 0.426  | turtle                | 3.050  |
| purse                | 3.319  | dragonfly   | 3.145  | lemon                 | 4.779  |
| lizard               | 3.873  | backpack    | 4.186  | tv or monitor         | 10.720 |
| cup or mug           | 2.553  | sheep       | 3.936  | ray                   | 1.485  |
| fox                  | 3.698  | whale       | 6.225  | salt or pepper shaker | 0.419  |
| computer keyboard    | 1.172  | fig         | 1.095  | bathing cap           | 1.576  |
| bookshelf            | 9.408  | ladybug     | 22.377 | crutch                | 0.023  |
| pretzel              | 4.263  | sunglasses  | 0.120  | starfish              | 4.654  |
| croquet ball         | 6.413  | lamp        | 1.238  | apple                 | 9.577  |
| cream                | 5.371  | artichoke   | 10.892 | train                 | 7.467  |
| elephant             | 8.051  | bell pepper | 3.510  | miniskirt             | 0.393  |
| orange               | 9.405  | tiger       | 2.443  | sofa                  | 2.114  |
| horse                | 4.845  | violin      | 0.413  | traffic light         | 1.882  |
| drum                 | 0.480  | strawberry  | 5.684  | laptop                | 5.176  |
| pomegranate          | 3.068  | cucumber    | 0.287  | bicycle               | 3.796  |
| banana               | 0.568  | baby bed    | 9.594  | jellyfish             | 5.001  |
| pitcher              | 2.349  | bagel       | 3.964  | beaker                | 4.084  |
| goldfish             | 3.587  | nail        | 0.070  | mushroom              | 1.430  |
| flower pot           | 0.727  | cattle      | 1.278  | zebra                 | 12.721 |
| wine bottle          | 1.888  |             |        |                       |        |
[11/17 10:49:20] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 10:49:20] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 10:49:20] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 10:49:20] d2.evaluation.testing INFO: copypaste: 5.3872,12.3044,3.8495,0.8541,2.3861,6.5026
[11/17 10:49:20] d2.utils.events INFO:  eta: 2:04:29  iter: 25999  total_loss: 0.243  loss_cls: 0.129  loss_box_reg: 0.08417  loss_rpn_cls: 0.013  loss_rpn_loc: 0.01619  time: 0.6811  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 10:49:33] d2.utils.events INFO:  eta: 2:04:17  iter: 26019  total_loss: 0.2551  loss_cls: 0.135  loss_box_reg: 0.0841  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01774  time: 0.6811  data_time: 0.0681  lr: 0.004  max_mem: 11812M
[11/17 10:49:47] d2.utils.events INFO:  eta: 2:04:04  iter: 26039  total_loss: 0.2516  loss_cls: 0.1338  loss_box_reg: 0.08513  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.01795  time: 0.6811  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 10:50:00] d2.utils.events INFO:  eta: 2:03:47  iter: 26059  total_loss: 0.2564  loss_cls: 0.1354  loss_box_reg: 0.08632  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.01937  time: 0.6811  data_time: 0.0650  lr: 0.004  max_mem: 11812M
[11/17 10:50:14] d2.utils.events INFO:  eta: 2:03:34  iter: 26079  total_loss: 0.2554  loss_cls: 0.1358  loss_box_reg: 0.08699  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.01858  time: 0.6811  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 10:50:28] d2.utils.events INFO:  eta: 2:03:20  iter: 26099  total_loss: 0.2576  loss_cls: 0.134  loss_box_reg: 0.0866  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01951  time: 0.6810  data_time: 0.0688  lr: 0.004  max_mem: 11812M
[11/17 10:50:41] d2.utils.events INFO:  eta: 2:03:05  iter: 26119  total_loss: 0.2564  loss_cls: 0.133  loss_box_reg: 0.08967  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.01943  time: 0.6810  data_time: 0.0695  lr: 0.004  max_mem: 11812M
[11/17 10:50:55] d2.utils.events INFO:  eta: 2:02:52  iter: 26139  total_loss: 0.2508  loss_cls: 0.1329  loss_box_reg: 0.0883  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.01693  time: 0.6810  data_time: 0.0629  lr: 0.004  max_mem: 11812M
[11/17 10:51:08] d2.utils.events INFO:  eta: 2:02:41  iter: 26159  total_loss: 0.2583  loss_cls: 0.1355  loss_box_reg: 0.08975  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.01748  time: 0.6810  data_time: 0.0726  lr: 0.004  max_mem: 11812M
[11/17 10:51:22] d2.utils.events INFO:  eta: 2:02:25  iter: 26179  total_loss: 0.2673  loss_cls: 0.1487  loss_box_reg: 0.09045  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01796  time: 0.6810  data_time: 0.0615  lr: 0.004  max_mem: 11812M
[11/17 10:51:36] d2.utils.events INFO:  eta: 2:02:14  iter: 26199  total_loss: 0.2635  loss_cls: 0.1385  loss_box_reg: 0.0908  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.01775  time: 0.6810  data_time: 0.0730  lr: 0.004  max_mem: 11812M
[11/17 10:51:49] d2.utils.events INFO:  eta: 2:01:59  iter: 26219  total_loss: 0.2578  loss_cls: 0.1381  loss_box_reg: 0.08367  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.0173  time: 0.6810  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 10:52:03] d2.utils.events INFO:  eta: 2:01:43  iter: 26239  total_loss: 0.2764  loss_cls: 0.1421  loss_box_reg: 0.09462  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.01848  time: 0.6810  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 10:52:16] d2.utils.events INFO:  eta: 2:01:25  iter: 26259  total_loss: 0.2871  loss_cls: 0.1523  loss_box_reg: 0.09115  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.01787  time: 0.6810  data_time: 0.0642  lr: 0.004  max_mem: 11812M
[11/17 10:52:30] d2.utils.events INFO:  eta: 2:01:12  iter: 26279  total_loss: 0.262  loss_cls: 0.1407  loss_box_reg: 0.0899  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.01756  time: 0.6810  data_time: 0.0659  lr: 0.004  max_mem: 11812M
[11/17 10:52:43] d2.utils.events INFO:  eta: 2:01:01  iter: 26299  total_loss: 0.2527  loss_cls: 0.1329  loss_box_reg: 0.08554  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.0177  time: 0.6810  data_time: 0.0716  lr: 0.004  max_mem: 11812M
[11/17 10:52:57] d2.utils.events INFO:  eta: 2:00:49  iter: 26319  total_loss: 0.2477  loss_cls: 0.1319  loss_box_reg: 0.08542  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.01866  time: 0.6810  data_time: 0.0706  lr: 0.004  max_mem: 11812M
[11/17 10:53:10] d2.utils.events INFO:  eta: 2:00:36  iter: 26339  total_loss: 0.2625  loss_cls: 0.1371  loss_box_reg: 0.08711  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.01882  time: 0.6810  data_time: 0.0703  lr: 0.004  max_mem: 11812M
[11/17 10:53:24] d2.utils.events INFO:  eta: 2:00:22  iter: 26359  total_loss: 0.2533  loss_cls: 0.1345  loss_box_reg: 0.08528  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01593  time: 0.6810  data_time: 0.0896  lr: 0.004  max_mem: 11812M
[11/17 10:53:38] d2.utils.events INFO:  eta: 2:00:03  iter: 26379  total_loss: 0.2364  loss_cls: 0.1246  loss_box_reg: 0.08372  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01641  time: 0.6810  data_time: 0.0672  lr: 0.004  max_mem: 11812M
[11/17 10:53:51] d2.utils.events INFO:  eta: 1:59:50  iter: 26399  total_loss: 0.2452  loss_cls: 0.1344  loss_box_reg: 0.08409  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01785  time: 0.6810  data_time: 0.0670  lr: 0.004  max_mem: 11812M
[11/17 10:54:05] d2.utils.events INFO:  eta: 1:59:37  iter: 26419  total_loss: 0.2755  loss_cls: 0.1474  loss_box_reg: 0.09133  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.01787  time: 0.6810  data_time: 0.0648  lr: 0.004  max_mem: 11812M
[11/17 10:54:19] d2.utils.events INFO:  eta: 1:59:23  iter: 26439  total_loss: 0.2564  loss_cls: 0.1368  loss_box_reg: 0.08775  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01887  time: 0.6810  data_time: 0.0673  lr: 0.004  max_mem: 11812M
[11/17 10:54:32] d2.utils.events INFO:  eta: 1:59:05  iter: 26459  total_loss: 0.2621  loss_cls: 0.1348  loss_box_reg: 0.09258  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.01862  time: 0.6810  data_time: 0.0608  lr: 0.004  max_mem: 11812M
[11/17 10:54:46] d2.utils.events INFO:  eta: 1:58:50  iter: 26479  total_loss: 0.2572  loss_cls: 0.137  loss_box_reg: 0.08706  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.01813  time: 0.6810  data_time: 0.0627  lr: 0.004  max_mem: 11812M
[11/17 10:54:59] d2.utils.events INFO:  eta: 1:58:40  iter: 26499  total_loss: 0.257  loss_cls: 0.1352  loss_box_reg: 0.08702  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01601  time: 0.6810  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 10:55:13] d2.utils.events INFO:  eta: 1:58:23  iter: 26519  total_loss: 0.2523  loss_cls: 0.1304  loss_box_reg: 0.08852  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.0182  time: 0.6810  data_time: 0.0607  lr: 0.004  max_mem: 11812M
[11/17 10:55:27] d2.utils.events INFO:  eta: 1:58:10  iter: 26539  total_loss: 0.2422  loss_cls: 0.1267  loss_box_reg: 0.08555  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.01759  time: 0.6810  data_time: 0.0709  lr: 0.004  max_mem: 11812M
[11/17 10:55:40] d2.utils.events INFO:  eta: 1:58:00  iter: 26559  total_loss: 0.2547  loss_cls: 0.135  loss_box_reg: 0.08436  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.01671  time: 0.6810  data_time: 0.0674  lr: 0.004  max_mem: 11812M
[11/17 10:55:54] d2.utils.events INFO:  eta: 1:57:43  iter: 26579  total_loss: 0.2515  loss_cls: 0.1333  loss_box_reg: 0.08725  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.01877  time: 0.6810  data_time: 0.0654  lr: 0.004  max_mem: 11812M
[11/17 10:56:07] d2.utils.events INFO:  eta: 1:57:31  iter: 26599  total_loss: 0.2565  loss_cls: 0.1358  loss_box_reg: 0.08831  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.0197  time: 0.6810  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 10:56:21] d2.utils.events INFO:  eta: 1:57:18  iter: 26619  total_loss: 0.2554  loss_cls: 0.136  loss_box_reg: 0.08583  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.01696  time: 0.6810  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 10:56:35] d2.utils.events INFO:  eta: 1:57:05  iter: 26639  total_loss: 0.2579  loss_cls: 0.1383  loss_box_reg: 0.09121  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.01733  time: 0.6810  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 10:56:48] d2.utils.events INFO:  eta: 1:56:51  iter: 26659  total_loss: 0.2559  loss_cls: 0.1372  loss_box_reg: 0.08487  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.01687  time: 0.6810  data_time: 0.0621  lr: 0.004  max_mem: 11812M
[11/17 10:57:02] d2.utils.events INFO:  eta: 1:56:39  iter: 26679  total_loss: 0.2389  loss_cls: 0.1272  loss_box_reg: 0.083  loss_rpn_cls: 0.01389  loss_rpn_loc: 0.01776  time: 0.6810  data_time: 0.0870  lr: 0.004  max_mem: 11812M
[11/17 10:57:15] d2.utils.events INFO:  eta: 1:56:20  iter: 26699  total_loss: 0.2518  loss_cls: 0.1332  loss_box_reg: 0.08615  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01711  time: 0.6810  data_time: 0.0668  lr: 0.004  max_mem: 11812M
[11/17 10:57:29] d2.utils.events INFO:  eta: 1:56:05  iter: 26719  total_loss: 0.2661  loss_cls: 0.1394  loss_box_reg: 0.0891  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.01833  time: 0.6810  data_time: 0.0695  lr: 0.004  max_mem: 11812M
[11/17 10:57:43] d2.utils.events INFO:  eta: 1:55:52  iter: 26739  total_loss: 0.2542  loss_cls: 0.1326  loss_box_reg: 0.08825  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.0158  time: 0.6810  data_time: 0.0756  lr: 0.004  max_mem: 11812M
[11/17 10:57:56] d2.utils.events INFO:  eta: 1:55:38  iter: 26759  total_loss: 0.2539  loss_cls: 0.1355  loss_box_reg: 0.08396  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.01843  time: 0.6810  data_time: 0.0682  lr: 0.004  max_mem: 11812M
[11/17 10:58:10] d2.utils.events INFO:  eta: 1:55:26  iter: 26779  total_loss: 0.2696  loss_cls: 0.1466  loss_box_reg: 0.09096  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.01726  time: 0.6810  data_time: 0.0616  lr: 0.004  max_mem: 11812M
[11/17 10:58:24] d2.utils.events INFO:  eta: 1:55:12  iter: 26799  total_loss: 0.2595  loss_cls: 0.1333  loss_box_reg: 0.08528  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.01802  time: 0.6810  data_time: 0.0693  lr: 0.004  max_mem: 11812M
[11/17 10:58:37] d2.utils.events INFO:  eta: 1:55:00  iter: 26819  total_loss: 0.2607  loss_cls: 0.1379  loss_box_reg: 0.08942  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.01706  time: 0.6810  data_time: 0.0694  lr: 0.004  max_mem: 11812M
[11/17 10:58:51] d2.utils.events INFO:  eta: 1:54:44  iter: 26839  total_loss: 0.2505  loss_cls: 0.127  loss_box_reg: 0.08326  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.01673  time: 0.6810  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 10:59:04] d2.utils.events INFO:  eta: 1:54:32  iter: 26859  total_loss: 0.2632  loss_cls: 0.1334  loss_box_reg: 0.08842  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01667  time: 0.6809  data_time: 0.0587  lr: 0.004  max_mem: 11812M
[11/17 10:59:18] d2.utils.events INFO:  eta: 1:54:20  iter: 26879  total_loss: 0.2565  loss_cls: 0.1354  loss_box_reg: 0.08776  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01802  time: 0.6809  data_time: 0.0623  lr: 0.004  max_mem: 11812M
[11/17 10:59:31] d2.utils.events INFO:  eta: 1:54:12  iter: 26899  total_loss: 0.2654  loss_cls: 0.1403  loss_box_reg: 0.08658  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.01818  time: 0.6809  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 10:59:45] d2.utils.events INFO:  eta: 1:54:00  iter: 26919  total_loss: 0.2606  loss_cls: 0.1379  loss_box_reg: 0.08609  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.01657  time: 0.6809  data_time: 0.0666  lr: 0.004  max_mem: 11812M
[11/17 10:59:58] d2.utils.events INFO:  eta: 1:53:46  iter: 26939  total_loss: 0.2687  loss_cls: 0.1418  loss_box_reg: 0.08989  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01792  time: 0.6809  data_time: 0.0643  lr: 0.004  max_mem: 11812M
[11/17 11:00:12] d2.utils.events INFO:  eta: 1:53:31  iter: 26959  total_loss: 0.2536  loss_cls: 0.1331  loss_box_reg: 0.08665  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.01628  time: 0.6809  data_time: 0.0699  lr: 0.004  max_mem: 11812M
[11/17 11:00:26] d2.utils.events INFO:  eta: 1:53:20  iter: 26979  total_loss: 0.2684  loss_cls: 0.1427  loss_box_reg: 0.08979  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.01911  time: 0.6809  data_time: 0.0676  lr: 0.004  max_mem: 11812M
[11/17 11:00:39] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0026999.pth
[11/17 11:00:40] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 11:00:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 11:00:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 11:00:40] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 11:00:40] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 11:00:41] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 11:00:48] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:02:18
[11/17 11:00:53] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0003 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/17 11:00:58] d2.evaluation.evaluator INFO: Inference done 253/3334. Dataloading: 0.0017 s/iter. Inference: 0.0395 s/iter. Eval: 0.0003 s/iter. Total: 0.0415 s/iter. ETA=0:02:07
[11/17 11:01:03] d2.evaluation.evaluator INFO: Inference done 376/3334. Dataloading: 0.0017 s/iter. Inference: 0.0393 s/iter. Eval: 0.0003 s/iter. Total: 0.0413 s/iter. ETA=0:02:02
[11/17 11:01:08] d2.evaluation.evaluator INFO: Inference done 496/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0003 s/iter. Total: 0.0414 s/iter. ETA=0:01:57
[11/17 11:01:13] d2.evaluation.evaluator INFO: Inference done 616/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:52
[11/17 11:01:18] d2.evaluation.evaluator INFO: Inference done 735/3334. Dataloading: 0.0016 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:48
[11/17 11:01:23] d2.evaluation.evaluator INFO: Inference done 859/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/17 11:01:28] d2.evaluation.evaluator INFO: Inference done 979/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:37
[11/17 11:01:33] d2.evaluation.evaluator INFO: Inference done 1101/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/17 11:01:38] d2.evaluation.evaluator INFO: Inference done 1224/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/17 11:01:43] d2.evaluation.evaluator INFO: Inference done 1345/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:22
[11/17 11:01:48] d2.evaluation.evaluator INFO: Inference done 1467/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:17
[11/17 11:01:53] d2.evaluation.evaluator INFO: Inference done 1589/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:12
[11/17 11:01:58] d2.evaluation.evaluator INFO: Inference done 1710/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:07
[11/17 11:02:03] d2.evaluation.evaluator INFO: Inference done 1831/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:02
[11/17 11:02:08] d2.evaluation.evaluator INFO: Inference done 1954/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:57
[11/17 11:02:13] d2.evaluation.evaluator INFO: Inference done 2078/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:51
[11/17 11:02:18] d2.evaluation.evaluator INFO: Inference done 2199/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:46
[11/17 11:02:23] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/17 11:02:28] d2.evaluation.evaluator INFO: Inference done 2438/3334. Dataloading: 0.0016 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:37
[11/17 11:02:33] d2.evaluation.evaluator INFO: Inference done 2556/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:32
[11/17 11:02:38] d2.evaluation.evaluator INFO: Inference done 2676/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:27
[11/17 11:02:43] d2.evaluation.evaluator INFO: Inference done 2798/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:22
[11/17 11:02:48] d2.evaluation.evaluator INFO: Inference done 2921/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:17
[11/17 11:02:53] d2.evaluation.evaluator INFO: Inference done 3041/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:12
[11/17 11:02:58] d2.evaluation.evaluator INFO: Inference done 3162/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:07
[11/17 11:03:03] d2.evaluation.evaluator INFO: Inference done 3279/3334. Dataloading: 0.0016 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:02
[11/17 11:03:05] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.122775 (0.041491 s / iter per device, on 6 devices)
[11/17 11:03:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039535 s / iter per device, on 6 devices)
[11/17 11:03:08] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 11:03:08] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 11:03:09] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 11:03:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 11:03:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.87 seconds.
[11/17 11:03:35] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 11:03:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.91 seconds.
[11/17 11:03:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.332 | 12.117 | 3.777  | 1.119 | 2.548 | 6.455 |
[11/17 11:03:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.323  | person      | 5.669  | bird                  | 18.408 |
| red panda            | 4.202  | dog         | 37.285 | snake                 | 5.747  |
| car                  | 23.792 | seal        | 1.303  | helmet                | 5.577  |
| motorcycle           | 8.934  | swine       | 4.472  | stove                 | 5.870  |
| monkey               | 5.478  | watercraft  | 15.200 | chair                 | 2.567  |
| domestic cat         | 4.112  | harp        | 4.941  | antelope              | 11.983 |
| camel                | 0.815  | koala bear  | 3.873  | bus                   | 16.252 |
| hat with a wide brim | 1.333  | ski         | 0.175  | piano                 | 6.346  |
| frog                 | 5.158  | dumbbell    | 0.087  | lobster               | 3.054  |
| bench                | 1.212  | rabbit      | 7.947  | porcupine             | 7.151  |
| butterfly            | 18.051 | guitar      | 3.129  | microphone            | 0.074  |
| tape player          | 5.376  | bear        | 7.759  | hippopotamus          | 0.235  |
| bowl                 | 4.813  | axe         | 1.456  | skunk                 | 0.808  |
| airplane             | 9.864  | otter       | 0.992  | table                 | 4.475  |
| coffee maker         | 12.538 | tie         | 1.915  | turtle                | 3.663  |
| purse                | 3.347  | dragonfly   | 4.175  | lemon                 | 6.746  |
| lizard               | 3.441  | backpack    | 2.890  | tv or monitor         | 10.894 |
| cup or mug           | 1.785  | sheep       | 2.996  | ray                   | 1.030  |
| fox                  | 3.126  | whale       | 6.771  | salt or pepper shaker | 0.270  |
| computer keyboard    | 2.242  | fig         | 1.679  | bathing cap           | 2.467  |
| bookshelf            | 6.982  | ladybug     | 19.056 | crutch                | 0.042  |
| pretzel              | 2.858  | sunglasses  | 0.282  | starfish              | 5.497  |
| croquet ball         | 6.121  | lamp        | 2.192  | apple                 | 10.538 |
| cream                | 5.139  | artichoke   | 9.785  | train                 | 9.258  |
| elephant             | 9.470  | bell pepper | 3.585  | miniskirt             | 1.874  |
| orange               | 10.744 | tiger       | 1.375  | sofa                  | 1.530  |
| horse                | 4.588  | violin      | 0.927  | traffic light         | 2.320  |
| drum                 | 0.643  | strawberry  | 6.781  | laptop                | 5.294  |
| pomegranate          | 2.213  | cucumber    | 0.166  | bicycle               | 3.643  |
| banana               | 0.336  | baby bed    | 8.023  | jellyfish             | 4.849  |
| pitcher              | 1.244  | bagel       | 3.111  | beaker                | 4.514  |
| goldfish             | 2.373  | nail        | 0.134  | mushroom              | 2.207  |
| flower pot           | 1.051  | cattle      | 1.290  | zebra                 | 13.637 |
| wine bottle          | 1.280  |             |        |                       |        |
[11/17 11:03:40] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 11:03:40] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 11:03:40] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 11:03:40] d2.evaluation.testing INFO: copypaste: 5.3323,12.1172,3.7773,1.1190,2.5476,6.4551
[11/17 11:03:40] d2.utils.events INFO:  eta: 1:53:07  iter: 26999  total_loss: 0.2558  loss_cls: 0.1384  loss_box_reg: 0.08663  loss_rpn_cls: 0.013  loss_rpn_loc: 0.01619  time: 0.6809  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 11:03:54] d2.utils.events INFO:  eta: 1:52:52  iter: 27019  total_loss: 0.2486  loss_cls: 0.1313  loss_box_reg: 0.08747  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.01625  time: 0.6809  data_time: 0.0687  lr: 0.004  max_mem: 11812M
[11/17 11:04:07] d2.utils.events INFO:  eta: 1:52:34  iter: 27039  total_loss: 0.2613  loss_cls: 0.135  loss_box_reg: 0.0903  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.01755  time: 0.6809  data_time: 0.0735  lr: 0.004  max_mem: 11812M
[11/17 11:04:21] d2.utils.events INFO:  eta: 1:52:21  iter: 27059  total_loss: 0.2557  loss_cls: 0.1383  loss_box_reg: 0.08847  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.0171  time: 0.6809  data_time: 0.0665  lr: 0.004  max_mem: 11812M
[11/17 11:04:34] d2.utils.events INFO:  eta: 1:52:09  iter: 27079  total_loss: 0.2538  loss_cls: 0.1325  loss_box_reg: 0.09016  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01659  time: 0.6809  data_time: 0.0695  lr: 0.004  max_mem: 11812M
[11/17 11:04:48] d2.utils.events INFO:  eta: 1:51:56  iter: 27099  total_loss: 0.2731  loss_cls: 0.1419  loss_box_reg: 0.09093  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.0181  time: 0.6809  data_time: 0.0618  lr: 0.004  max_mem: 11812M
[11/17 11:05:02] d2.utils.events INFO:  eta: 1:51:44  iter: 27119  total_loss: 0.2536  loss_cls: 0.1343  loss_box_reg: 0.08568  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.01603  time: 0.6809  data_time: 0.0701  lr: 0.004  max_mem: 11812M
[11/17 11:05:15] d2.utils.events INFO:  eta: 1:51:32  iter: 27139  total_loss: 0.2444  loss_cls: 0.1302  loss_box_reg: 0.08082  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.01901  time: 0.6809  data_time: 0.0653  lr: 0.004  max_mem: 11812M
[11/17 11:05:29] d2.utils.events INFO:  eta: 1:51:17  iter: 27159  total_loss: 0.2497  loss_cls: 0.131  loss_box_reg: 0.08728  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.01748  time: 0.6809  data_time: 0.0748  lr: 0.004  max_mem: 11812M
[11/17 11:05:42] d2.utils.events INFO:  eta: 1:51:05  iter: 27179  total_loss: 0.256  loss_cls: 0.1384  loss_box_reg: 0.08684  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.01612  time: 0.6809  data_time: 0.0641  lr: 0.004  max_mem: 11812M
[11/17 11:05:56] d2.utils.events INFO:  eta: 1:50:50  iter: 27199  total_loss: 0.2613  loss_cls: 0.1375  loss_box_reg: 0.09089  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01819  time: 0.6809  data_time: 0.0834  lr: 0.004  max_mem: 11812M
[11/17 11:06:10] d2.utils.events INFO:  eta: 1:50:41  iter: 27219  total_loss: 0.2623  loss_cls: 0.1347  loss_box_reg: 0.0915  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01826  time: 0.6809  data_time: 0.0656  lr: 0.004  max_mem: 11812M
[11/17 11:06:24] d2.utils.events INFO:  eta: 1:50:29  iter: 27239  total_loss: 0.2377  loss_cls: 0.1262  loss_box_reg: 0.08161  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.0184  time: 0.6809  data_time: 0.0631  lr: 0.004  max_mem: 11812M
[11/17 11:06:38] d2.utils.events INFO:  eta: 1:50:17  iter: 27259  total_loss: 0.2546  loss_cls: 0.1368  loss_box_reg: 0.08805  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01941  time: 0.6809  data_time: 0.0769  lr: 0.004  max_mem: 11812M
[11/17 11:06:51] d2.utils.events INFO:  eta: 1:50:05  iter: 27279  total_loss: 0.2474  loss_cls: 0.1306  loss_box_reg: 0.08532  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01734  time: 0.6809  data_time: 0.0677  lr: 0.004  max_mem: 11812M
[11/17 11:07:05] d2.utils.events INFO:  eta: 1:49:54  iter: 27299  total_loss: 0.2465  loss_cls: 0.1294  loss_box_reg: 0.08597  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01731  time: 0.6810  data_time: 0.0648  lr: 0.004  max_mem: 11812M
[11/17 11:07:19] d2.utils.events INFO:  eta: 1:49:41  iter: 27319  total_loss: 0.2441  loss_cls: 0.1292  loss_box_reg: 0.08499  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01697  time: 0.6810  data_time: 0.0658  lr: 0.004  max_mem: 11812M
[11/17 11:07:32] d2.utils.events INFO:  eta: 1:49:33  iter: 27339  total_loss: 0.2566  loss_cls: 0.1373  loss_box_reg: 0.08755  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01715  time: 0.6810  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 11:07:46] d2.utils.events INFO:  eta: 1:49:16  iter: 27359  total_loss: 0.2419  loss_cls: 0.1279  loss_box_reg: 0.08316  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.01729  time: 0.6810  data_time: 0.0700  lr: 0.004  max_mem: 11812M
[11/17 11:08:00] d2.utils.events INFO:  eta: 1:49:06  iter: 27379  total_loss: 0.2577  loss_cls: 0.137  loss_box_reg: 0.08871  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.0177  time: 0.6810  data_time: 0.0714  lr: 0.004  max_mem: 11812M
[11/17 11:08:13] d2.utils.events INFO:  eta: 1:48:53  iter: 27399  total_loss: 0.2565  loss_cls: 0.1318  loss_box_reg: 0.08887  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.01871  time: 0.6810  data_time: 0.0727  lr: 0.004  max_mem: 11812M
[11/17 11:08:27] d2.utils.events INFO:  eta: 1:48:40  iter: 27419  total_loss: 0.2666  loss_cls: 0.1401  loss_box_reg: 0.0946  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01802  time: 0.6810  data_time: 0.0743  lr: 0.004  max_mem: 11812M
[11/17 11:08:41] d2.utils.events INFO:  eta: 1:48:29  iter: 27439  total_loss: 0.2466  loss_cls: 0.1289  loss_box_reg: 0.08601  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01702  time: 0.6810  data_time: 0.0640  lr: 0.004  max_mem: 11812M
[11/17 11:08:54] d2.utils.events INFO:  eta: 1:48:17  iter: 27459  total_loss: 0.2616  loss_cls: 0.1411  loss_box_reg: 0.08768  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.01876  time: 0.6810  data_time: 0.0630  lr: 0.004  max_mem: 11812M
[11/17 11:09:08] d2.utils.events INFO:  eta: 1:48:09  iter: 27479  total_loss: 0.2549  loss_cls: 0.1359  loss_box_reg: 0.08684  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01654  time: 0.6810  data_time: 0.0703  lr: 0.004  max_mem: 11812M
[11/17 11:09:22] d2.utils.events INFO:  eta: 1:47:56  iter: 27499  total_loss: 0.2507  loss_cls: 0.1309  loss_box_reg: 0.08701  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.01865  time: 0.6810  data_time: 0.0659  lr: 0.004  max_mem: 11812M
[11/17 11:09:35] d2.utils.events INFO:  eta: 1:47:45  iter: 27519  total_loss: 0.2335  loss_cls: 0.1265  loss_box_reg: 0.08099  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.0159  time: 0.6810  data_time: 0.0744  lr: 0.004  max_mem: 11812M
[11/17 11:09:49] d2.utils.events INFO:  eta: 1:47:30  iter: 27539  total_loss: 0.2592  loss_cls: 0.137  loss_box_reg: 0.08673  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.01894  time: 0.6810  data_time: 0.0612  lr: 0.004  max_mem: 11812M
[11/17 11:10:03] d2.utils.events INFO:  eta: 1:47:16  iter: 27559  total_loss: 0.2519  loss_cls: 0.1324  loss_box_reg: 0.08756  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.01828  time: 0.6810  data_time: 0.0759  lr: 0.004  max_mem: 11812M
[11/17 11:10:16] d2.utils.events INFO:  eta: 1:47:02  iter: 27579  total_loss: 0.2531  loss_cls: 0.1335  loss_box_reg: 0.08429  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01777  time: 0.6810  data_time: 0.0717  lr: 0.004  max_mem: 11812M
[11/17 11:10:30] d2.utils.events INFO:  eta: 1:46:49  iter: 27599  total_loss: 0.2583  loss_cls: 0.1368  loss_box_reg: 0.08786  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.01734  time: 0.6810  data_time: 0.0655  lr: 0.004  max_mem: 11812M
[11/17 11:10:43] d2.utils.events INFO:  eta: 1:46:28  iter: 27619  total_loss: 0.2545  loss_cls: 0.1316  loss_box_reg: 0.08865  loss_rpn_cls: 0.01663  loss_rpn_loc: 0.01811  time: 0.6810  data_time: 0.0620  lr: 0.004  max_mem: 11812M
[11/17 11:10:57] d2.utils.events INFO:  eta: 1:46:11  iter: 27639  total_loss: 0.2527  loss_cls: 0.132  loss_box_reg: 0.09025  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01827  time: 0.6810  data_time: 0.0760  lr: 0.004  max_mem: 11812M
[11/17 11:11:10] d2.utils.events INFO:  eta: 1:45:56  iter: 27659  total_loss: 0.2411  loss_cls: 0.126  loss_box_reg: 0.08283  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.01715  time: 0.6810  data_time: 0.0667  lr: 0.004  max_mem: 11812M
[11/17 11:11:24] d2.utils.events INFO:  eta: 1:45:43  iter: 27679  total_loss: 0.2578  loss_cls: 0.133  loss_box_reg: 0.08601  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.01718  time: 0.6810  data_time: 0.0651  lr: 0.004  max_mem: 11812M
[11/17 11:11:38] d2.utils.events INFO:  eta: 1:45:34  iter: 27699  total_loss: 0.2688  loss_cls: 0.1399  loss_box_reg: 0.0909  loss_rpn_cls: 0.01579  loss_rpn_loc: 0.01857  time: 0.6810  data_time: 0.0718  lr: 0.004  max_mem: 11812M
[11/17 11:11:51] d2.utils.events INFO:  eta: 1:45:21  iter: 27719  total_loss: 0.252  loss_cls: 0.1341  loss_box_reg: 0.08536  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.01724  time: 0.6810  data_time: 0.0612  lr: 0.004  max_mem: 11812M
[11/17 11:12:05] d2.utils.events INFO:  eta: 1:45:12  iter: 27739  total_loss: 0.2614  loss_cls: 0.1398  loss_box_reg: 0.09039  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01876  time: 0.6810  data_time: 0.0748  lr: 0.004  max_mem: 11812M
[11/17 11:12:19] d2.utils.events INFO:  eta: 1:45:00  iter: 27759  total_loss: 0.2584  loss_cls: 0.1375  loss_box_reg: 0.08711  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01796  time: 0.6810  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 11:12:33] d2.utils.events INFO:  eta: 1:44:42  iter: 27779  total_loss: 0.2491  loss_cls: 0.1339  loss_box_reg: 0.08738  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.01655  time: 0.6810  data_time: 0.0717  lr: 0.004  max_mem: 11812M
[11/17 11:12:46] d2.utils.events INFO:  eta: 1:44:26  iter: 27799  total_loss: 0.2635  loss_cls: 0.1398  loss_box_reg: 0.08937  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01718  time: 0.6810  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 11:13:00] d2.utils.events INFO:  eta: 1:44:11  iter: 27819  total_loss: 0.2756  loss_cls: 0.1454  loss_box_reg: 0.09262  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.01773  time: 0.6810  data_time: 0.0756  lr: 0.004  max_mem: 11812M
[11/17 11:13:14] d2.utils.events INFO:  eta: 1:44:04  iter: 27839  total_loss: 0.2529  loss_cls: 0.136  loss_box_reg: 0.08899  loss_rpn_cls: 0.01137  loss_rpn_loc: 0.01669  time: 0.6810  data_time: 0.0685  lr: 0.004  max_mem: 11812M
[11/17 11:13:27] d2.utils.events INFO:  eta: 1:43:53  iter: 27859  total_loss: 0.2356  loss_cls: 0.1286  loss_box_reg: 0.08054  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01622  time: 0.6810  data_time: 0.0652  lr: 0.004  max_mem: 11812M
[11/17 11:13:41] d2.utils.events INFO:  eta: 1:43:40  iter: 27879  total_loss: 0.2578  loss_cls: 0.1386  loss_box_reg: 0.08812  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01706  time: 0.6810  data_time: 0.0634  lr: 0.004  max_mem: 11812M
[11/17 11:13:55] d2.utils.events INFO:  eta: 1:43:26  iter: 27899  total_loss: 0.2631  loss_cls: 0.1343  loss_box_reg: 0.09108  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.01914  time: 0.6810  data_time: 0.0647  lr: 0.004  max_mem: 11812M
[11/17 11:14:08] d2.utils.events INFO:  eta: 1:43:14  iter: 27919  total_loss: 0.2537  loss_cls: 0.1377  loss_box_reg: 0.08158  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.01825  time: 0.6811  data_time: 0.0771  lr: 0.004  max_mem: 11812M
[11/17 11:14:22] d2.utils.events INFO:  eta: 1:42:59  iter: 27939  total_loss: 0.2536  loss_cls: 0.1345  loss_box_reg: 0.08522  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01717  time: 0.6810  data_time: 0.0633  lr: 0.004  max_mem: 11812M
[11/17 11:14:35] d2.utils.events INFO:  eta: 1:42:46  iter: 27959  total_loss: 0.2518  loss_cls: 0.1336  loss_box_reg: 0.08741  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.01758  time: 0.6810  data_time: 0.0636  lr: 0.004  max_mem: 11812M
[11/17 11:14:49] d2.utils.events INFO:  eta: 1:42:36  iter: 27979  total_loss: 0.261  loss_cls: 0.1397  loss_box_reg: 0.08786  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.01941  time: 0.6810  data_time: 0.0638  lr: 0.004  max_mem: 11812M
[11/17 11:15:03] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0027999.pth
[11/17 11:15:03] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 11:15:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 11:15:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 11:15:04] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 11:15:04] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 11:15:04] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 11:15:11] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:19
[11/17 11:15:16] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:13
[11/17 11:15:21] d2.evaluation.evaluator INFO: Inference done 254/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/17 11:15:26] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:02
[11/17 11:15:31] d2.evaluation.evaluator INFO: Inference done 492/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:58
[11/17 11:15:36] d2.evaluation.evaluator INFO: Inference done 611/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:53
[11/17 11:15:41] d2.evaluation.evaluator INFO: Inference done 727/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:01:49
[11/17 11:15:46] d2.evaluation.evaluator INFO: Inference done 848/3334. Dataloading: 0.0015 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:44
[11/17 11:15:51] d2.evaluation.evaluator INFO: Inference done 968/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:39
[11/17 11:15:56] d2.evaluation.evaluator INFO: Inference done 1088/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:34
[11/17 11:16:01] d2.evaluation.evaluator INFO: Inference done 1207/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:01:29
[11/17 11:16:06] d2.evaluation.evaluator INFO: Inference done 1329/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:24
[11/17 11:16:11] d2.evaluation.evaluator INFO: Inference done 1450/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:18
[11/17 11:16:16] d2.evaluation.evaluator INFO: Inference done 1573/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:13
[11/17 11:16:21] d2.evaluation.evaluator INFO: Inference done 1693/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:08
[11/17 11:16:26] d2.evaluation.evaluator INFO: Inference done 1813/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:03
[11/17 11:16:31] d2.evaluation.evaluator INFO: Inference done 1933/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:58
[11/17 11:16:36] d2.evaluation.evaluator INFO: Inference done 2053/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:53
[11/17 11:16:41] d2.evaluation.evaluator INFO: Inference done 2173/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:48
[11/17 11:16:46] d2.evaluation.evaluator INFO: Inference done 2294/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:43
[11/17 11:16:51] d2.evaluation.evaluator INFO: Inference done 2415/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:38
[11/17 11:16:56] d2.evaluation.evaluator INFO: Inference done 2532/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:33
[11/17 11:17:01] d2.evaluation.evaluator INFO: Inference done 2655/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:28
[11/17 11:17:06] d2.evaluation.evaluator INFO: Inference done 2777/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:23
[11/17 11:17:11] d2.evaluation.evaluator INFO: Inference done 2897/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:18
[11/17 11:17:16] d2.evaluation.evaluator INFO: Inference done 3018/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:13
[11/17 11:17:21] d2.evaluation.evaluator INFO: Inference done 3138/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:08
[11/17 11:17:26] d2.evaluation.evaluator INFO: Inference done 3258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:03
[11/17 11:17:29] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.667869 (0.041655 s / iter per device, on 6 devices)
[11/17 11:17:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039696 s / iter per device, on 6 devices)
[11/17 11:17:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 11:17:31] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 11:17:32] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 11:17:32] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 11:17:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.99 seconds.
[11/17 11:17:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 11:17:58] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.06 seconds.
[11/17 11:17:58] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.681 | 12.880 | 4.012  | 1.133 | 2.427 | 6.765 |
[11/17 11:17:58] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 6.806  | person      | 5.938  | bird                  | 19.410 |
| red panda            | 8.192  | dog         | 37.545 | snake                 | 5.152  |
| car                  | 23.512 | seal        | 1.607  | helmet                | 7.353  |
| motorcycle           | 8.231  | swine       | 5.504  | stove                 | 7.415  |
| monkey               | 6.597  | watercraft  | 16.461 | chair                 | 2.920  |
| domestic cat         | 6.286  | harp        | 4.304  | antelope              | 11.872 |
| camel                | 1.187  | koala bear  | 4.852  | bus                   | 16.213 |
| hat with a wide brim | 2.444  | ski         | 1.169  | piano                 | 6.982  |
| frog                 | 4.144  | dumbbell    | 0.158  | lobster               | 3.339  |
| bench                | 0.656  | rabbit      | 8.420  | porcupine             | 7.025  |
| butterfly            | 18.724 | guitar      | 3.197  | microphone            | 0.068  |
| tape player          | 4.941  | bear        | 8.555  | hippopotamus          | 0.415  |
| bowl                 | 5.572  | axe         | 1.258  | skunk                 | 2.246  |
| airplane             | 14.287 | otter       | 1.718  | table                 | 4.070  |
| coffee maker         | 15.057 | tie         | 0.707  | turtle                | 3.376  |
| purse                | 2.576  | dragonfly   | 3.207  | lemon                 | 9.443  |
| lizard               | 3.678  | backpack    | 3.936  | tv or monitor         | 10.076 |
| cup or mug           | 2.831  | sheep       | 3.740  | ray                   | 1.321  |
| fox                  | 5.234  | whale       | 7.248  | salt or pepper shaker | 0.382  |
| computer keyboard    | 1.280  | fig         | 3.050  | bathing cap           | 2.961  |
| bookshelf            | 10.394 | ladybug     | 20.074 | crutch                | 0.037  |
| pretzel              | 3.097  | sunglasses  | 0.271  | starfish              | 4.552  |
| croquet ball         | 5.887  | lamp        | 1.769  | apple                 | 9.374  |
| cream                | 5.263  | artichoke   | 8.955  | train                 | 7.563  |
| elephant             | 9.749  | bell pepper | 2.981  | miniskirt             | 1.162  |
| orange               | 10.157 | tiger       | 2.088  | sofa                  | 2.350  |
| horse                | 5.233  | violin      | 0.394  | traffic light         | 2.032  |
| drum                 | 0.718  | strawberry  | 6.463  | laptop                | 5.027  |
| pomegranate          | 3.798  | cucumber    | 0.299  | bicycle               | 4.727  |
| banana               | 0.644  | baby bed    | 9.793  | jellyfish             | 3.651  |
| pitcher              | 0.429  | bagel       | 3.026  | beaker                | 3.907  |
| goldfish             | 3.528  | nail        | 0.146  | mushroom              | 1.962  |
| flower pot           | 1.297  | cattle      | 1.322  | zebra                 | 14.954 |
| wine bottle          | 2.174  |             |        |                       |        |
[11/17 11:18:01] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 11:18:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 11:18:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 11:18:01] d2.evaluation.testing INFO: copypaste: 5.6809,12.8802,4.0124,1.1328,2.4273,6.7646
[11/17 11:18:01] d2.utils.events INFO:  eta: 1:42:21  iter: 27999  total_loss: 0.2575  loss_cls: 0.1367  loss_box_reg: 0.08795  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.01694  time: 0.6810  data_time: 0.0622  lr: 0.004  max_mem: 11812M
[11/17 11:18:15] d2.utils.events INFO:  eta: 1:42:08  iter: 28019  total_loss: 0.2307  loss_cls: 0.1217  loss_box_reg: 0.0806  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.01745  time: 0.6810  data_time: 0.0725  lr: 0.0004  max_mem: 11812M
[11/17 11:18:29] d2.utils.events INFO:  eta: 1:41:58  iter: 28039  total_loss: 0.2438  loss_cls: 0.1295  loss_box_reg: 0.08434  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01686  time: 0.6810  data_time: 0.0687  lr: 0.0004  max_mem: 11812M
[11/17 11:18:43] d2.utils.events INFO:  eta: 1:41:50  iter: 28059  total_loss: 0.2449  loss_cls: 0.1241  loss_box_reg: 0.08771  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.0178  time: 0.6810  data_time: 0.0668  lr: 0.0004  max_mem: 11812M
[11/17 11:18:56] d2.utils.events INFO:  eta: 1:41:31  iter: 28079  total_loss: 0.2302  loss_cls: 0.1178  loss_box_reg: 0.08292  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.01747  time: 0.6810  data_time: 0.0570  lr: 0.0004  max_mem: 11812M
[11/17 11:19:09] d2.utils.events INFO:  eta: 1:41:14  iter: 28099  total_loss: 0.2319  loss_cls: 0.1214  loss_box_reg: 0.08401  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.01729  time: 0.6810  data_time: 0.0653  lr: 0.0004  max_mem: 11812M
[11/17 11:19:23] d2.utils.events INFO:  eta: 1:40:59  iter: 28119  total_loss: 0.2353  loss_cls: 0.1193  loss_box_reg: 0.08348  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01715  time: 0.6810  data_time: 0.0729  lr: 0.0004  max_mem: 11812M
[11/17 11:19:37] d2.utils.events INFO:  eta: 1:40:44  iter: 28139  total_loss: 0.244  loss_cls: 0.1252  loss_box_reg: 0.08407  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.01571  time: 0.6810  data_time: 0.0640  lr: 0.0004  max_mem: 11812M
[11/17 11:19:50] d2.utils.events INFO:  eta: 1:40:29  iter: 28159  total_loss: 0.2442  loss_cls: 0.1248  loss_box_reg: 0.08508  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.01635  time: 0.6810  data_time: 0.0649  lr: 0.0004  max_mem: 11812M
[11/17 11:20:04] d2.utils.events INFO:  eta: 1:40:16  iter: 28179  total_loss: 0.2564  loss_cls: 0.1324  loss_box_reg: 0.08713  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.01798  time: 0.6810  data_time: 0.0636  lr: 0.0004  max_mem: 11812M
[11/17 11:20:17] d2.utils.events INFO:  eta: 1:40:02  iter: 28199  total_loss: 0.2436  loss_cls: 0.1295  loss_box_reg: 0.08513  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.01811  time: 0.6810  data_time: 0.0710  lr: 0.0004  max_mem: 11812M
[11/17 11:20:31] d2.utils.events INFO:  eta: 1:39:45  iter: 28219  total_loss: 0.2405  loss_cls: 0.1258  loss_box_reg: 0.08421  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01716  time: 0.6810  data_time: 0.0696  lr: 0.0004  max_mem: 11812M
[11/17 11:20:45] d2.utils.events INFO:  eta: 1:39:34  iter: 28239  total_loss: 0.2443  loss_cls: 0.1271  loss_box_reg: 0.08289  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.01877  time: 0.6810  data_time: 0.0673  lr: 0.0004  max_mem: 11812M
[11/17 11:20:58] d2.utils.events INFO:  eta: 1:39:21  iter: 28259  total_loss: 0.2427  loss_cls: 0.1293  loss_box_reg: 0.08212  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01847  time: 0.6810  data_time: 0.0645  lr: 0.0004  max_mem: 11812M
[11/17 11:21:12] d2.utils.events INFO:  eta: 1:39:03  iter: 28279  total_loss: 0.2382  loss_cls: 0.1262  loss_box_reg: 0.08579  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.01674  time: 0.6810  data_time: 0.0700  lr: 0.0004  max_mem: 11812M
[11/17 11:21:25] d2.utils.events INFO:  eta: 1:38:46  iter: 28299  total_loss: 0.2383  loss_cls: 0.1238  loss_box_reg: 0.08474  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01641  time: 0.6810  data_time: 0.0642  lr: 0.0004  max_mem: 11812M
[11/17 11:21:39] d2.utils.events INFO:  eta: 1:38:31  iter: 28319  total_loss: 0.2572  loss_cls: 0.1319  loss_box_reg: 0.09166  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.01665  time: 0.6810  data_time: 0.0642  lr: 0.0004  max_mem: 11812M
[11/17 11:21:53] d2.utils.events INFO:  eta: 1:38:17  iter: 28339  total_loss: 0.2538  loss_cls: 0.1348  loss_box_reg: 0.09047  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.01845  time: 0.6810  data_time: 0.0804  lr: 0.0004  max_mem: 11812M
[11/17 11:22:06] d2.utils.events INFO:  eta: 1:38:02  iter: 28359  total_loss: 0.2424  loss_cls: 0.1273  loss_box_reg: 0.08342  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01724  time: 0.6810  data_time: 0.0689  lr: 0.0004  max_mem: 11812M
[11/17 11:22:20] d2.utils.events INFO:  eta: 1:37:48  iter: 28379  total_loss: 0.2462  loss_cls: 0.1254  loss_box_reg: 0.08537  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.01755  time: 0.6810  data_time: 0.0620  lr: 0.0004  max_mem: 11812M
[11/17 11:22:33] d2.utils.events INFO:  eta: 1:37:32  iter: 28399  total_loss: 0.2438  loss_cls: 0.1241  loss_box_reg: 0.08605  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.01862  time: 0.6810  data_time: 0.0650  lr: 0.0004  max_mem: 11812M
[11/17 11:22:47] d2.utils.events INFO:  eta: 1:37:17  iter: 28419  total_loss: 0.2475  loss_cls: 0.1313  loss_box_reg: 0.08427  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.01862  time: 0.6810  data_time: 0.0610  lr: 0.0004  max_mem: 11812M
[11/17 11:23:00] d2.utils.events INFO:  eta: 1:37:03  iter: 28439  total_loss: 0.2291  loss_cls: 0.118  loss_box_reg: 0.08203  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.0149  time: 0.6810  data_time: 0.0673  lr: 0.0004  max_mem: 11812M
[11/17 11:23:14] d2.utils.events INFO:  eta: 1:36:49  iter: 28459  total_loss: 0.2361  loss_cls: 0.1267  loss_box_reg: 0.0835  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01622  time: 0.6810  data_time: 0.0640  lr: 0.0004  max_mem: 11812M
[11/17 11:23:28] d2.utils.events INFO:  eta: 1:36:34  iter: 28479  total_loss: 0.2352  loss_cls: 0.1249  loss_box_reg: 0.08342  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01691  time: 0.6810  data_time: 0.0654  lr: 0.0004  max_mem: 11812M
[11/17 11:23:41] d2.utils.events INFO:  eta: 1:36:16  iter: 28499  total_loss: 0.245  loss_cls: 0.1281  loss_box_reg: 0.08488  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.01696  time: 0.6810  data_time: 0.0636  lr: 0.0004  max_mem: 11812M
[11/17 11:23:55] d2.utils.events INFO:  eta: 1:36:04  iter: 28519  total_loss: 0.2469  loss_cls: 0.1277  loss_box_reg: 0.08715  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01725  time: 0.6810  data_time: 0.0648  lr: 0.0004  max_mem: 11812M
[11/17 11:24:09] d2.utils.events INFO:  eta: 1:35:47  iter: 28539  total_loss: 0.2366  loss_cls: 0.1247  loss_box_reg: 0.08358  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.01656  time: 0.6810  data_time: 0.0654  lr: 0.0004  max_mem: 11812M
[11/17 11:24:22] d2.utils.events INFO:  eta: 1:35:36  iter: 28559  total_loss: 0.2393  loss_cls: 0.1263  loss_box_reg: 0.08456  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01705  time: 0.6810  data_time: 0.0699  lr: 0.0004  max_mem: 11812M
[11/17 11:24:36] d2.utils.events INFO:  eta: 1:35:24  iter: 28579  total_loss: 0.2479  loss_cls: 0.1316  loss_box_reg: 0.08696  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.01629  time: 0.6810  data_time: 0.0686  lr: 0.0004  max_mem: 11812M
[11/17 11:24:50] d2.utils.events INFO:  eta: 1:35:10  iter: 28599  total_loss: 0.2381  loss_cls: 0.1254  loss_box_reg: 0.08454  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01693  time: 0.6810  data_time: 0.0652  lr: 0.0004  max_mem: 11812M
[11/17 11:25:03] d2.utils.events INFO:  eta: 1:34:58  iter: 28619  total_loss: 0.2359  loss_cls: 0.1262  loss_box_reg: 0.08196  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01657  time: 0.6810  data_time: 0.0636  lr: 0.0004  max_mem: 11812M
[11/17 11:25:17] d2.utils.events INFO:  eta: 1:34:45  iter: 28639  total_loss: 0.2451  loss_cls: 0.1261  loss_box_reg: 0.08758  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.01678  time: 0.6810  data_time: 0.0749  lr: 0.0004  max_mem: 11812M
[11/17 11:25:30] d2.utils.events INFO:  eta: 1:34:35  iter: 28659  total_loss: 0.2388  loss_cls: 0.1258  loss_box_reg: 0.08321  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.01713  time: 0.6810  data_time: 0.0691  lr: 0.0004  max_mem: 11812M
[11/17 11:25:44] d2.utils.events INFO:  eta: 1:34:21  iter: 28679  total_loss: 0.2415  loss_cls: 0.1271  loss_box_reg: 0.08529  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.01829  time: 0.6810  data_time: 0.0648  lr: 0.0004  max_mem: 11812M
[11/17 11:25:57] d2.utils.events INFO:  eta: 1:34:04  iter: 28699  total_loss: 0.2383  loss_cls: 0.123  loss_box_reg: 0.0831  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01643  time: 0.6810  data_time: 0.0638  lr: 0.0004  max_mem: 11812M
[11/17 11:26:11] d2.utils.events INFO:  eta: 1:33:51  iter: 28719  total_loss: 0.2346  loss_cls: 0.1231  loss_box_reg: 0.08246  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.01774  time: 0.6810  data_time: 0.0676  lr: 0.0004  max_mem: 11812M
[11/17 11:26:25] d2.utils.events INFO:  eta: 1:33:33  iter: 28739  total_loss: 0.2395  loss_cls: 0.127  loss_box_reg: 0.08612  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01714  time: 0.6809  data_time: 0.0667  lr: 0.0004  max_mem: 11812M
[11/17 11:26:38] d2.utils.events INFO:  eta: 1:33:22  iter: 28759  total_loss: 0.2421  loss_cls: 0.125  loss_box_reg: 0.08442  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.01636  time: 0.6810  data_time: 0.0756  lr: 0.0004  max_mem: 11812M
[11/17 11:26:52] d2.utils.events INFO:  eta: 1:33:10  iter: 28779  total_loss: 0.2458  loss_cls: 0.1238  loss_box_reg: 0.08362  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01831  time: 0.6810  data_time: 0.0758  lr: 0.0004  max_mem: 11812M
[11/17 11:27:06] d2.utils.events INFO:  eta: 1:32:57  iter: 28799  total_loss: 0.2421  loss_cls: 0.1288  loss_box_reg: 0.08459  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.01554  time: 0.6810  data_time: 0.0694  lr: 0.0004  max_mem: 11812M
[11/17 11:27:19] d2.utils.events INFO:  eta: 1:32:45  iter: 28819  total_loss: 0.2519  loss_cls: 0.1314  loss_box_reg: 0.0871  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01922  time: 0.6810  data_time: 0.0663  lr: 0.0004  max_mem: 11812M
[11/17 11:27:33] d2.utils.events INFO:  eta: 1:32:32  iter: 28839  total_loss: 0.25  loss_cls: 0.1322  loss_box_reg: 0.0848  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01811  time: 0.6810  data_time: 0.0748  lr: 0.0004  max_mem: 11812M
[11/17 11:27:47] d2.utils.events INFO:  eta: 1:32:17  iter: 28859  total_loss: 0.2309  loss_cls: 0.1211  loss_box_reg: 0.08183  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.01752  time: 0.6810  data_time: 0.0851  lr: 0.0004  max_mem: 11812M
[11/17 11:28:00] d2.utils.events INFO:  eta: 1:32:03  iter: 28879  total_loss: 0.2462  loss_cls: 0.1329  loss_box_reg: 0.0853  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.01705  time: 0.6810  data_time: 0.0695  lr: 0.0004  max_mem: 11812M
[11/17 11:28:14] d2.utils.events INFO:  eta: 1:31:42  iter: 28899  total_loss: 0.2371  loss_cls: 0.1243  loss_box_reg: 0.08542  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01691  time: 0.6810  data_time: 0.0622  lr: 0.0004  max_mem: 11812M
[11/17 11:28:27] d2.utils.events INFO:  eta: 1:31:28  iter: 28919  total_loss: 0.2373  loss_cls: 0.1208  loss_box_reg: 0.08712  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.01819  time: 0.6810  data_time: 0.0630  lr: 0.0004  max_mem: 11812M
[11/17 11:28:41] d2.utils.events INFO:  eta: 1:31:16  iter: 28939  total_loss: 0.2408  loss_cls: 0.1268  loss_box_reg: 0.08499  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.0175  time: 0.6810  data_time: 0.0728  lr: 0.0004  max_mem: 11812M
[11/17 11:28:55] d2.utils.events INFO:  eta: 1:31:01  iter: 28959  total_loss: 0.2474  loss_cls: 0.1275  loss_box_reg: 0.08769  loss_rpn_cls: 0.01173  loss_rpn_loc: 0.01718  time: 0.6810  data_time: 0.0653  lr: 0.0004  max_mem: 11812M
[11/17 11:29:08] d2.utils.events INFO:  eta: 1:30:46  iter: 28979  total_loss: 0.2404  loss_cls: 0.1312  loss_box_reg: 0.08496  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01665  time: 0.6809  data_time: 0.0732  lr: 0.0004  max_mem: 11812M
[11/17 11:29:22] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0028999.pth
[11/17 11:29:22] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 11:29:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 11:29:23] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 11:29:23] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 11:29:23] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 11:29:23] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 11:29:30] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0379 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:02:10
[11/17 11:29:35] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:09
[11/17 11:29:40] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:05
[11/17 11:29:45] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/17 11:29:50] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/17 11:29:55] d2.evaluation.evaluator INFO: Inference done 619/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:52
[11/17 11:30:00] d2.evaluation.evaluator INFO: Inference done 739/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:47
[11/17 11:30:05] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/17 11:30:10] d2.evaluation.evaluator INFO: Inference done 980/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/17 11:30:15] d2.evaluation.evaluator INFO: Inference done 1102/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/17 11:30:20] d2.evaluation.evaluator INFO: Inference done 1220/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:27
[11/17 11:30:25] d2.evaluation.evaluator INFO: Inference done 1340/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:22
[11/17 11:30:30] d2.evaluation.evaluator INFO: Inference done 1462/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:17
[11/17 11:30:35] d2.evaluation.evaluator INFO: Inference done 1583/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:12
[11/17 11:30:40] d2.evaluation.evaluator INFO: Inference done 1702/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:07
[11/17 11:30:45] d2.evaluation.evaluator INFO: Inference done 1823/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/17 11:30:50] d2.evaluation.evaluator INFO: Inference done 1947/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:57
[11/17 11:30:55] d2.evaluation.evaluator INFO: Inference done 2069/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:00:52
[11/17 11:31:00] d2.evaluation.evaluator INFO: Inference done 2185/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:47
[11/17 11:31:05] d2.evaluation.evaluator INFO: Inference done 2304/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:42
[11/17 11:31:10] d2.evaluation.evaluator INFO: Inference done 2422/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/17 11:31:15] d2.evaluation.evaluator INFO: Inference done 2541/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:33
[11/17 11:31:20] d2.evaluation.evaluator INFO: Inference done 2663/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/17 11:31:25] d2.evaluation.evaluator INFO: Inference done 2784/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/17 11:31:30] d2.evaluation.evaluator INFO: Inference done 2904/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:17
[11/17 11:31:35] d2.evaluation.evaluator INFO: Inference done 3026/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 11:31:40] d2.evaluation.evaluator INFO: Inference done 3147/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/17 11:31:45] d2.evaluation.evaluator INFO: Inference done 3268/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/17 11:31:48] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.409584 (0.041577 s / iter per device, on 6 devices)
[11/17 11:31:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039651 s / iter per device, on 6 devices)
[11/17 11:31:51] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 11:31:51] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 11:31:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 11:31:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 11:32:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.42 seconds.
[11/17 11:32:16] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 11:32:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.91 seconds.
[11/17 11:32:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.325 | 14.118 | 4.699  | 1.164 | 3.340 | 7.558 |
[11/17 11:32:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.425  | person      | 6.129  | bird                  | 21.163 |
| red panda            | 8.173  | dog         | 39.638 | snake                 | 6.559  |
| car                  | 26.577 | seal        | 1.555  | helmet                | 7.835  |
| motorcycle           | 9.421  | swine       | 5.629  | stove                 | 7.692  |
| monkey               | 7.829  | watercraft  | 17.612 | chair                 | 3.852  |
| domestic cat         | 5.868  | harp        | 4.789  | antelope              | 13.038 |
| camel                | 1.637  | koala bear  | 7.024  | bus                   | 18.756 |
| hat with a wide brim | 2.302  | ski         | 0.972  | piano                 | 7.659  |
| frog                 | 6.329  | dumbbell    | 0.106  | lobster               | 4.193  |
| bench                | 0.598  | rabbit      | 9.683  | porcupine             | 7.578  |
| butterfly            | 20.740 | guitar      | 3.473  | microphone            | 0.059  |
| tape player          | 5.986  | bear        | 7.981  | hippopotamus          | 0.366  |
| bowl                 | 7.022  | axe         | 2.725  | skunk                 | 2.066  |
| airplane             | 14.628 | otter       | 2.251  | table                 | 4.923  |
| coffee maker         | 14.818 | tie         | 0.701  | turtle                | 3.704  |
| purse                | 3.439  | dragonfly   | 4.089  | lemon                 | 10.030 |
| lizard               | 4.464  | backpack    | 3.859  | tv or monitor         | 9.327  |
| cup or mug           | 2.458  | sheep       | 2.965  | ray                   | 1.642  |
| fox                  | 5.476  | whale       | 6.662  | salt or pepper shaker | 0.613  |
| computer keyboard    | 2.146  | fig         | 3.211  | bathing cap           | 2.783  |
| bookshelf            | 9.531  | ladybug     | 22.823 | crutch                | 0.030  |
| pretzel              | 3.457  | sunglasses  | 0.512  | starfish              | 6.278  |
| croquet ball         | 8.823  | lamp        | 1.649  | apple                 | 11.597 |
| cream                | 6.567  | artichoke   | 12.667 | train                 | 9.601  |
| elephant             | 10.246 | bell pepper | 4.512  | miniskirt             | 1.520  |
| orange               | 12.184 | tiger       | 2.694  | sofa                  | 2.900  |
| horse                | 6.024  | violin      | 0.372  | traffic light         | 1.888  |
| drum                 | 0.838  | strawberry  | 7.066  | laptop                | 6.018  |
| pomegranate          | 3.173  | cucumber    | 0.289  | bicycle               | 4.601  |
| banana               | 1.037  | baby bed    | 10.470 | jellyfish             | 4.330  |
| pitcher              | 1.489  | bagel       | 3.262  | beaker                | 4.461  |
| goldfish             | 5.259  | nail        | 0.143  | mushroom              | 3.022  |
| flower pot           | 1.065  | cattle      | 1.135  | zebra                 | 13.869 |
| wine bottle          | 1.826  |             |        |                       |        |
[11/17 11:32:21] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 11:32:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 11:32:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 11:32:21] d2.evaluation.testing INFO: copypaste: 6.3245,14.1175,4.6986,1.1638,3.3405,7.5577
[11/17 11:32:21] d2.utils.events INFO:  eta: 1:30:33  iter: 28999  total_loss: 0.2444  loss_cls: 0.1279  loss_box_reg: 0.08558  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01779  time: 0.6809  data_time: 0.0681  lr: 0.0004  max_mem: 11812M
[11/17 11:32:34] d2.utils.events INFO:  eta: 1:30:17  iter: 29019  total_loss: 0.2415  loss_cls: 0.123  loss_box_reg: 0.08752  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.01767  time: 0.6809  data_time: 0.0696  lr: 0.0004  max_mem: 11812M
[11/17 11:32:48] d2.utils.events INFO:  eta: 1:30:02  iter: 29039  total_loss: 0.2393  loss_cls: 0.1219  loss_box_reg: 0.08055  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01726  time: 0.6810  data_time: 0.0788  lr: 0.0004  max_mem: 11812M
[11/17 11:33:01] d2.utils.events INFO:  eta: 1:29:46  iter: 29059  total_loss: 0.2674  loss_cls: 0.139  loss_box_reg: 0.09161  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.0176  time: 0.6810  data_time: 0.0644  lr: 0.0004  max_mem: 11812M
[11/17 11:33:15] d2.utils.events INFO:  eta: 1:29:37  iter: 29079  total_loss: 0.2425  loss_cls: 0.1248  loss_box_reg: 0.08589  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.01763  time: 0.6810  data_time: 0.0646  lr: 0.0004  max_mem: 11812M
[11/17 11:33:29] d2.utils.events INFO:  eta: 1:29:23  iter: 29099  total_loss: 0.2346  loss_cls: 0.1234  loss_box_reg: 0.08289  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.01693  time: 0.6809  data_time: 0.0698  lr: 0.0004  max_mem: 11812M
[11/17 11:33:42] d2.utils.events INFO:  eta: 1:29:10  iter: 29119  total_loss: 0.2471  loss_cls: 0.1287  loss_box_reg: 0.08676  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.01652  time: 0.6810  data_time: 0.0720  lr: 0.0004  max_mem: 11812M
[11/17 11:33:56] d2.utils.events INFO:  eta: 1:28:56  iter: 29139  total_loss: 0.2446  loss_cls: 0.1265  loss_box_reg: 0.08317  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.01723  time: 0.6809  data_time: 0.0609  lr: 0.0004  max_mem: 11812M
[11/17 11:34:09] d2.utils.events INFO:  eta: 1:28:42  iter: 29159  total_loss: 0.2444  loss_cls: 0.1305  loss_box_reg: 0.08384  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.01637  time: 0.6809  data_time: 0.0648  lr: 0.0004  max_mem: 11812M
[11/17 11:34:23] d2.utils.events INFO:  eta: 1:28:25  iter: 29179  total_loss: 0.2393  loss_cls: 0.1239  loss_box_reg: 0.08154  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.01781  time: 0.6809  data_time: 0.0604  lr: 0.0004  max_mem: 11812M
[11/17 11:34:37] d2.utils.events INFO:  eta: 1:28:12  iter: 29199  total_loss: 0.2547  loss_cls: 0.1362  loss_box_reg: 0.09181  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.01623  time: 0.6809  data_time: 0.0673  lr: 0.0004  max_mem: 11812M
[11/17 11:34:50] d2.utils.events INFO:  eta: 1:28:02  iter: 29219  total_loss: 0.2386  loss_cls: 0.1268  loss_box_reg: 0.08357  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01753  time: 0.6809  data_time: 0.0700  lr: 0.0004  max_mem: 11812M
[11/17 11:35:04] d2.utils.events INFO:  eta: 1:27:49  iter: 29239  total_loss: 0.2288  loss_cls: 0.1221  loss_box_reg: 0.08409  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.01516  time: 0.6809  data_time: 0.0723  lr: 0.0004  max_mem: 11812M
[11/17 11:35:18] d2.utils.events INFO:  eta: 1:27:34  iter: 29259  total_loss: 0.2478  loss_cls: 0.1296  loss_box_reg: 0.08656  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.01693  time: 0.6810  data_time: 0.0784  lr: 0.0004  max_mem: 11812M
[11/17 11:35:31] d2.utils.events INFO:  eta: 1:27:21  iter: 29279  total_loss: 0.2475  loss_cls: 0.1293  loss_box_reg: 0.08673  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.01768  time: 0.6810  data_time: 0.0698  lr: 0.0004  max_mem: 11812M
[11/17 11:35:45] d2.utils.events INFO:  eta: 1:27:07  iter: 29299  total_loss: 0.2402  loss_cls: 0.1246  loss_box_reg: 0.08755  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01549  time: 0.6810  data_time: 0.0672  lr: 0.0004  max_mem: 11812M
[11/17 11:35:59] d2.utils.events INFO:  eta: 1:26:54  iter: 29319  total_loss: 0.2359  loss_cls: 0.1239  loss_box_reg: 0.0842  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.01747  time: 0.6810  data_time: 0.0680  lr: 0.0004  max_mem: 11812M
[11/17 11:36:12] d2.utils.events INFO:  eta: 1:26:39  iter: 29339  total_loss: 0.2364  loss_cls: 0.1226  loss_box_reg: 0.08243  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01593  time: 0.6809  data_time: 0.0628  lr: 0.0004  max_mem: 11812M
[11/17 11:36:26] d2.utils.events INFO:  eta: 1:26:27  iter: 29359  total_loss: 0.2402  loss_cls: 0.1269  loss_box_reg: 0.08673  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.01647  time: 0.6810  data_time: 0.0784  lr: 0.0004  max_mem: 11812M
[11/17 11:36:39] d2.utils.events INFO:  eta: 1:26:13  iter: 29379  total_loss: 0.2456  loss_cls: 0.1281  loss_box_reg: 0.08467  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.01797  time: 0.6810  data_time: 0.0644  lr: 0.0004  max_mem: 11812M
[11/17 11:36:53] d2.utils.events INFO:  eta: 1:25:59  iter: 29399  total_loss: 0.2481  loss_cls: 0.13  loss_box_reg: 0.08862  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01786  time: 0.6810  data_time: 0.0754  lr: 0.0004  max_mem: 11812M
[11/17 11:37:07] d2.utils.events INFO:  eta: 1:25:46  iter: 29419  total_loss: 0.2325  loss_cls: 0.1192  loss_box_reg: 0.08152  loss_rpn_cls: 0.01197  loss_rpn_loc: 0.01763  time: 0.6809  data_time: 0.0646  lr: 0.0004  max_mem: 11812M
[11/17 11:37:20] d2.utils.events INFO:  eta: 1:25:33  iter: 29439  total_loss: 0.2401  loss_cls: 0.1232  loss_box_reg: 0.08117  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01668  time: 0.6809  data_time: 0.0650  lr: 0.0004  max_mem: 11812M
[11/17 11:37:34] d2.utils.events INFO:  eta: 1:25:19  iter: 29459  total_loss: 0.247  loss_cls: 0.1295  loss_box_reg: 0.08882  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01639  time: 0.6809  data_time: 0.0650  lr: 0.0004  max_mem: 11812M
[11/17 11:37:47] d2.utils.events INFO:  eta: 1:25:00  iter: 29479  total_loss: 0.2398  loss_cls: 0.1268  loss_box_reg: 0.0826  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01721  time: 0.6809  data_time: 0.0669  lr: 0.0004  max_mem: 11812M
[11/17 11:38:01] d2.utils.events INFO:  eta: 1:24:48  iter: 29499  total_loss: 0.2448  loss_cls: 0.1282  loss_box_reg: 0.08591  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.01635  time: 0.6809  data_time: 0.0684  lr: 0.0004  max_mem: 11812M
[11/17 11:38:14] d2.utils.events INFO:  eta: 1:24:33  iter: 29519  total_loss: 0.2486  loss_cls: 0.1302  loss_box_reg: 0.08741  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01667  time: 0.6809  data_time: 0.0700  lr: 0.0004  max_mem: 11812M
[11/17 11:38:28] d2.utils.events INFO:  eta: 1:24:20  iter: 29539  total_loss: 0.244  loss_cls: 0.1273  loss_box_reg: 0.08291  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01726  time: 0.6809  data_time: 0.0750  lr: 0.0004  max_mem: 11812M
[11/17 11:38:42] d2.utils.events INFO:  eta: 1:24:06  iter: 29559  total_loss: 0.2449  loss_cls: 0.1275  loss_box_reg: 0.08494  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.01676  time: 0.6809  data_time: 0.0681  lr: 0.0004  max_mem: 11812M
[11/17 11:38:55] d2.utils.events INFO:  eta: 1:23:52  iter: 29579  total_loss: 0.2489  loss_cls: 0.131  loss_box_reg: 0.0876  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01797  time: 0.6809  data_time: 0.0774  lr: 0.0004  max_mem: 11812M
[11/17 11:39:09] d2.utils.events INFO:  eta: 1:23:38  iter: 29599  total_loss: 0.2412  loss_cls: 0.1256  loss_box_reg: 0.08522  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.0173  time: 0.6809  data_time: 0.0684  lr: 0.0004  max_mem: 11812M
[11/17 11:39:23] d2.utils.events INFO:  eta: 1:23:27  iter: 29619  total_loss: 0.2428  loss_cls: 0.1236  loss_box_reg: 0.08595  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.01785  time: 0.6809  data_time: 0.0728  lr: 0.0004  max_mem: 11812M
[11/17 11:39:36] d2.utils.events INFO:  eta: 1:23:14  iter: 29639  total_loss: 0.2351  loss_cls: 0.1246  loss_box_reg: 0.08369  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01764  time: 0.6809  data_time: 0.0665  lr: 0.0004  max_mem: 11812M
[11/17 11:39:50] d2.utils.events INFO:  eta: 1:22:58  iter: 29659  total_loss: 0.2293  loss_cls: 0.1189  loss_box_reg: 0.08115  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01766  time: 0.6809  data_time: 0.0682  lr: 0.0004  max_mem: 11812M
[11/17 11:40:03] d2.utils.events INFO:  eta: 1:22:45  iter: 29679  total_loss: 0.2447  loss_cls: 0.1246  loss_box_reg: 0.08756  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.01749  time: 0.6809  data_time: 0.0650  lr: 0.0004  max_mem: 11812M
[11/17 11:40:17] d2.utils.events INFO:  eta: 1:22:31  iter: 29699  total_loss: 0.2449  loss_cls: 0.1233  loss_box_reg: 0.08825  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.01819  time: 0.6809  data_time: 0.0694  lr: 0.0004  max_mem: 11812M
[11/17 11:40:31] d2.utils.events INFO:  eta: 1:22:17  iter: 29719  total_loss: 0.2466  loss_cls: 0.131  loss_box_reg: 0.08492  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01797  time: 0.6809  data_time: 0.0764  lr: 0.0004  max_mem: 11812M
[11/17 11:40:44] d2.utils.events INFO:  eta: 1:22:03  iter: 29739  total_loss: 0.2392  loss_cls: 0.1238  loss_box_reg: 0.0832  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.0174  time: 0.6809  data_time: 0.0625  lr: 0.0004  max_mem: 11812M
[11/17 11:40:58] d2.utils.events INFO:  eta: 1:21:50  iter: 29759  total_loss: 0.251  loss_cls: 0.1329  loss_box_reg: 0.08995  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.0186  time: 0.6809  data_time: 0.0728  lr: 0.0004  max_mem: 11812M
[11/17 11:41:11] d2.utils.events INFO:  eta: 1:21:36  iter: 29779  total_loss: 0.2551  loss_cls: 0.1326  loss_box_reg: 0.09118  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01694  time: 0.6809  data_time: 0.0600  lr: 0.0004  max_mem: 11812M
[11/17 11:41:25] d2.utils.events INFO:  eta: 1:21:22  iter: 29799  total_loss: 0.2457  loss_cls: 0.1279  loss_box_reg: 0.0878  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01728  time: 0.6809  data_time: 0.0636  lr: 0.0004  max_mem: 11812M
[11/17 11:41:38] d2.utils.events INFO:  eta: 1:21:07  iter: 29819  total_loss: 0.2316  loss_cls: 0.1216  loss_box_reg: 0.08026  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.01606  time: 0.6809  data_time: 0.0627  lr: 0.0004  max_mem: 11812M
[11/17 11:41:52] d2.utils.events INFO:  eta: 1:20:54  iter: 29839  total_loss: 0.2464  loss_cls: 0.1296  loss_box_reg: 0.08658  loss_rpn_cls: 0.0144  loss_rpn_loc: 0.01735  time: 0.6809  data_time: 0.0703  lr: 0.0004  max_mem: 11812M
[11/17 11:42:06] d2.utils.events INFO:  eta: 1:20:40  iter: 29859  total_loss: 0.2322  loss_cls: 0.1201  loss_box_reg: 0.08234  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01884  time: 0.6809  data_time: 0.0730  lr: 0.0004  max_mem: 11812M
[11/17 11:42:19] d2.utils.events INFO:  eta: 1:20:29  iter: 29879  total_loss: 0.2302  loss_cls: 0.1213  loss_box_reg: 0.0818  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.0167  time: 0.6809  data_time: 0.0703  lr: 0.0004  max_mem: 11812M
[11/17 11:42:33] d2.utils.events INFO:  eta: 1:20:17  iter: 29899  total_loss: 0.2469  loss_cls: 0.1257  loss_box_reg: 0.08703  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.0156  time: 0.6809  data_time: 0.0704  lr: 0.0004  max_mem: 11812M
[11/17 11:42:47] d2.utils.events INFO:  eta: 1:20:02  iter: 29919  total_loss: 0.2583  loss_cls: 0.131  loss_box_reg: 0.08939  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.01966  time: 0.6809  data_time: 0.0640  lr: 0.0004  max_mem: 11812M
[11/17 11:43:00] d2.utils.events INFO:  eta: 1:19:49  iter: 29939  total_loss: 0.2387  loss_cls: 0.1243  loss_box_reg: 0.08708  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01567  time: 0.6809  data_time: 0.0736  lr: 0.0004  max_mem: 11812M
[11/17 11:43:14] d2.utils.events INFO:  eta: 1:19:37  iter: 29959  total_loss: 0.2376  loss_cls: 0.1246  loss_box_reg: 0.08458  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01611  time: 0.6809  data_time: 0.0625  lr: 0.0004  max_mem: 11812M
[11/17 11:43:27] d2.utils.events INFO:  eta: 1:19:23  iter: 29979  total_loss: 0.24  loss_cls: 0.1223  loss_box_reg: 0.08743  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.018  time: 0.6809  data_time: 0.0641  lr: 0.0004  max_mem: 11812M
[11/17 11:43:41] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0029999.pth
[11/17 11:43:42] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 11:43:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 11:43:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 11:43:42] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 11:43:42] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 11:43:42] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 11:43:49] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0444 s/iter. Eval: 0.0003 s/iter. Total: 0.0458 s/iter. ETA=0:02:32
[11/17 11:43:54] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0017 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:12
[11/17 11:43:59] d2.evaluation.evaluator INFO: Inference done 256/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:06
[11/17 11:44:04] d2.evaluation.evaluator INFO: Inference done 379/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:02:01
[11/17 11:44:09] d2.evaluation.evaluator INFO: Inference done 499/3334. Dataloading: 0.0016 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:56
[11/17 11:44:14] d2.evaluation.evaluator INFO: Inference done 615/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:52
[11/17 11:44:19] d2.evaluation.evaluator INFO: Inference done 735/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:48
[11/17 11:44:24] d2.evaluation.evaluator INFO: Inference done 855/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:43
[11/17 11:44:29] d2.evaluation.evaluator INFO: Inference done 975/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:38
[11/17 11:44:34] d2.evaluation.evaluator INFO: Inference done 1092/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:33
[11/17 11:44:39] d2.evaluation.evaluator INFO: Inference done 1214/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:28
[11/17 11:44:44] d2.evaluation.evaluator INFO: Inference done 1333/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:23
[11/17 11:44:49] d2.evaluation.evaluator INFO: Inference done 1453/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:18
[11/17 11:44:54] d2.evaluation.evaluator INFO: Inference done 1574/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/17 11:44:59] d2.evaluation.evaluator INFO: Inference done 1692/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:08
[11/17 11:45:04] d2.evaluation.evaluator INFO: Inference done 1810/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:03
[11/17 11:45:09] d2.evaluation.evaluator INFO: Inference done 1930/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:58
[11/17 11:45:14] d2.evaluation.evaluator INFO: Inference done 2054/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:53
[11/17 11:45:19] d2.evaluation.evaluator INFO: Inference done 2172/3334. Dataloading: 0.0016 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:48
[11/17 11:45:24] d2.evaluation.evaluator INFO: Inference done 2290/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:00:43
[11/17 11:45:29] d2.evaluation.evaluator INFO: Inference done 2408/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:38
[11/17 11:45:34] d2.evaluation.evaluator INFO: Inference done 2528/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:33
[11/17 11:45:39] d2.evaluation.evaluator INFO: Inference done 2646/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:28
[11/17 11:45:44] d2.evaluation.evaluator INFO: Inference done 2767/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:23
[11/17 11:45:49] d2.evaluation.evaluator INFO: Inference done 2886/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:18
[11/17 11:45:55] d2.evaluation.evaluator INFO: Inference done 3008/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:13
[11/17 11:46:00] d2.evaluation.evaluator INFO: Inference done 3123/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:00:08
[11/17 11:46:05] d2.evaluation.evaluator INFO: Inference done 3244/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:00:03
[11/17 11:46:08] d2.evaluation.evaluator INFO: Total inference time: 0:02:19.512200 (0.041908 s / iter per device, on 6 devices)
[11/17 11:46:08] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039923 s / iter per device, on 6 devices)
[11/17 11:46:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 11:46:10] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 11:46:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 11:46:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 11:46:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.05 seconds.
[11/17 11:46:35] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 11:46:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.77 seconds.
[11/17 11:46:37] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.512 | 14.323 | 4.923  | 1.228 | 3.240 | 7.728 |
[11/17 11:46:37] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 9.178  | person      | 6.279  | bird                  | 20.646 |
| red panda            | 9.175  | dog         | 38.882 | snake                 | 6.963  |
| car                  | 27.588 | seal        | 1.675  | helmet                | 8.460  |
| motorcycle           | 9.355  | swine       | 5.935  | stove                 | 7.764  |
| monkey               | 6.958  | watercraft  | 17.648 | chair                 | 3.948  |
| domestic cat         | 6.208  | harp        | 6.320  | antelope              | 13.108 |
| camel                | 1.860  | koala bear  | 6.848  | bus                   | 19.028 |
| hat with a wide brim | 2.967  | ski         | 0.784  | piano                 | 7.365  |
| frog                 | 6.262  | dumbbell    | 0.096  | lobster               | 4.389  |
| bench                | 0.822  | rabbit      | 10.390 | porcupine             | 8.328  |
| butterfly            | 21.555 | guitar      | 3.380  | microphone            | 0.015  |
| tape player          | 5.912  | bear        | 7.720  | hippopotamus          | 0.349  |
| bowl                 | 6.689  | axe         | 3.048  | skunk                 | 2.321  |
| airplane             | 14.398 | otter       | 2.489  | table                 | 5.129  |
| coffee maker         | 14.994 | tie         | 0.822  | turtle                | 3.630  |
| purse                | 3.715  | dragonfly   | 4.053  | lemon                 | 10.146 |
| lizard               | 4.530  | backpack    | 4.088  | tv or monitor         | 9.476  |
| cup or mug           | 3.132  | sheep       | 4.535  | ray                   | 1.780  |
| fox                  | 5.115  | whale       | 7.283  | salt or pepper shaker | 0.444  |
| computer keyboard    | 1.651  | fig         | 2.400  | bathing cap           | 3.487  |
| bookshelf            | 9.938  | ladybug     | 24.950 | crutch                | 0.030  |
| pretzel              | 2.934  | sunglasses  | 0.406  | starfish              | 6.853  |
| croquet ball         | 8.883  | lamp        | 2.428  | apple                 | 12.160 |
| cream                | 6.225  | artichoke   | 10.383 | train                 | 10.073 |
| elephant             | 9.893  | bell pepper | 4.326  | miniskirt             | 1.716  |
| orange               | 12.152 | tiger       | 3.660  | sofa                  | 2.920  |
| horse                | 6.271  | violin      | 0.533  | traffic light         | 2.208  |
| drum                 | 0.798  | strawberry  | 6.601  | laptop                | 7.266  |
| pomegranate          | 3.250  | cucumber    | 0.290  | bicycle               | 5.003  |
| banana               | 0.951  | baby bed    | 10.777 | jellyfish             | 4.746  |
| pitcher              | 1.396  | bagel       | 3.205  | beaker                | 5.693  |
| goldfish             | 4.246  | nail        | 0.156  | mushroom              | 2.723  |
| flower pot           | 1.265  | cattle      | 1.232  | zebra                 | 16.721 |
| wine bottle          | 2.407  |             |        |                       |        |
[11/17 11:46:39] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 11:46:39] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 11:46:39] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 11:46:39] d2.evaluation.testing INFO: copypaste: 6.5118,14.3228,4.9233,1.2277,3.2400,7.7281
[11/17 11:46:39] d2.utils.events INFO:  eta: 1:19:11  iter: 29999  total_loss: 0.2432  loss_cls: 0.1272  loss_box_reg: 0.08352  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.01821  time: 0.6809  data_time: 0.0680  lr: 0.0004  max_mem: 11812M
[11/17 11:46:53] d2.utils.events INFO:  eta: 1:19:00  iter: 30019  total_loss: 0.2424  loss_cls: 0.1257  loss_box_reg: 0.0845  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01691  time: 0.6809  data_time: 0.0677  lr: 0.0004  max_mem: 11812M
[11/17 11:47:07] d2.utils.events INFO:  eta: 1:18:46  iter: 30039  total_loss: 0.2382  loss_cls: 0.1264  loss_box_reg: 0.0841  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01535  time: 0.6809  data_time: 0.0654  lr: 0.0004  max_mem: 11812M
[11/17 11:47:20] d2.utils.events INFO:  eta: 1:18:33  iter: 30059  total_loss: 0.2465  loss_cls: 0.1246  loss_box_reg: 0.08386  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01629  time: 0.6809  data_time: 0.0653  lr: 0.0004  max_mem: 11812M
[11/17 11:47:34] d2.utils.events INFO:  eta: 1:18:19  iter: 30079  total_loss: 0.2415  loss_cls: 0.1235  loss_box_reg: 0.08427  loss_rpn_cls: 0.01517  loss_rpn_loc: 0.01813  time: 0.6809  data_time: 0.0732  lr: 0.0004  max_mem: 11812M
[11/17 11:47:47] d2.utils.events INFO:  eta: 1:18:05  iter: 30099  total_loss: 0.2434  loss_cls: 0.1289  loss_box_reg: 0.08561  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01662  time: 0.6809  data_time: 0.0627  lr: 0.0004  max_mem: 11812M
[11/17 11:48:01] d2.utils.events INFO:  eta: 1:17:51  iter: 30119  total_loss: 0.2329  loss_cls: 0.1253  loss_box_reg: 0.08113  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01551  time: 0.6809  data_time: 0.0689  lr: 0.0004  max_mem: 11812M
[11/17 11:48:14] d2.utils.events INFO:  eta: 1:17:38  iter: 30139  total_loss: 0.2461  loss_cls: 0.1293  loss_box_reg: 0.08683  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01757  time: 0.6809  data_time: 0.0678  lr: 0.0004  max_mem: 11812M
[11/17 11:48:28] d2.utils.events INFO:  eta: 1:17:27  iter: 30159  total_loss: 0.2395  loss_cls: 0.1296  loss_box_reg: 0.08572  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01671  time: 0.6809  data_time: 0.0702  lr: 0.0004  max_mem: 11812M
[11/17 11:48:41] d2.utils.events INFO:  eta: 1:17:14  iter: 30179  total_loss: 0.2386  loss_cls: 0.1264  loss_box_reg: 0.08216  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01833  time: 0.6809  data_time: 0.0641  lr: 0.0004  max_mem: 11812M
[11/17 11:48:55] d2.utils.events INFO:  eta: 1:17:00  iter: 30199  total_loss: 0.2322  loss_cls: 0.1207  loss_box_reg: 0.08158  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.01923  time: 0.6809  data_time: 0.0675  lr: 0.0004  max_mem: 11812M
[11/17 11:49:08] d2.utils.events INFO:  eta: 1:16:44  iter: 30219  total_loss: 0.2423  loss_cls: 0.123  loss_box_reg: 0.08666  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.01742  time: 0.6809  data_time: 0.0649  lr: 0.0004  max_mem: 11812M
[11/17 11:49:22] d2.utils.events INFO:  eta: 1:16:30  iter: 30239  total_loss: 0.2485  loss_cls: 0.1303  loss_box_reg: 0.08815  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.01776  time: 0.6809  data_time: 0.0674  lr: 0.0004  max_mem: 11812M
[11/17 11:49:36] d2.utils.events INFO:  eta: 1:16:16  iter: 30259  total_loss: 0.2422  loss_cls: 0.1262  loss_box_reg: 0.08331  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.01491  time: 0.6809  data_time: 0.0652  lr: 0.0004  max_mem: 11812M
[11/17 11:49:49] d2.utils.events INFO:  eta: 1:16:03  iter: 30279  total_loss: 0.2512  loss_cls: 0.1303  loss_box_reg: 0.08987  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.01734  time: 0.6809  data_time: 0.0614  lr: 0.0004  max_mem: 11812M
[11/17 11:50:03] d2.utils.events INFO:  eta: 1:15:48  iter: 30299  total_loss: 0.2394  loss_cls: 0.1285  loss_box_reg: 0.08427  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.01735  time: 0.6809  data_time: 0.0670  lr: 0.0004  max_mem: 11812M
[11/17 11:50:17] d2.utils.events INFO:  eta: 1:15:36  iter: 30319  total_loss: 0.2348  loss_cls: 0.125  loss_box_reg: 0.08052  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01614  time: 0.6809  data_time: 0.0830  lr: 0.0004  max_mem: 11812M
[11/17 11:50:30] d2.utils.events INFO:  eta: 1:15:22  iter: 30339  total_loss: 0.2505  loss_cls: 0.1309  loss_box_reg: 0.08997  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.01839  time: 0.6809  data_time: 0.0593  lr: 0.0004  max_mem: 11812M
[11/17 11:50:44] d2.utils.events INFO:  eta: 1:15:07  iter: 30359  total_loss: 0.2325  loss_cls: 0.1205  loss_box_reg: 0.08322  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.01775  time: 0.6809  data_time: 0.0629  lr: 0.0004  max_mem: 11812M
[11/17 11:50:58] d2.utils.events INFO:  eta: 1:14:56  iter: 30379  total_loss: 0.2469  loss_cls: 0.1272  loss_box_reg: 0.08677  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.0168  time: 0.6809  data_time: 0.0741  lr: 0.0004  max_mem: 11812M
[11/17 11:51:11] d2.utils.events INFO:  eta: 1:14:42  iter: 30399  total_loss: 0.2464  loss_cls: 0.1261  loss_box_reg: 0.09088  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.01871  time: 0.6809  data_time: 0.0695  lr: 0.0004  max_mem: 11812M
[11/17 11:51:25] d2.utils.events INFO:  eta: 1:14:29  iter: 30419  total_loss: 0.2441  loss_cls: 0.1232  loss_box_reg: 0.08685  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01765  time: 0.6809  data_time: 0.0664  lr: 0.0004  max_mem: 11812M
[11/17 11:51:38] d2.utils.events INFO:  eta: 1:14:15  iter: 30439  total_loss: 0.2403  loss_cls: 0.1281  loss_box_reg: 0.08399  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01748  time: 0.6809  data_time: 0.0677  lr: 0.0004  max_mem: 11812M
[11/17 11:51:52] d2.utils.events INFO:  eta: 1:14:02  iter: 30459  total_loss: 0.2316  loss_cls: 0.1218  loss_box_reg: 0.08201  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.01555  time: 0.6809  data_time: 0.0673  lr: 0.0004  max_mem: 11812M
[11/17 11:52:06] d2.utils.events INFO:  eta: 1:13:50  iter: 30479  total_loss: 0.2398  loss_cls: 0.1302  loss_box_reg: 0.0852  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.0164  time: 0.6809  data_time: 0.0728  lr: 0.0004  max_mem: 11812M
[11/17 11:52:19] d2.utils.events INFO:  eta: 1:13:37  iter: 30499  total_loss: 0.2544  loss_cls: 0.1306  loss_box_reg: 0.08538  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.02014  time: 0.6809  data_time: 0.0632  lr: 0.0004  max_mem: 11812M
[11/17 11:52:33] d2.utils.events INFO:  eta: 1:13:25  iter: 30519  total_loss: 0.2501  loss_cls: 0.1282  loss_box_reg: 0.09034  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.0181  time: 0.6809  data_time: 0.0682  lr: 0.0004  max_mem: 11812M
[11/17 11:52:47] d2.utils.events INFO:  eta: 1:13:13  iter: 30539  total_loss: 0.2376  loss_cls: 0.1243  loss_box_reg: 0.0826  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.01734  time: 0.6809  data_time: 0.0652  lr: 0.0004  max_mem: 11812M
[11/17 11:53:00] d2.utils.events INFO:  eta: 1:12:58  iter: 30559  total_loss: 0.2368  loss_cls: 0.1253  loss_box_reg: 0.08315  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01838  time: 0.6809  data_time: 0.0668  lr: 0.0004  max_mem: 11812M
[11/17 11:53:14] d2.utils.events INFO:  eta: 1:12:46  iter: 30579  total_loss: 0.2427  loss_cls: 0.1288  loss_box_reg: 0.08426  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.01715  time: 0.6809  data_time: 0.0642  lr: 0.0004  max_mem: 11812M
[11/17 11:53:27] d2.utils.events INFO:  eta: 1:12:30  iter: 30599  total_loss: 0.2378  loss_cls: 0.1236  loss_box_reg: 0.08078  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01705  time: 0.6809  data_time: 0.0652  lr: 0.0004  max_mem: 11812M
[11/17 11:53:41] d2.utils.events INFO:  eta: 1:12:19  iter: 30619  total_loss: 0.2405  loss_cls: 0.1271  loss_box_reg: 0.08339  loss_rpn_cls: 0.01392  loss_rpn_loc: 0.01776  time: 0.6809  data_time: 0.0676  lr: 0.0004  max_mem: 11812M
[11/17 11:53:55] d2.utils.events INFO:  eta: 1:12:07  iter: 30639  total_loss: 0.2463  loss_cls: 0.1295  loss_box_reg: 0.08646  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01596  time: 0.6809  data_time: 0.0657  lr: 0.0004  max_mem: 11812M
[11/17 11:54:08] d2.utils.events INFO:  eta: 1:11:56  iter: 30659  total_loss: 0.2548  loss_cls: 0.1321  loss_box_reg: 0.08925  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01776  time: 0.6809  data_time: 0.0665  lr: 0.0004  max_mem: 11812M
[11/17 11:54:22] d2.utils.events INFO:  eta: 1:11:44  iter: 30679  total_loss: 0.2411  loss_cls: 0.1256  loss_box_reg: 0.08377  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.01674  time: 0.6809  data_time: 0.0698  lr: 0.0004  max_mem: 11812M
[11/17 11:54:36] d2.utils.events INFO:  eta: 1:11:30  iter: 30699  total_loss: 0.2278  loss_cls: 0.1222  loss_box_reg: 0.08094  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.01565  time: 0.6809  data_time: 0.0783  lr: 0.0004  max_mem: 11812M
[11/17 11:54:49] d2.utils.events INFO:  eta: 1:11:17  iter: 30719  total_loss: 0.2308  loss_cls: 0.1233  loss_box_reg: 0.0801  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01613  time: 0.6809  data_time: 0.0701  lr: 0.0004  max_mem: 11812M
[11/17 11:55:03] d2.utils.events INFO:  eta: 1:11:04  iter: 30739  total_loss: 0.2504  loss_cls: 0.1329  loss_box_reg: 0.08937  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.01603  time: 0.6809  data_time: 0.0662  lr: 0.0004  max_mem: 11812M
[11/17 11:55:16] d2.utils.events INFO:  eta: 1:10:50  iter: 30759  total_loss: 0.2488  loss_cls: 0.1322  loss_box_reg: 0.08737  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01696  time: 0.6809  data_time: 0.0598  lr: 0.0004  max_mem: 11812M
[11/17 11:55:30] d2.utils.events INFO:  eta: 1:10:36  iter: 30779  total_loss: 0.2332  loss_cls: 0.1228  loss_box_reg: 0.08083  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01766  time: 0.6809  data_time: 0.0684  lr: 0.0004  max_mem: 11812M
[11/17 11:55:44] d2.utils.events INFO:  eta: 1:10:23  iter: 30799  total_loss: 0.2434  loss_cls: 0.1256  loss_box_reg: 0.08429  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.0171  time: 0.6809  data_time: 0.0688  lr: 0.0004  max_mem: 11812M
[11/17 11:55:57] d2.utils.events INFO:  eta: 1:10:09  iter: 30819  total_loss: 0.2445  loss_cls: 0.1287  loss_box_reg: 0.08699  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01639  time: 0.6809  data_time: 0.0627  lr: 0.0004  max_mem: 11812M
[11/17 11:56:11] d2.utils.events INFO:  eta: 1:09:55  iter: 30839  total_loss: 0.234  loss_cls: 0.1204  loss_box_reg: 0.08314  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.01719  time: 0.6809  data_time: 0.0655  lr: 0.0004  max_mem: 11812M
[11/17 11:56:25] d2.utils.events INFO:  eta: 1:09:41  iter: 30859  total_loss: 0.2383  loss_cls: 0.1207  loss_box_reg: 0.08457  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01691  time: 0.6809  data_time: 0.0719  lr: 0.0004  max_mem: 11812M
[11/17 11:56:38] d2.utils.events INFO:  eta: 1:09:27  iter: 30879  total_loss: 0.2357  loss_cls: 0.1223  loss_box_reg: 0.08443  loss_rpn_cls: 0.01197  loss_rpn_loc: 0.01805  time: 0.6809  data_time: 0.0675  lr: 0.0004  max_mem: 11812M
[11/17 11:56:52] d2.utils.events INFO:  eta: 1:09:14  iter: 30899  total_loss: 0.2515  loss_cls: 0.1317  loss_box_reg: 0.0864  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01723  time: 0.6809  data_time: 0.0728  lr: 0.0004  max_mem: 11812M
[11/17 11:57:06] d2.utils.events INFO:  eta: 1:09:01  iter: 30919  total_loss: 0.2348  loss_cls: 0.1253  loss_box_reg: 0.08037  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01784  time: 0.6809  data_time: 0.0708  lr: 0.0004  max_mem: 11812M
[11/17 11:57:19] d2.utils.events INFO:  eta: 1:08:46  iter: 30939  total_loss: 0.2385  loss_cls: 0.1254  loss_box_reg: 0.08538  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.01687  time: 0.6809  data_time: 0.0751  lr: 0.0004  max_mem: 11812M
[11/17 11:57:33] d2.utils.events INFO:  eta: 1:08:33  iter: 30959  total_loss: 0.2527  loss_cls: 0.1324  loss_box_reg: 0.08599  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.01874  time: 0.6809  data_time: 0.0813  lr: 0.0004  max_mem: 11812M
[11/17 11:57:47] d2.utils.events INFO:  eta: 1:08:19  iter: 30979  total_loss: 0.241  loss_cls: 0.1241  loss_box_reg: 0.08653  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.01697  time: 0.6809  data_time: 0.0614  lr: 0.0004  max_mem: 11812M
[11/17 11:58:00] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0030999.pth
[11/17 11:58:00] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 11:58:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 11:58:01] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 11:58:01] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 11:58:01] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 11:58:01] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 11:58:08] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0441 s/iter. ETA=0:02:26
[11/17 11:58:13] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:14
[11/17 11:58:18] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0014 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0420 s/iter. ETA=0:02:09
[11/17 11:58:23] d2.evaluation.evaluator INFO: Inference done 371/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:04
[11/17 11:58:28] d2.evaluation.evaluator INFO: Inference done 493/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:58
[11/17 11:58:33] d2.evaluation.evaluator INFO: Inference done 614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:53
[11/17 11:58:38] d2.evaluation.evaluator INFO: Inference done 731/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:49
[11/17 11:58:43] d2.evaluation.evaluator INFO: Inference done 851/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:44
[11/17 11:58:48] d2.evaluation.evaluator INFO: Inference done 970/3334. Dataloading: 0.0016 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:39
[11/17 11:58:53] d2.evaluation.evaluator INFO: Inference done 1091/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:01:33
[11/17 11:58:58] d2.evaluation.evaluator INFO: Inference done 1212/3334. Dataloading: 0.0016 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:28
[11/17 11:59:03] d2.evaluation.evaluator INFO: Inference done 1334/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:23
[11/17 11:59:08] d2.evaluation.evaluator INFO: Inference done 1454/3334. Dataloading: 0.0015 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:01:18
[11/17 11:59:13] d2.evaluation.evaluator INFO: Inference done 1578/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:13
[11/17 11:59:18] d2.evaluation.evaluator INFO: Inference done 1700/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:01:08
[11/17 11:59:23] d2.evaluation.evaluator INFO: Inference done 1823/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:02
[11/17 11:59:28] d2.evaluation.evaluator INFO: Inference done 1942/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:57
[11/17 11:59:33] d2.evaluation.evaluator INFO: Inference done 2061/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:53
[11/17 11:59:38] d2.evaluation.evaluator INFO: Inference done 2182/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:47
[11/17 11:59:43] d2.evaluation.evaluator INFO: Inference done 2303/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:42
[11/17 11:59:48] d2.evaluation.evaluator INFO: Inference done 2428/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:37
[11/17 11:59:53] d2.evaluation.evaluator INFO: Inference done 2547/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:32
[11/17 11:59:58] d2.evaluation.evaluator INFO: Inference done 2669/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:27
[11/17 12:00:03] d2.evaluation.evaluator INFO: Inference done 2787/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:22
[11/17 12:00:08] d2.evaluation.evaluator INFO: Inference done 2906/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:00:17
[11/17 12:00:13] d2.evaluation.evaluator INFO: Inference done 3028/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:12
[11/17 12:00:18] d2.evaluation.evaluator INFO: Inference done 3150/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:07
[11/17 12:00:23] d2.evaluation.evaluator INFO: Inference done 3271/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:00:02
[11/17 12:00:26] d2.evaluation.evaluator INFO: Total inference time: 0:02:18.710584 (0.041667 s / iter per device, on 6 devices)
[11/17 12:00:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:12 (0.039735 s / iter per device, on 6 devices)
[11/17 12:00:28] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 12:00:28] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 12:00:29] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 12:00:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 12:00:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.99 seconds.
[11/17 12:00:55] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 12:00:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.05 seconds.
[11/17 12:00:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.561 | 14.435 | 5.021  | 1.230 | 3.298 | 7.836 |
[11/17 12:00:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.484  | person      | 6.054  | bird                  | 21.152 |
| red panda            | 7.894  | dog         | 40.045 | snake                 | 7.227  |
| car                  | 27.570 | seal        | 2.049  | helmet                | 9.156  |
| motorcycle           | 9.834  | swine       | 5.907  | stove                 | 7.875  |
| monkey               | 7.009  | watercraft  | 17.758 | chair                 | 3.628  |
| domestic cat         | 6.093  | harp        | 6.359  | antelope              | 12.943 |
| camel                | 1.579  | koala bear  | 8.431  | bus                   | 19.679 |
| hat with a wide brim | 2.388  | ski         | 0.798  | piano                 | 7.518  |
| frog                 | 7.012  | dumbbell    | 0.080  | lobster               | 3.673  |
| bench                | 0.960  | rabbit      | 10.700 | porcupine             | 7.805  |
| butterfly            | 21.696 | guitar      | 2.916  | microphone            | 0.012  |
| tape player          | 6.858  | bear        | 7.988  | hippopotamus          | 0.334  |
| bowl                 | 7.071  | axe         | 2.977  | skunk                 | 1.774  |
| airplane             | 13.920 | otter       | 2.121  | table                 | 4.663  |
| coffee maker         | 15.916 | tie         | 0.635  | turtle                | 3.682  |
| purse                | 3.899  | dragonfly   | 4.336  | lemon                 | 10.438 |
| lizard               | 4.439  | backpack    | 4.840  | tv or monitor         | 9.615  |
| cup or mug           | 3.200  | sheep       | 3.731  | ray                   | 1.881  |
| fox                  | 5.678  | whale       | 8.376  | salt or pepper shaker | 0.548  |
| computer keyboard    | 2.408  | fig         | 2.804  | bathing cap           | 2.829  |
| bookshelf            | 10.016 | ladybug     | 24.054 | crutch                | 0.046  |
| pretzel              | 3.510  | sunglasses  | 0.373  | starfish              | 6.452  |
| croquet ball         | 9.682  | lamp        | 1.643  | apple                 | 11.592 |
| cream                | 8.122  | artichoke   | 11.837 | train                 | 11.575 |
| elephant             | 10.122 | bell pepper | 4.434  | miniskirt             | 1.199  |
| orange               | 12.364 | tiger       | 3.095  | sofa                  | 2.989  |
| horse                | 6.215  | violin      | 0.635  | traffic light         | 2.024  |
| drum                 | 0.710  | strawberry  | 7.027  | laptop                | 5.674  |
| pomegranate          | 3.289  | cucumber    | 0.310  | bicycle               | 3.568  |
| banana               | 1.053  | baby bed    | 10.669 | jellyfish             | 5.137  |
| pitcher              | 1.188  | bagel       | 3.650  | beaker                | 4.548  |
| goldfish             | 3.864  | nail        | 0.147  | mushroom              | 2.626  |
| flower pot           | 1.002  | cattle      | 1.313  | zebra                 | 16.961 |
| wine bottle          | 2.145  |             |        |                       |        |
[11/17 12:01:00] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 12:01:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 12:01:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 12:01:00] d2.evaluation.testing INFO: copypaste: 6.5610,14.4354,5.0208,1.2304,3.2975,7.8356
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 12:29:32] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=True, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/17 12:29:32] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: ""
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"ene
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (102000, 108000)
  MAX_ITER: 111000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.01
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: "../../output/supervised"
[11/17 12:29:32] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ''
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 111000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 102000
  - 108000
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/17 12:29:32] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/17 12:29:32] d2.utils.env INFO: Using a generated random seed 34704005
[11/17 12:29:33] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/17 12:29:33] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/17 12:29:33] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/17 12:29:34] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 281          |   person    | 4657         |     bird      | 4331         |
|   red panda   | 108          |     dog     | 8341         |     snake     | 1001         |
|      car      | 1171         |    seal     | 224          |    helmet     | 433          |
|  motorcycle   | 278          |    swine    | 259          |     stove     | 156          |
|    monkey     | 1004         | watercraft  | 1038         |     chair     | 905          |
| domestic cat  | 395          |    harp     | 152          |   antelope    | 288          |
|     camel     | 276          | koala bear  | 139          |      bus      | 322          |
| hat with a .. | 206          |     ski     | 109          |     piano     | 199          |
|     frog      | 245          |  dumbbell   | 180          |    lobster    | 253          |
|     bench     | 150          |   rabbit    | 235          |   porcupine   | 126          |
|   butterfly   | 453          |   guitar    | 295          |  microphone   | 259          |
|  tape player  | 109          |    bear     | 361          | hippopotamus  | 118          |
|     bowl      | 335          |     axe     | 127          |     skunk     | 99           |
|   airplane    | 217          |    otter    | 127          |     table     | 786          |
| coffee maker  | 143          |     tie     | 124          |    turtle     | 313          |
|     purse     | 130          |  dragonfly  | 175          |     lemon     | 170          |
|    lizard     | 640          |  backpack   | 148          | tv or monitor | 212          |
|  cup or mug   | 283          |    sheep    | 196          |      ray      | 198          |
|      fox      | 292          |    whale    | 155          | salt or pep.. | 129          |
| computer ke.. | 102          |     fig     | 133          |  bathing cap  | 163          |
|   bookshelf   | 106          |   ladybug   | 138          |    crutch     | 138          |
|    pretzel    | 124          | sunglasses  | 243          |   starfish    | 130          |
| croquet ball  | 135          |    lamp     | 319          |     apple     | 216          |
|     cream     | 194          |  artichoke  | 180          |     train     | 178          |
|   elephant    | 242          | bell pepper | 146          |   miniskirt   | 118          |
|    orange     | 207          |    tiger    | 159          |     sofa      | 160          |
|     horse     | 265          |   violin    | 118          | traffic light | 142          |
|     drum      | 251          | strawberry  | 232          |    laptop     | 172          |
|  pomegranate  | 188          |  cucumber   | 114          |    bicycle    | 187          |
|    banana     | 244          |  baby bed   | 185          |   jellyfish   | 184          |
|    pitcher    | 120          |    bagel    | 125          |    beaker     | 115          |
|   goldfish    | 228          |    nail     | 86           |   mushroom    | 124          |
|  flower pot   | 189          |   cattle    | 148          |     zebra     | 135          |
|  wine bottle  | 154          |             |              |               |              |
|     total     | 41293        |             |              |               |              |[0m
[11/17 12:29:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/17 12:29:34] d2.data.build INFO: Using training sampler TrainingSampler
[11/17 12:29:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 12:29:34] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/17 12:29:34] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/17 12:29:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_0030999.pth ...
[11/17 12:29:34] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/17 12:29:34] fvcore.common.checkpoint INFO: Loading trainer from ../../output/supervised/model_0030999.pth ...
[11/17 12:29:34] d2.engine.hooks INFO: Loading scheduler from state_dict ...
[11/17 12:29:36] d2.engine.train_loop INFO: Starting training from iteration 31000
[11/17 12:29:58] d2.utils.events INFO:  eta: 15:05:57  iter: 31019  total_loss: 0.2445  loss_cls: 0.1298  loss_box_reg: 0.08537  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.01634  time: 0.6760  data_time: 0.4047  lr: 0.004  max_mem: 11813M
[11/17 12:30:12] d2.utils.events INFO:  eta: 15:09:32  iter: 31039  total_loss: 0.2431  loss_cls: 0.1318  loss_box_reg: 0.08159  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.01715  time: 0.6789  data_time: 0.0689  lr: 0.004  max_mem: 11813M
[11/17 12:30:25] d2.utils.events INFO:  eta: 15:07:56  iter: 31059  total_loss: 0.2664  loss_cls: 0.1416  loss_box_reg: 0.09036  loss_rpn_cls: 0.01364  loss_rpn_loc: 0.01707  time: 0.6791  data_time: 0.0663  lr: 0.004  max_mem: 11813M
[11/17 12:30:39] d2.utils.events INFO:  eta: 15:09:03  iter: 31079  total_loss: 0.2568  loss_cls: 0.1354  loss_box_reg: 0.08779  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.01777  time: 0.6798  data_time: 0.0674  lr: 0.004  max_mem: 11813M
[11/17 12:30:52] d2.utils.events INFO:  eta: 15:08:05  iter: 31099  total_loss: 0.2444  loss_cls: 0.1262  loss_box_reg: 0.08701  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.01804  time: 0.6802  data_time: 0.0709  lr: 0.004  max_mem: 11813M
[11/17 12:31:06] d2.utils.events INFO:  eta: 15:08:36  iter: 31119  total_loss: 0.2493  loss_cls: 0.1302  loss_box_reg: 0.08529  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01877  time: 0.6810  data_time: 0.0665  lr: 0.004  max_mem: 11814M
[11/17 12:31:20] d2.utils.events INFO:  eta: 15:07:59  iter: 31139  total_loss: 0.2425  loss_cls: 0.1282  loss_box_reg: 0.08606  loss_rpn_cls: 0.01471  loss_rpn_loc: 0.01625  time: 0.6807  data_time: 0.0673  lr: 0.004  max_mem: 11814M
[11/17 12:31:33] d2.utils.events INFO:  eta: 15:05:16  iter: 31159  total_loss: 0.245  loss_cls: 0.1302  loss_box_reg: 0.0824  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01844  time: 0.6793  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 12:31:47] d2.utils.events INFO:  eta: 15:04:47  iter: 31179  total_loss: 0.2568  loss_cls: 0.1355  loss_box_reg: 0.08862  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01597  time: 0.6788  data_time: 0.0596  lr: 0.004  max_mem: 11814M
[11/17 12:32:00] d2.utils.events INFO:  eta: 15:05:20  iter: 31199  total_loss: 0.2618  loss_cls: 0.1382  loss_box_reg: 0.08695  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.01842  time: 0.6797  data_time: 0.0699  lr: 0.004  max_mem: 11814M
[11/17 12:32:14] d2.utils.events INFO:  eta: 15:04:33  iter: 31219  total_loss: 0.2495  loss_cls: 0.1299  loss_box_reg: 0.08634  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01717  time: 0.6795  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 12:32:27] d2.utils.events INFO:  eta: 15:03:11  iter: 31239  total_loss: 0.2577  loss_cls: 0.1349  loss_box_reg: 0.08864  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.01794  time: 0.6787  data_time: 0.0629  lr: 0.004  max_mem: 11814M
[11/17 12:32:41] d2.utils.events INFO:  eta: 15:03:16  iter: 31259  total_loss: 0.2526  loss_cls: 0.1369  loss_box_reg: 0.08588  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01717  time: 0.6791  data_time: 0.0651  lr: 0.004  max_mem: 11814M
[11/17 12:32:55] d2.utils.events INFO:  eta: 15:03:02  iter: 31279  total_loss: 0.2347  loss_cls: 0.1235  loss_box_reg: 0.08311  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.0175  time: 0.6791  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 12:33:08] d2.utils.events INFO:  eta: 15:03:09  iter: 31299  total_loss: 0.2565  loss_cls: 0.1359  loss_box_reg: 0.0908  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01758  time: 0.6795  data_time: 0.0680  lr: 0.004  max_mem: 11814M
[11/17 12:33:22] d2.utils.events INFO:  eta: 15:03:40  iter: 31319  total_loss: 0.2477  loss_cls: 0.1297  loss_box_reg: 0.08543  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01671  time: 0.6800  data_time: 0.0711  lr: 0.004  max_mem: 11814M
[11/17 12:33:36] d2.utils.events INFO:  eta: 15:03:26  iter: 31339  total_loss: 0.2587  loss_cls: 0.1396  loss_box_reg: 0.08865  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.01751  time: 0.6800  data_time: 0.0668  lr: 0.004  max_mem: 11814M
[11/17 12:33:49] d2.utils.events INFO:  eta: 15:02:45  iter: 31359  total_loss: 0.2326  loss_cls: 0.1214  loss_box_reg: 0.08435  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.01628  time: 0.6798  data_time: 0.0658  lr: 0.004  max_mem: 11814M
[11/17 12:34:03] d2.utils.events INFO:  eta: 15:02:42  iter: 31379  total_loss: 0.245  loss_cls: 0.1286  loss_box_reg: 0.08555  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.01753  time: 0.6799  data_time: 0.0628  lr: 0.004  max_mem: 11814M
[11/17 12:34:16] d2.utils.events INFO:  eta: 15:02:39  iter: 31399  total_loss: 0.2509  loss_cls: 0.1329  loss_box_reg: 0.08771  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01744  time: 0.6800  data_time: 0.0606  lr: 0.004  max_mem: 11814M
[11/17 12:34:30] d2.utils.events INFO:  eta: 15:01:51  iter: 31419  total_loss: 0.2725  loss_cls: 0.1456  loss_box_reg: 0.09465  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.01701  time: 0.6798  data_time: 0.0633  lr: 0.004  max_mem: 11814M
[11/17 12:34:44] d2.utils.events INFO:  eta: 15:01:37  iter: 31439  total_loss: 0.2604  loss_cls: 0.1351  loss_box_reg: 0.0896  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.01756  time: 0.6802  data_time: 0.0788  lr: 0.004  max_mem: 11814M
[11/17 12:34:57] d2.utils.events INFO:  eta: 15:01:24  iter: 31459  total_loss: 0.2491  loss_cls: 0.1349  loss_box_reg: 0.08354  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01809  time: 0.6802  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 12:35:11] d2.utils.events INFO:  eta: 15:01:10  iter: 31479  total_loss: 0.2504  loss_cls: 0.13  loss_box_reg: 0.08375  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.01819  time: 0.6805  data_time: 0.0729  lr: 0.004  max_mem: 11814M
[11/17 12:35:25] d2.utils.events INFO:  eta: 15:01:09  iter: 31499  total_loss: 0.261  loss_cls: 0.1394  loss_box_reg: 0.09139  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01686  time: 0.6807  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 12:35:38] d2.utils.events INFO:  eta: 15:00:56  iter: 31519  total_loss: 0.2554  loss_cls: 0.1309  loss_box_reg: 0.08736  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.01854  time: 0.6808  data_time: 0.0692  lr: 0.004  max_mem: 11814M
[11/17 12:35:52] d2.utils.events INFO:  eta: 15:00:18  iter: 31539  total_loss: 0.2451  loss_cls: 0.1288  loss_box_reg: 0.08468  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.01909  time: 0.6805  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 12:36:06] d2.utils.events INFO:  eta: 15:00:06  iter: 31559  total_loss: 0.2495  loss_cls: 0.1286  loss_box_reg: 0.09018  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.01776  time: 0.6806  data_time: 0.0634  lr: 0.004  max_mem: 11814M
[11/17 12:36:19] d2.utils.events INFO:  eta: 15:00:26  iter: 31579  total_loss: 0.2384  loss_cls: 0.1264  loss_box_reg: 0.0813  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.01662  time: 0.6808  data_time: 0.0586  lr: 0.004  max_mem: 11814M
[11/17 12:36:33] d2.utils.events INFO:  eta: 15:00:29  iter: 31599  total_loss: 0.2534  loss_cls: 0.1338  loss_box_reg: 0.0866  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01671  time: 0.6809  data_time: 0.0732  lr: 0.004  max_mem: 11814M
[11/17 12:36:46] d2.utils.events INFO:  eta: 14:59:48  iter: 31619  total_loss: 0.251  loss_cls: 0.1293  loss_box_reg: 0.08816  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.01794  time: 0.6804  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 12:37:00] d2.utils.events INFO:  eta: 14:59:21  iter: 31639  total_loss: 0.2557  loss_cls: 0.1364  loss_box_reg: 0.0871  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.01682  time: 0.6806  data_time: 0.0796  lr: 0.004  max_mem: 11814M
[11/17 12:37:14] d2.utils.events INFO:  eta: 14:58:58  iter: 31659  total_loss: 0.2636  loss_cls: 0.1352  loss_box_reg: 0.08481  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.01997  time: 0.6806  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 12:37:27] d2.utils.events INFO:  eta: 14:58:43  iter: 31679  total_loss: 0.2507  loss_cls: 0.13  loss_box_reg: 0.08556  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.01738  time: 0.6803  data_time: 0.0628  lr: 0.004  max_mem: 11814M
[11/17 12:37:41] d2.utils.events INFO:  eta: 14:58:25  iter: 31699  total_loss: 0.2489  loss_cls: 0.1324  loss_box_reg: 0.0855  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.01615  time: 0.6801  data_time: 0.0659  lr: 0.004  max_mem: 11814M
[11/17 12:37:54] d2.utils.events INFO:  eta: 14:58:03  iter: 31719  total_loss: 0.2427  loss_cls: 0.1264  loss_box_reg: 0.08669  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.01702  time: 0.6799  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 12:38:08] d2.utils.events INFO:  eta: 14:57:55  iter: 31739  total_loss: 0.2595  loss_cls: 0.1368  loss_box_reg: 0.09012  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.0178  time: 0.6800  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 12:38:21] d2.utils.events INFO:  eta: 14:57:45  iter: 31759  total_loss: 0.2512  loss_cls: 0.1351  loss_box_reg: 0.0874  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.01817  time: 0.6800  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 12:38:35] d2.utils.events INFO:  eta: 14:57:04  iter: 31779  total_loss: 0.2538  loss_cls: 0.1304  loss_box_reg: 0.08885  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.01755  time: 0.6799  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 12:38:48] d2.utils.events INFO:  eta: 14:56:51  iter: 31799  total_loss: 0.2531  loss_cls: 0.1352  loss_box_reg: 0.09047  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.01664  time: 0.6797  data_time: 0.0651  lr: 0.004  max_mem: 11814M
[11/17 12:39:02] d2.utils.events INFO:  eta: 14:56:37  iter: 31819  total_loss: 0.2468  loss_cls: 0.1294  loss_box_reg: 0.08524  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01792  time: 0.6797  data_time: 0.0608  lr: 0.004  max_mem: 11814M
[11/17 12:39:16] d2.utils.events INFO:  eta: 14:56:50  iter: 31839  total_loss: 0.2395  loss_cls: 0.1255  loss_box_reg: 0.08548  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01994  time: 0.6806  data_time: 0.1025  lr: 0.004  max_mem: 11814M
[11/17 12:39:30] d2.utils.events INFO:  eta: 14:56:34  iter: 31859  total_loss: 0.2476  loss_cls: 0.1365  loss_box_reg: 0.08481  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01632  time: 0.6804  data_time: 0.0614  lr: 0.004  max_mem: 11814M
[11/17 12:39:43] d2.utils.events INFO:  eta: 14:55:56  iter: 31879  total_loss: 0.2407  loss_cls: 0.1273  loss_box_reg: 0.08571  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.017  time: 0.6806  data_time: 0.0822  lr: 0.004  max_mem: 11814M
[11/17 12:39:57] d2.utils.events INFO:  eta: 14:56:01  iter: 31899  total_loss: 0.2565  loss_cls: 0.1349  loss_box_reg: 0.0902  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.0173  time: 0.6806  data_time: 0.0675  lr: 0.004  max_mem: 11814M
[11/17 12:40:11] d2.utils.events INFO:  eta: 14:55:55  iter: 31919  total_loss: 0.269  loss_cls: 0.1388  loss_box_reg: 0.0925  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.01859  time: 0.6807  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 12:40:24] d2.utils.events INFO:  eta: 14:55:42  iter: 31939  total_loss: 0.2473  loss_cls: 0.1321  loss_box_reg: 0.08473  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.01598  time: 0.6806  data_time: 0.0641  lr: 0.004  max_mem: 11814M
[11/17 12:40:38] d2.utils.events INFO:  eta: 14:55:19  iter: 31959  total_loss: 0.2575  loss_cls: 0.1365  loss_box_reg: 0.09235  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.01666  time: 0.6805  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 12:40:51] d2.utils.events INFO:  eta: 14:55:15  iter: 31979  total_loss: 0.2563  loss_cls: 0.1316  loss_box_reg: 0.09067  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.01844  time: 0.6805  data_time: 0.0672  lr: 0.004  max_mem: 11814M
[11/17 12:41:05] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0031999.pth
[11/17 12:41:06] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 12:41:06] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |  category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-----------:|:-------------|:-------------:|:-------------|
|     cart      | 211          |   person    | 3096         |     bird      | 2810         |
|   red panda   | 61           |     dog     | 5631         |     snake     | 664          |
|      car      | 768          |    seal     | 120          |    helmet     | 237          |
|  motorcycle   | 224          |    swine    | 159          |     stove     | 110          |
|    monkey     | 683          | watercraft  | 686          |     chair     | 578          |
| domestic cat  | 290          |    harp     | 118          |   antelope    | 173          |
|     camel     | 138          | koala bear  | 71           |      bus      | 257          |
| hat with a .. | 160          |     ski     | 104          |     piano     | 128          |
|     frog      | 164          |  dumbbell   | 104          |    lobster    | 151          |
|     bench     | 107          |   rabbit    | 159          |   porcupine   | 73           |
|   butterfly   | 302          |   guitar    | 189          |  microphone   | 174          |
|  tape player  | 81           |    bear     | 205          | hippopotamus  | 82           |
|     bowl      | 202          |     axe     | 107          |     skunk     | 88           |
|   airplane    | 128          |    otter    | 74           |     table     | 496          |
| coffee maker  | 94           |     tie     | 91           |    turtle     | 206          |
|     purse     | 124          |  dragonfly  | 119          |     lemon     | 95           |
|    lizard     | 420          |  backpack   | 110          | tv or monitor | 165          |
|  cup or mug   | 200          |    sheep    | 149          |      ray      | 192          |
|      fox      | 195          |    whale    | 113          | salt or pep.. | 68           |
| computer ke.. | 66           |     fig     | 92           |  bathing cap  | 153          |
|   bookshelf   | 68           |   ladybug   | 85           |    crutch     | 75           |
|    pretzel    | 108          | sunglasses  | 145          |   starfish    | 92           |
| croquet ball  | 85           |    lamp     | 190          |     apple     | 145          |
|     cream     | 120          |  artichoke  | 96           |     train     | 89           |
|   elephant    | 159          | bell pepper | 98           |   miniskirt   | 73           |
|    orange     | 151          |    tiger    | 76           |     sofa      | 127          |
|     horse     | 171          |   violin    | 84           | traffic light | 109          |
|     drum      | 175          | strawberry  | 162          |    laptop     | 84           |
|  pomegranate  | 114          |  cucumber   | 67           |    bicycle    | 132          |
|    banana     | 169          |  baby bed   | 134          |   jellyfish   | 103          |
|    pitcher    | 95           |    bagel    | 76           |    beaker     | 85           |
|   goldfish    | 159          |    nail     | 91           |   mushroom    | 146          |
|  flower pot   | 113          |   cattle    | 92           |     zebra     | 97           |
|  wine bottle  | 129          |             |              |               |              |
|     total     | 27584        |             |              |               |              |[0m
[11/17 12:41:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 12:41:06] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 12:41:06] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 12:41:07] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 12:41:07] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 12:41:14] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0444 s/iter. Eval: 0.0002 s/iter. Total: 0.0456 s/iter. ETA=0:02:31
[11/17 12:41:19] d2.evaluation.evaluator INFO: Inference done 136/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/17 12:41:24] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:05
[11/17 12:41:29] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:00
[11/17 12:41:34] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:56
[11/17 12:41:39] d2.evaluation.evaluator INFO: Inference done 621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/17 12:41:44] d2.evaluation.evaluator INFO: Inference done 743/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/17 12:41:49] d2.evaluation.evaluator INFO: Inference done 866/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/17 12:41:54] d2.evaluation.evaluator INFO: Inference done 985/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:36
[11/17 12:41:59] d2.evaluation.evaluator INFO: Inference done 1104/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:32
[11/17 12:42:04] d2.evaluation.evaluator INFO: Inference done 1225/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:27
[11/17 12:42:09] d2.evaluation.evaluator INFO: Inference done 1348/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:22
[11/17 12:42:14] d2.evaluation.evaluator INFO: Inference done 1474/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/17 12:42:19] d2.evaluation.evaluator INFO: Inference done 1598/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/17 12:42:24] d2.evaluation.evaluator INFO: Inference done 1718/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:06
[11/17 12:42:29] d2.evaluation.evaluator INFO: Inference done 1842/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/17 12:42:34] d2.evaluation.evaluator INFO: Inference done 1964/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/17 12:42:39] d2.evaluation.evaluator INFO: Inference done 2085/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:51
[11/17 12:42:44] d2.evaluation.evaluator INFO: Inference done 2205/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:46
[11/17 12:42:49] d2.evaluation.evaluator INFO: Inference done 2325/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:41
[11/17 12:42:54] d2.evaluation.evaluator INFO: Inference done 2440/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:36
[11/17 12:42:59] d2.evaluation.evaluator INFO: Inference done 2564/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/17 12:43:04] d2.evaluation.evaluator INFO: Inference done 2687/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/17 12:43:09] d2.evaluation.evaluator INFO: Inference done 2810/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/17 12:43:14] d2.evaluation.evaluator INFO: Inference done 2930/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/17 12:43:19] d2.evaluation.evaluator INFO: Inference done 3054/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/17 12:43:24] d2.evaluation.evaluator INFO: Inference done 3181/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:06
[11/17 12:43:29] d2.evaluation.evaluator INFO: Inference done 3300/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:01
[11/17 12:43:31] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.660010 (0.041352 s / iter per device, on 6 devices)
[11/17 12:43:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039420 s / iter per device, on 6 devices)
[11/17 12:43:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 12:43:33] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 12:43:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 12:43:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 12:43:58] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.64 seconds.
[11/17 12:43:58] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 12:44:00] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.83 seconds.
[11/17 12:44:00] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.985 | 13.525 | 4.266  | 1.146 | 2.707 | 7.189 |
[11/17 12:44:00] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.797  | person      | 5.665  | bird                  | 19.633 |
| red panda            | 6.977  | dog         | 36.061 | snake                 | 6.649  |
| car                  | 26.762 | seal        | 0.770  | helmet                | 7.057  |
| motorcycle           | 8.997  | swine       | 4.967  | stove                 | 7.237  |
| monkey               | 6.139  | watercraft  | 16.865 | chair                 | 3.974  |
| domestic cat         | 5.070  | harp        | 3.903  | antelope              | 12.305 |
| camel                | 1.435  | koala bear  | 7.356  | bus                   | 18.939 |
| hat with a wide brim | 1.831  | ski         | 0.973  | piano                 | 7.208  |
| frog                 | 4.569  | dumbbell    | 0.092  | lobster               | 4.259  |
| bench                | 1.382  | rabbit      | 10.053 | porcupine             | 7.143  |
| butterfly            | 19.217 | guitar      | 2.814  | microphone            | 0.006  |
| tape player          | 5.652  | bear        | 6.424  | hippopotamus          | 0.313  |
| bowl                 | 7.494  | axe         | 3.943  | skunk                 | 1.743  |
| airplane             | 12.343 | otter       | 1.166  | table                 | 5.054  |
| coffee maker         | 16.342 | tie         | 0.585  | turtle                | 3.270  |
| purse                | 2.643  | dragonfly   | 3.328  | lemon                 | 7.392  |
| lizard               | 3.538  | backpack    | 4.429  | tv or monitor         | 9.338  |
| cup or mug           | 3.207  | sheep       | 2.824  | ray                   | 1.673  |
| fox                  | 4.221  | whale       | 6.873  | salt or pepper shaker | 0.153  |
| computer keyboard    | 1.682  | fig         | 2.885  | bathing cap           | 2.052  |
| bookshelf            | 11.096 | ladybug     | 25.136 | crutch                | 0.034  |
| pretzel              | 3.519  | sunglasses  | 0.271  | starfish              | 6.694  |
| croquet ball         | 7.519  | lamp        | 1.547  | apple                 | 10.629 |
| cream                | 6.465  | artichoke   | 11.905 | train                 | 9.057  |
| elephant             | 9.121  | bell pepper | 3.576  | miniskirt             | 2.155  |
| orange               | 10.249 | tiger       | 3.183  | sofa                  | 1.461  |
| horse                | 4.763  | violin      | 0.654  | traffic light         | 2.276  |
| drum                 | 0.730  | strawberry  | 5.848  | laptop                | 5.966  |
| pomegranate          | 1.976  | cucumber    | 0.277  | bicycle               | 4.549  |
| banana               | 0.546  | baby bed    | 10.028 | jellyfish             | 5.211  |
| pitcher              | 1.607  | bagel       | 3.596  | beaker                | 5.403  |
| goldfish             | 2.991  | nail        | 0.098  | mushroom              | 2.757  |
| flower pot           | 1.090  | cattle      | 1.215  | zebra                 | 15.720 |
| wine bottle          | 1.951  |             |        |                       |        |
[11/17 12:44:02] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 12:44:02] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 12:44:02] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 12:44:02] d2.evaluation.testing INFO: copypaste: 5.9854,13.5252,4.2661,1.1456,2.7070,7.1895
[11/17 12:44:02] d2.utils.events INFO:  eta: 14:54:59  iter: 31999  total_loss: 0.2467  loss_cls: 0.1319  loss_box_reg: 0.08756  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.01666  time: 0.6805  data_time: 0.0685  lr: 0.004  max_mem: 11814M
[11/17 12:44:16] d2.utils.events INFO:  eta: 14:54:38  iter: 32019  total_loss: 0.262  loss_cls: 0.1388  loss_box_reg: 0.08838  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01614  time: 0.6803  data_time: 0.0645  lr: 0.004  max_mem: 11814M
[11/17 12:44:29] d2.utils.events INFO:  eta: 14:54:04  iter: 32039  total_loss: 0.2546  loss_cls: 0.135  loss_box_reg: 0.08891  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.01667  time: 0.6803  data_time: 0.0628  lr: 0.004  max_mem: 11814M
[11/17 12:44:43] d2.utils.events INFO:  eta: 14:53:50  iter: 32059  total_loss: 0.253  loss_cls: 0.1304  loss_box_reg: 0.08663  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.01746  time: 0.6802  data_time: 0.0574  lr: 0.004  max_mem: 11814M
[11/17 12:44:57] d2.utils.events INFO:  eta: 14:53:31  iter: 32079  total_loss: 0.2545  loss_cls: 0.1344  loss_box_reg: 0.08674  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.01745  time: 0.6802  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 12:45:10] d2.utils.events INFO:  eta: 14:53:19  iter: 32099  total_loss: 0.258  loss_cls: 0.1353  loss_box_reg: 0.09026  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01753  time: 0.6803  data_time: 0.0590  lr: 0.004  max_mem: 11814M
[11/17 12:45:24] d2.utils.events INFO:  eta: 14:52:54  iter: 32119  total_loss: 0.246  loss_cls: 0.1331  loss_box_reg: 0.08405  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.01698  time: 0.6802  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 12:45:38] d2.utils.events INFO:  eta: 14:52:41  iter: 32139  total_loss: 0.2447  loss_cls: 0.13  loss_box_reg: 0.0846  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.01796  time: 0.6803  data_time: 0.0757  lr: 0.004  max_mem: 11814M
[11/17 12:45:51] d2.utils.events INFO:  eta: 14:52:36  iter: 32159  total_loss: 0.2527  loss_cls: 0.131  loss_box_reg: 0.08646  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01862  time: 0.6803  data_time: 0.0672  lr: 0.004  max_mem: 11814M
[11/17 12:46:05] d2.utils.events INFO:  eta: 14:52:35  iter: 32179  total_loss: 0.2439  loss_cls: 0.1233  loss_box_reg: 0.08473  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.01801  time: 0.6804  data_time: 0.0661  lr: 0.004  max_mem: 11814M
[11/17 12:46:18] d2.utils.events INFO:  eta: 14:52:11  iter: 32199  total_loss: 0.2496  loss_cls: 0.1303  loss_box_reg: 0.08811  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.01827  time: 0.6804  data_time: 0.0674  lr: 0.004  max_mem: 11814M
[11/17 12:46:32] d2.utils.events INFO:  eta: 14:52:08  iter: 32219  total_loss: 0.2513  loss_cls: 0.135  loss_box_reg: 0.0864  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.01597  time: 0.6803  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 12:46:45] d2.utils.events INFO:  eta: 14:51:42  iter: 32239  total_loss: 0.2341  loss_cls: 0.1224  loss_box_reg: 0.08451  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.01673  time: 0.6802  data_time: 0.0704  lr: 0.004  max_mem: 11814M
[11/17 12:46:59] d2.utils.events INFO:  eta: 14:51:15  iter: 32259  total_loss: 0.259  loss_cls: 0.1368  loss_box_reg: 0.09377  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.01767  time: 0.6802  data_time: 0.0610  lr: 0.004  max_mem: 11814M
[11/17 12:47:13] d2.utils.events INFO:  eta: 14:51:38  iter: 32279  total_loss: 0.2439  loss_cls: 0.1282  loss_box_reg: 0.08609  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.01675  time: 0.6804  data_time: 0.0698  lr: 0.004  max_mem: 11814M
[11/17 12:47:27] d2.utils.events INFO:  eta: 14:51:28  iter: 32299  total_loss: 0.2578  loss_cls: 0.1369  loss_box_reg: 0.08811  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.01709  time: 0.6804  data_time: 0.0706  lr: 0.004  max_mem: 11814M
[11/17 12:47:40] d2.utils.events INFO:  eta: 14:51:11  iter: 32319  total_loss: 0.2497  loss_cls: 0.1364  loss_box_reg: 0.08618  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01795  time: 0.6805  data_time: 0.0679  lr: 0.004  max_mem: 11814M
[11/17 12:47:54] d2.utils.events INFO:  eta: 14:51:08  iter: 32339  total_loss: 0.2452  loss_cls: 0.1266  loss_box_reg: 0.08459  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.01938  time: 0.6806  data_time: 0.0657  lr: 0.004  max_mem: 11814M
[11/17 12:48:08] d2.utils.events INFO:  eta: 14:50:59  iter: 32359  total_loss: 0.2518  loss_cls: 0.1332  loss_box_reg: 0.08801  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.01635  time: 0.6806  data_time: 0.0565  lr: 0.004  max_mem: 11814M
[11/17 12:48:21] d2.utils.events INFO:  eta: 14:50:30  iter: 32379  total_loss: 0.2324  loss_cls: 0.1258  loss_box_reg: 0.08006  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.0164  time: 0.6805  data_time: 0.0609  lr: 0.004  max_mem: 11814M
[11/17 12:48:35] d2.utils.events INFO:  eta: 14:49:53  iter: 32399  total_loss: 0.2557  loss_cls: 0.1348  loss_box_reg: 0.09223  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01548  time: 0.6806  data_time: 0.0774  lr: 0.004  max_mem: 11814M
[11/17 12:48:49] d2.utils.events INFO:  eta: 14:50:18  iter: 32419  total_loss: 0.2604  loss_cls: 0.1346  loss_box_reg: 0.08926  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.01726  time: 0.6807  data_time: 0.0625  lr: 0.004  max_mem: 11814M
[11/17 12:49:02] d2.utils.events INFO:  eta: 14:50:19  iter: 32439  total_loss: 0.252  loss_cls: 0.135  loss_box_reg: 0.08796  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.0177  time: 0.6807  data_time: 0.0655  lr: 0.004  max_mem: 11814M
[11/17 12:49:16] d2.utils.events INFO:  eta: 14:50:07  iter: 32459  total_loss: 0.259  loss_cls: 0.136  loss_box_reg: 0.08658  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01711  time: 0.6808  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 12:49:30] d2.utils.events INFO:  eta: 14:49:46  iter: 32479  total_loss: 0.2545  loss_cls: 0.1334  loss_box_reg: 0.08639  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.0182  time: 0.6807  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 12:49:43] d2.utils.events INFO:  eta: 14:49:38  iter: 32499  total_loss: 0.2579  loss_cls: 0.1342  loss_box_reg: 0.08977  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01704  time: 0.6808  data_time: 0.0695  lr: 0.004  max_mem: 11814M
[11/17 12:49:57] d2.utils.events INFO:  eta: 14:49:26  iter: 32519  total_loss: 0.2334  loss_cls: 0.1204  loss_box_reg: 0.08214  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01768  time: 0.6808  data_time: 0.0627  lr: 0.004  max_mem: 11814M
[11/17 12:50:10] d2.utils.events INFO:  eta: 14:49:24  iter: 32539  total_loss: 0.2542  loss_cls: 0.1335  loss_box_reg: 0.08449  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.0187  time: 0.6808  data_time: 0.0697  lr: 0.004  max_mem: 11814M
[11/17 12:50:24] d2.utils.events INFO:  eta: 14:49:11  iter: 32559  total_loss: 0.2448  loss_cls: 0.1291  loss_box_reg: 0.08581  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.01555  time: 0.6808  data_time: 0.0679  lr: 0.004  max_mem: 11814M
[11/17 12:50:38] d2.utils.events INFO:  eta: 14:48:49  iter: 32579  total_loss: 0.2521  loss_cls: 0.1324  loss_box_reg: 0.08441  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.01824  time: 0.6810  data_time: 0.0826  lr: 0.004  max_mem: 11814M
[11/17 12:50:52] d2.utils.events INFO:  eta: 14:48:13  iter: 32599  total_loss: 0.2486  loss_cls: 0.1306  loss_box_reg: 0.08651  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01682  time: 0.6809  data_time: 0.0639  lr: 0.004  max_mem: 11814M
[11/17 12:51:05] d2.utils.events INFO:  eta: 14:48:22  iter: 32619  total_loss: 0.2491  loss_cls: 0.1327  loss_box_reg: 0.08606  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.01779  time: 0.6809  data_time: 0.0610  lr: 0.004  max_mem: 11814M
[11/17 12:51:19] d2.utils.events INFO:  eta: 14:48:21  iter: 32639  total_loss: 0.2318  loss_cls: 0.1229  loss_box_reg: 0.08185  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01753  time: 0.6811  data_time: 0.0784  lr: 0.004  max_mem: 11814M
[11/17 12:51:33] d2.utils.events INFO:  eta: 14:48:07  iter: 32659  total_loss: 0.2475  loss_cls: 0.1335  loss_box_reg: 0.08851  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.01663  time: 0.6810  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 12:51:46] d2.utils.events INFO:  eta: 14:48:10  iter: 32679  total_loss: 0.2429  loss_cls: 0.1218  loss_box_reg: 0.08414  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.01738  time: 0.6810  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 12:52:00] d2.utils.events INFO:  eta: 14:48:23  iter: 32699  total_loss: 0.2462  loss_cls: 0.1322  loss_box_reg: 0.08492  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01725  time: 0.6810  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 12:52:14] d2.utils.events INFO:  eta: 14:48:53  iter: 32719  total_loss: 0.247  loss_cls: 0.125  loss_box_reg: 0.08715  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.01745  time: 0.6811  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 12:52:27] d2.utils.events INFO:  eta: 14:48:06  iter: 32739  total_loss: 0.2526  loss_cls: 0.1343  loss_box_reg: 0.0879  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01658  time: 0.6810  data_time: 0.0675  lr: 0.004  max_mem: 11814M
[11/17 12:52:41] d2.utils.events INFO:  eta: 14:48:26  iter: 32759  total_loss: 0.2623  loss_cls: 0.1382  loss_box_reg: 0.09274  loss_rpn_cls: 0.01476  loss_rpn_loc: 0.01923  time: 0.6811  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 12:52:55] d2.utils.events INFO:  eta: 14:48:36  iter: 32779  total_loss: 0.241  loss_cls: 0.1277  loss_box_reg: 0.08587  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.01744  time: 0.6812  data_time: 0.0737  lr: 0.004  max_mem: 11814M
[11/17 12:53:08] d2.utils.events INFO:  eta: 14:48:22  iter: 32799  total_loss: 0.2556  loss_cls: 0.1318  loss_box_reg: 0.0887  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01785  time: 0.6811  data_time: 0.0651  lr: 0.004  max_mem: 11814M
[11/17 12:53:22] d2.utils.events INFO:  eta: 14:48:13  iter: 32819  total_loss: 0.252  loss_cls: 0.1359  loss_box_reg: 0.08776  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.01658  time: 0.6812  data_time: 0.0711  lr: 0.004  max_mem: 11814M
[11/17 12:53:36] d2.utils.events INFO:  eta: 14:47:55  iter: 32839  total_loss: 0.2548  loss_cls: 0.1353  loss_box_reg: 0.086  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01715  time: 0.6812  data_time: 0.0732  lr: 0.004  max_mem: 11814M
[11/17 12:53:49] d2.utils.events INFO:  eta: 14:47:41  iter: 32859  total_loss: 0.2489  loss_cls: 0.1315  loss_box_reg: 0.08434  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01809  time: 0.6811  data_time: 0.0661  lr: 0.004  max_mem: 11814M
[11/17 12:54:03] d2.utils.events INFO:  eta: 14:47:28  iter: 32879  total_loss: 0.2481  loss_cls: 0.1301  loss_box_reg: 0.08614  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.01897  time: 0.6810  data_time: 0.0634  lr: 0.004  max_mem: 11814M
[11/17 12:54:16] d2.utils.events INFO:  eta: 14:47:11  iter: 32899  total_loss: 0.2384  loss_cls: 0.1238  loss_box_reg: 0.08188  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.0173  time: 0.6811  data_time: 0.0706  lr: 0.004  max_mem: 11814M
[11/17 12:54:30] d2.utils.events INFO:  eta: 14:46:17  iter: 32919  total_loss: 0.242  loss_cls: 0.1252  loss_box_reg: 0.08577  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.0173  time: 0.6810  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 12:54:43] d2.utils.events INFO:  eta: 14:45:53  iter: 32939  total_loss: 0.2582  loss_cls: 0.1372  loss_box_reg: 0.08793  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.01754  time: 0.6809  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 12:54:57] d2.utils.events INFO:  eta: 14:45:49  iter: 32959  total_loss: 0.258  loss_cls: 0.1376  loss_box_reg: 0.08911  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.01831  time: 0.6809  data_time: 0.0616  lr: 0.004  max_mem: 11814M
[11/17 12:55:10] d2.utils.events INFO:  eta: 14:45:15  iter: 32979  total_loss: 0.2584  loss_cls: 0.1389  loss_box_reg: 0.08849  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.01627  time: 0.6809  data_time: 0.0620  lr: 0.004  max_mem: 11814M
[11/17 12:55:24] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0032999.pth
[11/17 12:55:24] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 12:55:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 12:55:25] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 12:55:25] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 12:55:25] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 12:55:25] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 12:55:32] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0379 s/iter. Eval: 0.0002 s/iter. Total: 0.0391 s/iter. ETA=0:02:09
[11/17 12:55:37] d2.evaluation.evaluator INFO: Inference done 132/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:12
[11/17 12:55:42] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:05
[11/17 12:55:47] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/17 12:55:52] d2.evaluation.evaluator INFO: Inference done 504/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:55
[11/17 12:55:57] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:49
[11/17 12:56:02] d2.evaluation.evaluator INFO: Inference done 750/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:45
[11/17 12:56:07] d2.evaluation.evaluator INFO: Inference done 873/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/17 12:56:13] d2.evaluation.evaluator INFO: Inference done 993/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/17 12:56:18] d2.evaluation.evaluator INFO: Inference done 1118/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:30
[11/17 12:56:23] d2.evaluation.evaluator INFO: Inference done 1244/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:25
[11/17 12:56:28] d2.evaluation.evaluator INFO: Inference done 1366/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:20
[11/17 12:56:33] d2.evaluation.evaluator INFO: Inference done 1488/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/17 12:56:38] d2.evaluation.evaluator INFO: Inference done 1611/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:10
[11/17 12:56:43] d2.evaluation.evaluator INFO: Inference done 1733/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/17 12:56:48] d2.evaluation.evaluator INFO: Inference done 1857/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:00
[11/17 12:56:53] d2.evaluation.evaluator INFO: Inference done 1979/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:55
[11/17 12:56:58] d2.evaluation.evaluator INFO: Inference done 2105/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/17 12:57:03] d2.evaluation.evaluator INFO: Inference done 2229/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/17 12:57:08] d2.evaluation.evaluator INFO: Inference done 2353/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:39
[11/17 12:57:13] d2.evaluation.evaluator INFO: Inference done 2471/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/17 12:57:18] d2.evaluation.evaluator INFO: Inference done 2594/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/17 12:57:23] d2.evaluation.evaluator INFO: Inference done 2714/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/17 12:57:28] d2.evaluation.evaluator INFO: Inference done 2837/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 12:57:33] d2.evaluation.evaluator INFO: Inference done 2960/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:15
[11/17 12:57:38] d2.evaluation.evaluator INFO: Inference done 3084/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/17 12:57:43] d2.evaluation.evaluator INFO: Inference done 3209/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:05
[11/17 12:57:48] d2.evaluation.evaluator INFO: Inference done 3330/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:00
[11/17 12:57:49] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.488438 (0.041000 s / iter per device, on 6 devices)
[11/17 12:57:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038992 s / iter per device, on 6 devices)
[11/17 12:57:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 12:57:52] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 12:57:53] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 12:57:54] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 12:58:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 20.79 seconds.
[11/17 12:58:15] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 12:58:16] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.79 seconds.
[11/17 12:58:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.825 | 13.016 | 4.265  | 1.207 | 2.971 | 7.073 |
[11/17 12:58:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.368  | person      | 5.853  | bird                  | 20.195 |
| red panda            | 4.760  | dog         | 36.384 | snake                 | 6.056  |
| car                  | 24.377 | seal        | 1.083  | helmet                | 7.223  |
| motorcycle           | 8.856  | swine       | 4.463  | stove                 | 7.912  |
| monkey               | 6.954  | watercraft  | 16.393 | chair                 | 3.928  |
| domestic cat         | 4.998  | harp        | 5.192  | antelope              | 11.556 |
| camel                | 1.342  | koala bear  | 6.597  | bus                   | 18.897 |
| hat with a wide brim | 1.898  | ski         | 1.590  | piano                 | 6.950  |
| frog                 | 4.764  | dumbbell    | 0.088  | lobster               | 3.646  |
| bench                | 0.864  | rabbit      | 11.430 | porcupine             | 7.610  |
| butterfly            | 20.312 | guitar      | 2.707  | microphone            | 0.047  |
| tape player          | 5.398  | bear        | 6.246  | hippopotamus          | 0.218  |
| bowl                 | 5.681  | axe         | 2.917  | skunk                 | 1.872  |
| airplane             | 13.323 | otter       | 0.576  | table                 | 4.378  |
| coffee maker         | 15.637 | tie         | 0.281  | turtle                | 3.601  |
| purse                | 2.919  | dragonfly   | 3.874  | lemon                 | 6.332  |
| lizard               | 3.644  | backpack    | 5.230  | tv or monitor         | 9.359  |
| cup or mug           | 2.176  | sheep       | 2.870  | ray                   | 1.602  |
| fox                  | 4.849  | whale       | 6.147  | salt or pepper shaker | 0.547  |
| computer keyboard    | 1.145  | fig         | 1.229  | bathing cap           | 2.288  |
| bookshelf            | 13.229 | ladybug     | 23.604 | crutch                | 0.044  |
| pretzel              | 3.064  | sunglasses  | 0.315  | starfish              | 5.147  |
| croquet ball         | 9.080  | lamp        | 1.804  | apple                 | 7.797  |
| cream                | 5.964  | artichoke   | 8.729  | train                 | 9.790  |
| elephant             | 9.614  | bell pepper | 1.617  | miniskirt             | 1.548  |
| orange               | 10.156 | tiger       | 3.257  | sofa                  | 2.144  |
| horse                | 5.758  | violin      | 1.005  | traffic light         | 2.583  |
| drum                 | 0.693  | strawberry  | 5.537  | laptop                | 6.175  |
| pomegranate          | 1.926  | cucumber    | 0.229  | bicycle               | 4.501  |
| banana               | 0.550  | baby bed    | 9.985  | jellyfish             | 4.330  |
| pitcher              | 0.974  | bagel       | 4.417  | beaker                | 4.247  |
| goldfish             | 2.377  | nail        | 0.079  | mushroom              | 1.771  |
| flower pot           | 1.018  | cattle      | 0.843  | zebra                 | 16.064 |
| wine bottle          | 2.917  |             |        |                       |        |
[11/17 12:58:19] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 12:58:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 12:58:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 12:58:19] d2.evaluation.testing INFO: copypaste: 5.8251,13.0163,4.2649,1.2070,2.9709,7.0728
[11/17 12:58:19] d2.utils.events INFO:  eta: 14:45:05  iter: 32999  total_loss: 0.2484  loss_cls: 0.1297  loss_box_reg: 0.08269  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.01787  time: 0.6809  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 12:58:32] d2.utils.events INFO:  eta: 14:44:48  iter: 33019  total_loss: 0.2378  loss_cls: 0.1258  loss_box_reg: 0.08257  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.01698  time: 0.6808  data_time: 0.0645  lr: 0.004  max_mem: 11814M
[11/17 12:58:46] d2.utils.events INFO:  eta: 14:44:55  iter: 33039  total_loss: 0.2617  loss_cls: 0.1399  loss_box_reg: 0.09229  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.0175  time: 0.6809  data_time: 0.0698  lr: 0.004  max_mem: 11814M
[11/17 12:58:59] d2.utils.events INFO:  eta: 14:44:53  iter: 33059  total_loss: 0.2702  loss_cls: 0.1422  loss_box_reg: 0.0926  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01858  time: 0.6809  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 12:59:13] d2.utils.events INFO:  eta: 14:44:40  iter: 33079  total_loss: 0.2451  loss_cls: 0.1288  loss_box_reg: 0.08677  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.01778  time: 0.6809  data_time: 0.0654  lr: 0.004  max_mem: 11814M
[11/17 12:59:27] d2.utils.events INFO:  eta: 14:43:54  iter: 33099  total_loss: 0.2497  loss_cls: 0.1316  loss_box_reg: 0.08965  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.01915  time: 0.6809  data_time: 0.0673  lr: 0.004  max_mem: 11814M
[11/17 12:59:40] d2.utils.events INFO:  eta: 14:43:40  iter: 33119  total_loss: 0.236  loss_cls: 0.1227  loss_box_reg: 0.08167  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.01812  time: 0.6808  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 12:59:54] d2.utils.events INFO:  eta: 14:43:45  iter: 33139  total_loss: 0.2476  loss_cls: 0.1319  loss_box_reg: 0.08591  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01789  time: 0.6809  data_time: 0.0687  lr: 0.004  max_mem: 11814M
[11/17 13:00:07] d2.utils.events INFO:  eta: 14:43:58  iter: 33159  total_loss: 0.2545  loss_cls: 0.1365  loss_box_reg: 0.08682  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01738  time: 0.6809  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 13:00:21] d2.utils.events INFO:  eta: 14:43:05  iter: 33179  total_loss: 0.2446  loss_cls: 0.1306  loss_box_reg: 0.08304  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.01769  time: 0.6809  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 13:00:35] d2.utils.events INFO:  eta: 14:43:04  iter: 33199  total_loss: 0.2346  loss_cls: 0.1211  loss_box_reg: 0.08407  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.01761  time: 0.6810  data_time: 0.0731  lr: 0.004  max_mem: 11814M
[11/17 13:00:49] d2.utils.events INFO:  eta: 14:43:24  iter: 33219  total_loss: 0.2402  loss_cls: 0.1235  loss_box_reg: 0.0824  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.01772  time: 0.6811  data_time: 0.0602  lr: 0.004  max_mem: 11814M
[11/17 13:01:02] d2.utils.events INFO:  eta: 14:43:23  iter: 33239  total_loss: 0.2543  loss_cls: 0.1328  loss_box_reg: 0.08891  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.01855  time: 0.6811  data_time: 0.0739  lr: 0.004  max_mem: 11814M
[11/17 13:01:16] d2.utils.events INFO:  eta: 14:43:17  iter: 33259  total_loss: 0.2483  loss_cls: 0.1297  loss_box_reg: 0.0859  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.01862  time: 0.6811  data_time: 0.0746  lr: 0.004  max_mem: 11814M
[11/17 13:01:30] d2.utils.events INFO:  eta: 14:42:29  iter: 33279  total_loss: 0.2493  loss_cls: 0.1322  loss_box_reg: 0.08755  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.0164  time: 0.6811  data_time: 0.0759  lr: 0.004  max_mem: 11814M
[11/17 13:01:43] d2.utils.events INFO:  eta: 14:42:04  iter: 33299  total_loss: 0.2633  loss_cls: 0.134  loss_box_reg: 0.09214  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.01789  time: 0.6812  data_time: 0.0611  lr: 0.004  max_mem: 11814M
[11/17 13:01:57] d2.utils.events INFO:  eta: 14:41:41  iter: 33319  total_loss: 0.2527  loss_cls: 0.1328  loss_box_reg: 0.08939  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.01701  time: 0.6812  data_time: 0.0688  lr: 0.004  max_mem: 11814M
[11/17 13:02:11] d2.utils.events INFO:  eta: 14:41:37  iter: 33339  total_loss: 0.2554  loss_cls: 0.1376  loss_box_reg: 0.08718  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.01766  time: 0.6813  data_time: 0.0846  lr: 0.004  max_mem: 11814M
[11/17 13:02:25] d2.utils.events INFO:  eta: 14:41:26  iter: 33359  total_loss: 0.247  loss_cls: 0.1287  loss_box_reg: 0.08442  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.01718  time: 0.6813  data_time: 0.0607  lr: 0.004  max_mem: 11814M
[11/17 13:02:38] d2.utils.events INFO:  eta: 14:41:13  iter: 33379  total_loss: 0.2382  loss_cls: 0.1273  loss_box_reg: 0.08137  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01694  time: 0.6813  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:02:52] d2.utils.events INFO:  eta: 14:40:56  iter: 33399  total_loss: 0.2406  loss_cls: 0.1259  loss_box_reg: 0.08205  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.01625  time: 0.6813  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 13:03:06] d2.utils.events INFO:  eta: 14:40:18  iter: 33419  total_loss: 0.2434  loss_cls: 0.1296  loss_box_reg: 0.08216  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01758  time: 0.6813  data_time: 0.0706  lr: 0.004  max_mem: 11814M
[11/17 13:03:19] d2.utils.events INFO:  eta: 14:40:05  iter: 33439  total_loss: 0.2453  loss_cls: 0.1272  loss_box_reg: 0.08751  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.01709  time: 0.6813  data_time: 0.0692  lr: 0.004  max_mem: 11814M
[11/17 13:03:33] d2.utils.events INFO:  eta: 14:39:43  iter: 33459  total_loss: 0.2553  loss_cls: 0.1368  loss_box_reg: 0.08972  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01656  time: 0.6813  data_time: 0.0689  lr: 0.004  max_mem: 11814M
[11/17 13:03:46] d2.utils.events INFO:  eta: 14:39:38  iter: 33479  total_loss: 0.2474  loss_cls: 0.1318  loss_box_reg: 0.08496  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01624  time: 0.6812  data_time: 0.0645  lr: 0.004  max_mem: 11814M
[11/17 13:04:00] d2.utils.events INFO:  eta: 14:39:48  iter: 33499  total_loss: 0.2519  loss_cls: 0.1276  loss_box_reg: 0.0896  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.01795  time: 0.6812  data_time: 0.0641  lr: 0.004  max_mem: 11814M
[11/17 13:04:14] d2.utils.events INFO:  eta: 14:39:42  iter: 33519  total_loss: 0.2395  loss_cls: 0.1267  loss_box_reg: 0.08607  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01785  time: 0.6813  data_time: 0.0717  lr: 0.004  max_mem: 11814M
[11/17 13:04:27] d2.utils.events INFO:  eta: 14:39:00  iter: 33539  total_loss: 0.245  loss_cls: 0.1288  loss_box_reg: 0.08245  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.01771  time: 0.6812  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 13:04:41] d2.utils.events INFO:  eta: 14:38:57  iter: 33559  total_loss: 0.2326  loss_cls: 0.1221  loss_box_reg: 0.08027  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.01641  time: 0.6813  data_time: 0.0758  lr: 0.004  max_mem: 11814M
[11/17 13:04:55] d2.utils.events INFO:  eta: 14:38:54  iter: 33579  total_loss: 0.2495  loss_cls: 0.1291  loss_box_reg: 0.08578  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01757  time: 0.6813  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 13:05:08] d2.utils.events INFO:  eta: 14:38:40  iter: 33599  total_loss: 0.2554  loss_cls: 0.1311  loss_box_reg: 0.08838  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.01854  time: 0.6813  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 13:05:22] d2.utils.events INFO:  eta: 14:38:29  iter: 33619  total_loss: 0.2548  loss_cls: 0.1321  loss_box_reg: 0.08512  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.02005  time: 0.6813  data_time: 0.0709  lr: 0.004  max_mem: 11814M
[11/17 13:05:36] d2.utils.events INFO:  eta: 14:38:16  iter: 33639  total_loss: 0.2629  loss_cls: 0.1383  loss_box_reg: 0.08967  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.01692  time: 0.6813  data_time: 0.0609  lr: 0.004  max_mem: 11814M
[11/17 13:05:49] d2.utils.events INFO:  eta: 14:38:06  iter: 33659  total_loss: 0.2597  loss_cls: 0.1373  loss_box_reg: 0.08693  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01989  time: 0.6813  data_time: 0.0612  lr: 0.004  max_mem: 11814M
[11/17 13:06:03] d2.utils.events INFO:  eta: 14:37:53  iter: 33679  total_loss: 0.2401  loss_cls: 0.123  loss_box_reg: 0.08518  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01784  time: 0.6814  data_time: 0.0788  lr: 0.004  max_mem: 11814M
[11/17 13:06:16] d2.utils.events INFO:  eta: 14:36:33  iter: 33699  total_loss: 0.2512  loss_cls: 0.1323  loss_box_reg: 0.08639  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.01776  time: 0.6813  data_time: 0.0673  lr: 0.004  max_mem: 11814M
[11/17 13:06:30] d2.utils.events INFO:  eta: 14:35:50  iter: 33719  total_loss: 0.2453  loss_cls: 0.133  loss_box_reg: 0.0856  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.01728  time: 0.6814  data_time: 0.0766  lr: 0.004  max_mem: 11814M
[11/17 13:06:44] d2.utils.events INFO:  eta: 14:35:52  iter: 33739  total_loss: 0.2528  loss_cls: 0.1339  loss_box_reg: 0.08731  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.01612  time: 0.6814  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 13:06:58] d2.utils.events INFO:  eta: 14:35:10  iter: 33759  total_loss: 0.2421  loss_cls: 0.1294  loss_box_reg: 0.08493  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.01823  time: 0.6814  data_time: 0.0638  lr: 0.004  max_mem: 11814M
[11/17 13:07:11] d2.utils.events INFO:  eta: 14:35:03  iter: 33779  total_loss: 0.2462  loss_cls: 0.1273  loss_box_reg: 0.08593  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.018  time: 0.6814  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 13:07:25] d2.utils.events INFO:  eta: 14:35:20  iter: 33799  total_loss: 0.242  loss_cls: 0.1314  loss_box_reg: 0.08434  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01507  time: 0.6814  data_time: 0.0717  lr: 0.004  max_mem: 11814M
[11/17 13:07:39] d2.utils.events INFO:  eta: 14:34:36  iter: 33819  total_loss: 0.2543  loss_cls: 0.1302  loss_box_reg: 0.08986  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.01793  time: 0.6814  data_time: 0.0641  lr: 0.004  max_mem: 11814M
[11/17 13:07:52] d2.utils.events INFO:  eta: 14:34:22  iter: 33839  total_loss: 0.2493  loss_cls: 0.13  loss_box_reg: 0.09058  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.01884  time: 0.6814  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 13:08:06] d2.utils.events INFO:  eta: 14:34:11  iter: 33859  total_loss: 0.2341  loss_cls: 0.1184  loss_box_reg: 0.07793  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.01697  time: 0.6814  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 13:08:20] d2.utils.events INFO:  eta: 14:34:31  iter: 33879  total_loss: 0.2442  loss_cls: 0.1249  loss_box_reg: 0.08571  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01774  time: 0.6815  data_time: 0.0705  lr: 0.004  max_mem: 11814M
[11/17 13:08:33] d2.utils.events INFO:  eta: 14:34:18  iter: 33899  total_loss: 0.2552  loss_cls: 0.1342  loss_box_reg: 0.08802  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.01814  time: 0.6814  data_time: 0.0639  lr: 0.004  max_mem: 11814M
[11/17 13:08:47] d2.utils.events INFO:  eta: 14:34:18  iter: 33919  total_loss: 0.2475  loss_cls: 0.1323  loss_box_reg: 0.08677  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.01634  time: 0.6814  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 13:09:01] d2.utils.events INFO:  eta: 14:34:14  iter: 33939  total_loss: 0.2575  loss_cls: 0.1323  loss_box_reg: 0.09077  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.01782  time: 0.6815  data_time: 0.0795  lr: 0.004  max_mem: 11814M
[11/17 13:09:15] d2.utils.events INFO:  eta: 14:34:16  iter: 33959  total_loss: 0.2442  loss_cls: 0.1196  loss_box_reg: 0.08536  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01769  time: 0.6816  data_time: 0.0860  lr: 0.004  max_mem: 11814M
[11/17 13:09:28] d2.utils.events INFO:  eta: 14:34:23  iter: 33979  total_loss: 0.2386  loss_cls: 0.1268  loss_box_reg: 0.08361  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01658  time: 0.6816  data_time: 0.0680  lr: 0.004  max_mem: 11814M
[11/17 13:09:42] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0033999.pth
[11/17 13:09:42] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 13:09:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 13:09:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 13:09:43] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 13:09:43] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 13:09:43] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 13:09:50] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0008 s/iter. Inference: 0.0400 s/iter. Eval: 0.0003 s/iter. Total: 0.0411 s/iter. ETA=0:02:16
[11/17 13:09:55] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:09
[11/17 13:10:00] d2.evaluation.evaluator INFO: Inference done 260/3334. Dataloading: 0.0014 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:02:04
[11/17 13:10:05] d2.evaluation.evaluator INFO: Inference done 382/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:00
[11/17 13:10:10] d2.evaluation.evaluator INFO: Inference done 504/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:55
[11/17 13:10:15] d2.evaluation.evaluator INFO: Inference done 630/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:49
[11/17 13:10:20] d2.evaluation.evaluator INFO: Inference done 753/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:44
[11/17 13:10:25] d2.evaluation.evaluator INFO: Inference done 876/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:39
[11/17 13:10:30] d2.evaluation.evaluator INFO: Inference done 998/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:35
[11/17 13:10:35] d2.evaluation.evaluator INFO: Inference done 1119/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:30
[11/17 13:10:40] d2.evaluation.evaluator INFO: Inference done 1243/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:25
[11/17 13:10:45] d2.evaluation.evaluator INFO: Inference done 1364/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:20
[11/17 13:10:50] d2.evaluation.evaluator INFO: Inference done 1487/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/17 13:10:55] d2.evaluation.evaluator INFO: Inference done 1608/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/17 13:11:00] d2.evaluation.evaluator INFO: Inference done 1730/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:05
[11/17 13:11:05] d2.evaluation.evaluator INFO: Inference done 1852/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/17 13:11:10] d2.evaluation.evaluator INFO: Inference done 1976/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/17 13:11:15] d2.evaluation.evaluator INFO: Inference done 2103/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/17 13:11:20] d2.evaluation.evaluator INFO: Inference done 2228/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/17 13:11:25] d2.evaluation.evaluator INFO: Inference done 2352/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/17 13:11:30] d2.evaluation.evaluator INFO: Inference done 2476/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:34
[11/17 13:11:35] d2.evaluation.evaluator INFO: Inference done 2601/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:29
[11/17 13:11:40] d2.evaluation.evaluator INFO: Inference done 2725/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:24
[11/17 13:11:46] d2.evaluation.evaluator INFO: Inference done 2847/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:19
[11/17 13:11:51] d2.evaluation.evaluator INFO: Inference done 2970/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:14
[11/17 13:11:56] d2.evaluation.evaluator INFO: Inference done 3096/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:00:09
[11/17 13:12:01] d2.evaluation.evaluator INFO: Inference done 3216/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:04
[11/17 13:12:06] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.228657 (0.040922 s / iter per device, on 6 devices)
[11/17 13:12:06] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038932 s / iter per device, on 6 devices)
[11/17 13:12:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 13:12:11] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 13:12:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 13:12:15] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 13:12:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 24.39 seconds.
[11/17 13:12:39] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 13:12:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.23 seconds.
[11/17 13:12:41] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 5.748 | 13.145 | 4.004  | 0.899 | 3.104 | 6.958 |
[11/17 13:12:41] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.526  | person      | 5.891  | bird                  | 17.306 |
| red panda            | 6.178  | dog         | 37.430 | snake                 | 6.217  |
| car                  | 25.477 | seal        | 1.266  | helmet                | 5.796  |
| motorcycle           | 9.486  | swine       | 4.818  | stove                 | 8.083  |
| monkey               | 5.339  | watercraft  | 15.799 | chair                 | 2.725  |
| domestic cat         | 4.544  | harp        | 4.130  | antelope              | 11.246 |
| camel                | 1.056  | koala bear  | 7.289  | bus                   | 18.045 |
| hat with a wide brim | 2.388  | ski         | 1.039  | piano                 | 6.192  |
| frog                 | 4.979  | dumbbell    | 0.060  | lobster               | 4.444  |
| bench                | 0.528  | rabbit      | 9.547  | porcupine             | 8.702  |
| butterfly            | 21.776 | guitar      | 2.778  | microphone            | 0.027  |
| tape player          | 6.434  | bear        | 8.560  | hippopotamus          | 0.337  |
| bowl                 | 5.411  | axe         | 3.053  | skunk                 | 1.208  |
| airplane             | 13.945 | otter       | 1.510  | table                 | 5.106  |
| coffee maker         | 13.671 | tie         | 0.268  | turtle                | 3.844  |
| purse                | 3.433  | dragonfly   | 4.032  | lemon                 | 8.176  |
| lizard               | 3.206  | backpack    | 3.622  | tv or monitor         | 10.273 |
| cup or mug           | 2.336  | sheep       | 3.701  | ray                   | 1.322  |
| fox                  | 3.953  | whale       | 5.283  | salt or pepper shaker | 0.278  |
| computer keyboard    | 1.718  | fig         | 1.091  | bathing cap           | 1.722  |
| bookshelf            | 9.933  | ladybug     | 25.019 | crutch                | 0.009  |
| pretzel              | 2.580  | sunglasses  | 0.335  | starfish              | 5.894  |
| croquet ball         | 8.371  | lamp        | 1.909  | apple                 | 8.929  |
| cream                | 4.915  | artichoke   | 6.775  | train                 | 7.619  |
| elephant             | 11.491 | bell pepper | 5.121  | miniskirt             | 0.296  |
| orange               | 9.107  | tiger       | 4.295  | sofa                  | 1.456  |
| horse                | 5.575  | violin      | 0.463  | traffic light         | 2.178  |
| drum                 | 0.442  | strawberry  | 4.732  | laptop                | 4.598  |
| pomegranate          | 3.307  | cucumber    | 0.375  | bicycle               | 3.568  |
| banana               | 0.665  | baby bed    | 8.792  | jellyfish             | 4.219  |
| pitcher              | 0.684  | bagel       | 3.974  | beaker                | 4.717  |
| goldfish             | 3.587  | nail        | 0.168  | mushroom              | 2.600  |
| flower pot           | 0.558  | cattle      | 1.727  | zebra                 | 15.369 |
| wine bottle          | 1.819  |             |        |                       |        |
[11/17 13:12:44] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 13:12:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 13:12:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 13:12:44] d2.evaluation.testing INFO: copypaste: 5.7478,13.1449,4.0038,0.8986,3.1039,6.9577
[11/17 13:12:44] d2.utils.events INFO:  eta: 14:33:49  iter: 33999  total_loss: 0.2469  loss_cls: 0.1287  loss_box_reg: 0.08615  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.01753  time: 0.6816  data_time: 0.0736  lr: 0.004  max_mem: 11814M
[11/17 13:12:57] d2.utils.events INFO:  eta: 14:33:46  iter: 34019  total_loss: 0.2568  loss_cls: 0.1344  loss_box_reg: 0.08362  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01835  time: 0.6816  data_time: 0.0691  lr: 0.004  max_mem: 11814M
[11/17 13:13:11] d2.utils.events INFO:  eta: 14:33:07  iter: 34039  total_loss: 0.234  loss_cls: 0.1221  loss_box_reg: 0.0839  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01596  time: 0.6815  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 13:13:24] d2.utils.events INFO:  eta: 14:32:53  iter: 34059  total_loss: 0.2419  loss_cls: 0.1238  loss_box_reg: 0.08403  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01767  time: 0.6815  data_time: 0.0625  lr: 0.004  max_mem: 11814M
[11/17 13:13:38] d2.utils.events INFO:  eta: 14:32:29  iter: 34079  total_loss: 0.2333  loss_cls: 0.1175  loss_box_reg: 0.08297  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.01798  time: 0.6815  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 13:13:52] d2.utils.events INFO:  eta: 14:32:33  iter: 34099  total_loss: 0.2552  loss_cls: 0.1331  loss_box_reg: 0.09153  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.01944  time: 0.6815  data_time: 0.0724  lr: 0.004  max_mem: 11814M
[11/17 13:14:05] d2.utils.events INFO:  eta: 14:32:23  iter: 34119  total_loss: 0.2387  loss_cls: 0.1245  loss_box_reg: 0.08672  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.0168  time: 0.6815  data_time: 0.0735  lr: 0.004  max_mem: 11814M
[11/17 13:14:19] d2.utils.events INFO:  eta: 14:32:09  iter: 34139  total_loss: 0.2472  loss_cls: 0.1248  loss_box_reg: 0.08431  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01752  time: 0.6815  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 13:14:33] d2.utils.events INFO:  eta: 14:32:00  iter: 34159  total_loss: 0.2453  loss_cls: 0.127  loss_box_reg: 0.08522  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.01763  time: 0.6815  data_time: 0.0615  lr: 0.004  max_mem: 11814M
[11/17 13:14:46] d2.utils.events INFO:  eta: 14:32:03  iter: 34179  total_loss: 0.2574  loss_cls: 0.1377  loss_box_reg: 0.09165  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01737  time: 0.6815  data_time: 0.0817  lr: 0.004  max_mem: 11814M
[11/17 13:15:00] d2.utils.events INFO:  eta: 14:31:49  iter: 34199  total_loss: 0.2477  loss_cls: 0.1247  loss_box_reg: 0.08707  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01844  time: 0.6815  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 13:15:14] d2.utils.events INFO:  eta: 14:31:19  iter: 34219  total_loss: 0.247  loss_cls: 0.1333  loss_box_reg: 0.08652  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.01675  time: 0.6816  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 13:15:27] d2.utils.events INFO:  eta: 14:31:23  iter: 34239  total_loss: 0.2438  loss_cls: 0.126  loss_box_reg: 0.08376  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.01696  time: 0.6816  data_time: 0.0623  lr: 0.004  max_mem: 11814M
[11/17 13:15:41] d2.utils.events INFO:  eta: 14:31:09  iter: 34259  total_loss: 0.2636  loss_cls: 0.1337  loss_box_reg: 0.09026  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.01749  time: 0.6816  data_time: 0.0716  lr: 0.004  max_mem: 11814M
[11/17 13:15:55] d2.utils.events INFO:  eta: 14:31:22  iter: 34279  total_loss: 0.2556  loss_cls: 0.1325  loss_box_reg: 0.08959  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.01747  time: 0.6816  data_time: 0.0735  lr: 0.004  max_mem: 11814M
[11/17 13:16:09] d2.utils.events INFO:  eta: 14:31:04  iter: 34299  total_loss: 0.2516  loss_cls: 0.1309  loss_box_reg: 0.09042  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.01602  time: 0.6817  data_time: 0.0717  lr: 0.004  max_mem: 11814M
[11/17 13:16:22] d2.utils.events INFO:  eta: 14:30:52  iter: 34319  total_loss: 0.2496  loss_cls: 0.1286  loss_box_reg: 0.0896  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01767  time: 0.6817  data_time: 0.0803  lr: 0.004  max_mem: 11814M
[11/17 13:16:36] d2.utils.events INFO:  eta: 14:30:14  iter: 34339  total_loss: 0.24  loss_cls: 0.1269  loss_box_reg: 0.082  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.01639  time: 0.6817  data_time: 0.0608  lr: 0.004  max_mem: 11814M
[11/17 13:16:50] d2.utils.events INFO:  eta: 14:30:00  iter: 34359  total_loss: 0.2622  loss_cls: 0.1351  loss_box_reg: 0.09101  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.01694  time: 0.6817  data_time: 0.0732  lr: 0.004  max_mem: 11814M
[11/17 13:17:03] d2.utils.events INFO:  eta: 14:30:09  iter: 34379  total_loss: 0.2508  loss_cls: 0.1303  loss_box_reg: 0.08603  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.01722  time: 0.6817  data_time: 0.0629  lr: 0.004  max_mem: 11814M
[11/17 13:17:17] d2.utils.events INFO:  eta: 14:30:00  iter: 34399  total_loss: 0.2507  loss_cls: 0.1309  loss_box_reg: 0.08869  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01645  time: 0.6817  data_time: 0.0706  lr: 0.004  max_mem: 11814M
[11/17 13:17:31] d2.utils.events INFO:  eta: 14:29:58  iter: 34419  total_loss: 0.2596  loss_cls: 0.1375  loss_box_reg: 0.08821  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.01672  time: 0.6817  data_time: 0.0606  lr: 0.004  max_mem: 11814M
[11/17 13:17:44] d2.utils.events INFO:  eta: 14:29:30  iter: 34439  total_loss: 0.2409  loss_cls: 0.1244  loss_box_reg: 0.08572  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01739  time: 0.6817  data_time: 0.0727  lr: 0.004  max_mem: 11814M
[11/17 13:17:58] d2.utils.events INFO:  eta: 14:29:07  iter: 34459  total_loss: 0.2524  loss_cls: 0.1361  loss_box_reg: 0.08802  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.01808  time: 0.6817  data_time: 0.0758  lr: 0.004  max_mem: 11814M
[11/17 13:18:12] d2.utils.events INFO:  eta: 14:28:54  iter: 34479  total_loss: 0.2469  loss_cls: 0.1285  loss_box_reg: 0.08955  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.01707  time: 0.6817  data_time: 0.0697  lr: 0.004  max_mem: 11814M
[11/17 13:18:25] d2.utils.events INFO:  eta: 14:28:27  iter: 34499  total_loss: 0.2417  loss_cls: 0.1306  loss_box_reg: 0.08328  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.01683  time: 0.6817  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 13:18:39] d2.utils.events INFO:  eta: 14:28:11  iter: 34519  total_loss: 0.234  loss_cls: 0.1224  loss_box_reg: 0.08145  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01902  time: 0.6817  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 13:18:52] d2.utils.events INFO:  eta: 14:28:03  iter: 34539  total_loss: 0.2512  loss_cls: 0.1317  loss_box_reg: 0.08781  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01765  time: 0.6817  data_time: 0.0718  lr: 0.004  max_mem: 11814M
[11/17 13:19:06] d2.utils.events INFO:  eta: 14:27:29  iter: 34559  total_loss: 0.2528  loss_cls: 0.1288  loss_box_reg: 0.08945  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01695  time: 0.6816  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 13:19:19] d2.utils.events INFO:  eta: 14:27:11  iter: 34579  total_loss: 0.246  loss_cls: 0.1313  loss_box_reg: 0.0862  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.01788  time: 0.6816  data_time: 0.0624  lr: 0.004  max_mem: 11814M
[11/17 13:19:33] d2.utils.events INFO:  eta: 14:27:08  iter: 34599  total_loss: 0.2466  loss_cls: 0.1301  loss_box_reg: 0.08555  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.01923  time: 0.6816  data_time: 0.0596  lr: 0.004  max_mem: 11814M
[11/17 13:19:47] d2.utils.events INFO:  eta: 14:26:51  iter: 34619  total_loss: 0.2564  loss_cls: 0.1342  loss_box_reg: 0.09078  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01718  time: 0.6816  data_time: 0.0734  lr: 0.004  max_mem: 11814M
[11/17 13:20:00] d2.utils.events INFO:  eta: 14:26:37  iter: 34639  total_loss: 0.2527  loss_cls: 0.1335  loss_box_reg: 0.08919  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.0172  time: 0.6816  data_time: 0.0732  lr: 0.004  max_mem: 11814M
[11/17 13:20:14] d2.utils.events INFO:  eta: 14:26:38  iter: 34659  total_loss: 0.2316  loss_cls: 0.1221  loss_box_reg: 0.08752  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01683  time: 0.6817  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 13:20:28] d2.utils.events INFO:  eta: 14:26:22  iter: 34679  total_loss: 0.2421  loss_cls: 0.1266  loss_box_reg: 0.08432  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.01905  time: 0.6817  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 13:20:41] d2.utils.events INFO:  eta: 14:27:03  iter: 34699  total_loss: 0.2342  loss_cls: 0.123  loss_box_reg: 0.08532  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01667  time: 0.6817  data_time: 0.0691  lr: 0.004  max_mem: 11814M
[11/17 13:20:55] d2.utils.events INFO:  eta: 14:27:04  iter: 34719  total_loss: 0.2562  loss_cls: 0.1375  loss_box_reg: 0.08927  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01633  time: 0.6817  data_time: 0.0687  lr: 0.004  max_mem: 11814M
[11/17 13:21:09] d2.utils.events INFO:  eta: 14:26:59  iter: 34739  total_loss: 0.2439  loss_cls: 0.1279  loss_box_reg: 0.08622  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.0169  time: 0.6817  data_time: 0.0631  lr: 0.004  max_mem: 11814M
[11/17 13:21:22] d2.utils.events INFO:  eta: 14:26:38  iter: 34759  total_loss: 0.2576  loss_cls: 0.137  loss_box_reg: 0.08857  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.01586  time: 0.6817  data_time: 0.0662  lr: 0.004  max_mem: 11814M
[11/17 13:21:36] d2.utils.events INFO:  eta: 14:26:18  iter: 34779  total_loss: 0.2429  loss_cls: 0.1273  loss_box_reg: 0.08685  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.0168  time: 0.6817  data_time: 0.0709  lr: 0.004  max_mem: 11814M
[11/17 13:21:50] d2.utils.events INFO:  eta: 14:25:58  iter: 34799  total_loss: 0.2554  loss_cls: 0.1337  loss_box_reg: 0.08936  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.01615  time: 0.6817  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 13:22:03] d2.utils.events INFO:  eta: 14:26:05  iter: 34819  total_loss: 0.2479  loss_cls: 0.1281  loss_box_reg: 0.08893  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.01718  time: 0.6817  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 13:22:17] d2.utils.events INFO:  eta: 14:25:46  iter: 34839  total_loss: 0.2522  loss_cls: 0.1375  loss_box_reg: 0.08674  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01672  time: 0.6817  data_time: 0.0616  lr: 0.004  max_mem: 11814M
[11/17 13:22:30] d2.utils.events INFO:  eta: 14:25:29  iter: 34859  total_loss: 0.24  loss_cls: 0.1245  loss_box_reg: 0.08756  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.01596  time: 0.6816  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 13:22:44] d2.utils.events INFO:  eta: 14:25:00  iter: 34879  total_loss: 0.2461  loss_cls: 0.1291  loss_box_reg: 0.08535  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.01743  time: 0.6816  data_time: 0.0691  lr: 0.004  max_mem: 11814M
[11/17 13:22:58] d2.utils.events INFO:  eta: 14:24:46  iter: 34899  total_loss: 0.2666  loss_cls: 0.1402  loss_box_reg: 0.09084  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01591  time: 0.6816  data_time: 0.0616  lr: 0.004  max_mem: 11814M
[11/17 13:23:11] d2.utils.events INFO:  eta: 14:24:56  iter: 34919  total_loss: 0.2686  loss_cls: 0.1415  loss_box_reg: 0.09217  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.01795  time: 0.6817  data_time: 0.0642  lr: 0.004  max_mem: 11814M
[11/17 13:23:25] d2.utils.events INFO:  eta: 14:24:43  iter: 34939  total_loss: 0.2395  loss_cls: 0.1275  loss_box_reg: 0.08491  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.01784  time: 0.6816  data_time: 0.0633  lr: 0.004  max_mem: 11814M
[11/17 13:23:39] d2.utils.events INFO:  eta: 14:24:24  iter: 34959  total_loss: 0.252  loss_cls: 0.1317  loss_box_reg: 0.08682  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.01701  time: 0.6816  data_time: 0.0646  lr: 0.004  max_mem: 11814M
[11/17 13:23:52] d2.utils.events INFO:  eta: 14:24:00  iter: 34979  total_loss: 0.2399  loss_cls: 0.1302  loss_box_reg: 0.08685  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.01763  time: 0.6816  data_time: 0.0658  lr: 0.004  max_mem: 11814M
[11/17 13:24:06] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0034999.pth
[11/17 13:24:06] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 13:24:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 13:24:07] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 13:24:07] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 13:24:07] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 13:24:07] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 13:24:13] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0409 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:20
[11/17 13:24:18] d2.evaluation.evaluator INFO: Inference done 136/3334. Dataloading: 0.0015 s/iter. Inference: 0.0383 s/iter. Eval: 0.0002 s/iter. Total: 0.0401 s/iter. ETA=0:02:08
[11/17 13:24:23] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:04
[11/17 13:24:28] d2.evaluation.evaluator INFO: Inference done 384/3334. Dataloading: 0.0015 s/iter. Inference: 0.0385 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:59
[11/17 13:24:33] d2.evaluation.evaluator INFO: Inference done 507/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:54
[11/17 13:24:38] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:49
[11/17 13:24:43] d2.evaluation.evaluator INFO: Inference done 751/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:45
[11/17 13:24:48] d2.evaluation.evaluator INFO: Inference done 873/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:40
[11/17 13:24:53] d2.evaluation.evaluator INFO: Inference done 997/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:35
[11/17 13:24:58] d2.evaluation.evaluator INFO: Inference done 1120/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:30
[11/17 13:25:04] d2.evaluation.evaluator INFO: Inference done 1243/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:25
[11/17 13:25:09] d2.evaluation.evaluator INFO: Inference done 1370/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:19
[11/17 13:25:14] d2.evaluation.evaluator INFO: Inference done 1491/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:14
[11/17 13:25:19] d2.evaluation.evaluator INFO: Inference done 1610/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:10
[11/17 13:25:24] d2.evaluation.evaluator INFO: Inference done 1734/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/17 13:25:29] d2.evaluation.evaluator INFO: Inference done 1854/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:00
[11/17 13:25:34] d2.evaluation.evaluator INFO: Inference done 1978/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:55
[11/17 13:25:39] d2.evaluation.evaluator INFO: Inference done 2101/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/17 13:25:44] d2.evaluation.evaluator INFO: Inference done 2223/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/17 13:25:49] d2.evaluation.evaluator INFO: Inference done 2344/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:40
[11/17 13:25:54] d2.evaluation.evaluator INFO: Inference done 2461/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/17 13:25:59] d2.evaluation.evaluator INFO: Inference done 2585/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:30
[11/17 13:26:04] d2.evaluation.evaluator INFO: Inference done 2707/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/17 13:26:09] d2.evaluation.evaluator INFO: Inference done 2829/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:20
[11/17 13:26:14] d2.evaluation.evaluator INFO: Inference done 2951/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/17 13:26:19] d2.evaluation.evaluator INFO: Inference done 3071/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/17 13:26:24] d2.evaluation.evaluator INFO: Inference done 3194/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 13:26:29] d2.evaluation.evaluator INFO: Inference done 3317/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 13:26:30] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.927712 (0.041132 s / iter per device, on 6 devices)
[11/17 13:26:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039134 s / iter per device, on 6 devices)
[11/17 13:26:33] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 13:26:33] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 13:26:34] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 13:26:34] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 13:26:55] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.32 seconds.
[11/17 13:26:56] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 13:26:57] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.71 seconds.
[11/17 13:26:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.616 | 14.603 | 4.890  | 1.140 | 3.102 | 7.881 |
[11/17 13:26:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.715  | person      | 6.043  | bird                  | 21.691 |
| red panda            | 8.768  | dog         | 39.648 | snake                 | 6.343  |
| car                  | 23.874 | seal        | 1.567  | helmet                | 9.251  |
| motorcycle           | 10.572 | swine       | 5.483  | stove                 | 8.426  |
| monkey               | 7.602  | watercraft  | 18.377 | chair                 | 4.241  |
| domestic cat         | 5.023  | harp        | 5.018  | antelope              | 15.173 |
| camel                | 2.473  | koala bear  | 7.399  | bus                   | 18.873 |
| hat with a wide brim | 3.043  | ski         | 0.330  | piano                 | 7.873  |
| frog                 | 6.165  | dumbbell    | 0.062  | lobster               | 3.968  |
| bench                | 0.756  | rabbit      | 9.412  | porcupine             | 10.337 |
| butterfly            | 22.318 | guitar      | 4.159  | microphone            | 0.139  |
| tape player          | 5.785  | bear        | 8.247  | hippopotamus          | 0.565  |
| bowl                 | 7.494  | axe         | 3.455  | skunk                 | 3.850  |
| airplane             | 13.112 | otter       | 2.130  | table                 | 5.020  |
| coffee maker         | 14.884 | tie         | 1.052  | turtle                | 4.635  |
| purse                | 3.794  | dragonfly   | 4.295  | lemon                 | 7.669  |
| lizard               | 3.865  | backpack    | 6.132  | tv or monitor         | 9.345  |
| cup or mug           | 2.944  | sheep       | 4.152  | ray                   | 1.987  |
| fox                  | 5.094  | whale       | 8.383  | salt or pepper shaker | 0.516  |
| computer keyboard    | 3.404  | fig         | 2.893  | bathing cap           | 3.630  |
| bookshelf            | 8.462  | ladybug     | 24.654 | crutch                | 0.082  |
| pretzel              | 3.267  | sunglasses  | 0.336  | starfish              | 7.259  |
| croquet ball         | 9.975  | lamp        | 1.953  | apple                 | 9.084  |
| cream                | 7.256  | artichoke   | 12.957 | train                 | 11.174 |
| elephant             | 10.085 | bell pepper | 5.981  | miniskirt             | 2.533  |
| orange               | 9.510  | tiger       | 2.935  | sofa                  | 2.529  |
| horse                | 6.920  | violin      | 0.789  | traffic light         | 2.577  |
| drum                 | 0.718  | strawberry  | 5.814  | laptop                | 6.435  |
| pomegranate          | 2.818  | cucumber    | 0.445  | bicycle               | 4.896  |
| banana               | 1.057  | baby bed    | 12.293 | jellyfish             | 7.214  |
| pitcher              | 1.585  | bagel       | 3.163  | beaker                | 5.121  |
| goldfish             | 4.791  | nail        | 0.097  | mushroom              | 3.353  |
| flower pot           | 0.684  | cattle      | 0.965  | zebra                 | 15.668 |
| wine bottle          | 2.727  |             |        |                       |        |
[11/17 13:26:59] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 13:26:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 13:26:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 13:26:59] d2.evaluation.testing INFO: copypaste: 6.6162,14.6034,4.8898,1.1403,3.1018,7.8807
[11/17 13:26:59] d2.utils.events INFO:  eta: 14:24:02  iter: 34999  total_loss: 0.2272  loss_cls: 0.1213  loss_box_reg: 0.08002  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01574  time: 0.6816  data_time: 0.0683  lr: 0.004  max_mem: 11814M
[11/17 13:27:13] d2.utils.events INFO:  eta: 14:24:09  iter: 35019  total_loss: 0.2415  loss_cls: 0.1263  loss_box_reg: 0.08603  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01785  time: 0.6816  data_time: 0.0684  lr: 0.004  max_mem: 11814M
[11/17 13:27:27] d2.utils.events INFO:  eta: 14:24:31  iter: 35039  total_loss: 0.2336  loss_cls: 0.1256  loss_box_reg: 0.08455  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.01624  time: 0.6816  data_time: 0.0668  lr: 0.004  max_mem: 11814M
[11/17 13:27:40] d2.utils.events INFO:  eta: 14:23:59  iter: 35059  total_loss: 0.2409  loss_cls: 0.125  loss_box_reg: 0.0843  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.01678  time: 0.6816  data_time: 0.0667  lr: 0.004  max_mem: 11814M
[11/17 13:27:54] d2.utils.events INFO:  eta: 14:24:06  iter: 35079  total_loss: 0.2451  loss_cls: 0.1278  loss_box_reg: 0.0859  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.0166  time: 0.6816  data_time: 0.0619  lr: 0.004  max_mem: 11814M
[11/17 13:28:07] d2.utils.events INFO:  eta: 14:23:29  iter: 35099  total_loss: 0.2522  loss_cls: 0.1344  loss_box_reg: 0.08891  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.01727  time: 0.6816  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 13:28:21] d2.utils.events INFO:  eta: 14:23:29  iter: 35119  total_loss: 0.2313  loss_cls: 0.1194  loss_box_reg: 0.08387  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01687  time: 0.6816  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 13:28:35] d2.utils.events INFO:  eta: 14:23:02  iter: 35139  total_loss: 0.2448  loss_cls: 0.1237  loss_box_reg: 0.08526  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01592  time: 0.6816  data_time: 0.0719  lr: 0.004  max_mem: 11814M
[11/17 13:28:48] d2.utils.events INFO:  eta: 14:22:34  iter: 35159  total_loss: 0.242  loss_cls: 0.1213  loss_box_reg: 0.0822  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.0167  time: 0.6816  data_time: 0.0639  lr: 0.004  max_mem: 11814M
[11/17 13:29:02] d2.utils.events INFO:  eta: 14:22:17  iter: 35179  total_loss: 0.2425  loss_cls: 0.1281  loss_box_reg: 0.08586  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01653  time: 0.6816  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 13:29:15] d2.utils.events INFO:  eta: 14:21:45  iter: 35199  total_loss: 0.2477  loss_cls: 0.1286  loss_box_reg: 0.08627  loss_rpn_cls: 0.01699  loss_rpn_loc: 0.01767  time: 0.6815  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 13:29:29] d2.utils.events INFO:  eta: 14:21:02  iter: 35219  total_loss: 0.2428  loss_cls: 0.125  loss_box_reg: 0.08126  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.01647  time: 0.6816  data_time: 0.0772  lr: 0.004  max_mem: 11814M
[11/17 13:29:43] d2.utils.events INFO:  eta: 14:20:48  iter: 35239  total_loss: 0.245  loss_cls: 0.1312  loss_box_reg: 0.08469  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01842  time: 0.6816  data_time: 0.0609  lr: 0.004  max_mem: 11814M
[11/17 13:29:56] d2.utils.events INFO:  eta: 14:20:57  iter: 35259  total_loss: 0.2406  loss_cls: 0.1313  loss_box_reg: 0.08692  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.01639  time: 0.6816  data_time: 0.0641  lr: 0.004  max_mem: 11814M
[11/17 13:30:10] d2.utils.events INFO:  eta: 14:19:39  iter: 35279  total_loss: 0.2629  loss_cls: 0.1324  loss_box_reg: 0.08645  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.01837  time: 0.6816  data_time: 0.0624  lr: 0.004  max_mem: 11814M
[11/17 13:30:24] d2.utils.events INFO:  eta: 14:20:07  iter: 35299  total_loss: 0.2525  loss_cls: 0.1294  loss_box_reg: 0.08608  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.01879  time: 0.6816  data_time: 0.0683  lr: 0.004  max_mem: 11814M
[11/17 13:30:37] d2.utils.events INFO:  eta: 14:19:36  iter: 35319  total_loss: 0.2428  loss_cls: 0.1298  loss_box_reg: 0.08654  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.01778  time: 0.6816  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 13:30:51] d2.utils.events INFO:  eta: 14:19:11  iter: 35339  total_loss: 0.253  loss_cls: 0.1328  loss_box_reg: 0.08593  loss_rpn_cls: 0.01392  loss_rpn_loc: 0.01821  time: 0.6815  data_time: 0.0746  lr: 0.004  max_mem: 11814M
[11/17 13:31:05] d2.utils.events INFO:  eta: 14:18:50  iter: 35359  total_loss: 0.2477  loss_cls: 0.1265  loss_box_reg: 0.08798  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.01855  time: 0.6816  data_time: 0.0709  lr: 0.004  max_mem: 11814M
[11/17 13:31:18] d2.utils.events INFO:  eta: 14:18:13  iter: 35379  total_loss: 0.2402  loss_cls: 0.1268  loss_box_reg: 0.08475  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.01794  time: 0.6815  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 13:31:32] d2.utils.events INFO:  eta: 14:17:54  iter: 35399  total_loss: 0.2532  loss_cls: 0.134  loss_box_reg: 0.08714  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.01725  time: 0.6815  data_time: 0.0618  lr: 0.004  max_mem: 11814M
[11/17 13:31:45] d2.utils.events INFO:  eta: 14:16:52  iter: 35419  total_loss: 0.252  loss_cls: 0.134  loss_box_reg: 0.08965  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.01537  time: 0.6815  data_time: 0.0677  lr: 0.004  max_mem: 11814M
[11/17 13:31:59] d2.utils.events INFO:  eta: 14:17:13  iter: 35439  total_loss: 0.2542  loss_cls: 0.1328  loss_box_reg: 0.08551  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01772  time: 0.6814  data_time: 0.0638  lr: 0.004  max_mem: 11814M
[11/17 13:32:12] d2.utils.events INFO:  eta: 14:17:18  iter: 35459  total_loss: 0.2386  loss_cls: 0.1272  loss_box_reg: 0.084  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01827  time: 0.6815  data_time: 0.0700  lr: 0.004  max_mem: 11814M
[11/17 13:32:26] d2.utils.events INFO:  eta: 14:16:59  iter: 35479  total_loss: 0.2311  loss_cls: 0.12  loss_box_reg: 0.08286  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01601  time: 0.6815  data_time: 0.0691  lr: 0.004  max_mem: 11814M
[11/17 13:32:39] d2.utils.events INFO:  eta: 14:16:32  iter: 35499  total_loss: 0.237  loss_cls: 0.1242  loss_box_reg: 0.08242  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.0173  time: 0.6814  data_time: 0.0618  lr: 0.004  max_mem: 11814M
[11/17 13:32:53] d2.utils.events INFO:  eta: 14:15:51  iter: 35519  total_loss: 0.235  loss_cls: 0.126  loss_box_reg: 0.08148  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.01685  time: 0.6814  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 13:33:07] d2.utils.events INFO:  eta: 14:15:30  iter: 35539  total_loss: 0.2539  loss_cls: 0.1318  loss_box_reg: 0.08937  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01808  time: 0.6814  data_time: 0.0687  lr: 0.004  max_mem: 11814M
[11/17 13:33:20] d2.utils.events INFO:  eta: 14:15:53  iter: 35559  total_loss: 0.2564  loss_cls: 0.1322  loss_box_reg: 0.08611  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.0181  time: 0.6814  data_time: 0.0682  lr: 0.004  max_mem: 11814M
[11/17 13:33:34] d2.utils.events INFO:  eta: 14:15:10  iter: 35579  total_loss: 0.2468  loss_cls: 0.1283  loss_box_reg: 0.08399  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.01849  time: 0.6814  data_time: 0.0761  lr: 0.004  max_mem: 11814M
[11/17 13:33:47] d2.utils.events INFO:  eta: 14:14:47  iter: 35599  total_loss: 0.233  loss_cls: 0.1244  loss_box_reg: 0.08084  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.01652  time: 0.6813  data_time: 0.0670  lr: 0.004  max_mem: 11814M
[11/17 13:34:01] d2.utils.events INFO:  eta: 14:14:34  iter: 35619  total_loss: 0.2343  loss_cls: 0.1214  loss_box_reg: 0.08292  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.01778  time: 0.6813  data_time: 0.0618  lr: 0.004  max_mem: 11814M
[11/17 13:34:14] d2.utils.events INFO:  eta: 14:13:44  iter: 35639  total_loss: 0.2429  loss_cls: 0.1273  loss_box_reg: 0.08441  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.01717  time: 0.6813  data_time: 0.0659  lr: 0.004  max_mem: 11814M
[11/17 13:34:28] d2.utils.events INFO:  eta: 14:12:53  iter: 35659  total_loss: 0.2327  loss_cls: 0.1241  loss_box_reg: 0.08279  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.01633  time: 0.6813  data_time: 0.0642  lr: 0.004  max_mem: 11814M
[11/17 13:34:42] d2.utils.events INFO:  eta: 14:12:15  iter: 35679  total_loss: 0.2431  loss_cls: 0.1254  loss_box_reg: 0.08274  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01738  time: 0.6813  data_time: 0.0673  lr: 0.004  max_mem: 11814M
[11/17 13:34:55] d2.utils.events INFO:  eta: 14:12:22  iter: 35699  total_loss: 0.2563  loss_cls: 0.1331  loss_box_reg: 0.08939  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01756  time: 0.6813  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 13:35:09] d2.utils.events INFO:  eta: 14:10:53  iter: 35719  total_loss: 0.2504  loss_cls: 0.1323  loss_box_reg: 0.08828  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.01723  time: 0.6813  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 13:35:22] d2.utils.events INFO:  eta: 14:10:39  iter: 35739  total_loss: 0.2492  loss_cls: 0.1279  loss_box_reg: 0.08984  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.0175  time: 0.6813  data_time: 0.0634  lr: 0.004  max_mem: 11814M
[11/17 13:35:36] d2.utils.events INFO:  eta: 14:10:26  iter: 35759  total_loss: 0.2495  loss_cls: 0.1278  loss_box_reg: 0.08629  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.01737  time: 0.6813  data_time: 0.0575  lr: 0.004  max_mem: 11814M
[11/17 13:35:50] d2.utils.events INFO:  eta: 14:10:12  iter: 35779  total_loss: 0.2469  loss_cls: 0.1291  loss_box_reg: 0.08614  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.01687  time: 0.6813  data_time: 0.0642  lr: 0.004  max_mem: 11814M
[11/17 13:36:03] d2.utils.events INFO:  eta: 14:09:58  iter: 35799  total_loss: 0.2512  loss_cls: 0.1273  loss_box_reg: 0.0913  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.01762  time: 0.6812  data_time: 0.0682  lr: 0.004  max_mem: 11814M
[11/17 13:36:17] d2.utils.events INFO:  eta: 14:09:31  iter: 35819  total_loss: 0.2391  loss_cls: 0.1273  loss_box_reg: 0.08344  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.01719  time: 0.6812  data_time: 0.0755  lr: 0.004  max_mem: 11814M
[11/17 13:36:30] d2.utils.events INFO:  eta: 14:09:29  iter: 35839  total_loss: 0.2455  loss_cls: 0.1283  loss_box_reg: 0.08457  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.01657  time: 0.6812  data_time: 0.0670  lr: 0.004  max_mem: 11814M
[11/17 13:36:44] d2.utils.events INFO:  eta: 14:09:18  iter: 35859  total_loss: 0.2275  loss_cls: 0.1194  loss_box_reg: 0.08326  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.01492  time: 0.6812  data_time: 0.0621  lr: 0.004  max_mem: 11814M
[11/17 13:36:58] d2.utils.events INFO:  eta: 14:09:06  iter: 35879  total_loss: 0.2405  loss_cls: 0.1254  loss_box_reg: 0.08533  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.01848  time: 0.6812  data_time: 0.0704  lr: 0.004  max_mem: 11814M
[11/17 13:37:11] d2.utils.events INFO:  eta: 14:09:08  iter: 35899  total_loss: 0.2414  loss_cls: 0.129  loss_box_reg: 0.08563  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.01896  time: 0.6813  data_time: 0.0646  lr: 0.004  max_mem: 11814M
[11/17 13:37:25] d2.utils.events INFO:  eta: 14:08:41  iter: 35919  total_loss: 0.2396  loss_cls: 0.1248  loss_box_reg: 0.08515  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.01696  time: 0.6813  data_time: 0.0675  lr: 0.004  max_mem: 11814M
[11/17 13:37:39] d2.utils.events INFO:  eta: 14:08:28  iter: 35939  total_loss: 0.252  loss_cls: 0.1279  loss_box_reg: 0.08905  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.01749  time: 0.6813  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:37:52] d2.utils.events INFO:  eta: 14:08:19  iter: 35959  total_loss: 0.2404  loss_cls: 0.1256  loss_box_reg: 0.088  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.0174  time: 0.6813  data_time: 0.0625  lr: 0.004  max_mem: 11814M
[11/17 13:38:06] d2.utils.events INFO:  eta: 14:08:37  iter: 35979  total_loss: 0.2383  loss_cls: 0.126  loss_box_reg: 0.08117  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01965  time: 0.6814  data_time: 0.0848  lr: 0.004  max_mem: 11814M
[11/17 13:38:20] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0035999.pth
[11/17 13:38:20] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 13:38:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 13:38:21] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 13:38:21] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 13:38:21] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 13:38:21] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 13:38:28] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0405 s/iter. ETA=0:02:14
[11/17 13:38:33] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0016 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:09
[11/17 13:38:38] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:02:05
[11/17 13:38:43] d2.evaluation.evaluator INFO: Inference done 382/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:59
[11/17 13:38:48] d2.evaluation.evaluator INFO: Inference done 502/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/17 13:38:53] d2.evaluation.evaluator INFO: Inference done 622/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:51
[11/17 13:38:58] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/17 13:39:03] d2.evaluation.evaluator INFO: Inference done 866/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:41
[11/17 13:39:08] d2.evaluation.evaluator INFO: Inference done 984/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:36
[11/17 13:39:13] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0016 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/17 13:39:18] d2.evaluation.evaluator INFO: Inference done 1231/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/17 13:39:23] d2.evaluation.evaluator INFO: Inference done 1355/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/17 13:39:28] d2.evaluation.evaluator INFO: Inference done 1482/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/17 13:39:33] d2.evaluation.evaluator INFO: Inference done 1603/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:10
[11/17 13:39:38] d2.evaluation.evaluator INFO: Inference done 1729/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:05
[11/17 13:39:43] d2.evaluation.evaluator INFO: Inference done 1852/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/17 13:39:48] d2.evaluation.evaluator INFO: Inference done 1975/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/17 13:39:53] d2.evaluation.evaluator INFO: Inference done 2094/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:50
[11/17 13:39:58] d2.evaluation.evaluator INFO: Inference done 2217/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:45
[11/17 13:40:03] d2.evaluation.evaluator INFO: Inference done 2340/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:40
[11/17 13:40:08] d2.evaluation.evaluator INFO: Inference done 2460/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/17 13:40:13] d2.evaluation.evaluator INFO: Inference done 2583/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/17 13:40:19] d2.evaluation.evaluator INFO: Inference done 2705/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/17 13:40:24] d2.evaluation.evaluator INFO: Inference done 2832/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 13:40:29] d2.evaluation.evaluator INFO: Inference done 2954/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:15
[11/17 13:40:34] d2.evaluation.evaluator INFO: Inference done 3077/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/17 13:40:39] d2.evaluation.evaluator INFO: Inference done 3200/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:05
[11/17 13:40:44] d2.evaluation.evaluator INFO: Inference done 3322/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:00
[11/17 13:40:45] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.781825 (0.041088 s / iter per device, on 6 devices)
[11/17 13:40:45] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.039042 s / iter per device, on 6 devices)
[11/17 13:40:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 13:40:49] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 13:40:50] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 13:40:50] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 13:41:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.56 seconds.
[11/17 13:41:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 13:41:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.02 seconds.
[11/17 13:41:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.243 | 13.974 | 4.564  | 1.101 | 2.910 | 7.584 |
[11/17 13:41:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 7.190  | person      | 5.639  | bird                  | 21.153 |
| red panda            | 8.699  | dog         | 37.754 | snake                 | 6.421  |
| car                  | 26.073 | seal        | 1.754  | helmet                | 9.229  |
| motorcycle           | 9.239  | swine       | 4.720  | stove                 | 7.202  |
| monkey               | 7.856  | watercraft  | 16.305 | chair                 | 3.684  |
| domestic cat         | 6.235  | harp        | 5.182  | antelope              | 10.772 |
| camel                | 1.583  | koala bear  | 7.792  | bus                   | 19.507 |
| hat with a wide brim | 3.633  | ski         | 0.242  | piano                 | 10.144 |
| frog                 | 4.748  | dumbbell    | 0.160  | lobster               | 3.701  |
| bench                | 0.790  | rabbit      | 11.484 | porcupine             | 8.417  |
| butterfly            | 17.163 | guitar      | 3.510  | microphone            | 0.066  |
| tape player          | 5.852  | bear        | 9.547  | hippopotamus          | 1.237  |
| bowl                 | 6.306  | axe         | 4.227  | skunk                 | 3.892  |
| airplane             | 13.104 | otter       | 2.421  | table                 | 5.014  |
| coffee maker         | 14.622 | tie         | 0.709  | turtle                | 6.147  |
| purse                | 3.152  | dragonfly   | 3.539  | lemon                 | 7.756  |
| lizard               | 3.180  | backpack    | 4.350  | tv or monitor         | 9.192  |
| cup or mug           | 2.562  | sheep       | 2.327  | ray                   | 1.144  |
| fox                  | 5.646  | whale       | 10.786 | salt or pepper shaker | 0.628  |
| computer keyboard    | 2.243  | fig         | 2.127  | bathing cap           | 3.569  |
| bookshelf            | 7.792  | ladybug     | 22.467 | crutch                | 0.089  |
| pretzel              | 3.548  | sunglasses  | 0.667  | starfish              | 6.772  |
| croquet ball         | 7.289  | lamp        | 2.167  | apple                 | 11.233 |
| cream                | 7.221  | artichoke   | 11.919 | train                 | 8.135  |
| elephant             | 8.212  | bell pepper | 4.862  | miniskirt             | 1.950  |
| orange               | 10.241 | tiger       | 2.449  | sofa                  | 2.536  |
| horse                | 5.580  | violin      | 0.536  | traffic light         | 1.874  |
| drum                 | 0.719  | strawberry  | 4.326  | laptop                | 7.360  |
| pomegranate          | 2.252  | cucumber    | 0.251  | bicycle               | 3.114  |
| banana               | 0.960  | baby bed    | 10.931 | jellyfish             | 6.267  |
| pitcher              | 1.066  | bagel       | 5.376  | beaker                | 5.498  |
| goldfish             | 4.425  | nail        | 0.407  | mushroom              | 2.147  |
| flower pot           | 0.811  | cattle      | 1.223  | zebra                 | 13.583 |
| wine bottle          | 2.695  |             |        |                       |        |
[11/17 13:41:16] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 13:41:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 13:41:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 13:41:16] d2.evaluation.testing INFO: copypaste: 6.2428,13.9744,4.5639,1.1014,2.9102,7.5843
[11/17 13:41:16] d2.utils.events INFO:  eta: 14:08:35  iter: 35999  total_loss: 0.2524  loss_cls: 0.131  loss_box_reg: 0.08618  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01779  time: 0.6814  data_time: 0.0641  lr: 0.004  max_mem: 11814M
[11/17 13:41:30] d2.utils.events INFO:  eta: 14:08:44  iter: 36019  total_loss: 0.24  loss_cls: 0.1216  loss_box_reg: 0.08657  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.01757  time: 0.6814  data_time: 0.0835  lr: 0.004  max_mem: 11814M
[11/17 13:41:43] d2.utils.events INFO:  eta: 14:07:56  iter: 36039  total_loss: 0.2433  loss_cls: 0.1233  loss_box_reg: 0.08456  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01885  time: 0.6814  data_time: 0.0695  lr: 0.004  max_mem: 11814M
[11/17 13:41:57] d2.utils.events INFO:  eta: 14:08:03  iter: 36059  total_loss: 0.2387  loss_cls: 0.1262  loss_box_reg: 0.08489  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01652  time: 0.6814  data_time: 0.0670  lr: 0.004  max_mem: 11814M
[11/17 13:42:11] d2.utils.events INFO:  eta: 14:07:50  iter: 36079  total_loss: 0.2462  loss_cls: 0.129  loss_box_reg: 0.08531  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.0186  time: 0.6814  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 13:42:24] d2.utils.events INFO:  eta: 14:07:50  iter: 36099  total_loss: 0.2348  loss_cls: 0.1195  loss_box_reg: 0.08249  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.01596  time: 0.6814  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:42:38] d2.utils.events INFO:  eta: 14:07:40  iter: 36119  total_loss: 0.2502  loss_cls: 0.1313  loss_box_reg: 0.0887  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.01672  time: 0.6815  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 13:42:52] d2.utils.events INFO:  eta: 14:07:57  iter: 36139  total_loss: 0.2466  loss_cls: 0.1301  loss_box_reg: 0.08757  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01631  time: 0.6815  data_time: 0.0800  lr: 0.004  max_mem: 11814M
[11/17 13:43:06] d2.utils.events INFO:  eta: 14:07:43  iter: 36159  total_loss: 0.2347  loss_cls: 0.1224  loss_box_reg: 0.08469  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.01752  time: 0.6815  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:43:19] d2.utils.events INFO:  eta: 14:06:59  iter: 36179  total_loss: 0.2463  loss_cls: 0.1303  loss_box_reg: 0.08615  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.01718  time: 0.6815  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 13:43:33] d2.utils.events INFO:  eta: 14:07:37  iter: 36199  total_loss: 0.2289  loss_cls: 0.1196  loss_box_reg: 0.08032  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.01702  time: 0.6815  data_time: 0.0646  lr: 0.004  max_mem: 11814M
[11/17 13:43:46] d2.utils.events INFO:  eta: 14:07:21  iter: 36219  total_loss: 0.2363  loss_cls: 0.1241  loss_box_reg: 0.08388  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01703  time: 0.6814  data_time: 0.0677  lr: 0.004  max_mem: 11814M
[11/17 13:44:00] d2.utils.events INFO:  eta: 14:07:04  iter: 36239  total_loss: 0.2653  loss_cls: 0.137  loss_box_reg: 0.09241  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.01679  time: 0.6814  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 13:44:13] d2.utils.events INFO:  eta: 14:06:04  iter: 36259  total_loss: 0.2564  loss_cls: 0.1334  loss_box_reg: 0.09129  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.01584  time: 0.6814  data_time: 0.0717  lr: 0.004  max_mem: 11814M
[11/17 13:44:27] d2.utils.events INFO:  eta: 14:06:00  iter: 36279  total_loss: 0.2591  loss_cls: 0.1312  loss_box_reg: 0.09021  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.01799  time: 0.6814  data_time: 0.0710  lr: 0.004  max_mem: 11814M
[11/17 13:44:41] d2.utils.events INFO:  eta: 14:05:19  iter: 36299  total_loss: 0.2564  loss_cls: 0.1332  loss_box_reg: 0.08636  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.01736  time: 0.6814  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 13:44:54] d2.utils.events INFO:  eta: 14:05:05  iter: 36319  total_loss: 0.2349  loss_cls: 0.1281  loss_box_reg: 0.08218  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.01691  time: 0.6814  data_time: 0.0693  lr: 0.004  max_mem: 11814M
[11/17 13:45:08] d2.utils.events INFO:  eta: 14:05:41  iter: 36339  total_loss: 0.2453  loss_cls: 0.1262  loss_box_reg: 0.08672  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.01739  time: 0.6814  data_time: 0.0717  lr: 0.004  max_mem: 11814M
[11/17 13:45:22] d2.utils.events INFO:  eta: 14:05:40  iter: 36359  total_loss: 0.2608  loss_cls: 0.1346  loss_box_reg: 0.09269  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.01544  time: 0.6814  data_time: 0.0685  lr: 0.004  max_mem: 11814M
[11/17 13:45:36] d2.utils.events INFO:  eta: 14:06:28  iter: 36379  total_loss: 0.259  loss_cls: 0.1367  loss_box_reg: 0.09297  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.01703  time: 0.6815  data_time: 0.0791  lr: 0.004  max_mem: 11814M
[11/17 13:45:49] d2.utils.events INFO:  eta: 14:06:24  iter: 36399  total_loss: 0.2474  loss_cls: 0.1294  loss_box_reg: 0.08598  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01752  time: 0.6815  data_time: 0.0764  lr: 0.004  max_mem: 11814M
[11/17 13:46:03] d2.utils.events INFO:  eta: 14:06:41  iter: 36419  total_loss: 0.2474  loss_cls: 0.1276  loss_box_reg: 0.08793  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.01527  time: 0.6815  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 13:46:17] d2.utils.events INFO:  eta: 14:06:18  iter: 36439  total_loss: 0.242  loss_cls: 0.1281  loss_box_reg: 0.08651  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01661  time: 0.6815  data_time: 0.0611  lr: 0.004  max_mem: 11814M
[11/17 13:46:30] d2.utils.events INFO:  eta: 14:05:58  iter: 36459  total_loss: 0.2544  loss_cls: 0.1323  loss_box_reg: 0.09129  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.01875  time: 0.6815  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 13:46:44] d2.utils.events INFO:  eta: 14:05:51  iter: 36479  total_loss: 0.247  loss_cls: 0.131  loss_box_reg: 0.08537  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.0178  time: 0.6815  data_time: 0.0612  lr: 0.004  max_mem: 11814M
[11/17 13:46:58] d2.utils.events INFO:  eta: 14:05:56  iter: 36499  total_loss: 0.2509  loss_cls: 0.1344  loss_box_reg: 0.08667  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.01716  time: 0.6815  data_time: 0.0596  lr: 0.004  max_mem: 11814M
[11/17 13:47:11] d2.utils.events INFO:  eta: 14:05:42  iter: 36519  total_loss: 0.2449  loss_cls: 0.1288  loss_box_reg: 0.08682  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.01625  time: 0.6815  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 13:47:25] d2.utils.events INFO:  eta: 14:05:45  iter: 36539  total_loss: 0.2423  loss_cls: 0.1293  loss_box_reg: 0.08764  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01644  time: 0.6815  data_time: 0.0616  lr: 0.004  max_mem: 11814M
[11/17 13:47:39] d2.utils.events INFO:  eta: 14:05:28  iter: 36559  total_loss: 0.2509  loss_cls: 0.1304  loss_box_reg: 0.08692  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.01793  time: 0.6815  data_time: 0.0685  lr: 0.004  max_mem: 11814M
[11/17 13:47:52] d2.utils.events INFO:  eta: 14:05:18  iter: 36579  total_loss: 0.2389  loss_cls: 0.1253  loss_box_reg: 0.08723  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.01583  time: 0.6815  data_time: 0.0701  lr: 0.004  max_mem: 11814M
[11/17 13:48:06] d2.utils.events INFO:  eta: 14:05:05  iter: 36599  total_loss: 0.2369  loss_cls: 0.1226  loss_box_reg: 0.0822  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01717  time: 0.6815  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 13:48:19] d2.utils.events INFO:  eta: 14:05:01  iter: 36619  total_loss: 0.2398  loss_cls: 0.1221  loss_box_reg: 0.08356  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.01858  time: 0.6815  data_time: 0.0617  lr: 0.004  max_mem: 11814M
[11/17 13:48:33] d2.utils.events INFO:  eta: 14:04:48  iter: 36639  total_loss: 0.2542  loss_cls: 0.1334  loss_box_reg: 0.08899  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.01722  time: 0.6815  data_time: 0.0639  lr: 0.004  max_mem: 11814M
[11/17 13:48:47] d2.utils.events INFO:  eta: 14:04:34  iter: 36659  total_loss: 0.2546  loss_cls: 0.1349  loss_box_reg: 0.09293  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.01607  time: 0.6815  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 13:49:00] d2.utils.events INFO:  eta: 14:04:29  iter: 36679  total_loss: 0.2496  loss_cls: 0.1267  loss_box_reg: 0.08895  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.0186  time: 0.6815  data_time: 0.0618  lr: 0.004  max_mem: 11814M
[11/17 13:49:14] d2.utils.events INFO:  eta: 14:04:13  iter: 36699  total_loss: 0.2502  loss_cls: 0.1314  loss_box_reg: 0.08679  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.01873  time: 0.6815  data_time: 0.0630  lr: 0.004  max_mem: 11814M
[11/17 13:49:28] d2.utils.events INFO:  eta: 14:04:58  iter: 36719  total_loss: 0.2498  loss_cls: 0.1292  loss_box_reg: 0.0852  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.01797  time: 0.6815  data_time: 0.0681  lr: 0.004  max_mem: 11814M
[11/17 13:49:41] d2.utils.events INFO:  eta: 14:04:38  iter: 36739  total_loss: 0.2284  loss_cls: 0.1206  loss_box_reg: 0.08018  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.01651  time: 0.6815  data_time: 0.0727  lr: 0.004  max_mem: 11814M
[11/17 13:49:55] d2.utils.events INFO:  eta: 14:04:30  iter: 36759  total_loss: 0.2509  loss_cls: 0.1275  loss_box_reg: 0.08837  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01575  time: 0.6815  data_time: 0.0722  lr: 0.004  max_mem: 11814M
[11/17 13:50:08] d2.utils.events INFO:  eta: 14:03:28  iter: 36779  total_loss: 0.259  loss_cls: 0.1319  loss_box_reg: 0.0896  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01867  time: 0.6815  data_time: 0.0606  lr: 0.004  max_mem: 11814M
[11/17 13:50:22] d2.utils.events INFO:  eta: 14:03:49  iter: 36799  total_loss: 0.2327  loss_cls: 0.1216  loss_box_reg: 0.08115  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.01663  time: 0.6815  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:50:36] d2.utils.events INFO:  eta: 14:03:43  iter: 36819  total_loss: 0.2336  loss_cls: 0.1174  loss_box_reg: 0.08272  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.01721  time: 0.6815  data_time: 0.0628  lr: 0.004  max_mem: 11814M
[11/17 13:50:49] d2.utils.events INFO:  eta: 14:02:48  iter: 36839  total_loss: 0.2434  loss_cls: 0.1291  loss_box_reg: 0.08645  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.01465  time: 0.6815  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 13:51:03] d2.utils.events INFO:  eta: 14:02:14  iter: 36859  total_loss: 0.2354  loss_cls: 0.1241  loss_box_reg: 0.08574  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01663  time: 0.6815  data_time: 0.0860  lr: 0.004  max_mem: 11814M
[11/17 13:51:17] d2.utils.events INFO:  eta: 14:01:37  iter: 36879  total_loss: 0.2454  loss_cls: 0.1283  loss_box_reg: 0.08698  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.01734  time: 0.6815  data_time: 0.0674  lr: 0.004  max_mem: 11814M
[11/17 13:51:30] d2.utils.events INFO:  eta: 14:00:52  iter: 36899  total_loss: 0.2333  loss_cls: 0.1211  loss_box_reg: 0.082  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01806  time: 0.6815  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 13:51:44] d2.utils.events INFO:  eta: 14:00:45  iter: 36919  total_loss: 0.2444  loss_cls: 0.1276  loss_box_reg: 0.08966  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.0184  time: 0.6815  data_time: 0.0698  lr: 0.004  max_mem: 11814M
[11/17 13:51:58] d2.utils.events INFO:  eta: 14:00:31  iter: 36939  total_loss: 0.2612  loss_cls: 0.1338  loss_box_reg: 0.09141  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.01744  time: 0.6816  data_time: 0.0755  lr: 0.004  max_mem: 11814M
[11/17 13:52:12] d2.utils.events INFO:  eta: 14:00:49  iter: 36959  total_loss: 0.2482  loss_cls: 0.1356  loss_box_reg: 0.08662  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.01812  time: 0.6816  data_time: 0.0684  lr: 0.004  max_mem: 11814M
[11/17 13:52:25] d2.utils.events INFO:  eta: 14:00:36  iter: 36979  total_loss: 0.2391  loss_cls: 0.1231  loss_box_reg: 0.08538  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01639  time: 0.6816  data_time: 0.0728  lr: 0.004  max_mem: 11814M
[11/17 13:52:39] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0036999.pth
[11/17 13:52:39] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 13:52:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 13:52:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 13:52:40] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 13:52:40] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 13:52:40] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 13:52:47] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0400 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:16
[11/17 13:52:52] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:02:12
[11/17 13:52:57] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0409 s/iter. ETA=0:02:05
[11/17 13:53:02] d2.evaluation.evaluator INFO: Inference done 380/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0408 s/iter. ETA=0:02:00
[11/17 13:53:07] d2.evaluation.evaluator INFO: Inference done 503/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:55
[11/17 13:53:12] d2.evaluation.evaluator INFO: Inference done 626/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:50
[11/17 13:53:17] d2.evaluation.evaluator INFO: Inference done 750/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:45
[11/17 13:53:22] d2.evaluation.evaluator INFO: Inference done 872/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/17 13:53:27] d2.evaluation.evaluator INFO: Inference done 993/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/17 13:53:32] d2.evaluation.evaluator INFO: Inference done 1115/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/17 13:53:37] d2.evaluation.evaluator INFO: Inference done 1241/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:25
[11/17 13:53:42] d2.evaluation.evaluator INFO: Inference done 1362/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/17 13:53:47] d2.evaluation.evaluator INFO: Inference done 1481/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:15
[11/17 13:53:52] d2.evaluation.evaluator INFO: Inference done 1604/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/17 13:53:57] d2.evaluation.evaluator INFO: Inference done 1725/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:05
[11/17 13:54:02] d2.evaluation.evaluator INFO: Inference done 1851/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/17 13:54:07] d2.evaluation.evaluator INFO: Inference done 1973/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/17 13:54:12] d2.evaluation.evaluator INFO: Inference done 2100/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/17 13:54:17] d2.evaluation.evaluator INFO: Inference done 2224/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/17 13:54:22] d2.evaluation.evaluator INFO: Inference done 2350/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:40
[11/17 13:54:27] d2.evaluation.evaluator INFO: Inference done 2471/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/17 13:54:32] d2.evaluation.evaluator INFO: Inference done 2595/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/17 13:54:37] d2.evaluation.evaluator INFO: Inference done 2716/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:25
[11/17 13:54:42] d2.evaluation.evaluator INFO: Inference done 2835/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 13:54:47] d2.evaluation.evaluator INFO: Inference done 2957/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:15
[11/17 13:54:52] d2.evaluation.evaluator INFO: Inference done 3076/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:10
[11/17 13:54:57] d2.evaluation.evaluator INFO: Inference done 3197/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 13:55:02] d2.evaluation.evaluator INFO: Inference done 3320/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 13:55:03] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.808342 (0.041096 s / iter per device, on 6 devices)
[11/17 13:55:03] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039135 s / iter per device, on 6 devices)
[11/17 13:55:07] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 13:55:07] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 13:55:09] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 13:55:09] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 13:55:31] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.14 seconds.
[11/17 13:55:31] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 13:55:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.04 seconds.
[11/17 13:55:33] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 6.957 | 15.417 | 5.164  | 1.039 | 3.259 | 8.372 |
[11/17 13:55:33] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.704  | person      | 6.384  | bird                  | 20.718 |
| red panda            | 9.254  | dog         | 39.770 | snake                 | 7.407  |
| car                  | 25.416 | seal        | 2.921  | helmet                | 9.688  |
| motorcycle           | 9.343  | swine       | 5.708  | stove                 | 6.956  |
| monkey               | 8.257  | watercraft  | 19.517 | chair                 | 4.131  |
| domestic cat         | 6.437  | harp        | 3.302  | antelope              | 15.833 |
| camel                | 3.550  | koala bear  | 6.714  | bus                   | 19.647 |
| hat with a wide brim | 3.547  | ski         | 0.263  | piano                 | 9.046  |
| frog                 | 7.358  | dumbbell    | 0.097  | lobster               | 5.701  |
| bench                | 0.926  | rabbit      | 12.648 | porcupine             | 9.745  |
| butterfly            | 21.829 | guitar      | 4.912  | microphone            | 0.050  |
| tape player          | 6.988  | bear        | 8.954  | hippopotamus          | 0.572  |
| bowl                 | 8.293  | axe         | 5.152  | skunk                 | 3.279  |
| airplane             | 13.040 | otter       | 3.481  | table                 | 5.995  |
| coffee maker         | 15.169 | tie         | 0.983  | turtle                | 7.198  |
| purse                | 3.768  | dragonfly   | 4.154  | lemon                 | 10.623 |
| lizard               | 4.170  | backpack    | 5.693  | tv or monitor         | 10.550 |
| cup or mug           | 4.508  | sheep       | 3.750  | ray                   | 1.909  |
| fox                  | 7.034  | whale       | 8.623  | salt or pepper shaker | 1.316  |
| computer keyboard    | 2.544  | fig         | 3.522  | bathing cap           | 2.013  |
| bookshelf            | 8.529  | ladybug     | 26.075 | crutch                | 0.038  |
| pretzel              | 4.659  | sunglasses  | 0.363  | starfish              | 7.873  |
| croquet ball         | 8.244  | lamp        | 1.773  | apple                 | 11.586 |
| cream                | 8.665  | artichoke   | 12.885 | train                 | 9.585  |
| elephant             | 12.697 | bell pepper | 5.238  | miniskirt             | 2.385  |
| orange               | 10.826 | tiger       | 3.531  | sofa                  | 1.820  |
| horse                | 6.528  | violin      | 0.914  | traffic light         | 3.127  |
| drum                 | 0.767  | strawberry  | 6.172  | laptop                | 6.931  |
| pomegranate          | 2.844  | cucumber    | 0.369  | bicycle               | 3.875  |
| banana               | 0.883  | baby bed    | 11.999 | jellyfish             | 4.575  |
| pitcher              | 2.789  | bagel       | 4.240  | beaker                | 6.113  |
| goldfish             | 4.828  | nail        | 0.206  | mushroom              | 3.082  |
| flower pot           | 0.919  | cattle      | 1.903  | zebra                 | 14.631 |
| wine bottle          | 2.188  |             |        |                       |        |
[11/17 13:55:35] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 13:55:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 13:55:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 13:55:35] d2.evaluation.testing INFO: copypaste: 6.9572,15.4169,5.1635,1.0395,3.2591,8.3718
[11/17 13:55:35] d2.utils.events INFO:  eta: 14:00:15  iter: 36999  total_loss: 0.2428  loss_cls: 0.129  loss_box_reg: 0.08689  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.01614  time: 0.6816  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 13:55:49] d2.utils.events INFO:  eta: 13:59:19  iter: 37019  total_loss: 0.2486  loss_cls: 0.1283  loss_box_reg: 0.08627  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.01753  time: 0.6815  data_time: 0.0661  lr: 0.004  max_mem: 11814M
[11/17 13:56:03] d2.utils.events INFO:  eta: 13:59:09  iter: 37039  total_loss: 0.243  loss_cls: 0.1294  loss_box_reg: 0.08925  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.01583  time: 0.6815  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 13:56:16] d2.utils.events INFO:  eta: 13:58:48  iter: 37059  total_loss: 0.2435  loss_cls: 0.1253  loss_box_reg: 0.08405  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01686  time: 0.6815  data_time: 0.0752  lr: 0.004  max_mem: 11814M
[11/17 13:56:30] d2.utils.events INFO:  eta: 13:58:31  iter: 37079  total_loss: 0.2437  loss_cls: 0.1256  loss_box_reg: 0.08596  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01796  time: 0.6816  data_time: 0.0795  lr: 0.004  max_mem: 11814M
[11/17 13:56:44] d2.utils.events INFO:  eta: 13:58:25  iter: 37099  total_loss: 0.2413  loss_cls: 0.1218  loss_box_reg: 0.08492  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.01694  time: 0.6816  data_time: 0.0674  lr: 0.004  max_mem: 11814M
[11/17 13:56:57] d2.utils.events INFO:  eta: 13:57:39  iter: 37119  total_loss: 0.2295  loss_cls: 0.1176  loss_box_reg: 0.08324  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.01859  time: 0.6815  data_time: 0.0632  lr: 0.004  max_mem: 11814M
[11/17 13:57:11] d2.utils.events INFO:  eta: 13:57:33  iter: 37139  total_loss: 0.2503  loss_cls: 0.1352  loss_box_reg: 0.0891  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01688  time: 0.6816  data_time: 0.0668  lr: 0.004  max_mem: 11814M
[11/17 13:57:24] d2.utils.events INFO:  eta: 13:57:36  iter: 37159  total_loss: 0.2429  loss_cls: 0.1316  loss_box_reg: 0.08459  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.0153  time: 0.6815  data_time: 0.0617  lr: 0.004  max_mem: 11814M
[11/17 13:57:38] d2.utils.events INFO:  eta: 13:57:30  iter: 37179  total_loss: 0.2496  loss_cls: 0.1258  loss_box_reg: 0.09182  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01744  time: 0.6815  data_time: 0.0684  lr: 0.004  max_mem: 11814M
[11/17 13:57:52] d2.utils.events INFO:  eta: 13:57:08  iter: 37199  total_loss: 0.2467  loss_cls: 0.1289  loss_box_reg: 0.08332  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01782  time: 0.6815  data_time: 0.0622  lr: 0.004  max_mem: 11814M
[11/17 13:58:05] d2.utils.events INFO:  eta: 13:57:05  iter: 37219  total_loss: 0.2443  loss_cls: 0.1249  loss_box_reg: 0.08639  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.01725  time: 0.6815  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 13:58:19] d2.utils.events INFO:  eta: 13:56:45  iter: 37239  total_loss: 0.2349  loss_cls: 0.118  loss_box_reg: 0.08402  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.0173  time: 0.6815  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 13:58:32] d2.utils.events INFO:  eta: 13:56:39  iter: 37259  total_loss: 0.2343  loss_cls: 0.1248  loss_box_reg: 0.08462  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.01638  time: 0.6815  data_time: 0.0686  lr: 0.004  max_mem: 11814M
[11/17 13:58:46] d2.utils.events INFO:  eta: 13:56:22  iter: 37279  total_loss: 0.2396  loss_cls: 0.121  loss_box_reg: 0.08572  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01816  time: 0.6815  data_time: 0.0710  lr: 0.004  max_mem: 11814M
[11/17 13:58:59] d2.utils.events INFO:  eta: 13:56:23  iter: 37299  total_loss: 0.24  loss_cls: 0.1238  loss_box_reg: 0.08178  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01792  time: 0.6815  data_time: 0.0672  lr: 0.004  max_mem: 11814M
[11/17 13:59:13] d2.utils.events INFO:  eta: 13:55:58  iter: 37319  total_loss: 0.2417  loss_cls: 0.1248  loss_box_reg: 0.08584  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01612  time: 0.6815  data_time: 0.0790  lr: 0.004  max_mem: 11814M
[11/17 13:59:27] d2.utils.events INFO:  eta: 13:55:39  iter: 37339  total_loss: 0.2385  loss_cls: 0.1217  loss_box_reg: 0.08596  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.01733  time: 0.6815  data_time: 0.0654  lr: 0.004  max_mem: 11814M
[11/17 13:59:40] d2.utils.events INFO:  eta: 13:55:20  iter: 37359  total_loss: 0.2363  loss_cls: 0.1231  loss_box_reg: 0.0832  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.01581  time: 0.6815  data_time: 0.0677  lr: 0.004  max_mem: 11814M
[11/17 13:59:54] d2.utils.events INFO:  eta: 13:54:50  iter: 37379  total_loss: 0.2468  loss_cls: 0.1296  loss_box_reg: 0.08913  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01745  time: 0.6815  data_time: 0.0651  lr: 0.004  max_mem: 11814M
[11/17 14:00:08] d2.utils.events INFO:  eta: 13:54:26  iter: 37399  total_loss: 0.2403  loss_cls: 0.1256  loss_box_reg: 0.0871  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.01829  time: 0.6815  data_time: 0.0595  lr: 0.004  max_mem: 11814M
[11/17 14:00:21] d2.utils.events INFO:  eta: 13:53:56  iter: 37419  total_loss: 0.2415  loss_cls: 0.1247  loss_box_reg: 0.08659  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.01603  time: 0.6815  data_time: 0.0718  lr: 0.004  max_mem: 11814M
[11/17 14:00:35] d2.utils.events INFO:  eta: 13:53:35  iter: 37439  total_loss: 0.2577  loss_cls: 0.1311  loss_box_reg: 0.0893  loss_rpn_cls: 0.015  loss_rpn_loc: 0.01773  time: 0.6815  data_time: 0.0629  lr: 0.004  max_mem: 11814M
[11/17 14:00:49] d2.utils.events INFO:  eta: 13:53:21  iter: 37459  total_loss: 0.242  loss_cls: 0.1234  loss_box_reg: 0.08217  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.01822  time: 0.6815  data_time: 0.0707  lr: 0.004  max_mem: 11814M
[11/17 14:01:02] d2.utils.events INFO:  eta: 13:53:15  iter: 37479  total_loss: 0.2413  loss_cls: 0.127  loss_box_reg: 0.08651  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.01718  time: 0.6815  data_time: 0.0696  lr: 0.004  max_mem: 11814M
[11/17 14:01:16] d2.utils.events INFO:  eta: 13:53:13  iter: 37499  total_loss: 0.255  loss_cls: 0.1284  loss_box_reg: 0.08762  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.01878  time: 0.6815  data_time: 0.0625  lr: 0.004  max_mem: 11814M
[11/17 14:01:30] d2.utils.events INFO:  eta: 13:53:08  iter: 37519  total_loss: 0.2445  loss_cls: 0.1287  loss_box_reg: 0.08592  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.0174  time: 0.6815  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 14:01:43] d2.utils.events INFO:  eta: 13:52:46  iter: 37539  total_loss: 0.2515  loss_cls: 0.1295  loss_box_reg: 0.08823  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.01794  time: 0.6815  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 14:01:57] d2.utils.events INFO:  eta: 13:52:42  iter: 37559  total_loss: 0.2538  loss_cls: 0.133  loss_box_reg: 0.09137  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.01613  time: 0.6815  data_time: 0.0675  lr: 0.004  max_mem: 11814M
[11/17 14:02:11] d2.utils.events INFO:  eta: 13:52:27  iter: 37579  total_loss: 0.2344  loss_cls: 0.1226  loss_box_reg: 0.08468  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.01657  time: 0.6815  data_time: 0.0737  lr: 0.004  max_mem: 11814M
[11/17 14:02:24] d2.utils.events INFO:  eta: 13:52:18  iter: 37599  total_loss: 0.2422  loss_cls: 0.1263  loss_box_reg: 0.08452  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01716  time: 0.6815  data_time: 0.0661  lr: 0.004  max_mem: 11814M
[11/17 14:02:38] d2.utils.events INFO:  eta: 13:52:01  iter: 37619  total_loss: 0.247  loss_cls: 0.1249  loss_box_reg: 0.08683  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.0177  time: 0.6815  data_time: 0.0695  lr: 0.004  max_mem: 11814M
[11/17 14:02:52] d2.utils.events INFO:  eta: 13:51:50  iter: 37639  total_loss: 0.2546  loss_cls: 0.1317  loss_box_reg: 0.08924  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.0173  time: 0.6815  data_time: 0.0630  lr: 0.004  max_mem: 11814M
[11/17 14:03:05] d2.utils.events INFO:  eta: 13:51:48  iter: 37659  total_loss: 0.2443  loss_cls: 0.1212  loss_box_reg: 0.0827  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.01829  time: 0.6815  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 14:03:19] d2.utils.events INFO:  eta: 13:51:34  iter: 37679  total_loss: 0.2231  loss_cls: 0.114  loss_box_reg: 0.0778  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.01639  time: 0.6815  data_time: 0.0674  lr: 0.004  max_mem: 11814M
[11/17 14:03:32] d2.utils.events INFO:  eta: 13:51:10  iter: 37699  total_loss: 0.2486  loss_cls: 0.1291  loss_box_reg: 0.08705  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.01583  time: 0.6815  data_time: 0.0612  lr: 0.004  max_mem: 11814M
[11/17 14:03:46] d2.utils.events INFO:  eta: 13:50:55  iter: 37719  total_loss: 0.2364  loss_cls: 0.1221  loss_box_reg: 0.08547  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.01746  time: 0.6815  data_time: 0.0657  lr: 0.004  max_mem: 11814M
[11/17 14:04:00] d2.utils.events INFO:  eta: 13:50:39  iter: 37739  total_loss: 0.2429  loss_cls: 0.1289  loss_box_reg: 0.08698  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.01593  time: 0.6815  data_time: 0.0697  lr: 0.004  max_mem: 11814M
[11/17 14:04:13] d2.utils.events INFO:  eta: 13:50:27  iter: 37759  total_loss: 0.2361  loss_cls: 0.1205  loss_box_reg: 0.0864  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01693  time: 0.6815  data_time: 0.0715  lr: 0.004  max_mem: 11814M
[11/17 14:04:27] d2.utils.events INFO:  eta: 13:50:53  iter: 37779  total_loss: 0.2351  loss_cls: 0.1256  loss_box_reg: 0.08544  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.01785  time: 0.6815  data_time: 0.0627  lr: 0.004  max_mem: 11814M
[11/17 14:04:41] d2.utils.events INFO:  eta: 13:50:51  iter: 37799  total_loss: 0.2441  loss_cls: 0.1298  loss_box_reg: 0.09008  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.01673  time: 0.6815  data_time: 0.0572  lr: 0.004  max_mem: 11814M
[11/17 14:04:54] d2.utils.events INFO:  eta: 13:50:43  iter: 37819  total_loss: 0.2581  loss_cls: 0.1351  loss_box_reg: 0.09261  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.01828  time: 0.6815  data_time: 0.0704  lr: 0.004  max_mem: 11814M
[11/17 14:05:08] d2.utils.events INFO:  eta: 13:51:04  iter: 37839  total_loss: 0.2355  loss_cls: 0.1238  loss_box_reg: 0.08797  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.01668  time: 0.6815  data_time: 0.0622  lr: 0.004  max_mem: 11814M
[11/17 14:05:21] d2.utils.events INFO:  eta: 13:50:50  iter: 37859  total_loss: 0.2397  loss_cls: 0.1246  loss_box_reg: 0.08571  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.01668  time: 0.6815  data_time: 0.0683  lr: 0.004  max_mem: 11814M
[11/17 14:05:35] d2.utils.events INFO:  eta: 13:51:01  iter: 37879  total_loss: 0.2416  loss_cls: 0.1232  loss_box_reg: 0.08888  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.01626  time: 0.6815  data_time: 0.0633  lr: 0.004  max_mem: 11814M
[11/17 14:05:49] d2.utils.events INFO:  eta: 13:50:42  iter: 37899  total_loss: 0.2451  loss_cls: 0.1314  loss_box_reg: 0.08571  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.01806  time: 0.6815  data_time: 0.0662  lr: 0.004  max_mem: 11814M
[11/17 14:06:03] d2.utils.events INFO:  eta: 13:50:31  iter: 37919  total_loss: 0.2551  loss_cls: 0.1327  loss_box_reg: 0.0888  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.01856  time: 0.6815  data_time: 0.0791  lr: 0.004  max_mem: 11814M
[11/17 14:06:16] d2.utils.events INFO:  eta: 13:50:18  iter: 37939  total_loss: 0.2511  loss_cls: 0.1329  loss_box_reg: 0.09006  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.01719  time: 0.6816  data_time: 0.0793  lr: 0.004  max_mem: 11814M
[11/17 14:06:30] d2.utils.events INFO:  eta: 13:50:04  iter: 37959  total_loss: 0.2441  loss_cls: 0.1294  loss_box_reg: 0.08668  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.01786  time: 0.6816  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 14:06:44] d2.utils.events INFO:  eta: 13:49:43  iter: 37979  total_loss: 0.2475  loss_cls: 0.1285  loss_box_reg: 0.08411  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.01868  time: 0.6816  data_time: 0.0775  lr: 0.004  max_mem: 11814M
[11/17 14:06:58] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0037999.pth
[11/17 14:06:58] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 14:06:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 14:06:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 14:06:59] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 14:06:59] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 14:06:59] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 14:07:06] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0020 s/iter. Inference: 0.0407 s/iter. Eval: 0.0002 s/iter. Total: 0.0430 s/iter. ETA=0:02:22
[11/17 14:07:11] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0014 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:02:11
[11/17 14:07:16] d2.evaluation.evaluator INFO: Inference done 257/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:02:05
[11/17 14:07:21] d2.evaluation.evaluator INFO: Inference done 383/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:59
[11/17 14:07:26] d2.evaluation.evaluator INFO: Inference done 506/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:54
[11/17 14:07:31] d2.evaluation.evaluator INFO: Inference done 628/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:50
[11/17 14:07:36] d2.evaluation.evaluator INFO: Inference done 751/3334. Dataloading: 0.0015 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:45
[11/17 14:07:41] d2.evaluation.evaluator INFO: Inference done 874/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:40
[11/17 14:07:46] d2.evaluation.evaluator INFO: Inference done 991/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:36
[11/17 14:07:51] d2.evaluation.evaluator INFO: Inference done 1114/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:31
[11/17 14:07:56] d2.evaluation.evaluator INFO: Inference done 1235/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:26
[11/17 14:08:01] d2.evaluation.evaluator INFO: Inference done 1358/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:21
[11/17 14:08:06] d2.evaluation.evaluator INFO: Inference done 1478/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/17 14:08:11] d2.evaluation.evaluator INFO: Inference done 1599/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:11
[11/17 14:08:16] d2.evaluation.evaluator INFO: Inference done 1725/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:06
[11/17 14:08:22] d2.evaluation.evaluator INFO: Inference done 1849/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:00
[11/17 14:08:27] d2.evaluation.evaluator INFO: Inference done 1971/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:55
[11/17 14:08:32] d2.evaluation.evaluator INFO: Inference done 2091/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/17 14:08:37] d2.evaluation.evaluator INFO: Inference done 2214/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:45
[11/17 14:08:42] d2.evaluation.evaluator INFO: Inference done 2336/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/17 14:08:47] d2.evaluation.evaluator INFO: Inference done 2455/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/17 14:08:52] d2.evaluation.evaluator INFO: Inference done 2576/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/17 14:08:57] d2.evaluation.evaluator INFO: Inference done 2699/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:26
[11/17 14:09:02] d2.evaluation.evaluator INFO: Inference done 2823/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/17 14:09:07] d2.evaluation.evaluator INFO: Inference done 2946/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:15
[11/17 14:09:12] d2.evaluation.evaluator INFO: Inference done 3069/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:10
[11/17 14:09:17] d2.evaluation.evaluator INFO: Inference done 3195/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 14:09:22] d2.evaluation.evaluator INFO: Inference done 3317/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 14:09:23] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.001329 (0.041154 s / iter per device, on 6 devices)
[11/17 14:09:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039215 s / iter per device, on 6 devices)
[11/17 14:09:26] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 14:09:26] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 14:09:27] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 14:09:28] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 14:09:51] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 22.81 seconds.
[11/17 14:09:51] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 14:09:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.03 seconds.
[11/17 14:09:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.082 | 15.609 | 5.383  | 0.713 | 3.365 | 8.502 |
[11/17 14:09:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 9.783  | person      | 6.794  | bird                  | 22.870 |
| red panda            | 10.312 | dog         | 40.624 | snake                 | 7.015  |
| car                  | 25.823 | seal        | 3.317  | helmet                | 9.419  |
| motorcycle           | 10.111 | swine       | 6.594  | stove                 | 8.665  |
| monkey               | 9.063  | watercraft  | 19.228 | chair                 | 4.787  |
| domestic cat         | 5.732  | harp        | 6.051  | antelope              | 13.763 |
| camel                | 2.342  | koala bear  | 8.415  | bus                   | 20.935 |
| hat with a wide brim | 3.541  | ski         | 1.468  | piano                 | 9.983  |
| frog                 | 6.906  | dumbbell    | 0.056  | lobster               | 4.259  |
| bench                | 0.818  | rabbit      | 10.261 | porcupine             | 12.148 |
| butterfly            | 21.828 | guitar      | 4.124  | microphone            | 0.043  |
| tape player          | 7.137  | bear        | 9.672  | hippopotamus          | 0.728  |
| bowl                 | 8.500  | axe         | 3.773  | skunk                 | 5.355  |
| airplane             | 14.484 | otter       | 2.049  | table                 | 5.992  |
| coffee maker         | 15.657 | tie         | 1.068  | turtle                | 5.119  |
| purse                | 2.945  | dragonfly   | 4.675  | lemon                 | 8.834  |
| lizard               | 4.243  | backpack    | 5.554  | tv or monitor         | 10.427 |
| cup or mug           | 3.883  | sheep       | 4.068  | ray                   | 1.456  |
| fox                  | 6.130  | whale       | 8.354  | salt or pepper shaker | 0.766  |
| computer keyboard    | 2.542  | fig         | 3.801  | bathing cap           | 3.491  |
| bookshelf            | 11.377 | ladybug     | 25.245 | crutch                | 0.211  |
| pretzel              | 4.937  | sunglasses  | 0.550  | starfish              | 7.546  |
| croquet ball         | 6.937  | lamp        | 2.692  | apple                 | 11.364 |
| cream                | 7.352  | artichoke   | 8.610  | train                 | 11.555 |
| elephant             | 11.266 | bell pepper | 4.312  | miniskirt             | 2.242  |
| orange               | 11.642 | tiger       | 6.373  | sofa                  | 1.413  |
| horse                | 6.045  | violin      | 0.692  | traffic light         | 2.664  |
| drum                 | 0.818  | strawberry  | 6.367  | laptop                | 6.619  |
| pomegranate          | 1.812  | cucumber    | 0.270  | bicycle               | 4.831  |
| banana               | 0.987  | baby bed    | 12.514 | jellyfish             | 4.135  |
| pitcher              | 2.543  | bagel       | 3.235  | beaker                | 6.451  |
| goldfish             | 4.915  | nail        | 0.134  | mushroom              | 2.868  |
| flower pot           | 1.778  | cattle      | 1.730  | zebra                 | 19.561 |
| wine bottle          | 3.792  |             |        |                       |        |
[11/17 14:09:56] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 14:09:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 14:09:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 14:09:56] d2.evaluation.testing INFO: copypaste: 7.0817,15.6087,5.3827,0.7126,3.3646,8.5023
[11/17 14:09:56] d2.utils.events INFO:  eta: 13:49:29  iter: 37999  total_loss: 0.2377  loss_cls: 0.124  loss_box_reg: 0.08362  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.01634  time: 0.6816  data_time: 0.0811  lr: 0.004  max_mem: 11814M
[11/17 14:10:09] d2.utils.events INFO:  eta: 13:49:26  iter: 38019  total_loss: 0.2375  loss_cls: 0.1246  loss_box_reg: 0.08398  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.0167  time: 0.6816  data_time: 0.0696  lr: 0.004  max_mem: 11814M
[11/17 14:10:23] d2.utils.events INFO:  eta: 13:49:09  iter: 38039  total_loss: 0.2567  loss_cls: 0.1327  loss_box_reg: 0.08823  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01673  time: 0.6816  data_time: 0.0594  lr: 0.004  max_mem: 11814M
[11/17 14:10:37] d2.utils.events INFO:  eta: 13:49:05  iter: 38059  total_loss: 0.2401  loss_cls: 0.1254  loss_box_reg: 0.08291  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.0181  time: 0.6817  data_time: 0.0774  lr: 0.004  max_mem: 11814M
[11/17 14:10:50] d2.utils.events INFO:  eta: 13:48:35  iter: 38079  total_loss: 0.2278  loss_cls: 0.1198  loss_box_reg: 0.07736  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.0169  time: 0.6816  data_time: 0.0754  lr: 0.004  max_mem: 11814M
[11/17 14:11:04] d2.utils.events INFO:  eta: 13:48:07  iter: 38099  total_loss: 0.2437  loss_cls: 0.1257  loss_box_reg: 0.08735  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.0177  time: 0.6816  data_time: 0.0658  lr: 0.004  max_mem: 11814M
[11/17 14:11:17] d2.utils.events INFO:  eta: 13:47:59  iter: 38119  total_loss: 0.2303  loss_cls: 0.1167  loss_box_reg: 0.08593  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01771  time: 0.6816  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 14:11:31] d2.utils.events INFO:  eta: 13:47:32  iter: 38139  total_loss: 0.2364  loss_cls: 0.1249  loss_box_reg: 0.08443  loss_rpn_cls: 0.01155  loss_rpn_loc: 0.01783  time: 0.6816  data_time: 0.0619  lr: 0.004  max_mem: 11814M
[11/17 14:11:45] d2.utils.events INFO:  eta: 13:47:22  iter: 38159  total_loss: 0.251  loss_cls: 0.1291  loss_box_reg: 0.08735  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.01887  time: 0.6816  data_time: 0.0606  lr: 0.004  max_mem: 11814M
[11/17 14:11:58] d2.utils.events INFO:  eta: 13:47:20  iter: 38179  total_loss: 0.248  loss_cls: 0.1253  loss_box_reg: 0.08819  loss_rpn_cls: 0.01284  loss_rpn_loc: 0.01835  time: 0.6817  data_time: 0.0767  lr: 0.004  max_mem: 11814M
[11/17 14:12:12] d2.utils.events INFO:  eta: 13:47:01  iter: 38199  total_loss: 0.245  loss_cls: 0.1266  loss_box_reg: 0.0863  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.01702  time: 0.6817  data_time: 0.0686  lr: 0.004  max_mem: 11814M
[11/17 14:12:26] d2.utils.events INFO:  eta: 13:46:53  iter: 38219  total_loss: 0.2321  loss_cls: 0.1233  loss_box_reg: 0.08234  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.01824  time: 0.6817  data_time: 0.0704  lr: 0.004  max_mem: 11814M
[11/17 14:12:39] d2.utils.events INFO:  eta: 13:46:37  iter: 38239  total_loss: 0.2308  loss_cls: 0.1194  loss_box_reg: 0.0822  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.01658  time: 0.6816  data_time: 0.0627  lr: 0.004  max_mem: 11814M
[11/17 14:12:53] d2.utils.events INFO:  eta: 13:46:32  iter: 38259  total_loss: 0.2404  loss_cls: 0.1239  loss_box_reg: 0.08514  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01682  time: 0.6817  data_time: 0.0655  lr: 0.004  max_mem: 11814M
[11/17 14:13:07] d2.utils.events INFO:  eta: 13:46:36  iter: 38279  total_loss: 0.2313  loss_cls: 0.1202  loss_box_reg: 0.08377  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01576  time: 0.6816  data_time: 0.0627  lr: 0.004  max_mem: 11814M
[11/17 14:13:20] d2.utils.events INFO:  eta: 13:45:56  iter: 38299  total_loss: 0.2543  loss_cls: 0.1284  loss_box_reg: 0.08685  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.01727  time: 0.6816  data_time: 0.0612  lr: 0.004  max_mem: 11814M
[11/17 14:13:34] d2.utils.events INFO:  eta: 13:46:04  iter: 38319  total_loss: 0.2302  loss_cls: 0.1188  loss_box_reg: 0.08005  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.01775  time: 0.6816  data_time: 0.0673  lr: 0.004  max_mem: 11814M
[11/17 14:13:48] d2.utils.events INFO:  eta: 13:45:55  iter: 38339  total_loss: 0.2348  loss_cls: 0.1174  loss_box_reg: 0.08456  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.01825  time: 0.6817  data_time: 0.0751  lr: 0.004  max_mem: 11814M
[11/17 14:14:01] d2.utils.events INFO:  eta: 13:45:54  iter: 38359  total_loss: 0.2384  loss_cls: 0.1256  loss_box_reg: 0.08537  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.01653  time: 0.6817  data_time: 0.0620  lr: 0.004  max_mem: 11814M
[11/17 14:14:15] d2.utils.events INFO:  eta: 13:45:18  iter: 38379  total_loss: 0.242  loss_cls: 0.1253  loss_box_reg: 0.0821  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.01712  time: 0.6816  data_time: 0.0715  lr: 0.004  max_mem: 11814M
[11/17 14:14:28] d2.utils.events INFO:  eta: 13:45:07  iter: 38399  total_loss: 0.24  loss_cls: 0.1235  loss_box_reg: 0.0841  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01734  time: 0.6816  data_time: 0.0761  lr: 0.004  max_mem: 11814M
[11/17 14:14:42] d2.utils.events INFO:  eta: 13:44:54  iter: 38419  total_loss: 0.2429  loss_cls: 0.1259  loss_box_reg: 0.08832  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.01565  time: 0.6816  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 14:14:56] d2.utils.events INFO:  eta: 13:45:00  iter: 38439  total_loss: 0.2456  loss_cls: 0.1304  loss_box_reg: 0.09  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01616  time: 0.6816  data_time: 0.0714  lr: 0.004  max_mem: 11814M
[11/17 14:15:09] d2.utils.events INFO:  eta: 13:44:49  iter: 38459  total_loss: 0.2346  loss_cls: 0.1234  loss_box_reg: 0.08454  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.01741  time: 0.6816  data_time: 0.0682  lr: 0.004  max_mem: 11814M
[11/17 14:15:23] d2.utils.events INFO:  eta: 13:44:19  iter: 38479  total_loss: 0.2366  loss_cls: 0.1216  loss_box_reg: 0.08654  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.01767  time: 0.6817  data_time: 0.0735  lr: 0.004  max_mem: 11814M
[11/17 14:15:37] d2.utils.events INFO:  eta: 13:43:48  iter: 38499  total_loss: 0.2422  loss_cls: 0.1259  loss_box_reg: 0.0885  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.01599  time: 0.6817  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 14:15:50] d2.utils.events INFO:  eta: 13:43:29  iter: 38519  total_loss: 0.2418  loss_cls: 0.1271  loss_box_reg: 0.08224  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.01748  time: 0.6816  data_time: 0.0686  lr: 0.004  max_mem: 11814M
[11/17 14:16:04] d2.utils.events INFO:  eta: 13:43:15  iter: 38539  total_loss: 0.2357  loss_cls: 0.1205  loss_box_reg: 0.0836  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.01705  time: 0.6816  data_time: 0.0665  lr: 0.004  max_mem: 11814M
[11/17 14:16:18] d2.utils.events INFO:  eta: 13:43:01  iter: 38559  total_loss: 0.2338  loss_cls: 0.1215  loss_box_reg: 0.08406  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01682  time: 0.6817  data_time: 0.0724  lr: 0.004  max_mem: 11814M
[11/17 14:16:31] d2.utils.events INFO:  eta: 13:42:41  iter: 38579  total_loss: 0.2383  loss_cls: 0.1233  loss_box_reg: 0.08664  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.01678  time: 0.6817  data_time: 0.0796  lr: 0.004  max_mem: 11814M
[11/17 14:16:45] d2.utils.events INFO:  eta: 13:42:27  iter: 38599  total_loss: 0.248  loss_cls: 0.1278  loss_box_reg: 0.09034  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.01697  time: 0.6817  data_time: 0.0763  lr: 0.004  max_mem: 11814M
[11/17 14:16:59] d2.utils.events INFO:  eta: 13:42:13  iter: 38619  total_loss: 0.2353  loss_cls: 0.1201  loss_box_reg: 0.08259  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01764  time: 0.6817  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 14:17:12] d2.utils.events INFO:  eta: 13:41:58  iter: 38639  total_loss: 0.2434  loss_cls: 0.128  loss_box_reg: 0.08428  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.01758  time: 0.6817  data_time: 0.0633  lr: 0.004  max_mem: 11814M
[11/17 14:17:26] d2.utils.events INFO:  eta: 13:41:39  iter: 38659  total_loss: 0.2508  loss_cls: 0.1303  loss_box_reg: 0.0891  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.0151  time: 0.6817  data_time: 0.0741  lr: 0.004  max_mem: 11814M
[11/17 14:17:40] d2.utils.events INFO:  eta: 13:41:26  iter: 38679  total_loss: 0.2349  loss_cls: 0.1234  loss_box_reg: 0.08401  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.01722  time: 0.6817  data_time: 0.0706  lr: 0.004  max_mem: 11814M
[11/17 14:17:53] d2.utils.events INFO:  eta: 13:41:08  iter: 38699  total_loss: 0.2302  loss_cls: 0.1217  loss_box_reg: 0.08383  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.01555  time: 0.6817  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 14:18:07] d2.utils.events INFO:  eta: 13:40:51  iter: 38719  total_loss: 0.2502  loss_cls: 0.1299  loss_box_reg: 0.08859  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.0179  time: 0.6817  data_time: 0.0821  lr: 0.004  max_mem: 11814M
[11/17 14:18:21] d2.utils.events INFO:  eta: 13:40:41  iter: 38739  total_loss: 0.2377  loss_cls: 0.1265  loss_box_reg: 0.08368  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.01636  time: 0.6817  data_time: 0.0715  lr: 0.004  max_mem: 11814M
[11/17 14:18:34] d2.utils.events INFO:  eta: 13:40:06  iter: 38759  total_loss: 0.2346  loss_cls: 0.1181  loss_box_reg: 0.08389  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.0164  time: 0.6817  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 14:18:48] d2.utils.events INFO:  eta: 13:39:22  iter: 38779  total_loss: 0.2417  loss_cls: 0.1207  loss_box_reg: 0.08347  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01757  time: 0.6817  data_time: 0.0670  lr: 0.004  max_mem: 11814M
[11/17 14:19:01] d2.utils.events INFO:  eta: 13:39:07  iter: 38799  total_loss: 0.2374  loss_cls: 0.1259  loss_box_reg: 0.08607  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.01617  time: 0.6817  data_time: 0.0781  lr: 0.004  max_mem: 11814M
[11/17 14:19:15] d2.utils.events INFO:  eta: 13:39:15  iter: 38819  total_loss: 0.2478  loss_cls: 0.1282  loss_box_reg: 0.08951  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.0175  time: 0.6817  data_time: 0.0825  lr: 0.004  max_mem: 11814M
[11/17 14:19:29] d2.utils.events INFO:  eta: 13:38:48  iter: 38839  total_loss: 0.2318  loss_cls: 0.1191  loss_box_reg: 0.08331  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.01632  time: 0.6817  data_time: 0.0752  lr: 0.004  max_mem: 11814M
[11/17 14:19:43] d2.utils.events INFO:  eta: 13:38:35  iter: 38859  total_loss: 0.241  loss_cls: 0.124  loss_box_reg: 0.08513  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.01931  time: 0.6817  data_time: 0.0728  lr: 0.004  max_mem: 11814M
[11/17 14:19:56] d2.utils.events INFO:  eta: 13:38:15  iter: 38879  total_loss: 0.2442  loss_cls: 0.1248  loss_box_reg: 0.08356  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.01645  time: 0.6817  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 14:20:10] d2.utils.events INFO:  eta: 13:38:17  iter: 38899  total_loss: 0.2401  loss_cls: 0.1269  loss_box_reg: 0.08517  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.01721  time: 0.6817  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 14:20:24] d2.utils.events INFO:  eta: 13:37:54  iter: 38919  total_loss: 0.2366  loss_cls: 0.1254  loss_box_reg: 0.08454  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01783  time: 0.6817  data_time: 0.0684  lr: 0.004  max_mem: 11814M
[11/17 14:20:38] d2.utils.events INFO:  eta: 13:37:47  iter: 38939  total_loss: 0.2422  loss_cls: 0.1264  loss_box_reg: 0.08101  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01777  time: 0.6817  data_time: 0.0780  lr: 0.004  max_mem: 11814M
[11/17 14:20:51] d2.utils.events INFO:  eta: 13:37:27  iter: 38959  total_loss: 0.2465  loss_cls: 0.1283  loss_box_reg: 0.08944  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01659  time: 0.6817  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 14:21:05] d2.utils.events INFO:  eta: 13:37:20  iter: 38979  total_loss: 0.2323  loss_cls: 0.1199  loss_box_reg: 0.08282  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.01705  time: 0.6817  data_time: 0.0646  lr: 0.004  max_mem: 11814M
[11/17 14:21:18] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0038999.pth
[11/17 14:21:19] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 14:21:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 14:21:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 14:21:19] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 14:21:19] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 14:21:20] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 14:21:26] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0012 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0417 s/iter. ETA=0:02:18
[11/17 14:21:31] d2.evaluation.evaluator INFO: Inference done 135/3334. Dataloading: 0.0015 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/17 14:21:36] d2.evaluation.evaluator INFO: Inference done 259/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:02:04
[11/17 14:21:41] d2.evaluation.evaluator INFO: Inference done 384/3334. Dataloading: 0.0015 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0404 s/iter. ETA=0:01:59
[11/17 14:21:46] d2.evaluation.evaluator INFO: Inference done 506/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:54
[11/17 14:21:51] d2.evaluation.evaluator INFO: Inference done 629/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:50
[11/17 14:21:56] d2.evaluation.evaluator INFO: Inference done 752/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:45
[11/17 14:22:01] d2.evaluation.evaluator INFO: Inference done 878/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:01:39
[11/17 14:22:06] d2.evaluation.evaluator INFO: Inference done 999/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:35
[11/17 14:22:12] d2.evaluation.evaluator INFO: Inference done 1124/3334. Dataloading: 0.0016 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:29
[11/17 14:22:17] d2.evaluation.evaluator INFO: Inference done 1247/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:24
[11/17 14:22:22] d2.evaluation.evaluator INFO: Inference done 1368/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:20
[11/17 14:22:27] d2.evaluation.evaluator INFO: Inference done 1491/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:15
[11/17 14:22:32] d2.evaluation.evaluator INFO: Inference done 1615/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:09
[11/17 14:22:37] d2.evaluation.evaluator INFO: Inference done 1735/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/17 14:22:42] d2.evaluation.evaluator INFO: Inference done 1856/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:00
[11/17 14:22:47] d2.evaluation.evaluator INFO: Inference done 1979/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:55
[11/17 14:22:52] d2.evaluation.evaluator INFO: Inference done 2101/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:50
[11/17 14:22:57] d2.evaluation.evaluator INFO: Inference done 2225/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:45
[11/17 14:23:02] d2.evaluation.evaluator INFO: Inference done 2346/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:40
[11/17 14:23:07] d2.evaluation.evaluator INFO: Inference done 2470/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:35
[11/17 14:23:12] d2.evaluation.evaluator INFO: Inference done 2593/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:30
[11/17 14:23:17] d2.evaluation.evaluator INFO: Inference done 2713/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:25
[11/17 14:23:22] d2.evaluation.evaluator INFO: Inference done 2832/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:20
[11/17 14:23:27] d2.evaluation.evaluator INFO: Inference done 2952/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/17 14:23:32] d2.evaluation.evaluator INFO: Inference done 3072/3334. Dataloading: 0.0016 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/17 14:23:37] d2.evaluation.evaluator INFO: Inference done 3193/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/17 14:23:42] d2.evaluation.evaluator INFO: Inference done 3315/3334. Dataloading: 0.0016 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:00
[11/17 14:23:43] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.115586 (0.041188 s / iter per device, on 6 devices)
[11/17 14:23:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039159 s / iter per device, on 6 devices)
[11/17 14:23:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 14:23:47] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 14:23:48] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 14:23:48] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 14:24:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 21.32 seconds.
[11/17 14:24:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 14:24:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.96 seconds.
[11/17 14:24:12] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.414 | 16.125 | 5.773  | 1.184 | 3.322 | 8.945 |
[11/17 14:24:12] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 10.823 | person      | 6.772  | bird                  | 24.409 |
| red panda            | 10.034 | dog         | 40.310 | snake                 | 7.811  |
| car                  | 28.793 | seal        | 2.294  | helmet                | 10.783 |
| motorcycle           | 12.544 | swine       | 7.134  | stove                 | 8.054  |
| monkey               | 8.017  | watercraft  | 18.852 | chair                 | 4.772  |
| domestic cat         | 7.534  | harp        | 4.582  | antelope              | 15.174 |
| camel                | 2.473  | koala bear  | 10.283 | bus                   | 22.305 |
| hat with a wide brim | 2.757  | ski         | 0.603  | piano                 | 9.212  |
| frog                 | 7.466  | dumbbell    | 0.153  | lobster               | 5.594  |
| bench                | 0.977  | rabbit      | 13.767 | porcupine             | 11.859 |
| butterfly            | 22.820 | guitar      | 3.841  | microphone            | 0.098  |
| tape player          | 8.978  | bear        | 9.553  | hippopotamus          | 0.442  |
| bowl                 | 8.451  | axe         | 3.896  | skunk                 | 3.624  |
| airplane             | 15.730 | otter       | 2.213  | table                 | 6.466  |
| coffee maker         | 16.993 | tie         | 1.704  | turtle                | 6.074  |
| purse                | 3.130  | dragonfly   | 4.517  | lemon                 | 9.474  |
| lizard               | 5.169  | backpack    | 4.180  | tv or monitor         | 10.287 |
| cup or mug           | 4.465  | sheep       | 5.167  | ray                   | 1.452  |
| fox                  | 6.238  | whale       | 10.956 | salt or pepper shaker | 0.431  |
| computer keyboard    | 2.516  | fig         | 4.126  | bathing cap           | 4.241  |
| bookshelf            | 11.938 | ladybug     | 22.974 | crutch                | 0.028  |
| pretzel              | 3.885  | sunglasses  | 0.929  | starfish              | 6.956  |
| croquet ball         | 9.086  | lamp        | 2.385  | apple                 | 13.750 |
| cream                | 6.180  | artichoke   | 12.248 | train                 | 11.281 |
| elephant             | 11.805 | bell pepper | 5.821  | miniskirt             | 2.289  |
| orange               | 9.669  | tiger       | 5.869  | sofa                  | 1.634  |
| horse                | 6.920  | violin      | 1.494  | traffic light         | 2.302  |
| drum                 | 1.093  | strawberry  | 4.980  | laptop                | 8.544  |
| pomegranate          | 2.725  | cucumber    | 0.492  | bicycle               | 6.064  |
| banana               | 1.370  | baby bed    | 14.102 | jellyfish             | 4.358  |
| pitcher              | 1.849  | bagel       | 4.159  | beaker                | 5.713  |
| goldfish             | 4.664  | nail        | 0.090  | mushroom              | 3.421  |
| flower pot           | 1.873  | cattle      | 1.251  | zebra                 | 17.854 |
| wine bottle          | 3.947  |             |        |                       |        |
[11/17 14:24:14] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 14:24:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 14:24:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 14:24:14] d2.evaluation.testing INFO: copypaste: 7.4136,16.1255,5.7732,1.1842,3.3222,8.9450
[11/17 14:24:14] d2.utils.events INFO:  eta: 13:37:03  iter: 38999  total_loss: 0.246  loss_cls: 0.1273  loss_box_reg: 0.08393  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01664  time: 0.6817  data_time: 0.0662  lr: 0.004  max_mem: 11814M
[11/17 14:24:28] d2.utils.events INFO:  eta: 13:36:53  iter: 39019  total_loss: 0.2386  loss_cls: 0.1213  loss_box_reg: 0.08416  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.0162  time: 0.6817  data_time: 0.0738  lr: 0.004  max_mem: 11814M
[11/17 14:24:41] d2.utils.events INFO:  eta: 13:36:45  iter: 39039  total_loss: 0.2323  loss_cls: 0.1175  loss_box_reg: 0.08066  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.01668  time: 0.6817  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 14:24:55] d2.utils.events INFO:  eta: 13:36:22  iter: 39059  total_loss: 0.226  loss_cls: 0.1154  loss_box_reg: 0.08029  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01712  time: 0.6817  data_time: 0.0624  lr: 0.004  max_mem: 11814M
[11/17 14:25:08] d2.utils.events INFO:  eta: 13:36:31  iter: 39079  total_loss: 0.2468  loss_cls: 0.1285  loss_box_reg: 0.08906  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.01631  time: 0.6817  data_time: 0.0672  lr: 0.004  max_mem: 11814M
[11/17 14:25:22] d2.utils.events INFO:  eta: 13:36:20  iter: 39099  total_loss: 0.2381  loss_cls: 0.1229  loss_box_reg: 0.08578  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01693  time: 0.6817  data_time: 0.0662  lr: 0.004  max_mem: 11814M
[11/17 14:25:36] d2.utils.events INFO:  eta: 13:36:32  iter: 39119  total_loss: 0.2468  loss_cls: 0.1281  loss_box_reg: 0.08829  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.01563  time: 0.6817  data_time: 0.0770  lr: 0.004  max_mem: 11814M
[11/17 14:25:49] d2.utils.events INFO:  eta: 13:36:25  iter: 39139  total_loss: 0.2407  loss_cls: 0.1226  loss_box_reg: 0.08302  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.01764  time: 0.6817  data_time: 0.0646  lr: 0.004  max_mem: 11814M
[11/17 14:26:03] d2.utils.events INFO:  eta: 13:36:12  iter: 39159  total_loss: 0.2419  loss_cls: 0.1258  loss_box_reg: 0.08444  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.0172  time: 0.6817  data_time: 0.0744  lr: 0.004  max_mem: 11814M
[11/17 14:26:17] d2.utils.events INFO:  eta: 13:35:38  iter: 39179  total_loss: 0.2395  loss_cls: 0.1197  loss_box_reg: 0.08001  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.01909  time: 0.6817  data_time: 0.0603  lr: 0.004  max_mem: 11814M
[11/17 14:26:30] d2.utils.events INFO:  eta: 13:35:38  iter: 39199  total_loss: 0.2412  loss_cls: 0.1254  loss_box_reg: 0.08828  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.01765  time: 0.6817  data_time: 0.0689  lr: 0.004  max_mem: 11814M
[11/17 14:26:44] d2.utils.events INFO:  eta: 13:34:58  iter: 39219  total_loss: 0.2273  loss_cls: 0.1176  loss_box_reg: 0.07994  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.01552  time: 0.6817  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 14:26:57] d2.utils.events INFO:  eta: 13:34:41  iter: 39239  total_loss: 0.2367  loss_cls: 0.1252  loss_box_reg: 0.08388  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.0166  time: 0.6817  data_time: 0.0642  lr: 0.004  max_mem: 11814M
[11/17 14:27:11] d2.utils.events INFO:  eta: 13:34:11  iter: 39259  total_loss: 0.2347  loss_cls: 0.1249  loss_box_reg: 0.08476  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.01675  time: 0.6817  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 14:27:25] d2.utils.events INFO:  eta: 13:34:03  iter: 39279  total_loss: 0.2312  loss_cls: 0.1168  loss_box_reg: 0.08604  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01699  time: 0.6817  data_time: 0.0636  lr: 0.004  max_mem: 11814M
[11/17 14:27:38] d2.utils.events INFO:  eta: 13:34:00  iter: 39299  total_loss: 0.2301  loss_cls: 0.1184  loss_box_reg: 0.08423  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01803  time: 0.6817  data_time: 0.0718  lr: 0.004  max_mem: 11814M
[11/17 14:27:52] d2.utils.events INFO:  eta: 13:33:46  iter: 39319  total_loss: 0.24  loss_cls: 0.1303  loss_box_reg: 0.08474  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01739  time: 0.6817  data_time: 0.0675  lr: 0.004  max_mem: 11814M
[11/17 14:28:05] d2.utils.events INFO:  eta: 13:33:19  iter: 39339  total_loss: 0.2409  loss_cls: 0.1194  loss_box_reg: 0.08591  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.01642  time: 0.6817  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 14:28:19] d2.utils.events INFO:  eta: 13:33:08  iter: 39359  total_loss: 0.2271  loss_cls: 0.1165  loss_box_reg: 0.08203  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.01639  time: 0.6817  data_time: 0.0694  lr: 0.004  max_mem: 11814M
[11/17 14:28:33] d2.utils.events INFO:  eta: 13:32:56  iter: 39379  total_loss: 0.245  loss_cls: 0.1317  loss_box_reg: 0.08574  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.01726  time: 0.6817  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 14:28:47] d2.utils.events INFO:  eta: 13:32:55  iter: 39399  total_loss: 0.2384  loss_cls: 0.1231  loss_box_reg: 0.08533  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.01703  time: 0.6817  data_time: 0.0792  lr: 0.004  max_mem: 11814M
[11/17 14:29:00] d2.utils.events INFO:  eta: 13:32:46  iter: 39419  total_loss: 0.2436  loss_cls: 0.1283  loss_box_reg: 0.08899  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.01644  time: 0.6817  data_time: 0.0616  lr: 0.004  max_mem: 11814M
[11/17 14:29:14] d2.utils.events INFO:  eta: 13:32:28  iter: 39439  total_loss: 0.2414  loss_cls: 0.1222  loss_box_reg: 0.09037  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01907  time: 0.6817  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 14:29:27] d2.utils.events INFO:  eta: 13:31:54  iter: 39459  total_loss: 0.2376  loss_cls: 0.1243  loss_box_reg: 0.0826  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01671  time: 0.6817  data_time: 0.0688  lr: 0.004  max_mem: 11814M
[11/17 14:29:41] d2.utils.events INFO:  eta: 13:31:03  iter: 39479  total_loss: 0.2351  loss_cls: 0.1221  loss_box_reg: 0.0818  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.0178  time: 0.6817  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 14:29:55] d2.utils.events INFO:  eta: 13:31:30  iter: 39499  total_loss: 0.2501  loss_cls: 0.1277  loss_box_reg: 0.0861  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.01791  time: 0.6817  data_time: 0.0685  lr: 0.004  max_mem: 11814M
[11/17 14:30:09] d2.utils.events INFO:  eta: 13:31:14  iter: 39519  total_loss: 0.2277  loss_cls: 0.1121  loss_box_reg: 0.08241  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.01537  time: 0.6817  data_time: 0.0733  lr: 0.004  max_mem: 11814M
[11/17 14:30:22] d2.utils.events INFO:  eta: 13:31:08  iter: 39539  total_loss: 0.2479  loss_cls: 0.1266  loss_box_reg: 0.08528  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.01744  time: 0.6818  data_time: 0.0777  lr: 0.004  max_mem: 11814M
[11/17 14:30:36] d2.utils.events INFO:  eta: 13:30:52  iter: 39559  total_loss: 0.2339  loss_cls: 0.1222  loss_box_reg: 0.08411  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01642  time: 0.6818  data_time: 0.0695  lr: 0.004  max_mem: 11814M
[11/17 14:30:49] d2.utils.events INFO:  eta: 13:30:33  iter: 39579  total_loss: 0.2275  loss_cls: 0.1171  loss_box_reg: 0.08581  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.01632  time: 0.6817  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 14:31:03] d2.utils.events INFO:  eta: 13:30:18  iter: 39599  total_loss: 0.2363  loss_cls: 0.1279  loss_box_reg: 0.08708  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.01769  time: 0.6817  data_time: 0.0623  lr: 0.004  max_mem: 11814M
[11/17 14:31:17] d2.utils.events INFO:  eta: 13:29:28  iter: 39619  total_loss: 0.2446  loss_cls: 0.1301  loss_box_reg: 0.087  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.01606  time: 0.6817  data_time: 0.0635  lr: 0.004  max_mem: 11814M
[11/17 14:31:30] d2.utils.events INFO:  eta: 13:29:50  iter: 39639  total_loss: 0.2437  loss_cls: 0.1273  loss_box_reg: 0.08929  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.01741  time: 0.6817  data_time: 0.0702  lr: 0.004  max_mem: 11814M
[11/17 14:31:44] d2.utils.events INFO:  eta: 13:29:36  iter: 39659  total_loss: 0.2462  loss_cls: 0.1263  loss_box_reg: 0.08688  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.01814  time: 0.6817  data_time: 0.0748  lr: 0.004  max_mem: 11814M
[11/17 14:31:58] d2.utils.events INFO:  eta: 13:29:11  iter: 39679  total_loss: 0.2344  loss_cls: 0.1245  loss_box_reg: 0.08306  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01721  time: 0.6817  data_time: 0.0682  lr: 0.004  max_mem: 11814M
[11/17 14:32:11] d2.utils.events INFO:  eta: 13:28:34  iter: 39699  total_loss: 0.2563  loss_cls: 0.1318  loss_box_reg: 0.08804  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.01906  time: 0.6817  data_time: 0.0638  lr: 0.004  max_mem: 11814M
[11/17 14:32:25] d2.utils.events INFO:  eta: 13:28:20  iter: 39719  total_loss: 0.2454  loss_cls: 0.1273  loss_box_reg: 0.08409  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.01821  time: 0.6817  data_time: 0.0639  lr: 0.004  max_mem: 11814M
[11/17 14:32:38] d2.utils.events INFO:  eta: 13:28:06  iter: 39739  total_loss: 0.2468  loss_cls: 0.1268  loss_box_reg: 0.08903  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.01647  time: 0.6817  data_time: 0.0710  lr: 0.004  max_mem: 11814M
[11/17 14:32:52] d2.utils.events INFO:  eta: 13:28:03  iter: 39759  total_loss: 0.2488  loss_cls: 0.1249  loss_box_reg: 0.09038  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.01789  time: 0.6817  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 14:33:05] d2.utils.events INFO:  eta: 13:28:09  iter: 39779  total_loss: 0.2256  loss_cls: 0.1155  loss_box_reg: 0.081  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01726  time: 0.6817  data_time: 0.0652  lr: 0.004  max_mem: 11814M
[11/17 14:33:19] d2.utils.events INFO:  eta: 13:27:35  iter: 39799  total_loss: 0.2312  loss_cls: 0.1207  loss_box_reg: 0.08272  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.01719  time: 0.6817  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 14:33:33] d2.utils.events INFO:  eta: 13:26:58  iter: 39819  total_loss: 0.2354  loss_cls: 0.1205  loss_box_reg: 0.0855  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01616  time: 0.6817  data_time: 0.0657  lr: 0.004  max_mem: 11814M
[11/17 14:33:46] d2.utils.events INFO:  eta: 13:27:08  iter: 39839  total_loss: 0.2413  loss_cls: 0.1266  loss_box_reg: 0.08423  loss_rpn_cls: 0.01095  loss_rpn_loc: 0.01722  time: 0.6817  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 14:34:00] d2.utils.events INFO:  eta: 13:27:10  iter: 39859  total_loss: 0.2422  loss_cls: 0.1229  loss_box_reg: 0.0847  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.01799  time: 0.6817  data_time: 0.0663  lr: 0.004  max_mem: 11814M
[11/17 14:34:14] d2.utils.events INFO:  eta: 13:27:01  iter: 39879  total_loss: 0.2432  loss_cls: 0.1288  loss_box_reg: 0.08518  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.01731  time: 0.6817  data_time: 0.0687  lr: 0.004  max_mem: 11814M
[11/17 14:34:27] d2.utils.events INFO:  eta: 13:26:21  iter: 39899  total_loss: 0.2322  loss_cls: 0.1234  loss_box_reg: 0.08274  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01639  time: 0.6817  data_time: 0.0720  lr: 0.004  max_mem: 11814M
[11/17 14:34:41] d2.utils.events INFO:  eta: 13:26:00  iter: 39919  total_loss: 0.2372  loss_cls: 0.1233  loss_box_reg: 0.0825  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.01708  time: 0.6817  data_time: 0.0723  lr: 0.004  max_mem: 11814M
[11/17 14:34:54] d2.utils.events INFO:  eta: 13:25:47  iter: 39939  total_loss: 0.2427  loss_cls: 0.1221  loss_box_reg: 0.08549  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.01737  time: 0.6817  data_time: 0.0589  lr: 0.004  max_mem: 11814M
[11/17 14:35:08] d2.utils.events INFO:  eta: 13:25:33  iter: 39959  total_loss: 0.2386  loss_cls: 0.1236  loss_box_reg: 0.08428  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.01654  time: 0.6817  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 14:35:22] d2.utils.events INFO:  eta: 13:25:09  iter: 39979  total_loss: 0.2394  loss_cls: 0.128  loss_box_reg: 0.08307  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.0159  time: 0.6817  data_time: 0.0678  lr: 0.004  max_mem: 11814M
[11/17 14:35:35] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0039999.pth
[11/17 14:35:36] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 14:35:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 14:35:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 14:35:36] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 14:35:37] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 14:35:37] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 14:35:44] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0393 s/iter. Eval: 0.0003 s/iter. Total: 0.0406 s/iter. ETA=0:02:14
[11/17 14:35:49] d2.evaluation.evaluator INFO: Inference done 131/3334. Dataloading: 0.0014 s/iter. Inference: 0.0402 s/iter. Eval: 0.0002 s/iter. Total: 0.0419 s/iter. ETA=0:02:14
[11/17 14:35:54] d2.evaluation.evaluator INFO: Inference done 250/3334. Dataloading: 0.0015 s/iter. Inference: 0.0403 s/iter. Eval: 0.0002 s/iter. Total: 0.0421 s/iter. ETA=0:02:09
[11/17 14:35:59] d2.evaluation.evaluator INFO: Inference done 371/3334. Dataloading: 0.0015 s/iter. Inference: 0.0401 s/iter. Eval: 0.0002 s/iter. Total: 0.0418 s/iter. ETA=0:02:03
[11/17 14:36:04] d2.evaluation.evaluator INFO: Inference done 493/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:58
[11/17 14:36:09] d2.evaluation.evaluator INFO: Inference done 614/3334. Dataloading: 0.0015 s/iter. Inference: 0.0399 s/iter. Eval: 0.0002 s/iter. Total: 0.0416 s/iter. ETA=0:01:53
[11/17 14:36:14] d2.evaluation.evaluator INFO: Inference done 736/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:01:47
[11/17 14:36:19] d2.evaluation.evaluator INFO: Inference done 860/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:42
[11/17 14:36:24] d2.evaluation.evaluator INFO: Inference done 981/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:37
[11/17 14:36:29] d2.evaluation.evaluator INFO: Inference done 1106/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:31
[11/17 14:36:34] d2.evaluation.evaluator INFO: Inference done 1233/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:26
[11/17 14:36:39] d2.evaluation.evaluator INFO: Inference done 1355/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:21
[11/17 14:36:44] d2.evaluation.evaluator INFO: Inference done 1477/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:16
[11/17 14:36:49] d2.evaluation.evaluator INFO: Inference done 1599/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:11
[11/17 14:36:54] d2.evaluation.evaluator INFO: Inference done 1719/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:06
[11/17 14:36:59] d2.evaluation.evaluator INFO: Inference done 1843/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:01:01
[11/17 14:37:04] d2.evaluation.evaluator INFO: Inference done 1963/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:56
[11/17 14:37:09] d2.evaluation.evaluator INFO: Inference done 2087/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:51
[11/17 14:37:14] d2.evaluation.evaluator INFO: Inference done 2210/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:46
[11/17 14:37:19] d2.evaluation.evaluator INFO: Inference done 2329/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:41
[11/17 14:37:24] d2.evaluation.evaluator INFO: Inference done 2445/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:36
[11/17 14:37:29] d2.evaluation.evaluator INFO: Inference done 2564/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/17 14:37:34] d2.evaluation.evaluator INFO: Inference done 2686/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/17 14:37:39] d2.evaluation.evaluator INFO: Inference done 2809/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/17 14:37:45] d2.evaluation.evaluator INFO: Inference done 2931/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/17 14:37:50] d2.evaluation.evaluator INFO: Inference done 3053/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/17 14:37:55] d2.evaluation.evaluator INFO: Inference done 3172/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/17 14:38:00] d2.evaluation.evaluator INFO: Inference done 3287/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:00:01
[11/17 14:38:02] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.930080 (0.041433 s / iter per device, on 6 devices)
[11/17 14:38:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039568 s / iter per device, on 6 devices)
[11/17 14:38:05] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 14:38:05] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 14:38:06] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 14:38:07] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 14:38:33] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 25.74 seconds.
[11/17 14:38:33] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 14:38:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.26 seconds.
[11/17 14:38:36] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.189 | 15.665 | 5.474  | 1.001 | 3.313 | 8.663 |
[11/17 14:38:36] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.655  | person      | 6.852  | bird                  | 22.988 |
| red panda            | 10.257 | dog         | 41.860 | snake                 | 7.411  |
| car                  | 27.481 | seal        | 2.008  | helmet                | 9.268  |
| motorcycle           | 12.556 | swine       | 5.320  | stove                 | 10.639 |
| monkey               | 6.160  | watercraft  | 19.184 | chair                 | 3.998  |
| domestic cat         | 6.950  | harp        | 5.014  | antelope              | 14.445 |
| camel                | 1.471  | koala bear  | 10.051 | bus                   | 21.294 |
| hat with a wide brim | 3.094  | ski         | 1.346  | piano                 | 9.875  |
| frog                 | 7.215  | dumbbell    | 0.092  | lobster               | 5.117  |
| bench                | 0.759  | rabbit      | 11.260 | porcupine             | 11.083 |
| butterfly            | 22.824 | guitar      | 4.463  | microphone            | 0.128  |
| tape player          | 8.239  | bear        | 9.122  | hippopotamus          | 0.972  |
| bowl                 | 8.175  | axe         | 3.978  | skunk                 | 3.733  |
| airplane             | 15.640 | otter       | 1.541  | table                 | 5.935  |
| coffee maker         | 15.994 | tie         | 0.823  | turtle                | 4.847  |
| purse                | 3.612  | dragonfly   | 5.069  | lemon                 | 12.326 |
| lizard               | 4.980  | backpack    | 7.838  | tv or monitor         | 11.481 |
| cup or mug           | 4.683  | sheep       | 4.015  | ray                   | 1.574  |
| fox                  | 4.047  | whale       | 9.361  | salt or pepper shaker | 0.494  |
| computer keyboard    | 3.211  | fig         | 1.121  | bathing cap           | 3.648  |
| bookshelf            | 12.509 | ladybug     | 23.541 | crutch                | 0.051  |
| pretzel              | 4.137  | sunglasses  | 0.417  | starfish              | 8.544  |
| croquet ball         | 7.965  | lamp        | 2.711  | apple                 | 12.111 |
| cream                | 6.597  | artichoke   | 11.281 | train                 | 10.744 |
| elephant             | 13.270 | bell pepper | 6.387  | miniskirt             | 2.665  |
| orange               | 9.498  | tiger       | 4.099  | sofa                  | 2.517  |
| horse                | 5.840  | violin      | 1.477  | traffic light         | 3.127  |
| drum                 | 1.545  | strawberry  | 6.008  | laptop                | 5.187  |
| pomegranate          | 2.596  | cucumber    | 0.418  | bicycle               | 6.398  |
| banana               | 1.017  | baby bed    | 12.304 | jellyfish             | 6.620  |
| pitcher              | 1.460  | bagel       | 3.944  | beaker                | 5.695  |
| goldfish             | 1.329  | nail        | 0.096  | mushroom              | 3.666  |
| flower pot           | 0.819  | cattle      | 1.266  | zebra                 | 18.551 |
| wine bottle          | 2.922  |             |        |                       |        |
[11/17 14:38:38] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 14:38:38] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 14:38:38] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 14:38:38] d2.evaluation.testing INFO: copypaste: 7.1891,15.6650,5.4739,1.0005,3.3131,8.6628
[11/17 14:38:38] d2.utils.events INFO:  eta: 13:24:44  iter: 39999  total_loss: 0.2314  loss_cls: 0.116  loss_box_reg: 0.08177  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.01824  time: 0.6817  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 14:38:52] d2.utils.events INFO:  eta: 13:24:38  iter: 40019  total_loss: 0.2228  loss_cls: 0.1152  loss_box_reg: 0.08168  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01535  time: 0.6817  data_time: 0.0645  lr: 0.004  max_mem: 11814M
[11/17 14:39:05] d2.utils.events INFO:  eta: 13:24:17  iter: 40039  total_loss: 0.2411  loss_cls: 0.1241  loss_box_reg: 0.08464  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.01609  time: 0.6816  data_time: 0.0606  lr: 0.004  max_mem: 11814M
[11/17 14:39:19] d2.utils.events INFO:  eta: 13:24:04  iter: 40059  total_loss: 0.2347  loss_cls: 0.1202  loss_box_reg: 0.08482  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.01631  time: 0.6816  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 14:39:32] d2.utils.events INFO:  eta: 13:23:35  iter: 40079  total_loss: 0.2464  loss_cls: 0.1255  loss_box_reg: 0.08945  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.0154  time: 0.6816  data_time: 0.0677  lr: 0.004  max_mem: 11814M
[11/17 14:39:46] d2.utils.events INFO:  eta: 13:23:39  iter: 40099  total_loss: 0.2468  loss_cls: 0.1265  loss_box_reg: 0.08905  loss_rpn_cls: 0.01413  loss_rpn_loc: 0.01657  time: 0.6817  data_time: 0.0716  lr: 0.004  max_mem: 11814M
[11/17 14:39:59] d2.utils.events INFO:  eta: 13:22:47  iter: 40119  total_loss: 0.2218  loss_cls: 0.1113  loss_box_reg: 0.07947  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.01639  time: 0.6816  data_time: 0.0638  lr: 0.004  max_mem: 11814M
[11/17 14:40:13] d2.utils.events INFO:  eta: 13:22:21  iter: 40139  total_loss: 0.2362  loss_cls: 0.1219  loss_box_reg: 0.08574  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.01639  time: 0.6816  data_time: 0.0613  lr: 0.004  max_mem: 11814M
[11/17 14:40:27] d2.utils.events INFO:  eta: 13:22:05  iter: 40159  total_loss: 0.232  loss_cls: 0.1208  loss_box_reg: 0.08365  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.01788  time: 0.6816  data_time: 0.0690  lr: 0.004  max_mem: 11814M
[11/17 14:40:40] d2.utils.events INFO:  eta: 13:22:01  iter: 40179  total_loss: 0.2402  loss_cls: 0.1216  loss_box_reg: 0.08593  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.01675  time: 0.6816  data_time: 0.0701  lr: 0.004  max_mem: 11814M
[11/17 14:40:54] d2.utils.events INFO:  eta: 13:22:00  iter: 40199  total_loss: 0.2332  loss_cls: 0.1202  loss_box_reg: 0.08748  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.01818  time: 0.6816  data_time: 0.0679  lr: 0.004  max_mem: 11814M
[11/17 14:41:08] d2.utils.events INFO:  eta: 13:21:57  iter: 40219  total_loss: 0.2466  loss_cls: 0.1277  loss_box_reg: 0.08653  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.01653  time: 0.6817  data_time: 0.0784  lr: 0.004  max_mem: 11814M
[11/17 14:41:22] d2.utils.events INFO:  eta: 13:22:02  iter: 40239  total_loss: 0.2344  loss_cls: 0.1193  loss_box_reg: 0.08355  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.01762  time: 0.6817  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 14:41:35] d2.utils.events INFO:  eta: 13:21:57  iter: 40259  total_loss: 0.2396  loss_cls: 0.1261  loss_box_reg: 0.08508  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01689  time: 0.6817  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 14:41:49] d2.utils.events INFO:  eta: 13:21:43  iter: 40279  total_loss: 0.2442  loss_cls: 0.1282  loss_box_reg: 0.08992  loss_rpn_cls: 0.01112  loss_rpn_loc: 0.01821  time: 0.6817  data_time: 0.0632  lr: 0.004  max_mem: 11814M
[11/17 14:42:02] d2.utils.events INFO:  eta: 13:21:31  iter: 40299  total_loss: 0.243  loss_cls: 0.1199  loss_box_reg: 0.08433  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.01786  time: 0.6817  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 14:42:16] d2.utils.events INFO:  eta: 13:20:57  iter: 40319  total_loss: 0.2488  loss_cls: 0.1298  loss_box_reg: 0.09218  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.0171  time: 0.6816  data_time: 0.0687  lr: 0.004  max_mem: 11814M
[11/17 14:42:29] d2.utils.events INFO:  eta: 13:20:35  iter: 40339  total_loss: 0.2268  loss_cls: 0.1152  loss_box_reg: 0.08004  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01726  time: 0.6816  data_time: 0.0617  lr: 0.004  max_mem: 11814M
[11/17 14:42:43] d2.utils.events INFO:  eta: 13:19:52  iter: 40359  total_loss: 0.2368  loss_cls: 0.123  loss_box_reg: 0.08368  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.01748  time: 0.6816  data_time: 0.0626  lr: 0.004  max_mem: 11814M
[11/17 14:42:56] d2.utils.events INFO:  eta: 13:19:50  iter: 40379  total_loss: 0.2416  loss_cls: 0.1256  loss_box_reg: 0.0852  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.0157  time: 0.6816  data_time: 0.0740  lr: 0.004  max_mem: 11814M
[11/17 14:43:10] d2.utils.events INFO:  eta: 13:19:18  iter: 40399  total_loss: 0.2465  loss_cls: 0.1244  loss_box_reg: 0.08758  loss_rpn_cls: 0.0122  loss_rpn_loc: 0.01739  time: 0.6816  data_time: 0.0660  lr: 0.004  max_mem: 11814M
[11/17 14:43:24] d2.utils.events INFO:  eta: 13:18:52  iter: 40419  total_loss: 0.2407  loss_cls: 0.125  loss_box_reg: 0.08338  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01653  time: 0.6816  data_time: 0.0657  lr: 0.004  max_mem: 11814M
[11/17 14:43:37] d2.utils.events INFO:  eta: 13:18:43  iter: 40439  total_loss: 0.2286  loss_cls: 0.1179  loss_box_reg: 0.08113  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.01598  time: 0.6816  data_time: 0.0699  lr: 0.004  max_mem: 11814M
[11/17 14:43:51] d2.utils.events INFO:  eta: 13:19:17  iter: 40459  total_loss: 0.2269  loss_cls: 0.1156  loss_box_reg: 0.083  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.01671  time: 0.6816  data_time: 0.0670  lr: 0.004  max_mem: 11814M
[11/17 14:44:05] d2.utils.events INFO:  eta: 13:19:29  iter: 40479  total_loss: 0.2335  loss_cls: 0.1203  loss_box_reg: 0.08348  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01539  time: 0.6816  data_time: 0.0700  lr: 0.004  max_mem: 11814M
[11/17 14:44:19] d2.utils.events INFO:  eta: 13:18:46  iter: 40499  total_loss: 0.2335  loss_cls: 0.1186  loss_box_reg: 0.08419  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.01803  time: 0.6816  data_time: 0.0746  lr: 0.004  max_mem: 11814M
[11/17 14:44:32] d2.utils.events INFO:  eta: 13:18:41  iter: 40519  total_loss: 0.2359  loss_cls: 0.1207  loss_box_reg: 0.08823  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.01701  time: 0.6816  data_time: 0.0682  lr: 0.004  max_mem: 11814M
[11/17 14:44:46] d2.utils.events INFO:  eta: 13:17:43  iter: 40539  total_loss: 0.234  loss_cls: 0.1231  loss_box_reg: 0.08373  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.01709  time: 0.6816  data_time: 0.0672  lr: 0.004  max_mem: 11814M
[11/17 14:44:59] d2.utils.events INFO:  eta: 13:17:37  iter: 40559  total_loss: 0.2385  loss_cls: 0.1218  loss_box_reg: 0.08602  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.01625  time: 0.6816  data_time: 0.0696  lr: 0.004  max_mem: 11814M
[11/17 14:45:13] d2.utils.events INFO:  eta: 13:17:44  iter: 40579  total_loss: 0.2173  loss_cls: 0.1149  loss_box_reg: 0.07904  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.01562  time: 0.6816  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 14:45:26] d2.utils.events INFO:  eta: 13:17:19  iter: 40599  total_loss: 0.2396  loss_cls: 0.124  loss_box_reg: 0.08541  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01714  time: 0.6816  data_time: 0.0758  lr: 0.004  max_mem: 11814M
[11/17 14:45:40] d2.utils.events INFO:  eta: 13:17:33  iter: 40619  total_loss: 0.2302  loss_cls: 0.1232  loss_box_reg: 0.08803  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.01722  time: 0.6816  data_time: 0.0614  lr: 0.004  max_mem: 11814M
[11/17 14:45:54] d2.utils.events INFO:  eta: 13:17:19  iter: 40639  total_loss: 0.2454  loss_cls: 0.128  loss_box_reg: 0.08734  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01738  time: 0.6816  data_time: 0.0755  lr: 0.004  max_mem: 11814M
[11/17 14:46:07] d2.utils.events INFO:  eta: 13:16:49  iter: 40659  total_loss: 0.2306  loss_cls: 0.1179  loss_box_reg: 0.08258  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.01759  time: 0.6816  data_time: 0.0735  lr: 0.004  max_mem: 11814M
[11/17 14:46:21] d2.utils.events INFO:  eta: 13:16:27  iter: 40679  total_loss: 0.2268  loss_cls: 0.1161  loss_box_reg: 0.08183  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.01634  time: 0.6816  data_time: 0.0731  lr: 0.004  max_mem: 11814M
[11/17 14:46:35] d2.utils.events INFO:  eta: 13:16:39  iter: 40699  total_loss: 0.23  loss_cls: 0.1171  loss_box_reg: 0.0834  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.01607  time: 0.6816  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 14:46:48] d2.utils.events INFO:  eta: 13:16:31  iter: 40719  total_loss: 0.2296  loss_cls: 0.1169  loss_box_reg: 0.08118  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.01554  time: 0.6816  data_time: 0.0729  lr: 0.004  max_mem: 11814M
[11/17 14:47:02] d2.utils.events INFO:  eta: 13:16:34  iter: 40739  total_loss: 0.2318  loss_cls: 0.1179  loss_box_reg: 0.08418  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.01669  time: 0.6816  data_time: 0.0705  lr: 0.004  max_mem: 11814M
[11/17 14:47:15] d2.utils.events INFO:  eta: 13:16:04  iter: 40759  total_loss: 0.2399  loss_cls: 0.1223  loss_box_reg: 0.0862  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.01798  time: 0.6816  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 14:47:29] d2.utils.events INFO:  eta: 13:16:07  iter: 40779  total_loss: 0.2412  loss_cls: 0.1233  loss_box_reg: 0.08698  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.0178  time: 0.6816  data_time: 0.0691  lr: 0.004  max_mem: 11814M
[11/17 14:47:43] d2.utils.events INFO:  eta: 13:16:02  iter: 40799  total_loss: 0.2363  loss_cls: 0.1238  loss_box_reg: 0.08627  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.0152  time: 0.6816  data_time: 0.0667  lr: 0.004  max_mem: 11814M
[11/17 14:47:56] d2.utils.events INFO:  eta: 13:15:33  iter: 40819  total_loss: 0.241  loss_cls: 0.1232  loss_box_reg: 0.08678  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.01724  time: 0.6816  data_time: 0.0679  lr: 0.004  max_mem: 11814M
[11/17 14:48:10] d2.utils.events INFO:  eta: 13:14:39  iter: 40839  total_loss: 0.2224  loss_cls: 0.1167  loss_box_reg: 0.08039  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01774  time: 0.6815  data_time: 0.0620  lr: 0.004  max_mem: 11814M
[11/17 14:48:23] d2.utils.events INFO:  eta: 13:14:12  iter: 40859  total_loss: 0.2479  loss_cls: 0.1306  loss_box_reg: 0.08771  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.01796  time: 0.6815  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 14:48:37] d2.utils.events INFO:  eta: 13:14:07  iter: 40879  total_loss: 0.2433  loss_cls: 0.1238  loss_box_reg: 0.08674  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01715  time: 0.6815  data_time: 0.0664  lr: 0.004  max_mem: 11814M
[11/17 14:48:51] d2.utils.events INFO:  eta: 13:14:10  iter: 40899  total_loss: 0.2411  loss_cls: 0.1252  loss_box_reg: 0.08624  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.01759  time: 0.6816  data_time: 0.0680  lr: 0.004  max_mem: 11814M
[11/17 14:49:04] d2.utils.events INFO:  eta: 13:14:21  iter: 40919  total_loss: 0.23  loss_cls: 0.1212  loss_box_reg: 0.08119  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.01743  time: 0.6816  data_time: 0.0621  lr: 0.004  max_mem: 11814M
[11/17 14:49:18] d2.utils.events INFO:  eta: 13:13:18  iter: 40939  total_loss: 0.2356  loss_cls: 0.1199  loss_box_reg: 0.08256  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.01701  time: 0.6815  data_time: 0.0696  lr: 0.004  max_mem: 11814M
[11/17 14:49:32] d2.utils.events INFO:  eta: 13:13:17  iter: 40959  total_loss: 0.2329  loss_cls: 0.1213  loss_box_reg: 0.08214  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.01694  time: 0.6816  data_time: 0.0879  lr: 0.004  max_mem: 11814M
[11/17 14:49:45] d2.utils.events INFO:  eta: 13:13:16  iter: 40979  total_loss: 0.2511  loss_cls: 0.1333  loss_box_reg: 0.09277  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.01749  time: 0.6816  data_time: 0.0681  lr: 0.004  max_mem: 11814M
[11/17 14:49:59] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0040999.pth
[11/17 14:49:59] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/17 14:50:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/17 14:50:00] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/17 14:50:00] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/17 14:50:00] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/17 14:50:00] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/17 14:50:07] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0010 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:28
[11/17 14:50:12] d2.evaluation.evaluator INFO: Inference done 133/3334. Dataloading: 0.0015 s/iter. Inference: 0.0397 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:02:12
[11/17 14:50:17] d2.evaluation.evaluator INFO: Inference done 255/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:02:07
[11/17 14:50:22] d2.evaluation.evaluator INFO: Inference done 375/3334. Dataloading: 0.0015 s/iter. Inference: 0.0398 s/iter. Eval: 0.0002 s/iter. Total: 0.0415 s/iter. ETA=0:02:02
[11/17 14:50:27] d2.evaluation.evaluator INFO: Inference done 497/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0414 s/iter. ETA=0:01:57
[11/17 14:50:32] d2.evaluation.evaluator INFO: Inference done 621/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:51
[11/17 14:50:37] d2.evaluation.evaluator INFO: Inference done 742/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:46
[11/17 14:50:42] d2.evaluation.evaluator INFO: Inference done 864/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:41
[11/17 14:50:47] d2.evaluation.evaluator INFO: Inference done 985/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:36
[11/17 14:50:52] d2.evaluation.evaluator INFO: Inference done 1107/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:31
[11/17 14:50:57] d2.evaluation.evaluator INFO: Inference done 1229/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:26
[11/17 14:51:03] d2.evaluation.evaluator INFO: Inference done 1352/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:21
[11/17 14:51:08] d2.evaluation.evaluator INFO: Inference done 1473/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:16
[11/17 14:51:13] d2.evaluation.evaluator INFO: Inference done 1595/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:11
[11/17 14:51:18] d2.evaluation.evaluator INFO: Inference done 1716/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:01:06
[11/17 14:51:23] d2.evaluation.evaluator INFO: Inference done 1839/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:01:01
[11/17 14:51:28] d2.evaluation.evaluator INFO: Inference done 1961/3334. Dataloading: 0.0015 s/iter. Inference: 0.0394 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:56
[11/17 14:51:33] d2.evaluation.evaluator INFO: Inference done 2082/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:51
[11/17 14:51:38] d2.evaluation.evaluator INFO: Inference done 2203/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0412 s/iter. ETA=0:00:46
[11/17 14:51:43] d2.evaluation.evaluator INFO: Inference done 2321/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:41
[11/17 14:51:48] d2.evaluation.evaluator INFO: Inference done 2440/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:36
[11/17 14:51:53] d2.evaluation.evaluator INFO: Inference done 2561/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:31
[11/17 14:51:58] d2.evaluation.evaluator INFO: Inference done 2683/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:26
[11/17 14:52:03] d2.evaluation.evaluator INFO: Inference done 2806/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:21
[11/17 14:52:08] d2.evaluation.evaluator INFO: Inference done 2927/3334. Dataloading: 0.0015 s/iter. Inference: 0.0396 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:16
[11/17 14:52:13] d2.evaluation.evaluator INFO: Inference done 3051/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:11
[11/17 14:52:18] d2.evaluation.evaluator INFO: Inference done 3174/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:06
[11/17 14:52:23] d2.evaluation.evaluator INFO: Inference done 3294/3334. Dataloading: 0.0015 s/iter. Inference: 0.0395 s/iter. Eval: 0.0002 s/iter. Total: 0.0413 s/iter. ETA=0:00:01
[11/17 14:52:25] d2.evaluation.evaluator INFO: Total inference time: 0:02:17.913704 (0.041428 s / iter per device, on 6 devices)
[11/17 14:52:25] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:11 (0.039518 s / iter per device, on 6 devices)
[11/17 14:52:28] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/17 14:52:28] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/17 14:52:30] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/17 14:52:30] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/17 14:52:54] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.23 seconds.
[11/17 14:52:54] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/17 14:52:56] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 2.34 seconds.
[11/17 14:52:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox:
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 7.301 | 15.687 | 5.762  | 0.888 | 3.466 | 9.027 |
[11/17 14:52:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP:
| category             | AP     | category    | AP     | category              | AP     |
|:---------------------|:-------|:------------|:-------|:----------------------|:-------|
| cart                 | 8.414  | person      | 6.686  | bird                  | 23.422 |
| red panda            | 15.591 | dog         | 41.271 | snake                 | 7.562  |
| car                  | 29.084 | seal        | 1.843  | helmet                | 9.454  |
| motorcycle           | 11.052 | swine       | 6.106  | stove                 | 9.060  |
| monkey               | 8.336  | watercraft  | 20.185 | chair                 | 4.212  |
| domestic cat         | 6.486  | harp        | 4.131  | antelope              | 16.968 |
| camel                | 3.635  | koala bear  | 8.115  | bus                   | 22.483 |
| hat with a wide brim | 3.168  | ski         | 1.598  | piano                 | 10.801 |
| frog                 | 7.704  | dumbbell    | 0.088  | lobster               | 4.712  |
| bench                | 0.898  | rabbit      | 10.363 | porcupine             | 10.921 |
| butterfly            | 22.500 | guitar      | 5.137  | microphone            | 0.056  |
| tape player          | 7.675  | bear        | 9.337  | hippopotamus          | 0.558  |
| bowl                 | 8.720  | axe         | 4.402  | skunk                 | 2.518  |
| airplane             | 16.314 | otter       | 2.036  | table                 | 6.051  |
| coffee maker         | 16.729 | tie         | 0.660  | turtle                | 5.778  |
| purse                | 4.072  | dragonfly   | 5.129  | lemon                 | 7.767  |
| lizard               | 4.813  | backpack    | 6.618  | tv or monitor         | 10.452 |
| cup or mug           | 5.360  | sheep       | 6.116  | ray                   | 1.525  |
| fox                  | 7.041  | whale       | 8.091  | salt or pepper shaker | 0.447  |
| computer keyboard    | 2.048  | fig         | 3.145  | bathing cap           | 3.523  |
| bookshelf            | 10.530 | ladybug     | 21.722 | crutch                | 0.047  |
| pretzel              | 3.499  | sunglasses  | 0.862  | starfish              | 9.602  |
| croquet ball         | 6.460  | lamp        | 2.797  | apple                 | 10.711 |
| cream                | 7.985  | artichoke   | 9.291  | train                 | 11.361 |
| elephant             | 13.521 | bell pepper | 4.905  | miniskirt             | 0.770  |
| orange               | 11.491 | tiger       | 7.727  | sofa                  | 2.304  |
| horse                | 5.485  | violin      | 1.831  | traffic light         | 2.738  |
| drum                 | 0.526  | strawberry  | 6.896  | laptop                | 7.734  |
| pomegranate          | 3.374  | cucumber    | 0.194  | bicycle               | 4.207  |
| banana               | 0.773  | baby bed    | 12.384 | jellyfish             | 2.993  |
| pitcher              | 2.348  | bagel       | 5.592  | beaker                | 6.200  |
| goldfish             | 3.202  | nail        | 0.419  | mushroom              | 2.764  |
| flower pot           | 0.587  | cattle      | 1.755  | zebra                 | 20.967 |
| wine bottle          | 2.604  |             |        |                       |        |
[11/17 14:52:59] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/17 14:52:59] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/17 14:52:59] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/17 14:52:59] d2.evaluation.testing INFO: copypaste: 7.3013,15.6868,5.7619,0.8877,3.4656,9.0269
[11/17 14:52:59] d2.utils.events INFO:  eta: 13:13:14  iter: 40999  total_loss: 0.2416  loss_cls: 0.1279  loss_box_reg: 0.08571  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.01738  time: 0.6816  data_time: 0.0676  lr: 0.004  max_mem: 11814M
[11/17 14:53:12] d2.utils.events INFO:  eta: 13:12:34  iter: 41019  total_loss: 0.2179  loss_cls: 0.1135  loss_box_reg: 0.07987  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.01792  time: 0.6816  data_time: 0.0632  lr: 0.004  max_mem: 11814M
[11/17 14:53:26] d2.utils.events INFO:  eta: 13:12:34  iter: 41039  total_loss: 0.2298  loss_cls: 0.1152  loss_box_reg: 0.08065  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.01645  time: 0.6816  data_time: 0.0669  lr: 0.004  max_mem: 11814M
[11/17 14:53:39] d2.utils.events INFO:  eta: 13:11:50  iter: 41059  total_loss: 0.2408  loss_cls: 0.1222  loss_box_reg: 0.08523  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.01718  time: 0.6815  data_time: 0.0726  lr: 0.004  max_mem: 11814M
[11/17 14:53:53] d2.utils.events INFO:  eta: 13:11:38  iter: 41079  total_loss: 0.2365  loss_cls: 0.1236  loss_box_reg: 0.08438  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.01702  time: 0.6815  data_time: 0.0634  lr: 0.004  max_mem: 11814M
[11/17 14:54:06] d2.utils.events INFO:  eta: 13:11:03  iter: 41099  total_loss: 0.2239  loss_cls: 0.1135  loss_box_reg: 0.08133  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01706  time: 0.6815  data_time: 0.0647  lr: 0.004  max_mem: 11814M
[11/17 14:54:20] d2.utils.events INFO:  eta: 13:10:51  iter: 41119  total_loss: 0.239  loss_cls: 0.1239  loss_box_reg: 0.08175  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.01704  time: 0.6815  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 14:54:33] d2.utils.events INFO:  eta: 13:10:36  iter: 41139  total_loss: 0.2431  loss_cls: 0.1246  loss_box_reg: 0.08481  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.01634  time: 0.6815  data_time: 0.0661  lr: 0.004  max_mem: 11814M
[11/17 14:54:47] d2.utils.events INFO:  eta: 13:10:24  iter: 41159  total_loss: 0.2485  loss_cls: 0.1273  loss_box_reg: 0.09155  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.01666  time: 0.6815  data_time: 0.0771  lr: 0.004  max_mem: 11814M
[11/17 14:55:01] d2.utils.events INFO:  eta: 13:10:04  iter: 41179  total_loss: 0.2338  loss_cls: 0.1234  loss_box_reg: 0.08445  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.01591  time: 0.6815  data_time: 0.0666  lr: 0.004  max_mem: 11814M
[11/17 14:55:14] d2.utils.events INFO:  eta: 13:09:47  iter: 41199  total_loss: 0.2423  loss_cls: 0.1264  loss_box_reg: 0.08587  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.01629  time: 0.6815  data_time: 0.0658  lr: 0.004  max_mem: 11814M
[11/17 14:55:28] d2.utils.events INFO:  eta: 13:09:23  iter: 41219  total_loss: 0.2398  loss_cls: 0.1231  loss_box_reg: 0.08734  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.01839  time: 0.6815  data_time: 0.0650  lr: 0.004  max_mem: 11814M
[11/17 14:55:41] d2.utils.events INFO:  eta: 13:09:18  iter: 41239  total_loss: 0.2336  loss_cls: 0.1208  loss_box_reg: 0.08384  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.01716  time: 0.6815  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 14:55:55] d2.utils.events INFO:  eta: 13:09:05  iter: 41259  total_loss: 0.2336  loss_cls: 0.1204  loss_box_reg: 0.08649  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.01684  time: 0.6815  data_time: 0.0655  lr: 0.004  max_mem: 11814M
[11/17 14:56:09] d2.utils.events INFO:  eta: 13:08:36  iter: 41279  total_loss: 0.234  loss_cls: 0.1224  loss_box_reg: 0.08464  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.01609  time: 0.6815  data_time: 0.0679  lr: 0.004  max_mem: 11814M
[11/17 14:56:22] d2.utils.events INFO:  eta: 13:08:17  iter: 41299  total_loss: 0.242  loss_cls: 0.1222  loss_box_reg: 0.08655  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.01597  time: 0.6815  data_time: 0.0621  lr: 0.004  max_mem: 11814M
[11/17 14:56:36] d2.utils.events INFO:  eta: 13:08:20  iter: 41319  total_loss: 0.2415  loss_cls: 0.1243  loss_box_reg: 0.08723  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.01769  time: 0.6815  data_time: 0.0643  lr: 0.004  max_mem: 11814M
[11/17 14:56:50] d2.utils.events INFO:  eta: 13:08:15  iter: 41339  total_loss: 0.2367  loss_cls: 0.1254  loss_box_reg: 0.08736  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.01751  time: 0.6815  data_time: 0.0644  lr: 0.004  max_mem: 11814M
[11/17 14:57:03] d2.utils.events INFO:  eta: 13:08:11  iter: 41359  total_loss: 0.2412  loss_cls: 0.121  loss_box_reg: 0.0889  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01753  time: 0.6815  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 14:57:17] d2.utils.events INFO:  eta: 13:08:06  iter: 41379  total_loss: 0.2324  loss_cls: 0.117  loss_box_reg: 0.08687  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.01619  time: 0.6815  data_time: 0.0640  lr: 0.004  max_mem: 11814M
[11/17 14:57:30] d2.utils.events INFO:  eta: 13:07:42  iter: 41399  total_loss: 0.2304  loss_cls: 0.1204  loss_box_reg: 0.08189  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.01723  time: 0.6815  data_time: 0.0614  lr: 0.004  max_mem: 11814M
[11/17 14:57:44] d2.utils.events INFO:  eta: 13:07:24  iter: 41419  total_loss: 0.2301  loss_cls: 0.1181  loss_box_reg: 0.08276  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01681  time: 0.6815  data_time: 0.0637  lr: 0.004  max_mem: 11814M
[11/17 14:57:57] d2.utils.events INFO:  eta: 13:06:51  iter: 41439  total_loss: 0.2326  loss_cls: 0.1189  loss_box_reg: 0.08008  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.01647  time: 0.6815  data_time: 0.0627  lr: 0.004  max_mem: 11814M
[11/17 14:58:11] d2.utils.events INFO:  eta: 13:06:40  iter: 41459  total_loss: 0.2469  loss_cls: 0.1231  loss_box_reg: 0.08817  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.0163  time: 0.6815  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 14:58:25] d2.utils.events INFO:  eta: 13:05:59  iter: 41479  total_loss: 0.2312  loss_cls: 0.1142  loss_box_reg: 0.08349  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.01765  time: 0.6815  data_time: 0.0732  lr: 0.004  max_mem: 11814M
[11/17 14:58:38] d2.utils.events INFO:  eta: 13:05:41  iter: 41499  total_loss: 0.2345  loss_cls: 0.1184  loss_box_reg: 0.08318  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.01646  time: 0.6815  data_time: 0.0745  lr: 0.004  max_mem: 11814M
[11/17 14:58:52] d2.utils.events INFO:  eta: 13:06:04  iter: 41519  total_loss: 0.228  loss_cls: 0.1182  loss_box_reg: 0.08164  loss_rpn_cls: 0.012  loss_rpn_loc: 0.016  time: 0.6815  data_time: 0.0651  lr: 0.004  max_mem: 11814M
[11/17 14:59:06] d2.utils.events INFO:  eta: 13:06:13  iter: 41539  total_loss: 0.2458  loss_cls: 0.1249  loss_box_reg: 0.08788  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.01909  time: 0.6815  data_time: 0.0692  lr: 0.004  max_mem: 11814M
[11/17 14:59:20] d2.utils.events INFO:  eta: 13:06:07  iter: 41559  total_loss: 0.2359  loss_cls: 0.1207  loss_box_reg: 0.08283  loss_rpn_cls: 0.01206  loss_rpn_loc: 0.01652  time: 0.6815  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 14:59:33] d2.utils.events INFO:  eta: 13:06:07  iter: 41579  total_loss: 0.222  loss_cls: 0.1142  loss_box_reg: 0.08061  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.01558  time: 0.6815  data_time: 0.0653  lr: 0.004  max_mem: 11814M
[11/17 14:59:47] d2.utils.events INFO:  eta: 13:06:30  iter: 41599  total_loss: 0.2325  loss_cls: 0.119  loss_box_reg: 0.08383  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.01701  time: 0.6815  data_time: 0.0668  lr: 0.004  max_mem: 11814M
[11/17 15:00:01] d2.utils.events INFO:  eta: 13:06:20  iter: 41619  total_loss: 0.2404  loss_cls: 0.1208  loss_box_reg: 0.08793  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.01819  time: 0.6815  data_time: 0.0642  lr: 0.004  max_mem: 11814M
[11/17 15:00:14] d2.utils.events INFO:  eta: 13:06:04  iter: 41639  total_loss: 0.2332  loss_cls: 0.1191  loss_box_reg: 0.08195  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.01784  time: 0.6815  data_time: 0.0621  lr: 0.004  max_mem: 11814M
[11/17 15:00:28] d2.utils.events INFO:  eta: 13:06:03  iter: 41659  total_loss: 0.2289  loss_cls: 0.1189  loss_box_reg: 0.07995  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.01622  time: 0.6815  data_time: 0.0648  lr: 0.004  max_mem: 11814M
[11/17 15:00:42] d2.utils.events INFO:  eta: 13:05:54  iter: 41679  total_loss: 0.2459  loss_cls: 0.1232  loss_box_reg: 0.08695  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.01683  time: 0.6815  data_time: 0.0604  lr: 0.004  max_mem: 11814M
[11/17 15:00:55] d2.utils.events INFO:  eta: 13:05:35  iter: 41699  total_loss: 0.2294  loss_cls: 0.117  loss_box_reg: 0.08492  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.01675  time: 0.6815  data_time: 0.0629  lr: 0.004  max_mem: 11814M
[11/17 15:01:09] d2.utils.events INFO:  eta: 13:05:12  iter: 41719  total_loss: 0.2337  loss_cls: 0.1177  loss_box_reg: 0.08094  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.018  time: 0.6815  data_time: 0.0602  lr: 0.004  max_mem: 11814M
[11/17 15:01:22] d2.utils.events INFO:  eta: 13:04:54  iter: 41739  total_loss: 0.2286  loss_cls: 0.1162  loss_box_reg: 0.08133  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.01649  time: 0.6815  data_time: 0.0704  lr: 0.004  max_mem: 11814M
[11/17 15:01:36] d2.utils.events INFO:  eta: 13:04:41  iter: 41759  total_loss: 0.2366  loss_cls: 0.1228  loss_box_reg: 0.08391  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.01638  time: 0.6815  data_time: 0.0669  lr: 0.004  max_mem: 11814M
[11/17 15:01:49] d2.utils.events INFO:  eta: 13:04:10  iter: 41779  total_loss: 0.2289  loss_cls: 0.1181  loss_box_reg: 0.08627  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.01681  time: 0.6815  data_time: 0.0618  lr: 0.004  max_mem: 11814M
[11/17 15:02:03] d2.utils.events INFO:  eta: 13:03:56  iter: 41799  total_loss: 0.2471  loss_cls: 0.1249  loss_box_reg: 0.0858  loss_rpn_cls: 0.01365  loss_rpn_loc: 0.01804  time: 0.6815  data_time: 0.0656  lr: 0.004  max_mem: 11814M
[11/17 15:02:16] d2.utils.events INFO:  eta: 13:03:59  iter: 41819  total_loss: 0.2377  loss_cls: 0.1203  loss_box_reg: 0.08533  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01812  time: 0.6815  data_time: 0.0657  lr: 0.004  max_mem: 11814M
[11/17 15:02:30] d2.utils.events INFO:  eta: 13:03:47  iter: 41839  total_loss: 0.2337  loss_cls: 0.1188  loss_box_reg: 0.0864  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.01725  time: 0.6814  data_time: 0.0590  lr: 0.004  max_mem: 11814M
[11/17 15:02:44] d2.utils.events INFO:  eta: 13:03:33  iter: 41859  total_loss: 0.2379  loss_cls: 0.1196  loss_box_reg: 0.08895  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01748  time: 0.6814  data_time: 0.0649  lr: 0.004  max_mem: 11814M
[11/17 15:02:57] d2.utils.events INFO:  eta: 13:03:19  iter: 41879  total_loss: 0.235  loss_cls: 0.1234  loss_box_reg: 0.087  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.01601  time: 0.6814  data_time: 0.0671  lr: 0.004  max_mem: 11814M
[11/17 15:03:11] d2.utils.events INFO:  eta: 13:03:08  iter: 41899  total_loss: 0.2572  loss_cls: 0.1328  loss_box_reg: 0.09248  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.01708  time: 0.6815  data_time: 0.0720  lr: 0.004  max_mem: 11814M
[11/17 15:03:25] d2.utils.events INFO:  eta: 13:02:59  iter: 41919  total_loss: 0.2499  loss_cls: 0.1296  loss_box_reg: 0.08747  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.01601  time: 0.6815  data_time: 0.0757  lr: 0.004  max_mem: 11814M
[11/17 15:03:39] d2.utils.events INFO:  eta: 13:03:00  iter: 41939  total_loss: 0.2345  loss_cls: 0.1174  loss_box_reg: 0.08232  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01744  time: 0.6815  data_time: 0.0734  lr: 0.004  max_mem: 11814M
[11/17 15:03:52] d2.utils.events INFO:  eta: 13:02:38  iter: 41959  total_loss: 0.235  loss_cls: 0.1208  loss_box_reg: 0.0825  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.0175  time: 0.6815  data_time: 0.0665  lr: 0.004  max_mem: 11814M
[11/17 15:04:06] d2.utils.events INFO:  eta: 13:02:27  iter: 41979  total_loss: 0.2258  loss_cls: 0.1147  loss_box_reg: 0.08273  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.0174  time: 0.6815  data_time: 0.0645  lr: 0.004  max_mem: 11814M
[11/17 15:04:20] d2.utils.events INFO:  eta: 13:02:11  iter: 41999  total_loss: 0.2228  loss_cls: 0.1157  loss_box_reg: 0.08061  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.01699  time: 0.6815  data_time: 0.0751  lr: 0.004  max_mem: 11814M
