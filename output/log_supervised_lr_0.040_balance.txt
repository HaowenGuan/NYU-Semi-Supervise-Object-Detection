[11/19 08:55:03] detectron2 INFO: Rank of current process: 0. World size: 6
[11/19 08:55:06] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.12 (main, Apr  5 2022, 06:56:58) [GCC 7.5.0]
numpy                   1.23.4
detectron2              0.6 @/data/sbcaesar/semi_object_detection/detectron2/detectron2
Compiler                GCC 8.5
CUDA compiler           CUDA 11.6
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3,4,5         NVIDIA RTX A6000 (arch=8.6)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.3.0
torchvision             0.14.0+cu116 @/data/sbcaesar/venv_detectron/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.6
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/19 08:55:06] detectron2 INFO: Command line arguments: Namespace(config_file='../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=6, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:62994', opts=[])
[11/19 08:55:06] detectron2 INFO: Contents of args.config_file=../../configs/supervised-RCNN/faster_rcnn_R_50_FPN_3x.yaml:
_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "../../output/supervised/model_lr_0.04.pth"
  # "../../output/supervised/model_lr_0.004_14999_iter.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  ROI_HEADS:
    NUM_CLASSES: 100
DATASETS:
  TRAIN: ("nyu_train",)
  TEST: ("nyu_val",)
SOLVER:
  # 3x schedule of COCO dataset is ~37 epoch
  # for NYU dataset 30000 labeled images, 1 epoch is 500 (iteration) = 30000 (images) / 60 (images / iterations)
  # Therefore, in contrast, we need 18500 iterations.
  # LR reduced at the 28 epoch and 34 epoch, end at 37 epoch.
  # 6x schedule is 37000
  STEPS: (102000, 108000)
  MAX_ITER: 111000
  IMS_PER_BATCH: 60
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.04
  # Avoid Inf/NaN error
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 1000
  WARMUP_METHOD: "linear"
TEST:
  EVAL_PERIOD: 1000
DATALOADER:
  SAMPLER_TRAIN: "RepeatFactorTrainingSampler"
  REPEAT_THRESHOLD: 8341.0
OUTPUT_DIR: "../../output/supervised"
#OUTPUT_DIR: "output/eval"
[11/19 08:55:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 8341.0
  SAMPLER_TRAIN: RepeatFactorTrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - nyu_val
  TRAIN:
  - nyu_train
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 100
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ../../output/supervised/model_lr_0.04.pth
OUTPUT_DIR: ../../output/supervised
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.04
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 1000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 60
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 111000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 102000
  - 108000
  WARMUP_FACTOR: 0.5
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 1000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[11/19 08:55:06] detectron2 INFO: Full config saved to ../../output/supervised/config.yaml
[11/19 08:55:06] d2.utils.env INFO: Using a generated random seed 9450846
[11/19 08:55:07] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=101, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)
    )
  )
)
[11/19 08:55:08] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/19 08:55:08] d2.data.datasets.coco INFO: Loaded 30000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_train.json
[11/19 08:55:08] d2.data.build INFO: Removed 0 images with no usable annotations. 30000 images left.
[11/19 08:55:09] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 283          |     bird      | 4331         | hat with a .. | 206          |
|    person     | 4657         |      dog      | 8341         |    lizard     | 640          |
|     sheep     | 196          |  wine bottle  | 154          |     bowl      | 335          |
|   airplane    | 217          | domestic cat  | 395          |      car      | 1171         |
|   porcupine   | 126          |     bear      | 361          |  tape player  | 109          |
|      ray      | 198          |    laptop     | 172          |     zebra     | 135          |
| computer ke.. | 102          |    pitcher    | 120          |   artichoke   | 180          |
| tv or monitor | 212          |     table     | 786          |     chair     | 905          |
|    helmet     | 433          | traffic light | 142          |   red panda   | 108          |
|  sunglasses   | 243          |     lamp      | 319          |    bicycle    | 187          |
|   backpack    | 148          |   mushroom    | 124          |      fox      | 292          |
|     otter     | 127          |    guitar     | 295          |  microphone   | 259          |
|  strawberry   | 232          |     stove     | 156          |    violin     | 118          |
|   bookshelf   | 106          |     sofa      | 160          |  bell pepper  | 146          |
|     bagel     | 125          |     lemon     | 170          |    orange     | 207          |
|     bench     | 150          |     piano     | 199          |  flower pot   | 189          |
|   butterfly   | 453          |     purse     | 130          |  pomegranate  | 188          |
|     train     | 178          |     drum      | 251          | hippopotamus  | 118          |
|      ski      | 109          |    ladybug    | 138          |    banana     | 244          |
|    monkey     | 1004         |      bus      | 322          |   miniskirt   | 118          |
|     camel     | 276          |     cream     | 194          |    lobster    | 253          |
|     seal      | 224          |     horse     | 265          |     cart      | 281          |
|   elephant    | 242          |     snake     | 1001         |      fig      | 133          |
|  watercraft   | 1038         |     apple     | 216          |   antelope    | 288          |
|    cattle     | 148          |     whale     | 155          | coffee maker  | 143          |
|   baby bed    | 185          |     frog      | 245          |  bathing cap  | 163          |
|    crutch     | 138          |  koala bear   | 139          |      tie      | 124          |
|   dumbbell    | 180          |     tiger     | 159          |   dragonfly   | 175          |
|   goldfish    | 228          |   cucumber    | 114          |    turtle     | 313          |
|     harp      | 152          |   jellyfish   | 184          |     swine     | 259          |
|    pretzel    | 124          |  motorcycle   | 278          |    beaker     | 115          |
|    rabbit     | 235          |     nail      | 86           |      axe      | 127          |
| salt or pep.. | 129          | croquet ball  | 135          |     skunk     | 99           |
|   starfish    | 130          |               |              |               |              |
|     total     | 41293        |               |              |               |              |[0m
[11/19 08:55:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/19 08:55:09] d2.data.build INFO: Using training sampler RepeatFactorTrainingSampler
[11/19 08:55:09] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/19 08:55:09] d2.data.common INFO: Serializing 30000 elements to byte tensors and concatenating them all ...
[11/19 08:55:09] d2.data.common INFO: Serialized dataset takes 7.45 MiB
[11/19 08:55:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ../../output/supervised/model_lr_0.04.pth ...
[11/19 08:55:10] d2.checkpoint.c2_model_loading INFO: Following weights matched with model:
| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |
|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|
| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |
| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |
| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |
| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |
| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |
| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |
| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |
| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |
| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |
| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (400,) (400,1024)                               |
| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (101,) (101,1024)                               |
[11/19 08:55:10] d2.engine.train_loop INFO: Starting training from iteration 0
[11/19 08:55:34] d2.utils.events INFO:  eta: 20:50:49  iter: 19  total_loss: 0.1562  loss_cls: 0.05295  loss_box_reg: 0.07796  loss_rpn_cls: 0.008431  loss_rpn_loc: 0.01908  time: 0.6777  data_time: 0.5136  lr: 0.02038  max_mem: 11811M
[11/19 08:55:48] d2.utils.events INFO:  eta: 20:51:37  iter: 39  total_loss: 0.1541  loss_cls: 0.05086  loss_box_reg: 0.07626  loss_rpn_cls: 0.008402  loss_rpn_loc: 0.01667  time: 0.6780  data_time: 0.0716  lr: 0.02078  max_mem: 11811M
[11/19 08:56:02] d2.utils.events INFO:  eta: 20:58:58  iter: 59  total_loss: 0.1545  loss_cls: 0.04872  loss_box_reg: 0.07925  loss_rpn_cls: 0.008442  loss_rpn_loc: 0.01663  time: 0.6796  data_time: 0.0621  lr: 0.02118  max_mem: 11811M
[11/19 08:56:15] d2.utils.events INFO:  eta: 20:52:52  iter: 79  total_loss: 0.1452  loss_cls: 0.04709  loss_box_reg: 0.07152  loss_rpn_cls: 0.007471  loss_rpn_loc: 0.01679  time: 0.6773  data_time: 0.0672  lr: 0.02158  max_mem: 11811M
[11/19 08:56:29] d2.utils.events INFO:  eta: 20:59:34  iter: 99  total_loss: 0.152  loss_cls: 0.04835  loss_box_reg: 0.07727  loss_rpn_cls: 0.007181  loss_rpn_loc: 0.0189  time: 0.6798  data_time: 0.0665  lr: 0.02198  max_mem: 11811M
[11/19 08:56:43] d2.utils.events INFO:  eta: 20:56:12  iter: 119  total_loss: 0.1483  loss_cls: 0.04592  loss_box_reg: 0.07396  loss_rpn_cls: 0.007972  loss_rpn_loc: 0.01779  time: 0.6801  data_time: 0.0678  lr: 0.02238  max_mem: 11811M
[11/19 08:56:56] d2.utils.events INFO:  eta: 20:58:04  iter: 139  total_loss: 0.1498  loss_cls: 0.04715  loss_box_reg: 0.07591  loss_rpn_cls: 0.008041  loss_rpn_loc: 0.01796  time: 0.6810  data_time: 0.0638  lr: 0.02278  max_mem: 11811M
[11/19 08:57:10] d2.utils.events INFO:  eta: 20:58:18  iter: 159  total_loss: 0.1501  loss_cls: 0.04816  loss_box_reg: 0.07543  loss_rpn_cls: 0.007796  loss_rpn_loc: 0.01782  time: 0.6812  data_time: 0.0650  lr: 0.02318  max_mem: 11811M
[11/19 08:57:23] d2.utils.events INFO:  eta: 20:58:05  iter: 179  total_loss: 0.1515  loss_cls: 0.04735  loss_box_reg: 0.07612  loss_rpn_cls: 0.008186  loss_rpn_loc: 0.01908  time: 0.6809  data_time: 0.0649  lr: 0.02358  max_mem: 11811M
[11/19 08:57:37] d2.utils.events INFO:  eta: 20:57:51  iter: 199  total_loss: 0.1425  loss_cls: 0.04524  loss_box_reg: 0.07138  loss_rpn_cls: 0.007978  loss_rpn_loc: 0.01761  time: 0.6809  data_time: 0.0663  lr: 0.02398  max_mem: 11811M
[11/19 08:57:51] d2.utils.events INFO:  eta: 20:59:29  iter: 219  total_loss: 0.1492  loss_cls: 0.04615  loss_box_reg: 0.07289  loss_rpn_cls: 0.007355  loss_rpn_loc: 0.01857  time: 0.6820  data_time: 0.0714  lr: 0.02438  max_mem: 11811M
[11/19 08:58:05] d2.utils.events INFO:  eta: 21:00:07  iter: 239  total_loss: 0.1442  loss_cls: 0.04473  loss_box_reg: 0.07309  loss_rpn_cls: 0.008112  loss_rpn_loc: 0.01861  time: 0.6824  data_time: 0.0718  lr: 0.02478  max_mem: 11811M
[11/19 08:58:18] d2.utils.events INFO:  eta: 21:00:48  iter: 259  total_loss: 0.1419  loss_cls: 0.04515  loss_box_reg: 0.07138  loss_rpn_cls: 0.006868  loss_rpn_loc: 0.01774  time: 0.6828  data_time: 0.0776  lr: 0.02518  max_mem: 11811M
[11/19 08:58:32] d2.utils.events INFO:  eta: 20:59:40  iter: 279  total_loss: 0.1447  loss_cls: 0.04848  loss_box_reg: 0.07615  loss_rpn_cls: 0.0073  loss_rpn_loc: 0.01747  time: 0.6831  data_time: 0.0810  lr: 0.02558  max_mem: 11811M
[11/19 08:58:46] d2.utils.events INFO:  eta: 20:58:41  iter: 299  total_loss: 0.1491  loss_cls: 0.04661  loss_box_reg: 0.075  loss_rpn_cls: 0.007808  loss_rpn_loc: 0.01871  time: 0.6833  data_time: 0.0674  lr: 0.02598  max_mem: 11811M
[11/19 08:59:00] d2.utils.events INFO:  eta: 20:58:20  iter: 319  total_loss: 0.1461  loss_cls: 0.04608  loss_box_reg: 0.071  loss_rpn_cls: 0.008258  loss_rpn_loc: 0.01897  time: 0.6830  data_time: 0.0622  lr: 0.02638  max_mem: 11811M
[11/19 08:59:13] d2.utils.events INFO:  eta: 20:58:07  iter: 339  total_loss: 0.1479  loss_cls: 0.04471  loss_box_reg: 0.07376  loss_rpn_cls: 0.007191  loss_rpn_loc: 0.01895  time: 0.6832  data_time: 0.0708  lr: 0.02678  max_mem: 11811M
[11/19 08:59:27] d2.utils.events INFO:  eta: 20:57:49  iter: 359  total_loss: 0.1533  loss_cls: 0.04859  loss_box_reg: 0.07778  loss_rpn_cls: 0.007741  loss_rpn_loc: 0.01858  time: 0.6832  data_time: 0.0630  lr: 0.02718  max_mem: 11811M
[11/19 08:59:41] d2.utils.events INFO:  eta: 20:57:26  iter: 379  total_loss: 0.1513  loss_cls: 0.04885  loss_box_reg: 0.07251  loss_rpn_cls: 0.00846  loss_rpn_loc: 0.01842  time: 0.6830  data_time: 0.0711  lr: 0.02758  max_mem: 11811M
[11/19 08:59:54] d2.utils.events INFO:  eta: 20:57:26  iter: 399  total_loss: 0.1463  loss_cls: 0.04865  loss_box_reg: 0.07275  loss_rpn_cls: 0.007623  loss_rpn_loc: 0.01959  time: 0.6828  data_time: 0.0659  lr: 0.02798  max_mem: 11811M
[11/19 09:00:08] d2.utils.events INFO:  eta: 20:57:12  iter: 419  total_loss: 0.1459  loss_cls: 0.04603  loss_box_reg: 0.07225  loss_rpn_cls: 0.007759  loss_rpn_loc: 0.01887  time: 0.6828  data_time: 0.0676  lr: 0.02838  max_mem: 11811M
[11/19 09:00:22] d2.utils.events INFO:  eta: 20:57:14  iter: 439  total_loss: 0.1523  loss_cls: 0.04768  loss_box_reg: 0.07768  loss_rpn_cls: 0.007495  loss_rpn_loc: 0.01812  time: 0.6831  data_time: 0.0728  lr: 0.02878  max_mem: 11811M
[11/19 09:00:35] d2.utils.events INFO:  eta: 20:56:52  iter: 459  total_loss: 0.1525  loss_cls: 0.04734  loss_box_reg: 0.0769  loss_rpn_cls: 0.007594  loss_rpn_loc: 0.01858  time: 0.6829  data_time: 0.0613  lr: 0.02918  max_mem: 11811M
[11/19 09:00:49] d2.utils.events INFO:  eta: 20:56:27  iter: 479  total_loss: 0.1596  loss_cls: 0.04901  loss_box_reg: 0.08234  loss_rpn_cls: 0.009279  loss_rpn_loc: 0.01884  time: 0.6825  data_time: 0.0662  lr: 0.02958  max_mem: 11811M
[11/19 09:01:02] d2.utils.events INFO:  eta: 20:57:27  iter: 499  total_loss: 0.1462  loss_cls: 0.04697  loss_box_reg: 0.07521  loss_rpn_cls: 0.00792  loss_rpn_loc: 0.01803  time: 0.6829  data_time: 0.0619  lr: 0.02998  max_mem: 11811M
[11/19 09:01:16] d2.utils.events INFO:  eta: 20:57:36  iter: 519  total_loss: 0.1529  loss_cls: 0.0478  loss_box_reg: 0.07442  loss_rpn_cls: 0.008473  loss_rpn_loc: 0.01922  time: 0.6831  data_time: 0.0654  lr: 0.03038  max_mem: 11811M
[11/19 09:01:30] d2.utils.events INFO:  eta: 20:57:22  iter: 539  total_loss: 0.1599  loss_cls: 0.05208  loss_box_reg: 0.0783  loss_rpn_cls: 0.009377  loss_rpn_loc: 0.01916  time: 0.6833  data_time: 0.0736  lr: 0.03078  max_mem: 11811M
[11/19 09:01:44] d2.utils.events INFO:  eta: 20:57:57  iter: 559  total_loss: 0.1428  loss_cls: 0.04784  loss_box_reg: 0.07215  loss_rpn_cls: 0.006831  loss_rpn_loc: 0.01686  time: 0.6835  data_time: 0.0674  lr: 0.03118  max_mem: 11811M
[11/19 09:01:58] d2.utils.events INFO:  eta: 20:57:59  iter: 579  total_loss: 0.1437  loss_cls: 0.04672  loss_box_reg: 0.07262  loss_rpn_cls: 0.007835  loss_rpn_loc: 0.01887  time: 0.6837  data_time: 0.0647  lr: 0.03158  max_mem: 11811M
[11/19 09:02:11] d2.utils.events INFO:  eta: 20:57:38  iter: 599  total_loss: 0.1462  loss_cls: 0.04691  loss_box_reg: 0.07433  loss_rpn_cls: 0.00759  loss_rpn_loc: 0.01789  time: 0.6835  data_time: 0.0656  lr: 0.03198  max_mem: 11811M
[11/19 09:02:25] d2.utils.events INFO:  eta: 20:57:16  iter: 619  total_loss: 0.1604  loss_cls: 0.04992  loss_box_reg: 0.07907  loss_rpn_cls: 0.008367  loss_rpn_loc: 0.0191  time: 0.6836  data_time: 0.0691  lr: 0.03238  max_mem: 11811M
[11/19 09:02:38] d2.utils.events INFO:  eta: 20:56:44  iter: 639  total_loss: 0.1547  loss_cls: 0.05239  loss_box_reg: 0.07746  loss_rpn_cls: 0.007804  loss_rpn_loc: 0.01744  time: 0.6832  data_time: 0.0659  lr: 0.03278  max_mem: 11811M
[11/19 09:02:52] d2.utils.events INFO:  eta: 20:56:37  iter: 659  total_loss: 0.1479  loss_cls: 0.04918  loss_box_reg: 0.07352  loss_rpn_cls: 0.008227  loss_rpn_loc: 0.01879  time: 0.6833  data_time: 0.0618  lr: 0.03318  max_mem: 11811M
[11/19 09:03:05] d2.utils.events INFO:  eta: 20:55:31  iter: 679  total_loss: 0.151  loss_cls: 0.04891  loss_box_reg: 0.07662  loss_rpn_cls: 0.008609  loss_rpn_loc: 0.01871  time: 0.6830  data_time: 0.0623  lr: 0.03358  max_mem: 11811M
[11/19 09:03:19] d2.utils.events INFO:  eta: 20:55:28  iter: 699  total_loss: 0.1587  loss_cls: 0.0502  loss_box_reg: 0.08158  loss_rpn_cls: 0.007543  loss_rpn_loc: 0.01955  time: 0.6830  data_time: 0.0667  lr: 0.03398  max_mem: 11811M
[11/19 09:03:33] d2.utils.events INFO:  eta: 20:55:05  iter: 719  total_loss: 0.1529  loss_cls: 0.0514  loss_box_reg: 0.07632  loss_rpn_cls: 0.007552  loss_rpn_loc: 0.01858  time: 0.6834  data_time: 0.0826  lr: 0.03438  max_mem: 11811M
[11/19 09:03:47] d2.utils.events INFO:  eta: 20:54:51  iter: 739  total_loss: 0.1446  loss_cls: 0.04805  loss_box_reg: 0.07078  loss_rpn_cls: 0.007609  loss_rpn_loc: 0.01895  time: 0.6833  data_time: 0.0653  lr: 0.03478  max_mem: 11811M
[11/19 09:04:00] d2.utils.events INFO:  eta: 20:54:25  iter: 759  total_loss: 0.1549  loss_cls: 0.05088  loss_box_reg: 0.07686  loss_rpn_cls: 0.009039  loss_rpn_loc: 0.01874  time: 0.6833  data_time: 0.0676  lr: 0.03518  max_mem: 11811M
[11/19 09:04:14] d2.utils.events INFO:  eta: 20:54:12  iter: 779  total_loss: 0.1548  loss_cls: 0.05137  loss_box_reg: 0.07814  loss_rpn_cls: 0.009193  loss_rpn_loc: 0.01776  time: 0.6834  data_time: 0.0733  lr: 0.03558  max_mem: 11811M
[11/19 09:04:28] d2.utils.events INFO:  eta: 20:53:50  iter: 799  total_loss: 0.1555  loss_cls: 0.0537  loss_box_reg: 0.07659  loss_rpn_cls: 0.007833  loss_rpn_loc: 0.01732  time: 0.6832  data_time: 0.0626  lr: 0.03598  max_mem: 11811M
[11/19 09:04:41] d2.utils.events INFO:  eta: 20:53:40  iter: 819  total_loss: 0.1628  loss_cls: 0.05605  loss_box_reg: 0.08215  loss_rpn_cls: 0.008284  loss_rpn_loc: 0.01782  time: 0.6832  data_time: 0.0738  lr: 0.03638  max_mem: 11811M
[11/19 09:04:55] d2.utils.events INFO:  eta: 20:53:13  iter: 839  total_loss: 0.16  loss_cls: 0.05373  loss_box_reg: 0.07811  loss_rpn_cls: 0.008265  loss_rpn_loc: 0.01937  time: 0.6830  data_time: 0.0666  lr: 0.03678  max_mem: 11811M
[11/19 09:05:09] d2.utils.events INFO:  eta: 20:53:22  iter: 859  total_loss: 0.1517  loss_cls: 0.05293  loss_box_reg: 0.07497  loss_rpn_cls: 0.007386  loss_rpn_loc: 0.01749  time: 0.6832  data_time: 0.0677  lr: 0.03718  max_mem: 11811M
[11/19 09:05:22] d2.utils.events INFO:  eta: 20:53:00  iter: 879  total_loss: 0.1505  loss_cls: 0.04879  loss_box_reg: 0.07255  loss_rpn_cls: 0.007673  loss_rpn_loc: 0.01913  time: 0.6831  data_time: 0.0662  lr: 0.03758  max_mem: 11811M
[11/19 09:05:36] d2.utils.events INFO:  eta: 20:52:50  iter: 899  total_loss: 0.1548  loss_cls: 0.05203  loss_box_reg: 0.07399  loss_rpn_cls: 0.008897  loss_rpn_loc: 0.0204  time: 0.6830  data_time: 0.0657  lr: 0.03798  max_mem: 11811M
[11/19 09:05:50] d2.utils.events INFO:  eta: 20:52:32  iter: 919  total_loss: 0.1565  loss_cls: 0.05336  loss_box_reg: 0.07741  loss_rpn_cls: 0.008616  loss_rpn_loc: 0.0195  time: 0.6831  data_time: 0.0653  lr: 0.03838  max_mem: 11811M
[11/19 09:06:03] d2.utils.events INFO:  eta: 20:52:15  iter: 939  total_loss: 0.1646  loss_cls: 0.05653  loss_box_reg: 0.07906  loss_rpn_cls: 0.009252  loss_rpn_loc: 0.01974  time: 0.6831  data_time: 0.0710  lr: 0.03878  max_mem: 11811M
[11/19 09:06:17] d2.utils.events INFO:  eta: 20:52:09  iter: 959  total_loss: 0.1647  loss_cls: 0.05618  loss_box_reg: 0.0784  loss_rpn_cls: 0.009237  loss_rpn_loc: 0.02125  time: 0.6831  data_time: 0.0661  lr: 0.03918  max_mem: 11811M
[11/19 09:06:30] d2.utils.events INFO:  eta: 20:51:38  iter: 979  total_loss: 0.1607  loss_cls: 0.05576  loss_box_reg: 0.07511  loss_rpn_cls: 0.008171  loss_rpn_loc: 0.01879  time: 0.6828  data_time: 0.0770  lr: 0.03958  max_mem: 11811M
[11/19 09:06:44] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0000999.pth
[11/19 09:06:45] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/19 09:06:45] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/19 09:06:45] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/19 09:06:45] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/19 09:06:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/19 09:06:45] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/19 09:06:45] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/19 09:06:46] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/19 09:06:52] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0011 s/iter. Inference: 0.0355 s/iter. Eval: 0.0002 s/iter. Total: 0.0368 s/iter. ETA=0:02:02
[11/19 09:06:57] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0014 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0406 s/iter. ETA=0:02:09
[11/19 09:07:02] d2.evaluation.evaluator INFO: Inference done 259/3334. Dataloading: 0.0014 s/iter. Inference: 0.0386 s/iter. Eval: 0.0002 s/iter. Total: 0.0403 s/iter. ETA=0:02:04
[11/19 09:07:07] d2.evaluation.evaluator INFO: Inference done 382/3334. Dataloading: 0.0015 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0405 s/iter. ETA=0:01:59
[11/19 09:07:12] d2.evaluation.evaluator INFO: Inference done 501/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:55
[11/19 09:07:18] d2.evaluation.evaluator INFO: Inference done 624/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:50
[11/19 09:07:23] d2.evaluation.evaluator INFO: Inference done 744/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:46
[11/19 09:07:28] d2.evaluation.evaluator INFO: Inference done 868/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:40
[11/19 09:07:33] d2.evaluation.evaluator INFO: Inference done 993/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/19 09:07:38] d2.evaluation.evaluator INFO: Inference done 1115/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/19 09:07:43] d2.evaluation.evaluator INFO: Inference done 1238/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:25
[11/19 09:07:48] d2.evaluation.evaluator INFO: Inference done 1362/3334. Dataloading: 0.0014 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:20
[11/19 09:07:53] d2.evaluation.evaluator INFO: Inference done 1486/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:15
[11/19 09:07:58] d2.evaluation.evaluator INFO: Inference done 1607/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:10
[11/19 09:08:03] d2.evaluation.evaluator INFO: Inference done 1731/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:05
[11/19 09:08:08] d2.evaluation.evaluator INFO: Inference done 1853/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:00
[11/19 09:08:13] d2.evaluation.evaluator INFO: Inference done 1976/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:55
[11/19 09:08:18] d2.evaluation.evaluator INFO: Inference done 2098/3334. Dataloading: 0.0015 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:50
[11/19 09:08:23] d2.evaluation.evaluator INFO: Inference done 2219/3334. Dataloading: 0.0015 s/iter. Inference: 0.0392 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:00:45
[11/19 09:08:28] d2.evaluation.evaluator INFO: Inference done 2334/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:41
[11/19 09:08:33] d2.evaluation.evaluator INFO: Inference done 2452/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:36
[11/19 09:08:38] d2.evaluation.evaluator INFO: Inference done 2577/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:31
[11/19 09:08:43] d2.evaluation.evaluator INFO: Inference done 2700/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:26
[11/19 09:08:48] d2.evaluation.evaluator INFO: Inference done 2817/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:21
[11/19 09:08:53] d2.evaluation.evaluator INFO: Inference done 2941/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:16
[11/19 09:08:58] d2.evaluation.evaluator INFO: Inference done 3064/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:11
[11/19 09:09:03] d2.evaluation.evaluator INFO: Inference done 3183/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:06
[11/19 09:09:08] d2.evaluation.evaluator INFO: Inference done 3305/3334. Dataloading: 0.0015 s/iter. Inference: 0.0393 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:01
[11/19 09:09:09] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.985997 (0.041149 s / iter per device, on 6 devices)
[11/19 09:09:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:10 (0.039239 s / iter per device, on 6 devices)
[11/19 09:09:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/19 09:09:11] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/19 09:09:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/19 09:09:13] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/19 09:09:37] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 23.73 seconds.
[11/19 09:09:37] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/19 09:09:39] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.78 seconds.
[11/19 09:09:39] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 14.803 | 28.889 | 13.376 | 1.174 | 5.675 | 18.177 |
[11/19 09:09:39] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 13.086 | bird          | 39.500 | hat with a wide brim | 10.112 |
| person                | 9.675  | dog           | 51.546 | lizard               | 13.300 |
| sheep                 | 14.570 | wine bottle   | 13.029 | bowl                 | 16.039 |
| airplane              | 30.538 | domestic cat  | 15.247 | car                  | 38.494 |
| porcupine             | 20.279 | bear          | 22.994 | tape player          | 13.704 |
| ray                   | 6.135  | laptop        | 13.849 | zebra                | 31.359 |
| computer keyboard     | 18.934 | pitcher       | 14.355 | artichoke            | 28.334 |
| tv or monitor         | 15.991 | table         | 9.589  | chair                | 8.213  |
| helmet                | 15.975 | traffic light | 6.902  | red panda            | 27.780 |
| sunglasses            | 3.346  | lamp          | 4.671  | bicycle              | 11.358 |
| backpack              | 12.869 | mushroom      | 3.888  | fox                  | 16.386 |
| otter                 | 8.346  | guitar        | 9.062  | microphone           | 1.267  |
| strawberry            | 9.616  | stove         | 14.230 | violin               | 2.162  |
| bookshelf             | 15.966 | sofa          | 9.031  | bell pepper          | 15.660 |
| bagel                 | 11.207 | lemon         | 14.610 | orange               | 15.560 |
| bench                 | 2.713  | piano         | 22.662 | flower pot           | 3.204  |
| butterfly             | 36.652 | purse         | 6.782  | pomegranate          | 6.897  |
| train                 | 26.719 | drum          | 2.888  | hippopotamus         | 5.431  |
| ski                   | 2.025  | ladybug       | 24.941 | banana               | 0.579  |
| monkey                | 18.017 | bus           | 39.817 | miniskirt            | 6.258  |
| camel                 | 17.699 | cream         | 22.285 | lobster              | 11.187 |
| seal                  | 7.042  | horse         | 10.558 | cart                 | 19.296 |
| elephant              | 26.784 | snake         | 14.082 | fig                  | 4.129  |
| watercraft            | 27.955 | apple         | 18.375 | antelope             | 32.180 |
| cattle                | 6.921  | whale         | 20.025 | coffee maker         | 25.035 |
| baby bed              | 25.983 | frog          | 24.231 | bathing cap          | 8.204  |
| crutch                | 0.607  | koala bear    | 18.475 | tie                  | 5.072  |
| dumbbell              | 2.264  | tiger         | 15.806 | dragonfly            | 12.943 |
| goldfish              | 10.923 | cucumber      | 3.389  | turtle               | 21.292 |
| harp                  | 13.675 | jellyfish     | 13.976 | swine                | 12.195 |
| pretzel               | 6.222  | motorcycle    | 24.114 | beaker               | 11.255 |
| rabbit                | 29.420 | nail          | 0.430  | axe                  | 6.248  |
| salt or pepper shaker | 5.137  | croquet ball  | 12.990 | skunk                | 13.305 |
| starfish              | 14.284 |               |        |                      |        |
[11/19 09:09:41] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/19 09:09:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/19 09:09:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/19 09:09:41] d2.evaluation.testing INFO: copypaste: 14.8034,28.8891,13.3763,1.1741,5.6752,18.1768
[11/19 09:19:35] d2.utils.events INFO:  eta: 20:54:55  iter: 1019  total_loss: 0.163  loss_cls: 0.05806  loss_box_reg: 0.07878  loss_rpn_cls: 0.009506  loss_rpn_loc: 0.0198  time: 0.6953  data_time: 0.5769  lr: 0.04  max_mem: 11813M
[11/19 09:19:49] d2.utils.events INFO:  eta: 20:52:25  iter: 1039  total_loss: 0.1669  loss_cls: 0.0554  loss_box_reg: 0.0811  loss_rpn_cls: 0.009143  loss_rpn_loc: 0.01884  time: 0.6855  data_time: 0.0671  lr: 0.04  max_mem: 11813M
[11/19 09:20:03] d2.utils.events INFO:  eta: 20:49:06  iter: 1059  total_loss: 0.165  loss_cls: 0.05559  loss_box_reg: 0.08188  loss_rpn_cls: 0.008858  loss_rpn_loc: 0.01897  time: 0.6826  data_time: 0.0640  lr: 0.04  max_mem: 11813M
[11/19 09:20:16] d2.utils.events INFO:  eta: 20:51:58  iter: 1079  total_loss: 0.1599  loss_cls: 0.05596  loss_box_reg: 0.07679  loss_rpn_cls: 0.008602  loss_rpn_loc: 0.01908  time: 0.6832  data_time: 0.0642  lr: 0.04  max_mem: 11813M
[11/19 09:20:30] d2.utils.events INFO:  eta: 20:51:55  iter: 1099  total_loss: 0.1716  loss_cls: 0.05877  loss_box_reg: 0.08294  loss_rpn_cls: 0.008651  loss_rpn_loc: 0.02011  time: 0.6838  data_time: 0.0630  lr: 0.04  max_mem: 11813M
[11/19 09:20:44] d2.utils.events INFO:  eta: 20:53:44  iter: 1119  total_loss: 0.1677  loss_cls: 0.05841  loss_box_reg: 0.08314  loss_rpn_cls: 0.009231  loss_rpn_loc: 0.01911  time: 0.6850  data_time: 0.0663  lr: 0.04  max_mem: 11813M
[11/19 09:20:57] d2.utils.events INFO:  eta: 20:52:50  iter: 1139  total_loss: 0.1675  loss_cls: 0.05841  loss_box_reg: 0.07817  loss_rpn_cls: 0.008642  loss_rpn_loc: 0.01916  time: 0.6842  data_time: 0.0647  lr: 0.04  max_mem: 11813M
[11/19 09:21:11] d2.utils.events INFO:  eta: 20:53:17  iter: 1159  total_loss: 0.1617  loss_cls: 0.05622  loss_box_reg: 0.07693  loss_rpn_cls: 0.008217  loss_rpn_loc: 0.01907  time: 0.6839  data_time: 0.0674  lr: 0.04  max_mem: 11813M
[11/19 09:21:25] d2.utils.events INFO:  eta: 20:51:02  iter: 1179  total_loss: 0.172  loss_cls: 0.05741  loss_box_reg: 0.07983  loss_rpn_cls: 0.009355  loss_rpn_loc: 0.02091  time: 0.6833  data_time: 0.0743  lr: 0.04  max_mem: 11813M
[11/19 09:21:38] d2.utils.events INFO:  eta: 20:52:12  iter: 1199  total_loss: 0.1704  loss_cls: 0.05722  loss_box_reg: 0.08066  loss_rpn_cls: 0.009197  loss_rpn_loc: 0.02074  time: 0.6837  data_time: 0.0645  lr: 0.04  max_mem: 11813M
[11/19 09:21:52] d2.utils.events INFO:  eta: 20:51:59  iter: 1219  total_loss: 0.1676  loss_cls: 0.05824  loss_box_reg: 0.08084  loss_rpn_cls: 0.008809  loss_rpn_loc: 0.02019  time: 0.6835  data_time: 0.0698  lr: 0.04  max_mem: 11813M
[11/19 09:22:05] d2.utils.events INFO:  eta: 20:51:30  iter: 1239  total_loss: 0.1579  loss_cls: 0.05249  loss_box_reg: 0.07558  loss_rpn_cls: 0.008944  loss_rpn_loc: 0.01921  time: 0.6827  data_time: 0.0636  lr: 0.04  max_mem: 11813M
[11/19 09:22:19] d2.utils.events INFO:  eta: 20:51:48  iter: 1259  total_loss: 0.1695  loss_cls: 0.05817  loss_box_reg: 0.0829  loss_rpn_cls: 0.009009  loss_rpn_loc: 0.02016  time: 0.6829  data_time: 0.0640  lr: 0.04  max_mem: 11813M
[11/19 09:22:33] d2.utils.events INFO:  eta: 20:51:03  iter: 1279  total_loss: 0.1736  loss_cls: 0.05904  loss_box_reg: 0.08608  loss_rpn_cls: 0.009781  loss_rpn_loc: 0.0193  time: 0.6828  data_time: 0.0715  lr: 0.04  max_mem: 11813M
[11/19 09:22:47] d2.utils.events INFO:  eta: 20:50:49  iter: 1299  total_loss: 0.1701  loss_cls: 0.06183  loss_box_reg: 0.07821  loss_rpn_cls: 0.00892  loss_rpn_loc: 0.01916  time: 0.6830  data_time: 0.0657  lr: 0.04  max_mem: 11813M
[11/19 09:23:00] d2.utils.events INFO:  eta: 20:48:58  iter: 1319  total_loss: 0.1545  loss_cls: 0.05224  loss_box_reg: 0.07374  loss_rpn_cls: 0.009207  loss_rpn_loc: 0.01857  time: 0.6833  data_time: 0.0823  lr: 0.04  max_mem: 11813M
[11/19 09:23:14] d2.utils.events INFO:  eta: 20:49:39  iter: 1339  total_loss: 0.1611  loss_cls: 0.05552  loss_box_reg: 0.07546  loss_rpn_cls: 0.008366  loss_rpn_loc: 0.01969  time: 0.6837  data_time: 0.0711  lr: 0.04  max_mem: 11813M
[11/19 09:23:28] d2.utils.events INFO:  eta: 20:48:31  iter: 1359  total_loss: 0.1749  loss_cls: 0.06219  loss_box_reg: 0.08184  loss_rpn_cls: 0.009521  loss_rpn_loc: 0.01887  time: 0.6838  data_time: 0.0775  lr: 0.04  max_mem: 11813M
[11/19 09:23:41] d2.utils.events INFO:  eta: 20:46:44  iter: 1379  total_loss: 0.1632  loss_cls: 0.05654  loss_box_reg: 0.07829  loss_rpn_cls: 0.009966  loss_rpn_loc: 0.01878  time: 0.6831  data_time: 0.0617  lr: 0.04  max_mem: 11813M
[11/19 09:23:55] d2.utils.events INFO:  eta: 20:45:43  iter: 1399  total_loss: 0.1571  loss_cls: 0.05435  loss_box_reg: 0.07495  loss_rpn_cls: 0.008229  loss_rpn_loc: 0.02023  time: 0.6830  data_time: 0.0711  lr: 0.04  max_mem: 11813M
[11/19 09:24:09] d2.utils.events INFO:  eta: 20:46:09  iter: 1419  total_loss: 0.1513  loss_cls: 0.05387  loss_box_reg: 0.07171  loss_rpn_cls: 0.008901  loss_rpn_loc: 0.01809  time: 0.6833  data_time: 0.0706  lr: 0.04  max_mem: 11813M
[11/19 09:24:23] d2.utils.events INFO:  eta: 20:45:56  iter: 1439  total_loss: 0.1686  loss_cls: 0.05918  loss_box_reg: 0.07989  loss_rpn_cls: 0.009864  loss_rpn_loc: 0.01798  time: 0.6839  data_time: 0.0791  lr: 0.04  max_mem: 11813M
[11/19 09:24:36] d2.utils.events INFO:  eta: 20:46:22  iter: 1459  total_loss: 0.15  loss_cls: 0.05286  loss_box_reg: 0.0714  loss_rpn_cls: 0.007868  loss_rpn_loc: 0.01766  time: 0.6839  data_time: 0.0642  lr: 0.04  max_mem: 11813M
[11/19 09:24:50] d2.utils.events INFO:  eta: 20:46:08  iter: 1479  total_loss: 0.1617  loss_cls: 0.0554  loss_box_reg: 0.07664  loss_rpn_cls: 0.009351  loss_rpn_loc: 0.01994  time: 0.6839  data_time: 0.0628  lr: 0.04  max_mem: 11813M
[11/19 09:25:04] d2.utils.events INFO:  eta: 20:45:15  iter: 1499  total_loss: 0.158  loss_cls: 0.05397  loss_box_reg: 0.07502  loss_rpn_cls: 0.008276  loss_rpn_loc: 0.01991  time: 0.6837  data_time: 0.0611  lr: 0.04  max_mem: 11813M
[11/19 09:25:17] d2.utils.events INFO:  eta: 20:45:01  iter: 1519  total_loss: 0.1564  loss_cls: 0.05603  loss_box_reg: 0.07465  loss_rpn_cls: 0.008389  loss_rpn_loc: 0.01948  time: 0.6839  data_time: 0.0667  lr: 0.04  max_mem: 11813M
[11/19 09:25:31] d2.utils.events INFO:  eta: 20:44:55  iter: 1539  total_loss: 0.1672  loss_cls: 0.06137  loss_box_reg: 0.07867  loss_rpn_cls: 0.008584  loss_rpn_loc: 0.0188  time: 0.6840  data_time: 0.0662  lr: 0.04  max_mem: 11813M
[11/19 09:25:45] d2.utils.events INFO:  eta: 20:44:41  iter: 1559  total_loss: 0.1753  loss_cls: 0.06189  loss_box_reg: 0.08491  loss_rpn_cls: 0.009941  loss_rpn_loc: 0.01981  time: 0.6839  data_time: 0.0691  lr: 0.04  max_mem: 11813M
[11/19 09:25:58] d2.utils.events INFO:  eta: 20:44:36  iter: 1579  total_loss: 0.1735  loss_cls: 0.06255  loss_box_reg: 0.07853  loss_rpn_cls: 0.00928  loss_rpn_loc: 0.02059  time: 0.6839  data_time: 0.0645  lr: 0.04  max_mem: 11813M
[11/19 09:26:12] d2.utils.events INFO:  eta: 20:44:11  iter: 1599  total_loss: 0.1625  loss_cls: 0.05862  loss_box_reg: 0.07302  loss_rpn_cls: 0.008467  loss_rpn_loc: 0.01822  time: 0.6838  data_time: 0.0654  lr: 0.04  max_mem: 11813M
[11/19 09:26:26] d2.utils.events INFO:  eta: 20:44:09  iter: 1619  total_loss: 0.158  loss_cls: 0.05533  loss_box_reg: 0.07403  loss_rpn_cls: 0.008381  loss_rpn_loc: 0.01738  time: 0.6838  data_time: 0.0658  lr: 0.04  max_mem: 11813M
[11/19 09:26:39] d2.utils.events INFO:  eta: 20:43:28  iter: 1639  total_loss: 0.1621  loss_cls: 0.05785  loss_box_reg: 0.07597  loss_rpn_cls: 0.007888  loss_rpn_loc: 0.01949  time: 0.6835  data_time: 0.0679  lr: 0.04  max_mem: 11813M
[11/19 09:26:53] d2.utils.events INFO:  eta: 20:43:14  iter: 1659  total_loss: 0.1606  loss_cls: 0.05501  loss_box_reg: 0.07403  loss_rpn_cls: 0.008364  loss_rpn_loc: 0.01926  time: 0.6834  data_time: 0.0627  lr: 0.04  max_mem: 11813M
[11/19 09:27:07] d2.utils.events INFO:  eta: 20:43:10  iter: 1679  total_loss: 0.1636  loss_cls: 0.05247  loss_box_reg: 0.07716  loss_rpn_cls: 0.008502  loss_rpn_loc: 0.02029  time: 0.6835  data_time: 0.0654  lr: 0.04  max_mem: 11813M
[11/19 09:27:20] d2.utils.events INFO:  eta: 20:42:25  iter: 1699  total_loss: 0.1627  loss_cls: 0.05656  loss_box_reg: 0.07754  loss_rpn_cls: 0.008484  loss_rpn_loc: 0.01899  time: 0.6835  data_time: 0.0700  lr: 0.04  max_mem: 11813M
[11/19 09:27:34] d2.utils.events INFO:  eta: 20:42:22  iter: 1719  total_loss: 0.1785  loss_cls: 0.05837  loss_box_reg: 0.08648  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.02081  time: 0.6834  data_time: 0.0674  lr: 0.04  max_mem: 11813M
[11/19 09:27:47] d2.utils.events INFO:  eta: 20:41:58  iter: 1739  total_loss: 0.162  loss_cls: 0.05639  loss_box_reg: 0.07714  loss_rpn_cls: 0.00916  loss_rpn_loc: 0.0204  time: 0.6832  data_time: 0.0670  lr: 0.04  max_mem: 11813M
[11/19 09:28:01] d2.utils.events INFO:  eta: 20:41:44  iter: 1759  total_loss: 0.1638  loss_cls: 0.05744  loss_box_reg: 0.08031  loss_rpn_cls: 0.008436  loss_rpn_loc: 0.01723  time: 0.6835  data_time: 0.0854  lr: 0.04  max_mem: 11813M
[11/19 09:28:15] d2.utils.events INFO:  eta: 20:41:12  iter: 1779  total_loss: 0.1581  loss_cls: 0.05533  loss_box_reg: 0.08055  loss_rpn_cls: 0.00964  loss_rpn_loc: 0.01928  time: 0.6833  data_time: 0.0704  lr: 0.04  max_mem: 11813M
[11/19 09:28:28] d2.utils.events INFO:  eta: 20:40:56  iter: 1799  total_loss: 0.1474  loss_cls: 0.05258  loss_box_reg: 0.07411  loss_rpn_cls: 0.007911  loss_rpn_loc: 0.01781  time: 0.6832  data_time: 0.0641  lr: 0.04  max_mem: 11813M
[11/19 09:28:42] d2.utils.events INFO:  eta: 20:40:37  iter: 1819  total_loss: 0.1683  loss_cls: 0.05977  loss_box_reg: 0.07842  loss_rpn_cls: 0.009768  loss_rpn_loc: 0.01929  time: 0.6832  data_time: 0.0648  lr: 0.04  max_mem: 11813M
[11/19 09:28:56] d2.utils.events INFO:  eta: 20:40:31  iter: 1839  total_loss: 0.157  loss_cls: 0.0549  loss_box_reg: 0.07326  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.01868  time: 0.6834  data_time: 0.0712  lr: 0.04  max_mem: 11813M
[11/19 09:29:10] d2.utils.events INFO:  eta: 20:40:36  iter: 1859  total_loss: 0.1612  loss_cls: 0.05431  loss_box_reg: 0.07942  loss_rpn_cls: 0.009772  loss_rpn_loc: 0.01989  time: 0.6835  data_time: 0.0670  lr: 0.04  max_mem: 11813M
[11/19 09:29:23] d2.utils.events INFO:  eta: 20:40:51  iter: 1879  total_loss: 0.1635  loss_cls: 0.05731  loss_box_reg: 0.07673  loss_rpn_cls: 0.009358  loss_rpn_loc: 0.02068  time: 0.6836  data_time: 0.0685  lr: 0.04  max_mem: 11813M
[11/19 09:29:37] d2.utils.events INFO:  eta: 20:40:30  iter: 1899  total_loss: 0.1576  loss_cls: 0.05371  loss_box_reg: 0.07511  loss_rpn_cls: 0.008796  loss_rpn_loc: 0.02059  time: 0.6838  data_time: 0.0862  lr: 0.04  max_mem: 11813M
[11/19 09:29:51] d2.utils.events INFO:  eta: 20:40:24  iter: 1919  total_loss: 0.1617  loss_cls: 0.05371  loss_box_reg: 0.07872  loss_rpn_cls: 0.009126  loss_rpn_loc: 0.01798  time: 0.6839  data_time: 0.0651  lr: 0.04  max_mem: 11813M
[11/19 09:30:05] d2.utils.events INFO:  eta: 20:40:10  iter: 1939  total_loss: 0.1574  loss_cls: 0.05455  loss_box_reg: 0.07438  loss_rpn_cls: 0.00947  loss_rpn_loc: 0.0188  time: 0.6844  data_time: 0.0940  lr: 0.04  max_mem: 11813M
[11/19 09:30:19] d2.utils.events INFO:  eta: 20:40:06  iter: 1959  total_loss: 0.1549  loss_cls: 0.0521  loss_box_reg: 0.07328  loss_rpn_cls: 0.009133  loss_rpn_loc: 0.02011  time: 0.6844  data_time: 0.0627  lr: 0.04  max_mem: 11813M
[11/19 09:30:33] d2.utils.events INFO:  eta: 20:39:53  iter: 1979  total_loss: 0.1634  loss_cls: 0.05849  loss_box_reg: 0.07894  loss_rpn_cls: 0.008133  loss_rpn_loc: 0.01835  time: 0.6849  data_time: 0.0936  lr: 0.04  max_mem: 11813M
[11/19 09:30:47] fvcore.common.checkpoint INFO: Saving checkpoint to ../../output/supervised/model_0001999.pth
[11/19 09:30:47] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/19 09:30:47] d2.data.datasets.coco INFO: Loaded 20000 images in COCO format from /data/sbcaesar/nyu/labeled_data/annotation/labeled_val.json
[11/19 09:30:48] d2.data.build INFO: Distribution of instances among all 100 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|  cup or mug   | 200          |     bird      | 2810         | hat with a .. | 160          |
|    person     | 3096         |      dog      | 5631         |    lizard     | 420          |
|     sheep     | 149          |  wine bottle  | 129          |     bowl      | 202          |
|   airplane    | 128          | domestic cat  | 290          |      car      | 768          |
|   porcupine   | 73           |     bear      | 205          |  tape player  | 81           |
|      ray      | 192          |    laptop     | 84           |     zebra     | 97           |
| computer ke.. | 66           |    pitcher    | 95           |   artichoke   | 96           |
| tv or monitor | 165          |     table     | 496          |     chair     | 578          |
|    helmet     | 237          | traffic light | 109          |   red panda   | 61           |
|  sunglasses   | 145          |     lamp      | 190          |    bicycle    | 132          |
|   backpack    | 110          |   mushroom    | 146          |      fox      | 195          |
|     otter     | 74           |    guitar     | 189          |  microphone   | 174          |
|  strawberry   | 162          |     stove     | 110          |    violin     | 84           |
|   bookshelf   | 68           |     sofa      | 127          |  bell pepper  | 98           |
|     bagel     | 76           |     lemon     | 95           |    orange     | 151          |
|     bench     | 107          |     piano     | 128          |  flower pot   | 113          |
|   butterfly   | 302          |     purse     | 124          |  pomegranate  | 114          |
|     train     | 89           |     drum      | 175          | hippopotamus  | 82           |
|      ski      | 104          |    ladybug    | 85           |    banana     | 169          |
|    monkey     | 683          |      bus      | 257          |   miniskirt   | 73           |
|     camel     | 138          |     cream     | 120          |    lobster    | 151          |
|     seal      | 120          |     horse     | 171          |     cart      | 211          |
|   elephant    | 159          |     snake     | 664          |      fig      | 92           |
|  watercraft   | 686          |     apple     | 145          |   antelope    | 173          |
|    cattle     | 92           |     whale     | 113          | coffee maker  | 94           |
|   baby bed    | 134          |     frog      | 164          |  bathing cap  | 153          |
|    crutch     | 75           |  koala bear   | 71           |      tie      | 91           |
|   dumbbell    | 104          |     tiger     | 76           |   dragonfly   | 119          |
|   goldfish    | 159          |   cucumber    | 67           |    turtle     | 206          |
|     harp      | 118          |   jellyfish   | 103          |     swine     | 159          |
|    pretzel    | 108          |  motorcycle   | 224          |    beaker     | 85           |
|    rabbit     | 159          |     nail      | 91           |      axe      | 107          |
| salt or pep.. | 68           | croquet ball  | 85           |     skunk     | 88           |
|   starfish    | 92           |               |              |               |              |
|     total     | 27584        |               |              |               |              |[0m
[11/19 09:30:48] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/19 09:30:48] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/19 09:30:48] d2.data.common INFO: Serializing 20000 elements to byte tensors and concatenating them all ...
[11/19 09:30:48] d2.data.common INFO: Serialized dataset takes 4.93 MiB
[11/19 09:30:48] d2.evaluation.evaluator INFO: Start inference on 3334 batches
[11/19 09:30:56] d2.evaluation.evaluator INFO: Inference done 11/3334. Dataloading: 0.0009 s/iter. Inference: 0.0412 s/iter. Eval: 0.0002 s/iter. Total: 0.0424 s/iter. ETA=0:02:20
[11/19 09:31:01] d2.evaluation.evaluator INFO: Inference done 134/3334. Dataloading: 0.0015 s/iter. Inference: 0.0390 s/iter. Eval: 0.0003 s/iter. Total: 0.0408 s/iter. ETA=0:02:10
[11/19 09:31:06] d2.evaluation.evaluator INFO: Inference done 258/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:05
[11/19 09:31:11] d2.evaluation.evaluator INFO: Inference done 381/3334. Dataloading: 0.0016 s/iter. Inference: 0.0388 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:02:00
[11/19 09:31:16] d2.evaluation.evaluator INFO: Inference done 505/3334. Dataloading: 0.0017 s/iter. Inference: 0.0387 s/iter. Eval: 0.0002 s/iter. Total: 0.0407 s/iter. ETA=0:01:55
[11/19 09:31:21] d2.evaluation.evaluator INFO: Inference done 625/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:50
[11/19 09:31:26] d2.evaluation.evaluator INFO: Inference done 748/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:45
[11/19 09:31:31] d2.evaluation.evaluator INFO: Inference done 871/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:40
[11/19 09:31:36] d2.evaluation.evaluator INFO: Inference done 993/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:35
[11/19 09:31:41] d2.evaluation.evaluator INFO: Inference done 1118/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:30
[11/19 09:31:46] d2.evaluation.evaluator INFO: Inference done 1241/3334. Dataloading: 0.0016 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:01:25
[11/19 09:31:51] d2.evaluation.evaluator INFO: Inference done 1362/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:20
[11/19 09:31:56] d2.evaluation.evaluator INFO: Inference done 1485/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0409 s/iter. ETA=0:01:15
[11/19 09:32:01] d2.evaluation.evaluator INFO: Inference done 1606/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:10
[11/19 09:32:06] d2.evaluation.evaluator INFO: Inference done 1728/3334. Dataloading: 0.0016 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:05
[11/19 09:32:11] d2.evaluation.evaluator INFO: Inference done 1849/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:01:00
[11/19 09:32:16] d2.evaluation.evaluator INFO: Inference done 1971/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:55
[11/19 09:32:21] d2.evaluation.evaluator INFO: Inference done 2095/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:50
[11/19 09:32:26] d2.evaluation.evaluator INFO: Inference done 2218/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:45
[11/19 09:32:31] d2.evaluation.evaluator INFO: Inference done 2340/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:40
[11/19 09:32:36] d2.evaluation.evaluator INFO: Inference done 2462/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:35
[11/19 09:32:41] d2.evaluation.evaluator INFO: Inference done 2585/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:30
[11/19 09:32:46] d2.evaluation.evaluator INFO: Inference done 2706/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:25
[11/19 09:32:51] d2.evaluation.evaluator INFO: Inference done 2823/3334. Dataloading: 0.0017 s/iter. Inference: 0.0391 s/iter. Eval: 0.0002 s/iter. Total: 0.0411 s/iter. ETA=0:00:20
[11/19 09:32:56] d2.evaluation.evaluator INFO: Inference done 2948/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:15
[11/19 09:33:01] d2.evaluation.evaluator INFO: Inference done 3071/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:10
[11/19 09:33:06] d2.evaluation.evaluator INFO: Inference done 3194/3334. Dataloading: 0.0017 s/iter. Inference: 0.0390 s/iter. Eval: 0.0002 s/iter. Total: 0.0410 s/iter. ETA=0:00:05
[11/19 09:33:11] d2.evaluation.evaluator INFO: Inference done 3330/3334. Dataloading: 0.0017 s/iter. Inference: 0.0389 s/iter. Eval: 0.0002 s/iter. Total: 0.0408 s/iter. ETA=0:00:00
[11/19 09:33:12] d2.evaluation.evaluator INFO: Total inference time: 0:02:16.288763 (0.040940 s / iter per device, on 6 devices)
[11/19 09:33:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:09 (0.038872 s / iter per device, on 6 devices)
[11/19 09:33:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/19 09:33:13] d2.evaluation.coco_evaluation INFO: Saving results to ../../output/supervised/inference/coco_instances_results.json
[11/19 09:33:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/19 09:33:15] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/19 09:33:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 25.19 seconds.
[11/19 09:33:41] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/19 09:33:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 1.93 seconds.
[11/19 09:33:43] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |
|:------:|:------:|:------:|:-----:|:-----:|:------:|
| 15.156 | 29.080 | 14.098 | 1.148 | 5.394 | 18.578 |
[11/19 09:33:43] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category              | AP     | category      | AP     | category             | AP     |
|:----------------------|:-------|:--------------|:-------|:---------------------|:-------|
| cup or mug            | 15.141 | bird          | 39.546 | hat with a wide brim | 11.810 |
| person                | 9.798  | dog           | 53.695 | lizard               | 11.616 |
| sheep                 | 14.180 | wine bottle   | 9.945  | bowl                 | 15.815 |
| airplane              | 26.490 | domestic cat  | 15.844 | car                  | 38.618 |
| porcupine             | 23.377 | bear          | 20.607 | tape player          | 9.997  |
| ray                   | 7.184  | laptop        | 9.245  | zebra                | 30.486 |
| computer keyboard     | 14.169 | pitcher       | 16.723 | artichoke            | 21.897 |
| tv or monitor         | 13.710 | table         | 11.982 | chair                | 7.474  |
| helmet                | 13.765 | traffic light | 6.254  | red panda            | 24.940 |
| sunglasses            | 2.605  | lamp          | 3.345  | bicycle              | 11.650 |
| backpack              | 10.003 | mushroom      | 6.406  | fox                  | 19.235 |
| otter                 | 5.055  | guitar        | 12.704 | microphone           | 1.413  |
| strawberry            | 4.766  | stove         | 17.341 | violin               | 1.735  |
| bookshelf             | 19.286 | sofa          | 12.381 | bell pepper          | 12.892 |
| bagel                 | 15.822 | lemon         | 14.282 | orange               | 18.965 |
| bench                 | 3.172  | piano         | 25.549 | flower pot           | 4.141  |
| butterfly             | 38.357 | purse         | 6.195  | pomegranate          | 7.843  |
| train                 | 27.479 | drum          | 2.929  | hippopotamus         | 5.804  |
| ski                   | 2.479  | ladybug       | 29.138 | banana               | 4.042  |
| monkey                | 16.145 | bus           | 36.183 | miniskirt            | 9.282  |
| camel                 | 15.289 | cream         | 20.810 | lobster              | 11.188 |
| seal                  | 5.763  | horse         | 14.191 | cart                 | 16.642 |
| elephant              | 26.897 | snake         | 14.682 | fig                  | 3.304  |
| watercraft            | 27.983 | apple         | 20.909 | antelope             | 34.420 |
| cattle                | 3.800  | whale         | 21.115 | coffee maker         | 29.026 |
| baby bed              | 31.345 | frog          | 23.148 | bathing cap          | 11.699 |
| crutch                | 0.496  | koala bear    | 21.120 | tie                  | 3.111  |
| dumbbell              | 0.901  | tiger         | 18.577 | dragonfly            | 17.254 |
| goldfish              | 14.524 | cucumber      | 3.590  | turtle               | 20.571 |
| harp                  | 13.448 | jellyfish     | 13.395 | swine                | 13.771 |
| pretzel               | 7.802  | motorcycle    | 25.421 | beaker               | 15.023 |
| rabbit                | 31.387 | nail          | 1.396  | axe                  | 6.847  |
| salt or pepper shaker | 5.966  | croquet ball  | 15.079 | skunk                | 14.579 |
| starfish              | 16.190 |               |        |                      |        |
[11/19 09:33:45] d2.engine.defaults INFO: Evaluation results for nyu_val in csv format:
[11/19 09:33:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/19 09:33:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/19 09:33:45] d2.evaluation.testing INFO: copypaste: 15.1559,29.0805,14.0979,1.1482,5.3938,18.5776
